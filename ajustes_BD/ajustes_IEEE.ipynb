{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "317791d6",
   "metadata": {},
   "source": [
    "# Consolidação de Base de Dados - IEEE Xplore\n",
    "Este notebook tem como objetivo unificar as exportações de metadados da base IEEE Xplore, padronizando os dados para a etapa de extração da revisão da literatura (Metodologia TEMAC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466c5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Definição do diretório onde estão os arquivos brutos exportados\n",
    "pasta_origem = \"/home/silvio/Projetos/TEMAC/IEEE_XPRES\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3601326",
   "metadata": {},
   "source": [
    "### 1. Mapeamento dos Arquivos CSV\n",
    "Verificamos o diretório e listamos todos os arquivos com a extensão `.csv` para garantir que apenas os dados corretos sejam processados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3add5fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 17 arquivos CSV prontos para leitura.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(pasta_origem):\n",
    "    print(f\"Erro: A pasta '{pasta_origem}' não foi encontrada no diretório atual.\")\n",
    "    arquivos_csv = []\n",
    "else:\n",
    "    # Lista apenas os arquivos terminados em .csv usando list comprehension\n",
    "    arquivos_csv = [arquivo for arquivo in os.listdir(pasta_origem) if arquivo.endswith('.csv')]\n",
    "    \n",
    "    if not arquivos_csv:\n",
    "        print(f\"Nenhum arquivo CSV encontrado na pasta '{pasta_origem}'.\")\n",
    "    else:\n",
    "        print(f\"Encontrados {len(arquivos_csv)} arquivos CSV prontos para leitura.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8793d79",
   "metadata": {},
   "source": [
    "### 2. Leitura e Concatenação\n",
    "Aqui iteramos sobre a lista de arquivos mapeados, carregamos cada um em um DataFrame do Pandas e, em seguida, unimos todos em uma única estrutura. O `pd.concat` se encarrega de alinhar as colunas e manter o cabeçalho apenas uma vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5b847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lido: export2026.02.20-18.39.57.csv - 1 linhas\n",
      "Lido: export2026.02.20-18.41.22.csv - 13 linhas\n",
      "Lido: export2026.02.20-18.39.10.csv - 2 linhas\n",
      "Lido: export2026.02.20-18.48.20.csv - 50 linhas\n",
      "Lido: export2026.02.20-18.44.57.csv - 982 linhas\n",
      "Lido: export2026.02.20-18.39.39.csv - 21 linhas\n",
      "Lido: export2026.02.20-18.48.55.csv - 14 linhas\n",
      "Lido: export2026.02.20-18.46.06.csv - 60 linhas\n",
      "Lido: export2026.02.20-18.41.43.csv - 53 linhas\n",
      "Lido: export2026.02.20-18.47.06.csv - 588 linhas\n",
      "Lido: export2026.02.20-18.40.13.csv - 30 linhas\n",
      "Lido: export2026.02.20-18.46.33.csv - 81 linhas\n",
      "Lido: export2026.02.20-18.40.51.csv - 1 linhas\n",
      "Lido: export2026.02.20-18.47.55.csv - 51 linhas\n",
      "Lido: export2026.02.20-18.40.37.csv - 1 linhas\n",
      "Lido: export2026.02.20-18.42.07.csv - 14 linhas\n",
      "Lido: export2026.02.20-18.47.30.csv - 35 linhas\n",
      "\n",
      "Total de registros empilhados: 1997\n"
     ]
    }
   ],
   "source": [
    "lista_dataframes = []\n",
    "\n",
    "if arquivos_csv:\n",
    "    for nome_arquivo in arquivos_csv:\n",
    "        caminho_completo = os.path.join(pasta_origem, nome_arquivo)\n",
    "        \n",
    "        # Leitura do CSV\n",
    "        df = pd.read_csv(caminho_completo, encoding='utf-8') \n",
    "        lista_dataframes.append(df)\n",
    "        print(f\"Lido: {nome_arquivo} - {len(df)} linhas\")\n",
    "\n",
    "    # Junta tudo em uma única base de dados\n",
    "    base_consolidada = pd.concat(lista_dataframes, ignore_index=True)\n",
    "    total_inicial = len(base_consolidada)\n",
    "    print(f\"\\nTotal de registros empilhados: {total_inicial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84710a96",
   "metadata": {},
   "source": [
    "### 3. Limpeza de Duplicatas e Exportação\n",
    "Para garantir a integridade do portfólio bibliográfico final, removemos publicações duplicadas utilizando o Título do Documento e o DOI como chave de verificação. Por fim, exportamos a base limpa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625781cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumo da Limpeza ---\n",
      "Registros originais (com possíveis duplicatas): 1997\n",
      "Registros únicos mantidos: 1646\n",
      "Duplicatas removidas: 351\n",
      "\n",
      "Base final pronta e salva como: base_ieee_consolidada.csv\n"
     ]
    }
   ],
   "source": [
    "if arquivos_csv and 'base_consolidada' in locals():\n",
    "    # Remoção de duplicatas baseada em Título e DOI\n",
    "    base_deduplicada = base_consolidada.drop_duplicates(subset=['Document Title', 'DOI'], keep='first')\n",
    "    total_final = len(base_deduplicada)\n",
    "    \n",
    "    print(\"--- Resumo da Limpeza ---\")\n",
    "    print(f\"Registros originais (com possíveis duplicatas): {total_inicial}\")\n",
    "    print(f\"Registros únicos mantidos: {total_final}\")\n",
    "    print(f\"Duplicatas removidas: {total_inicial - total_final}\")\n",
    "    \n",
    "    # Salva o arquivo final consolidado\n",
    "    arquivo_saida = \"base_ieee_consolidada.csv\"\n",
    "    base_deduplicada.to_csv(arquivo_saida, index=False, encoding='utf-8')\n",
    "    print(f\"\\nBase final pronta e salva como: {arquivo_saida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91216adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base da IEEE harmonizada (Enriquecida e Blindada) salva como: base_ieee_adaptada_scopus.csv\n"
     ]
    }
   ],
   "source": [
    "df_ieee = pd.read_csv(\"base_ieee_consolidada.csv\")\n",
    "\n",
    "# 2. Dicionário base de tradução AMPLIADO (aproveitando mais dados do IEEE)\n",
    "de_para_scopus = {\n",
    "    \"Document Title\": \"Title\",\n",
    "    \"Authors\": \"Authors\",\n",
    "    \"Author Affiliations\": \"Affiliations\",\n",
    "    \"Publication Title\": \"Source title\",\n",
    "    \"Publication Year\": \"Year\",\n",
    "    \"Abstract\": \"Abstract\",\n",
    "    \"DOI\": \"DOI\",\n",
    "    \"Article Citation Count\": \"Cited by\",\n",
    "    \"Author Keywords\": \"Author Keywords\",\n",
    "    \"IEEE Terms\": \"Index Keywords\",\n",
    "    # NOVAS COLUNAS MAPEADAS PARA ENRIQUECER A BASE:\n",
    "    \"Volume\": \"Volume\",\n",
    "    \"Issue\": \"Issue\",\n",
    "    \"Start Page\": \"Page start\",\n",
    "    \"End Page\": \"Page end\",\n",
    "    \"Publisher\": \"Publisher\",\n",
    "    \"ISSN\": \"ISSN\"\n",
    "}\n",
    "\n",
    "df_ieee_scopus_format = df_ieee.rename(columns=de_para_scopus)\n",
    "\n",
    "# 3. Adicionar as colunas obrigatórias de sistema da Scopus e a de Referências vazia\n",
    "df_ieee_scopus_format[\"Source\"] = \"Scopus\"\n",
    "df_ieee_scopus_format[\"Document Type\"] = \"Article\"\n",
    "df_ieee_scopus_format[\"EID\"] = \"IEEE_\" + df_ieee_scopus_format.index.astype(str)\n",
    "df_ieee_scopus_format[\"References\"] = \"NA\" # Previne erros de incompatibilidade no merge\n",
    "\n",
    "# 4. Manter apenas as colunas mapeadas e as novas\n",
    "colunas_scopus = list(de_para_scopus.values()) + [\"Source\", \"Document Type\", \"EID\", \"References\"]\n",
    "df_ieee_final = df_ieee_scopus_format[[col for col in colunas_scopus if col in df_ieee_scopus_format.columns]].copy()\n",
    "\n",
    "# 5. O ATALHO NINJA (Crucial para o R não travar nas afiliações da IEEE)\n",
    "# Troca ponto-e-vírgula por vírgula nas afiliações para evitar o loop infinito no bibliometrix\n",
    "if \"Affiliations\" in df_ieee_final.columns:\n",
    "    df_ieee_final[\"Affiliations\"] = df_ieee_final[\"Affiliations\"].astype(str).str.replace(\";\", \",\", regex=False)\n",
    "\n",
    "# 6. Blindagem de campos vazios para o R não engasgar\n",
    "df_ieee_final = df_ieee_final.astype(object).fillna(\"\")\n",
    "\n",
    "# 7. Salvar o arquivo\n",
    "arquivo_adaptado = \"base_ieee_adaptada_scopus.csv\"\n",
    "df_ieee_final.to_csv(arquivo_adaptado, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Base da IEEE harmonizada (Enriquecida e Blindada) salva como: {arquivo_adaptado}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temac (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
