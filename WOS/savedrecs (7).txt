FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Yi, Xiaomeng
   Liu, Fangming
   Liu, Jiangchuan
   Jin, Hai
TI Building a Network Highway for Big Data: Architecture and Challenges
SO IEEE NETWORK
VL 28
IS 4
SI SI
BP 5
EP 13
DI 10.1109/MNET.2014.6863125
DT Article
PD JUL-AUG 2014
PY 2014
AB Big data, with their promise to discover valuable insights for better
   decision making, have recently attracted significant interest from both
   academia and industry. Voluminous data are generated from a variety of
   users and devices, and are to be stored and processed in powerful data
   centers. As such, there is a strong demand for building an unimpeded
   network infrastructure to gather geologically distributed and rapidly
   generated data, and move them to data centers for effective knowledge
   discovery. The express network should also be seamlessly extended to
   interconnect multiple data centers as well as interconnect the server
   nodes within a data center. In this article, we take a close look at the
   unique challenges in building such a network infrastructure for big
   data. Our study covers each and every segment in this network highway:
   the access networks that connect data sources, the Internet backbone
   that bridges them to remote data centers, as well as the dedicated
   network among data centers and within a data center. We also present two
   case studies of real-world big data applications that are empowered by
   networking, highlighting interesting and promising future research
   directions.
RI Liu, Fangming/HLG-2050-2023
ZR 0
Z8 3
ZA 0
ZB 1
TC 119
ZS 0
Z9 137
U1 1
U2 51
SN 0890-8044
EI 1558-156X
DA 2014-07-01
UT WOS:000345579100003
ER

PT J
AU Immonen, Anne
   Paakkonen, Pekka
   Ovaska, Eila
TI Evaluating the Quality of Social Media Data in Big Data Architecture
SO IEEE ACCESS
VL 3
BP 2028
EP 2043
DI 10.1109/ACCESS.2015.2490723
DT Article
PD 2015
PY 2015
AB The use of freely available online data is rapidly increasing, as
   companies have detected the possibilities and the value of these data in
   their businesses. In particular, data from social media are seen as
   interesting as they can, when properly treated, assist in achieving
   customer insight into business decision making. However, the
   unstructured and uncertain nature of this kind of big data presents a
   new kind of challenge: how to evaluate the quality of data and manage
   the value of data within a big data architecture? This paper contributes
   to addressing this challenge by introducing a new architectural solution
   to evaluate and manage the quality of social media data in each
   processing phase of the big data pipeline. The proposed solution
   improves business decision making by providing real-time, validated data
   for the user. The solution is validated with an industrial case example,
   in which the customer insight is extracted from social media data in
   order to determine the customer satisfaction regarding the quality of a
   product.
ZR 0
Z8 3
TC 62
ZA 0
ZB 1
ZS 2
Z9 81
U1 0
U2 52
SN 2169-3536
DA 2016-03-23
UT WOS:000371388200155
ER

PT J
AU Sarabia-Jacome, David
   Palau, Carlos E.
   Esteve, Manuel
   Boronat, Fernando
TI Seaport Data Space for Improving Logistic Maritime Operations
SO IEEE ACCESS
VL 8
BP 4372
EP 4382
DI 10.1109/ACCESS.2019.2963283
DT Article
PD 2020
PY 2020
AB The maritime industry expects several improvements to efficiently manage
   the operation processes by introducing Industry 4.0 enabling
   technologies. Seaports are the most critical point in the maritime
   logistics chain because of its multimodal and complex nature.
   Consequently, coordinated communication among any seaport stakeholders
   is vital to improving their operations. Currently, Electronic Data
   Interchange (EDI) and Port Community Systems (PCS), as primary enablers
   of digital seaports, have demonstrated their limitations to interchange
   information on time, accurately, efficiently, and securely, causing high
   operation costs, low resource management, and low performance. For these
   reasons, this contribution presents the Seaport Data Space (SDS) based
   on the Industrial Data Space (IDS) reference architecture model to
   enable a secure data sharing space and promote an intelligent transport
   multimodal terminal. Each seaport stakeholders implements the IDS
   connector to take part in the SDS and share their data. On top of SDS, a
   Big Data architecture is integrated to manage the massive data shared in
   the SDS and extract useful information to improve the decision-making.
   The architecture has been evaluated by enabling a port authority and a
   container terminal to share its data with a shipping company. As a
   result, several Key Performance Indicators (KPIs) have been developed by
   using the Big Data architecture functionalities. The KPIs have been
   shown in a dashboard to allow easy interpretability of results for
   planning vessel operations. The SDS environment may improve the
   communication between stakeholders by reducing the transaction costs,
   enhancing the quality of information, and exhibiting effectiveness.
RI Palau, Carlos E/HCH-5674-2022; Esteve, Manuel/; Sarabia-Jácome, David/AAG-5233-2019; Sarabia, David/AAG-5233-2019; Boronat, Fernando/A-3234-2011
OI Palau, Carlos E/0000-0002-3795-5404; Esteve, Manuel/0000-0002-7985-3270;
   Sarabia, David/0000-0003-4930-9677; Boronat,
   Fernando/0000-0001-5525-3441
ZA 0
TC 27
ZR 0
ZS 0
ZB 1
Z8 1
Z9 33
U1 7
U2 78
SN 2169-3536
DA 2020-07-28
UT WOS:000549773400004
ER

PT J
AU Shrouf, Fadi
   Gong, Bing
   Ordieres-Mere, Joaquin
TI Multi-level awareness of energy used in production processes
SO JOURNAL OF CLEANER PRODUCTION
VL 142
BP 2570
EP 2585
DI 10.1016/j.jclepro.2016.11.019
PN 4
DT Article
PD JAN 20 2017
PY 2017
AB To ensure green manufacturing, the energy consumption of production
   processes should be transparent and minimized. Also, to achieve the
   desired level of energy consumption awareness and efficiency
   improvements, energy use should be measured in more detail and linked to
   production data. In this scenario, real-time monitoring of energy
   consumption represents an essential step to increasing energy awareness,
   efficiency and the support of energy-aware production processes. This
   paper seeks to provide a way to achieve multi-level awareness of the
   energy used during production processes. The multi-level awareness of
   energy consumption means identifying the amount of energy used, CO2
   emitted, and the cost of the energy used at operation, product, and
   order level. This multi-level awareness is achieved by integrating
   energy usage data with production data at the operational level.
   Furthermore, energy sources need to be considered to define the amount
   of CO2 that is emitted from the production process for each product. A
   pilot study was carried out to integrate electrical energy data,
   production data and scheduling data in real time to achieve the
   multi-level awareness of energy used in production. The results show
   that integrating energy with production data enables factories to
   provide specific energy consumption information for decision makers at
   the factory level, as well as for the consumers and the regulators. This
   integration of energy and production data is achieved efficiently when
   there is a high level of standardization of production processes and the
   availability of detailed energy usage data. (C) 2016 Elsevier Ltd. All
   rights reserved.
RI Ordieres-Meré, Joaquín/B-9677-2011; Gong, Bing/ADD-1408-2022
OI Ordieres-Meré, Joaquín/0000-0002-9677-6764; Gong,
   Bing/0000-0001-7770-2738
Z8 0
ZR 0
ZA 0
ZB 1
ZS 0
TC 29
Z9 32
U1 0
U2 36
SN 0959-6526
EI 1879-1786
DA 2017-02-08
UT WOS:000391516300016
ER

PT C
AU Matsebula, Fezile
   Mnkandla, Ernest
BE Cornish, DR
TI A BIG DATA ARCHITECTURE FOR LEARNING ANALYTICS IN HIGHER EDUCATION
SO 2017 IEEE AFRICON
SE Africon
BP 951
EP 956
DT Proceedings Paper
PD 2017
PY 2017
AB Data with high volume, velocity, variety and veracity brings the new
   experience curve of analytics. Big data in higher education comes from
   different sources that include blogs, social networks, student
   information systems, learning management systems, research, and other
   machine-generated data. Once the data is analysed it promises better
   student placement processes; more accurate enrolment forecasts, and
   early warning systems that identify and assist students at-risk of
   failing or dropping out. Big data is becoming a key to creating
   competitive advantages in higher education. Like with any organization,
   traditional data processing and analysis of structured and unstructured
   data using RDBMS and data warehousing no longer satisfy big data
   challenges. The lack of adequate conceptual architectures for big data
   tailored for institutions of higher education has led to many failures
   to produce meaningful, accessible, and timely information for decision
   making. Therefore, this calls for the development of conceptual
   architectures for big data in higher education. This paper presents an
   architecture for big data analytics in higher education.
CT IEEE AFRICON Conference - Science, Technology and Innovation for Africa
CY SEP 18-20, 2017
CL Cape Town, SOUTH AFRICA
SP IEEE; mlab; IEEE Reg 8; IEEE S Africa Sect; IES; Univ Pretoria; SAiEE;
   IBM; Altair; CST
RI Mnkandla, Ernest/G-5235-2012; Matsebula, Fezile/JDD-6998-2023; Matsebula, Fezile/
OI Matsebula, Fezile/0000-0001-7646-6243
ZB 0
ZS 0
TC 16
ZA 0
Z8 1
ZR 0
Z9 29
U1 0
U2 17
SN 2153-0025
BN 978-1-5386-2775-4
DA 2017-01-01
UT WOS:000424741600162
ER

PT J
AU Errami, Soukaina Ait
   Hajji, Hicham
   Kadi, Kenza Ait El
   Badir, Hassan
TI Spatial big data architecture: From Data Warehouses and Data Lakes to
   the LakeHouse
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
VL 176
BP 70
EP 79
DI 10.1016/j.jpdc.2023.02.007
EA MAR 2023
DT Article
PD JUN 2023
PY 2023
AB The construction of systems supporting spatial data has experienced
   great enthusiasm in the past, due to the richness of this type of data
   and their semantics, which can be used in the decision-making process in
   various fields. Thus, the problem of integrating spatial data into
   existing databases and information systems has been addressed by
   creating spatial extensions to relational tables or by creating spatial
   data warehouses, while arranging data structures and query languages by
   making them more spatiallyaware. With the advent of Big Data, these
   conventional storage and spatial representation structures are becoming
   increasingly outdated, and required a new organization of spatial data.
   Approaches based on distributed storage and data lakes have been
   proposed, to integrate the complexity of spatial data, with operational
   and analytical systems which unfortunately quickly showed their limits.
   Recently the concept of lakehouse was introduced in order to integrate,
   among other things, the notion of reliability and ACID properties to the
   volume of data to be managed. This new data architecture is a
   combination of governed and reliable Data Warehouses and flexible,
   scalable and cost-effective Data Lakes.In this paper, we present how
   traditional approaches of spatial data management in the context of
   spatial big data have quickly shown their limits. We present a
   literature overview of these approaches, and how they led to the Data
   LakeHouse. We detail how the Lakehouse paradigm can be used and extended
   for managing spatial big data, by giving the different components and
   best practices for building a spatial data LakeHouse architecture
   optimized for the storage and computing over spatial big data.(c) 2023
   Elsevier Inc. All rights reserved.
RI aitelkadi, aitelkadi/; Hassan, BADIR/R-6226-2019
OI aitelkadi, aitelkadi/0000-0002-4233-1292; 
ZS 0
TC 21
ZR 0
ZB 0
Z8 0
ZA 0
Z9 28
U1 4
U2 45
SN 0743-7315
EI 1096-0848
DA 2023-04-10
UT WOS:000956881700001
ER

PT J
AU Brous, Paul
   Janssen, Marijn
TI Trusted Decision-Making: Data Governance for Creating Trust in Data
   Science Decision Outcomes
SO ADMINISTRATIVE SCIENCES
VL 10
IS 4
AR 81
DI 10.3390/admsci10040081
DT Article
PD DEC 2020
PY 2020
AB Organizations are increasingly introducing data science initiatives to
   support decision-making. However, the decision outcomes of data science
   initiatives are not always used or adopted by decision-makers, often due
   to uncertainty about the quality of data input. It is, therefore, not
   surprising that organizations are increasingly turning to data
   governance as a means to improve the acceptance of data science decision
   outcomes. In this paper, propositions will be developed to understand
   the role of data governance in creating trust in data science decision
   outcomes. Two explanatory case studies in the asset management domain
   are analyzed to derive boundary conditions. The first case study is a
   data science project designed to improve the efficiency of road
   management through predictive maintenance, and the second case study is
   a data science project designed to detect fraudulent usage of
   electricity in medium and low voltage electrical grids without
   infringing privacy regulations. The duality of technology is used as our
   theoretical lens to understand the interactions between the
   organization, decision-makers, and technology. The results show that
   data science decision outcomes are more likely to be accepted if the
   organization has an established data governance capability. Data
   governance is also needed to ensure that organizational conditions of
   data science are met, and that incurred organizational changes are
   managed efficiently. These results imply that a mature data governance
   capability is required before sufficient trust can be placed in data
   science decision outcomes for decision-making.
RI Brous, Paul/; Janssen, Marijn/H-6223-2013
OI Brous, Paul/0000-0002-0593-1168; Janssen, Marijn/0000-0001-6211-8790
ZS 0
ZA 0
TC 21
ZR 0
Z8 0
ZB 0
Z9 27
U1 3
U2 84
EI 2076-3387
DA 2021-01-06
UT WOS:000601534200001
ER

PT C
AU Giebler, Corinna
   Groger, Christoph
   Hoos, Eva
   Schwarz, Holger
   Mitschang, Bernhard
GP IEEE
TI A Zone Reference Model for Enterprise-Grade Data Lake Management
SO 2020 IEEE 24TH INTERNATIONAL ENTERPRISE DISTRIBUTED OBJECT COMPUTING
   CONFERENCE (EDOC 2020)
SE IEEE International Enterprise Distributed Object Computing
   Conference-EDOC
BP 57
EP 66
DI 10.1109/EDOC49727.2020.00017
DT Proceedings Paper
PD 2020
PY 2020
AB Data lakes are on the rise as data platforms for any kind of analytics,
   from data exploration to machine learning. They achieve the required
   flexibility by storing heterogeneous data in their raw format, and by
   avoiding the need for pre-defined use cases. However, storing only raw
   data is inefficient, as for many applications, the same data processing
   has to be applied repeatedly. To foster the reuse of processing steps,
   literature proposes to store data in different degrees of processing in
   addition to their raw format. To this end, data lakes are typically
   structured in zones. There exists various zone models, but they are
   varied, vague, and no assessments are given. It is unclear which of
   these zone models is applicable in a practical data lake implementation
   in enterprises. In this work, we assess existing zone models using
   requirements derived from multiple representative data analytics use
   cases of a real-world industry case. We identify the shortcomings of
   existing work and develop a zone reference model for enterprise-grade
   data lake management in a detailed manner. We assess the reference
   model's applicability through a prototypical implementation for a
   real-world enterprise data lake use case. This assessment shows that the
   zone reference model meets the requirements relevant in practice and is
   ready for industry use.
CT 24th IEEE International Enterprise Distributed Object Computing
   Conference (IEEE EDOC)
CY OCT 05-08, 2020
CL ELECTR NETWORK
SP IEEE; IEEE Comp Soc
RI Schwarz, Holger/AAP-1719-2020
TC 18
Z8 1
ZR 0
ZB 0
ZA 0
ZS 0
Z9 23
U1 0
U2 3
SN 2325-6354
BN 978-1-7281-6473-1
DA 2021-04-20
UT WOS:000630246800007
ER

PT C
AU Li, Xiaoquan
   Zhang, Fujiang
   Wang, Yongliang
GP IEEE
TI Research on Big Data Architecture, Key Technologies and its Measures
SO 2013 IEEE 11TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND
   SECURE COMPUTING (DASC)
BP 1
EP 4
DI 10.1109/DASC.2013.28
DT Proceedings Paper
PD 2013
PY 2013
AB Big data require exceptional technologies to efficiently process large
   quantities of data within tolerable elapsed times, such as capture,
   curation, storage, search, sharing, transfer, analysis and
   visualization. Concept, features, construction importance, architecture,
   run mode, and its key technologies of big data are analyzed in this
   paper. Information sharing and data security under big data constructin
   are studied, at last, four measures for building big data are
   putforward, which can provide good decision-making for big data
   construction.
CT 11th IEEE International Conference on Dependable, Autonomic and Secure
   Computing (DASC)
CY DEC 21-22, 2013
CL Chengdu, PEOPLES R CHINA
SP IEEE; NSFC; IEEE Comp Soc; Unive Elect Sci & Technol China; StFX Univ;
   Ubiquitous Media Communicat Lab; IEEE Tech Comm Scalable Comp
ZB 5
ZR 0
ZS 0
ZA 0
TC 15
Z8 0
Z9 16
U1 0
U2 9
BN 978-1-4799-3381-5
DA 2013-01-01
UT WOS:000360991500001
ER

PT C
AU Wibowo, Merlinda
   Sulaiman, Sarina
   Shamsuddin, Siti Mariyam
BA Shi, Y
BE Tan, Y
   Takagi, H
TI Machine Learning in Data Lake for Combining Data Silos
SO DATA MINING AND BIG DATA, DMBD 2017
SE Lecture Notes in Computer Science
VL 10387
BP 294
EP 306
DI 10.1007/978-3-319-61845-6_30
DT Proceedings Paper
PD 2017
PY 2017
AB Data silo can grow to be a large-scale data for years, overlapping and
   has an indefinite quality. It allows an organization to develop their
   own analytical capabilities. Data lake has the ability to solve this
   problem efficiently with the data analysis by using statistical and
   predictive modeling techniques which can be applied to enhance and
   support an organization's business strategy. This study provides an
   overview of the process of decision-making, operational efficiency, and
   creating the solution for an organization. Machine Learning can
   distribute the architecture of data model and integrate the data silo
   with other organizations data to optimize the operational business
   processes within an organization in order to improve data quality and
   efficiency. Testing is done by utilizing the data from the Malaysia's
   and Singapore's Government Open Data on the Air Pollutant Index to
   determine the condition of air pollution levels for the health and
   safety of the population.
CT 2nd International Conference on Data Mining and Big Data (DMBD)
CY JUL 27-AUG 01, 2017
CL Fukuoka, JAPAN
SP Peking Univ, Computat Intelligence Lab; Kyushu Univ, Res Ctr Appl
   Perceptual Sci; IEEE Computat Intelligence Soc; IEEE Syst, Man &
   Cybernet Soc, Japan Chapter
RI Wibowo, Merlinda/AAD-1609-2021; Sulaiman, Sarina/A-1704-2013
Z8 0
TC 8
ZA 0
ZB 0
ZS 0
ZR 0
Z9 14
U1 0
U2 40
SN 0302-9743
EI 1611-3349
BN 978-3-319-61845-6; 978-3-319-61844-9
DA 2018-08-15
UT WOS:000440465200030
ER

PT J
AU Lopez, Ivan Dario
   Grass, Jose Fernando
   Figueroa, Apolinar
   Corrales, Juan Carlos
TI A proposal for a multi-domain data fusion strategy in a climate-smart
   agriculture context
SO INTERNATIONAL TRANSACTIONS IN OPERATIONAL RESEARCH
VL 30
IS 4
SI SI
BP 2049
EP 2070
DI 10.1111/itor.12899
EA OCT 2020
DT Article
PD JUL 2023
PY 2023
AB Agriculture provides food, raw materials, and employment opportunities
   for a significant percentage of the world's population. Climate,
   economic, political, social, and other conditions affect decision making
   in agricultural processes. In many cases, these conditions imply the
   loss of suitability of many areas for some traditional crops. In
   contrast, these areas can produce new crops by taking advantage of
   changing conditions. In this sense, having reliable tools and
   information for decision making is essential in adapting to new
   agricultural productivity scenarios. The above implies having sufficient
   and relevant data sources to reduce the uncertainty in the
   decision-making processes. However, data by nature tend to be diverse in
   structure, storage formats, and access protocols. Data fusion tasks have
   been immersed in a multitude of applications and have been approached
   from different points of view when implementing a suitable solution. We
   propose a multi-domain data fusion strategy to support data analysis
   tasks in agricultural contexts. We also describe all the data sources
   collected, which are the main input to the proposed strategy. The
   combined data sources were also evaluated through a preliminary
   exploratory analysis in a multi-label learning approach. Finally, the
   data fusion strategy is explained through an example in agricultural
   crop production.
RI Figueroa Casas, Apolinar/AAC-3182-2019; Lopez Gomez, Ivan Dario/; lopez, ivan/GSM-8495-2022
OI Figueroa Casas, Apolinar/0000-0003-3586-8187; Lopez Gomez, Ivan
   Dario/0000-0002-9781-6094; 
ZS 0
Z8 0
TC 11
ZR 0
ZA 0
ZB 3
Z9 13
U1 0
U2 25
SN 0969-6016
EI 1475-3995
DA 2020-11-19
UT WOS:000587020700001
ER

PT C
AU Li, Sujie
   Zhang, Guigang
   Wang, Jian
GP IEEE
TI Civil Aircraft Health Management Research based on Big Data and Deep
   Learning Technologies
SO 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT
   (ICPHM)
BP 154
EP 159
DT Proceedings Paper
PD 2017
PY 2017
AB the coupling and correlation degree between aircraft systems is higher,
   and the diagnosis and prognosis of aircraft are more complex. Building a
   platform for storing and analyzing the aviation big data becomes an
   important task for civil aviation. This paper proposes a civil aircraft
   health management big data architecture. The civil aircraft health
   management system includes airborne PHM, ground PHM, remote diagnosis
   system, portable maintenance assistant system, maintenance center,
   automatic test equipment, special test equipment. Airborne PHM collects
   data from multiple types of data sources. Ground PHM provides decision
   making support for civil aircrafts including real-time alarm, health
   management, maintenance plan, spare parts. The paper introduces deep
   learning algorithm and aircraft fault diagnosis and prognosis
   implementation.
CT IEEE International Conference on Prognostics and Health Management
   (ICPHM)
CY JUN 19-21, 2017
CL Dallas, TX
SP IEEE; IEEE Reliabil Soc
ZS 0
TC 9
ZB 0
Z8 2
ZR 0
ZA 0
Z9 13
U1 3
U2 18
BN 978-1-5090-5710-8
DA 2017-01-01
UT WOS:000452639100025
ER

PT C
AU Spangenberg, Norman
   Wilke, Moritz
   Franczyk, Bogdan
BE Shakshuki, E
TI A Big Data architecture for intra-surgical remaining time predictions
SO 8TH INTERNATIONAL CONFERENCE ON EMERGING UBIQUITOUS SYSTEMS AND
   PERVASIVE NETWORKS (EUSPN 2017) / 7TH INTERNATIONAL CONFERENCE ON
   CURRENT AND FUTURE TRENDS OF INFORMATION AND COMMUNICATION TECHNOLOGIES
   IN HEALTHCARE (ICTH-2017) / AFFILIATED WORKSHOPS
SE Procedia Computer Science
VL 113
BP 310
EP 317
DI 10.1016/j.procs.2017.08.332
DT Proceedings Paper
PD 2017
PY 2017
AB The operating room area is still one of the most expensive sections in
   the hospital due to the high resource requirements and the diverse
   uncertainties. However there are few solutions that support monitoring
   and decision-making in operating room management. But with new data
   sources and analytical methods of big data research more improvements
   could be achieved. In this work we utilize surgical phase events
   recognized in surgical device data to learn prediction models and
   trigger online predictions for remaining intervention times in operating
   rooms. To identify the best algorithm for prediction model computation
   with the existing data, we evaluate a set of regression algorithms.
   Based on this methods we propose an architecture approach for the
   integrated processing of real-time data and historic learning data. The
   evaluation and comparison with related work shows that our prototype is
   competitive regarding prediction accuracy. (C) 2017 The Authors.
   Published by Elsevier B.V.
CT 8th International Conference on Emerging Ubiquitous Systems and
   Pervasive Networks (EUSPN) / 7th International Conference on Current and
   Future Trends of Information and Communication Technologies in
   Healthcare (ICTH)
CY SEP 18-20, 2017
CL Lund, SWEDEN
ZB 0
TC 9
Z8 0
ZR 0
ZS 0
ZA 0
Z9 13
U1 0
U2 9
SN 1877-0509
BN *****************
DA 2018-02-01
UT WOS:000419236500040
ER

PT C
AU Goncalves, Andre
   Portela, Filipe
   Santos, Manuel Filipe
   Rua, Fernando
BE Shakshuki, E
TI Towards of a Real-time Big Data Architecture to Intensive Care
SO 8TH INTERNATIONAL CONFERENCE ON EMERGING UBIQUITOUS SYSTEMS AND
   PERVASIVE NETWORKS (EUSPN 2017) / 7TH INTERNATIONAL CONFERENCE ON
   CURRENT AND FUTURE TRENDS OF INFORMATION AND COMMUNICATION TECHNOLOGIES
   IN HEALTHCARE (ICTH-2017) / AFFILIATED WORKSHOPS
SE Procedia Computer Science
VL 113
BP 585
EP 590
DI 10.1016/j.procs.2017.08.294
DT Proceedings Paper
PD 2017
PY 2017
AB These days the exponential increase in the volume and variety of data
   stored by companies and organizations of various sectors of activity,
   has required to organizations the search for new solutions to improve
   their services and/or products, taking advantage of technological
   evolution. As a response to the inability of organizations to process
   large quantities and varieties of data, in the technological market,
   arise the Big Data. This emerging concept defined mainly by the volume,
   velocity and variety has evolved greatly in part by its ability to
   generate value for organizations in decision making. Currently, the
   health care sector is one of the five sectors of activity where the
   potential of Big Data growth most stands out. However, the way to go is
   still long and in fact there are few organizations, related to health
   care, that are taking advantage of the true potential of Big Data. The
   main target of this research is to produce a real-time Big Data
   architecture to the INTCare system, of the Centro Hospitalar do Porto,
   using the main open source big data solution, the Apache Hadoop. As a
   result of the first phase of this research we obtained a generic
   architecture who can be adopted by other Intensive Care Units. (c) 2017
   The Authors. Published by Elsevier B.V.
CT 8th International Conference on Emerging Ubiquitous Systems and
   Pervasive Networks (EUSPN) / 7th International Conference on Current and
   Future Trends of Information and Communication Technologies in
   Healthcare (ICTH)
CY SEP 18-20, 2017
CL Lund, SWEDEN
RI Gomes, André/KXQ-9620-2024; Santos, Manuel/ABD-3467-2020; Portela, Filipe/G-5324-2012
OI Santos, Manuel/0000-0002-5441-3316; Portela, Filipe/0000-0003-2181-6837
TC 5
ZB 0
Z8 1
ZR 0
ZA 0
ZS 1
Z9 11
U1 0
U2 4
SN 1877-0509
BN *****************
DA 2018-02-01
UT WOS:000419236500080
ER

PT J
AU Eltabakh, Mohamed Y.
   Kunjir, Mayuresh
   Elmagarmid, Ahmed K.
   Ahmad, Mohammad Shahmeer
TI Cross Modal Data Discovery over Structured and Unstructured Data Lakes
SO PROCEEDINGS OF THE VLDB ENDOWMENT
VL 16
IS 11
BP 3377
EP 3390
DI 10.14778/3611479.3611533
DT Article; Proceedings Paper
PD JUL 2023
PY 2023
AB Organizations are collecting increasingly large amounts of data for
   data-driven decision making. These data are often dumped into a
   centralized repository, e.g., a data lake, consisting of thousands of
   structured and unstructured datasets. Perversely, such mixture makes the
   problem of discovering tables or documents that are relevant to a user's
   query very challenging. Despite the recent efforts in data discovery,
   the problem remains widely open especially in the two fronts of (1)
   discovering relationships and relatedness across structured and
   unstructured datasets-where existing techniques suffer from either
   scalability, being customized for a specific problem type (e.g., entity
   matching or data integration), or demolishing the structural properties
   on its way, and (2) developing a holistic system for integrating various
   similarity measurements and sketches in an effective way to boost the
   discovery accuracy.
   In this paper, we propose a new data discovery system, named CMDL, for
   addressing these two limitations. CMDL supports the data discovery
   process over both structured and unstructured data while retaining the
   structural properties of tables. As a result, CMDL is the only system to
   date that empowers end-users to seamlessly pipeline the discovery tasks
   across the two modalities. We propose a novel multi-modal embedding
   representation that captures the similarities between text documents and
   tabular columns. The model training relies on labeled datasets generated
   though weak supervision, and thus the system is domain agnostic and
   easily generalizable. We evaluate CMDL on three real-world data lakes
   with diverse applications and show that our system is significantly more
   effective for cross-modality discovery compared to the search-based
   baseline techniques. Moreover, CMDL is more accurate and robust to
   different data types and distributions compared to the state-of-the-art
   systems that are limited to only the structured datasets.
CT 49th International Conference on Very Large Data Bases (VLDB)
CY AUG 28-SEP 01, 2023
CL Vancouver, CANADA
TC 6
Z8 0
ZB 0
ZS 0
ZA 0
ZR 0
Z9 8
U1 0
U2 7
SN 2150-8097
DA 2023-10-12
UT WOS:001059181900055
ER

PT C
AU Molnar, Balint
   Pisoni, Galena
   Tarcsi, Adam
BE Vansinderen, M
   Obaidat, M
   Benothman, J
TI Data Lakes for Insurance Industry: Exploring Challenges and
   Opportunities for Customer Behaviour Analytics, Risk Assessment, and
   Industry Adoption
SO ICE-B: PROCEEDINGS OF THE 17TH INTERNATIONAL JOINT CONFERENCE ON
   E-BUSINESS AND TELECOMMUNICATIONS, VOL 3: ICE-B
BP 127
EP 134
DI 10.5220/0009972301270134
DT Proceedings Paper
PD 2020
PY 2020
AB The proliferation of the big data movement has led to volumes of data.
   The data explosion has surpassed enterprises' ability to consume the
   various data types that may exist. This paper discusses the
   opportunities and challenges associated with implementing data lakes, a
   potential strategy for leveraging data as a strategic asset for
   enterprise decision-making The paper analyzes an information ecosystem
   of an Insurance Company environment. There are two types of data
   sources, information systems based on a transactional databases for
   recording claims, as the basis of financial administration and systems
   policies. There exists neither Data Warehouse solutions nor any other
   data collection solutions dedicated to utilizing by Data Science methods
   and tools. The emerging technologies provide opportunities for synergy
   between the traditional Data Warehouse and the most recent Data Lake
   approaches. Therefore, it seems feasible and reasonable to integrate
   these two architecture approaches to support data analytics on several
   aspects of insurance, financial activities, risk analysis, prediction
   and forecasting.
CT 17th International Joint Conference on e-Business and Telecommunications
   (ICE-B)
CY JUL 08-10, 2020
CL Paris, FRANCE
RI Molnár, Bálint/AAA-7271-2021; Pisoni, Galena/O-4598-2019
ZR 0
ZB 0
ZA 0
ZS 0
Z8 0
TC 6
Z9 8
U1 1
U2 8
BN 978-989-758-447-3
DA 2020-01-01
UT WOS:000836152300010
ER

PT J
AU Cherradi, Mohamed
   Bouhafer, Fadwa
   EL Haddadi, Anass
TI Data lake governance using IBM-Watson knowledge catalog
SO SCIENTIFIC AFRICAN
VL 21
AR e01854
DI 10.1016/j.sciaf.2023.e01854
EA AUG 2023
DT Article
PD SEP 2023
PY 2023
AB The strategic importance of data in decision-making is increasingly
   recognized, demanding efficient solutions such as data catalogs to
   ensure data governance and emphasize data interoperability, in
   accordance with the FAIR (Findable, Accessible, Interoperable, and
   Reusable) principles. However, the usage of FAIR-compliant data catalogs
   lacks empirical studies due to its novelty. This study aims to promote
   the practical adoption of data catalogs as a means to manage the
   expanding data landscape. We differentiate our contribution by providing
   an empirical evaluation and comparison of IBM Watson Knowledge Catalog
   (IBM-WKC), a leading data cataloging solution, with two other prominent
   alternatives, Open-Metadata and Data-Galaxy, for extracting relevant
   information from data lakes containing heterogeneous data sources in
   their native formats. Our proposed methodology utilizes an innovative
   tool built on IBM-WKC for annotating collected documents. To evaluate
   our approach, we conducted experiments on a dataset of 100 documents
   sourced from scientific databases. Moreover, to assess our proposal, we
   compare the retrieved text to the appropriate interventions that use the
   original checklist. The results demonstrate the superiority of IBM-WKC
   over its competitors, showcasing its enhanced performance in addressing
   data cataloging challenges. Notably, the tested queries achieved an
   impressive accuracy, precision, and recall value of 96%. These findings
   highlight the reliability and alignment of IBM-WKC with the FAIR
   principles.
RI EL HADDADI, Anass/ABD-8465-2021
OI EL HADDADI, Anass/0000-0002-3338-2477
ZA 0
ZB 0
Z8 0
ZR 0
TC 5
ZS 0
Z9 7
U1 1
U2 9
SN 2468-2276
DA 2024-02-25
UT WOS:001165433200001
ER

PT J
AU Correa, Christian
   Dujovne, Diego
   Bolano, Fernando
TI Design and Implementation of an Embedded Edge-Processing Water Quality
   Monitoring System for Underground Waters
SO IEEE EMBEDDED SYSTEMS LETTERS
VL 15
IS 2
BP 81
EP 84
DI 10.1109/LES.2022.3184925
DT Article
PD JUN 2023
PY 2023
AB Global warming effects are seen around the world and Latin American
   countries are not an exception, especially for expanding drought areas.
   Therefore, underground water resources used in the region are
   incrementing exponentially. However, temporal and spatial underground
   water information concerning availability and quality is scarce,
   disabling proper decision making. In order to close that breach, we
   propose and embedded edge-processing Internet of Things (IoT)-based
   water quality monitoring system. This letter introduces the design and
   implementation of this solution, specifically targeted to monitor
   irrigation and drinking water extracted from water wells. The system is
   designed to be deployed in central Chile, considering the topographic
   conditions, which severely affect power availability and communication
   resources. The captured data are stored in a data lake, for further
   processing according to water quality models.
RI Correa, Christian/AAP-1823-2020
OI Correa, Christian/0000-0002-4748-2129
ZA 0
ZS 0
Z8 0
ZR 0
TC 7
ZB 1
Z9 7
U1 0
U2 30
SN 1943-0663
EI 1943-0671
DA 2023-06-25
UT WOS:000995882700007
ER

PT C
AU Ren, Peng
   Li, Shuaibo
   Hou, Wei
   Zheng, Wenkui
   Li, Zhen
   Cui, Qin
   Chang, Wang
   Li, Xin
   Zeng, Chun
   Sheng, Ming
   Zhang, Yong
BE Xing, C
   Fu, X
   Zhang, Y
   Zhang, G
   Borjigin, C
TI MHDP: An Efficient Data Lake Platform for Medical Multi-source
   Heterogeneous Data
SO WEB INFORMATION SYSTEMS AND APPLICATIONS (WISA 2021)
SE Lecture Notes in Computer Science
VL 12999
BP 727
EP 738
DI 10.1007/978-3-030-87571-8_63
DT Proceedings Paper
PD 2021
PY 2021
AB In medical domain, huge amounts of data are generated at all times.
   These data are usually difficult to access, with poor data quality and
   many data islands. Besides, with a wide range of sources and complex
   structure, these data contain essential information and are difficult to
   manage. However, few existing data management frameworks based on Data
   Lake excel in solving the persistence and the analysis efficiency for
   medical multi-source heterogeneous data. In this paper, we propose an
   efficient Multi-source Heterogeneous Data Lake Platform (MHDP) to
   realize the efficient medical data management. Firstly, we propose an
   efficient and unified method based on Data Lake to store data of
   different types and different sources persistently. Secondly, based on
   the unified data store, an efficient multi-source heterogeneous data
   fusion is implemented to effectively manage data. Finally, an efficient
   data query strategy is carried out to assist doctors in medical
   decision-making. In-depth analysis on applications shows that MHDP
   delivers better performance for data management in medical domain.
CT 18th Web Information Systems and Applications Conference (WISA)
CY SEP 24-26, 2021
CL Kaifeng, PEOPLES R CHINA
SP China Comp Federat Tech Comm Informat Syst; Henan Univ; China Comp
   Federat
RI Cui, Qin/GQQ-3888-2022
TC 5
ZB 0
ZA 0
ZS 0
ZR 0
Z8 0
Z9 7
U1 2
U2 29
SN 0302-9743
EI 1611-3349
BN 978-3-030-87571-8; 978-3-030-87570-1
DA 2022-03-25
UT WOS:000767941100063
ER

PT J
AU Talha, Mohamed
   Elmarzouqi, Nabil
   Kalam, Anas Abou El
TI Towards a Powerful Solution for Data Accuracy Assessment in the Big Data
   Context
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
VL 11
IS 2
BP 419
EP 429
DT Article
PD FEB 2020
PY 2020
AB Data Accuracy is one of the main dimensions of Data Quality; it measures
   the degree to which data are correct. Knowing the accuracy of an
   organization's data reflects the level of reliability it can assign to
   them in decision-making processes. Measuring data accuracy in Big Data
   environment is a process that involves comparing data to assess with
   some "reference data" considered by the system to be correct. However,
   such a process can be complex or even impossible in the absence of
   appropriate reference data. In this paper, we focus on this problem and
   propose an approach to obtain the reference data thanks to the emergence
   of Big Data technologies. Our approach is based on the upstream
   selection of a set of criteria that we define as "Accuracy Criteria". We
   use furthermore a set of techniques such as Big Data Sampling, Schema
   Matching, Record Linkage, and Similarity Measurement. The proposed model
   and experiment results allow us to be more confident in the importance
   of data quality assessment solution and the configuration of the
   accuracy criteria to automate the selection of reference data in a Data
   Lake.
RI abou el kalam, anas/; ELMARZOUQI, Nabil/AAK-8004-2020
OI abou el kalam, anas/0000-0001-7714-4801; 
TC 4
Z8 0
ZR 0
ZB 0
ZA 0
ZS 0
Z9 7
U1 0
U2 10
SN 2158-107X
EI 2156-5570
DA 2020-03-24
UT WOS:000518468600054
ER

PT J
AU Mitrovic, Stanislav
TI Specifics of the integration of Business Intelligence and Big Data
   technologies in the processes of economic analysis
SO BIZNES INFORMATIKA-BUSINESS INFORMATICS
VL 42
IS 4
BP 40
EP 46
DI 10.17323/1998-0663.2017.4.40.46
DT Article
PD 2017
PY 2017
AB The volume of data used for economic analysis of the activities of
   organizations is growing every year. Despite the fact that all
   information required for economic analysis is available from various
   sources, such data are very often useless for analysis from the point of
   view of their economic potential.
   The purpose of this study is to outline a foundation for integrating
   Business Intelligence and Big Data into economic analysis processes. The
   theoretical and methodological basis of this study is provided by
   scientific research, methodological and practical developments of
   domestic and foreign authors on the application of IT solutions in
   economic analysis.
   According to the results of the research, modern information
   technologies, in particular, the Business Intelligence and Big Data
   systems have considerably changed the possibilities for improving
   economic analysis and reducing decision-making time. From the
   methodological point of view, many aspects of integration of BI and Big
   Data solutions and their implementation in the economic analysis
   processes in Russia's companies remain insufficiently developed. The
   foreign market of modern information technologies for business analytics
   has a longer history and is being developed more rapidly.
   The main conclusions of the study indicate that modern organizations
   operating on a highly competitive market should understand that the
   accumulation of Big Data does not always lead to the expected business
   benefits. In this context, the conclusion is that a modern company
   should not set as its goal to process all the available data in order to
   improve the quality of its economic analysis. It is more significant to
   use the entire volume of data for segmentation, which allows effective
   construction of a large number of models for small clusters, solving
   specific problems of economic analysis based on the application of
   modern IT systems.
RI Stanislav, Mitrovic/A-3060-2009
OI Stanislav, Mitrovic/0000-0003-0664-7270
ZS 0
Z8 0
ZR 0
ZA 0
TC 2
ZB 0
Z9 7
U1 0
U2 19
SN 1998-0663
DA 2018-12-28
UT WOS:000426970600004
ER

PT J
AU Salierno, Giulio
   Leonardi, Letizia
   Cabri, Giacomo
TI A Big Data Architecture for Digital Twin Creation of Railway Signals
   Based on Synthetic Data
SO IEEE OPEN JOURNAL OF INTELLIGENT TRANSPORTATION SYSTEMS
VL 5
BP 1
EP 18
DI 10.1109/OJITS.2024.3412820
DT Article
PD 2024
PY 2024
AB Industry 5.0 has introduced new possibilities for defining key features
   of the factories of the future. This trend has transformed traditional
   industrial production by exploiting Digital Twin (DT) models as virtual
   representations of physical manufacturing assets. In the railway
   industry, Digital Twin models offer significant benefits by enabling
   anticipation of developments in rail systems and subsystems, providing
   insight into the future performance of physical assets, and allowing
   testing and prototyping solutions prior to implementation. This paper
   presents our approach for creating a Digital Twin model in the railway
   domain. We particularly emphasize the critical role of Big Data in
   supporting decision-making for railway companies and the importance of
   data in creating virtual representations of physical objects in railway
   systems. Our results show that the Digital Twin model of railway switch
   points, based on synthetic data, accurately represents the behavior of
   physical railway switches in terms of data points.
RI Leonardi, Letizia/L-9722-2015; Salierno, Giulio/; Cabri, Giacomo/M-6723-2015
OI Leonardi, Letizia/0000-0003-4035-8560; Salierno,
   Giulio/0000-0002-9617-4448; Cabri, Giacomo/0000-0002-4942-2453
ZA 0
Z8 0
TC 4
ZB 0
ZR 0
ZS 0
Z9 6
U1 1
U2 12
EI 2687-7813
DA 2024-07-28
UT WOS:001273038700001
ER

PT J
AU Munshi, Amr
   Alhindi, Ahmad
   Qadah, Thamir M.
   Alqurashi, Amjad
TI An Electronic Commerce Big Data Analytics Architecture and Platform
SO APPLIED SCIENCES-BASEL
VL 13
IS 19
AR 10962
DI 10.3390/app131910962
DT Article
PD OCT 2023
PY 2023
AB The COVID-19 pandemic significantly increased e-commerce growth, adding
   more than 218 billion US dollars to the United States e-commerce sales.
   With this significant growth, various operational challenges have
   appeared, including logistic difficulties and customer satisfaction.
   Businesses that strive to take advantage of increased e-commerce growth
   must understand data and rely on e-commerce analytics. The large scale
   of e-commerce data requires sophisticated information technology
   techniques and cyber-infrastructure to leverage and analyze. This study
   presents a big e-commerce data platform to address several challenges in
   e-commerce. The presented platform's design is based on a distributed
   system architecture that supports e-commerce analytics applications
   using historical and real-time data and features a continuous feedback
   loop to observe the decision-making and evaluation processes to achieve
   the desired objectives. The platform was validated using two analytical
   applications. The first application was to identify the periods in which
   customers prefer to place orders, while the second was used to verify
   the big e-commerce data platform. The resulting insights and findings
   promote informed e-commerce decisions. Furthermore, viewing and acting
   on insight results and findings promote informed decisions that
   potentially benefit the e-commerce industry. The proposed platform can
   perform numerous e-commerce applications that potentially benefit the
   e-commerce industry.
RI Qadah, Thamir/AAG-7508-2019; Munshi, Amr/AHB-7543-2022; Alhindi, Ahmad/U-5347-2019
OI Qadah, Thamir/0000-0003-0754-0504; Munshi, Amr/0000-0002-4002-3755;
   Alhindi, Ahmad/0000-0002-0516-7868
ZS 0
ZA 0
ZR 0
Z8 0
ZB 0
TC 4
Z9 6
U1 17
U2 106
EI 2076-3417
DA 2023-11-01
UT WOS:001085550300001
ER

PT J
AU Benjelloun, Sarah
   El Aissi, Mohamed El Mehdi
   Lakhrissi, Younes
   El Haj Ben Ali, Safae
TI Data Lake Architecture for Smart Fish Farming Data-Driven Strategy
SO APPLIED SYSTEM INNOVATION
VL 6
IS 1
AR 8
DI 10.3390/asi6010008
DT Article
PD FEB 2023
PY 2023
AB Thanks to continuously evolving data management solutions, data-driven
   strategies are considered the main success factor in many domains. These
   strategies consider data as the backbone, allowing advanced data
   analytics. However, in the agricultural field, and especially in fish
   farming, data-driven strategies have yet to be widely adopted. This
   research paper aims to demystify the situation of the fish farming
   domain in general by shedding light on big data generated in fish farms.
   The purpose is to propose a dedicated data lake functional architecture
   and extend it to a technical architecture to initiate a fish farming
   data-driven strategy. The research opted for an exploratory study to
   explore the existing big data technologies and to propose an
   architecture applicable to the fish farming data-driven strategy. The
   paper provides a review of how big data technologies offer multiple
   advantages for decision making and enabling prediction use cases. It
   also highlights different big data technologies and their use. Finally,
   the paper presents the proposed architecture to initiate a data-driven
   strategy in the fish farming domain.
RI Lakhrissi, Younes/AAA-8819-2021
OI Lakhrissi, Younes/0000-0003-2718-7090
ZS 0
TC 5
ZA 0
Z8 0
ZB 2
ZR 0
Z9 6
U1 1
U2 8
EI 2571-5577
DA 2023-03-20
UT WOS:000938241700001
ER

PT J
AU Di Martino, Beniamino
   Cante, Luigi Colucci
   D'Angelo, Salvatore
   Esposito, Antonio
   Graziano, Mariangela
   Marulli, Fiammetta
   Lupi, Pietro
   Cataldi, Alessandra
TI A Big Data Pipeline and Machine Learning for Uniform Semantic
   Representation of Data and Documents From IT Systems of the Italian
   Ministry of Justice
SO INTERNATIONAL JOURNAL OF GRID AND HIGH PERFORMANCE COMPUTING
VL 14
IS 1
DI 10.4018/IJGHPC.301579
DT Article
PD 2022
PY 2022
AB In this paper, a big data pipeline is presented, taking in consideration
   both structured and unstructured data made available by the Italian
   Ministry of Justice, regarding their telematic civil process. Indeed,
   the complexity and volume of the data provided by the ministry requires
   the application of big data analysis techniques, in concert with machine
   and deep learning frameworks, to be correctly analysed and to obtain
   meaningful information that could support the ministry itself in better
   managing civil processes. The pipeline has two main objectives: to
   provide a consistent workflow of activities to be applied to the
   incoming data, aiming at extracting useful information for the
   ministry's decision making tasks, and to homogenize the incoming data,
   so that they can be stored in a centralized and coherent data lake to be
   used as a reference for further analysis and considerations.
RI Di Martino, Beniamino/O-6876-2015; Esposito, Antonio/AHC-3301-2022; Colucci Cante, Luigi/; Graziano, Mariangela/HPF-2471-2023; Marulli, Fiammetta/AAD-4051-2022; D'Angelo, Salvatore/GQB-4948-2022
OI Di Martino, Beniamino/0000-0001-7613-1312; Esposito,
   Antonio/0000-0002-2004-4815; Colucci Cante, Luigi/0009-0005-5226-6737;
   Graziano, Mariangela/0000-0002-1258-8249; 
ZA 0
ZS 0
ZB 0
TC 5
ZR 0
Z8 0
Z9 6
U1 0
U2 1
SN 1938-0259
EI 1938-0267
DA 2023-02-17
UT WOS:000916579600019
ER

PT J
AU Kachaoui, Jabrane
   Belangour, Abdessamad
TI Enhanced Data Lake Clustering Design based on K-means Algorithm
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
VL 11
IS 4
BP 547
EP 554
DT Article
PD APR 2020
PY 2020
AB In recent years, Big Data requirements have evolved. Organizations are
   trying more than ever to accent their efforts on industrial development
   of all data at their disposal and move further away from underpinning
   technologies. After investing around Data Lake concept, organizations
   must now overhaul their data architecture to face IoT (Internet of
   Things) and AI (Artificial Intelligence) expansion. Efficient and
   effective data mapping treatments could serve in understanding the
   importance of data being transformed and used for decision-making
   process endorsement. As current relational databases are not able to
   manage large amounts of data, organizations headed towards NoSQL (Not
   only Structured Query Language) databases. One such known NoSQL database
   is MongoDB, which has a high scalability. This article mainly put
   forward a new data model able to extract, classify, and then map data
   for the purpose of generating new more structured data that meet
   organizational needs. This can be carried out by calculating various
   metadata attributes weights, which are considered as important
   information. It also processed on data clustering stored into MongoDB.
   This categorization based on data mining clustering algorithm named
   K-Means.
RI Belangour, Abdessamad/KAL-6712-2024
ZB 1
TC 6
ZA 0
ZR 0
Z8 0
ZS 0
Z9 6
U1 0
U2 4
SN 2158-107X
EI 2156-5570
DA 2020-06-16
UT WOS:000537489900072
ER

PT J
AU Simionato, Rafael
   Torres Neto, Jose Rodrigues
   dos Santos, Carla Julciane
   Ribeiro, Bruno Silva
   Britto de Araujo, Fernando Cesar
   de Paula, Antonio Robson
   de Lima Oliveira, Pedro Augusto
   Fernandes, Paulo Silas
   Yi, Jin Hong
TI Survey on connectivity and cloud computing technologies:
   State-of-the-art applied to Agriculture 4.0
SO REVISTA CIENCIA AGRONOMICA
VL 51
SI SI
AR e20207755
DI 10.5935/1806-6690.20200085
DT Article
PD 2020
PY 2020
AB In recent years, agriculture has faced many challenges, from a growing
   global population to be fed, the work power evasion in the sector, to
   sustainability requirements and environmental constraints. To satisfy
   the increasingly demanding stakeholders, the agricultural sector has
   looked for new ways to tackle these issues. In this context, Information
   and Communications Technologies (ICTs) have been applied to help the
   agricultural sector overcome these challenges. This article investigates
   how two ICTs - connectivity and cloud computing - can leverage and
   traverse other ICTs, such as Internet of Things and artificial
   intelligence, enabling the entire productive sector to be supported by
   decision-making systems, which in turn are based on data-driven models.
   Moreover, a successful case study on how cloud computing has helped one
   of SiDi's biggest customers - a global company - improve its operational
   performance by obtaining insights from its data is presented.
ZS 0
ZR 0
ZA 0
ZB 2
TC 3
Z8 0
Z9 6
U1 1
U2 15
SN 0045-6888
EI 1806-6690
DA 2021-09-17
UT WOS:000692719200019
ER

PT C
AU Lamrhari, Soumaya
   Elghazi, Hamid
   Sadiki, Tayeb
   El Faker, Abdellatif
BE Essaaidi, M
   ElHani, S
TI A Profile-Based Big Data Architecture for Agricultural Context
SO 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES
   (ICEIT)
BP 22
EP 27
DT Proceedings Paper
PD 2016
PY 2016
AB Bringing Big data technologies into agriculture presents a significant
   challenge; at the same time, this technology contributes effectively in
   many countries' economic and social development. In this work, we will
   study environmental data provided by precision agriculture information
   technologies, which represents a crucial source of data in need of being
   wisely managed and analyzed with appropriate methods and tools in order
   to extract the meaningful information.
   Our main purpose through this paper is to propose an effective Big data
   architecture based on profiling system which can assist (among others)
   producers, consulting companies, public bodies and research laboratories
   to make better decisions by providing them real time data processing,
   and a dynamic big data service composition method, to enhance and
   monitor the agricultural productivity. Thus, improve their traditional
   decision-making process, and allow better management of the natural
   resources.
CT 2nd International Conference on Electrical and Information Technologies
   (ICEIT)
CY MAY 04-07, 2016
CL Tangier, MOROCCO
RI EL GHAZI, Hamid/KFB-5688-2024; EL FAKER, Abdellatif/HGD-3815-2022
OI EL GHAZI, Hamid/0000-0002-2790-4419; 
ZS 0
ZB 1
ZR 0
Z8 0
TC 5
ZA 0
Z9 6
U1 0
U2 3
BN 978-1-4673-8469-8
DA 2017-02-08
UT WOS:000391354500004
ER

PT C
AU Silva, Alecio
   Souza, Gilberto F. M.
GP IEEE
TI Prognosis Smart System AI-based Applied to Equipment Health Monitoring
   in 4.0 Industry Scenario
SO 67TH ANNUAL RELIABILITY & MAINTAINABILITY SYMPOSIUM (RAMS 2021)
SE Reliability and Maintainability Symposium
DI 10.1109/RAMS48097.2021.9605722
DT Proceedings Paper
PD 2021
PY 2021
AB In the age of IIoT - Industrial Internet of Things, data lake, data
   mining, big data, and cloud computing, the smart manufacturing enables
   to make more informed decisions in real-time by using the database
   extracted from sensors in its equipment. During an operational campaign,
   the Health Monitoring System (HMS) also allows an understanding of how
   component degradation is affecting the performance of the equipment.
   Through a structure supported by AI, as data lake and cloud computing,
   the HMS provides to monitored equipment a fault detection system, early
   warning alarms to prevent failures and a calculation of the remaining
   useful life (RUL).
   The purpose of this paper is to present a prognosis smart system based
   on AI applied to HMS to support decision-making regarding operational
   performance of equipment. A Recurrent Neural Network (RNN) procedure is
   developed to continuously analyze the mass of monitoring data generated
   during the machine operation. The ability to learn the behavior patterns
   of the collected signals and in this way to be able to make parameter
   predictions with high accuracy makes artificial neural networks a
   powerful tool to carry out an effective prognosis. Machine operational
   parameters are monitored simultaneously by the prognosis smart system.
   Then, this information is processed by the neural network and used to
   characterize the machine operational condition. Upon detecting a failure
   trend for one or more parameters monitored by recognizing deterioration
   patterns, the prognosis system calculates the remaining useful life
   (RUL) and allows maintainers to take early actions before the failure
   occurrence.
   The proposed methodology is applied as part of a HMS of a hydro
   generator based on parameters registered in operator inspections routes
   designed to identify critical equipment degradation. The registered data
   representing one operational year are used to train the neural network
   regarding normal and abnormal machine condition. After training, the
   neural network is able to predict failure trends for monitored
   temperature parameters of the hydro-generator lubricating system that is
   critical to support equipment performance. Comparing prediction data and
   data collected by the sensors, the developed neural network reached
   about 0,98 RMSE score. The remaining useful life prognosis proved to be
   an important tool to avoid hydro generator components unexpected
   failures which may affect power output and cause penalties to the power
   generation company.
CT 67th Annual Reliability and Maintainability Symposium (RAMS)
CY MAY 24-27, 2021
CL Orlando, FL
RI de Souza, Gilberto/P-1299-2018
ZR 0
ZS 0
TC 5
ZA 0
Z8 0
ZB 0
Z9 5
U1 0
U2 3
SN 0149-144X
BN 978-1-7281-8017-5
DA 2022-05-11
UT WOS:000784131300024
ER

PT C
AU Neves, Ricardo A.
   Cruvinel, Paulo E.
GP IEEE
TI Model for Semantic Base Structuring of Digital Data to Support
   Agricultural Management
SO 2020 IEEE 14TH INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC
   2020)
SE IEEE International Conference on Semantic Computing
BP 337
EP 340
DI 10.1109/ICSC.2020.00067
DT Proceedings Paper
PD 2020
PY 2020
AB This article presents a semantic model for structuring digital databases
   to function in a cloud environment and connect to data sources
   originating from Big Data. The work examines the process of receiving
   structured, semi-structured and unstructured data for use in
   agricultural risk management. It is conceived as an architecture that
   combines Data Mart, Data Warehouse (NoSQL), and Data Lake resources to
   support decision making, through knowledge discovery and applies
   algorithms for data mining by machine learning resources. The
   configuration presented addresses scenarios involving agricultural data,
   obtained from sensors operating in multiple modes.
CT 14th IEEE International Conference on Semantic Computing (ICSC)
CY FEB 03-05, 2020
CL San Diego, CA
SP IEEE; IEEE Comp Soc
RI Cruvinel, Paulo/C-7687-2015
ZR 0
TC 4
ZB 0
Z8 0
ZS 0
ZA 0
Z9 5
U1 1
U2 4
SN 2325-6516
BN 978-1-7281-6332-1
DA 2020-09-17
UT WOS:000565450400058
ER

PT C
AU Wiener, Patrick
   Stein, Manuel
   Seebacher, Daniel
   Bruns, Julian
   Frank, Matthias
   Simko, Viliam
   Zander, Stefan
   Nimis, Jens
BE Ali, M
   Newsam, S
   Ravada, S
   Renz, M
   Trajcevski, G
TI BigGIS: A Continuous Refinement Approach to Master Heterogeneity and
   Uncertainty in Spatio-Temporal Big Data (Vision Paper)
SO 24TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC
   INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2016)
DI 10.1145/2996913.2996931
DT Proceedings Paper
PD 2016
PY 2016
AB Geographic information systems (GIS) are important for decision support
   based on spatial data. Due to technical and economical progress an ever
   increasing number of data sources are available leading to a rapidly
   growing fast and unreliable amount of data that can be bene ficial (1)
   in the approximation of multivariate and causal predictions of future
   values as well as (2) in robust and proactive decision-making processes.
   However, today's GIS are not designed for such big data demands and
   require new methodologies to effectively model uncertainty and generate
   meaningful knowledge. As a consequence, we introduce BigGIS, a
   predictive and prescriptive spatio-temporal analytics platform, that
   symbiotically combines big data analytics, semantic web technologies and
   visual analytics methodologies. We present a novel continuous refinement
   model and show future challenges as an intermediate result of a
   collaborative research project into big data methodologies for
   spatio-temporal analysis and design for a big data enabled GIS.
CT 24th ACM SIGSPATIAL International Conference on Advances in Geographic
   Information Systems (ACM SIGSPATIAL GIS)
CY OCT 31-NOV 03, 2016
CL San Francisco, CA
SP ACM Special Interest Grp Spatial Informat; ACM; Amazon; ESRI; Facebook;
   Google; Oracle; Microsoft
OI Nimis, Jens/0000-0001-8300-0134; Stein, Manuel/0000-0002-7198-1438;
   Bruns, Julian/0000-0002-6592-7371
ZR 0
ZB 0
TC 5
ZA 0
ZS 0
Z8 0
Z9 5
U1 0
U2 9
BN 978-1-4503-4589-7
DA 2017-07-04
UT WOS:000403647900008
ER

PT J
AU Le, Ngoc-Bao-van
   Seo, Yeong-Seok
   Huh, Jun-Ho
TI Artificial Intelligence in Finance: Coffee Commodity Trading Big Data
   for Informed Decision Making
SO IEEE ACCESS
VL 12
BP 91780
EP 91792
DI 10.1109/ACCESS.2024.3409762
DT Article
PD 2024
PY 2024
AB Coffee, the second-largest global soft commodity, can take advantage of
   a comprehensive mining of daily and historical market data for more
   effective informed trading decisions. Advanced ICT and data mining
   technologies can change the trading market operation. The existing
   systems are confronted with certain constraints, including incomplete
   data, insufficient documentation for storage, and a requirement for a
   scalable infrastructure for big data analytics, such as a data warehouse
   or data lakehouse. To address this issue, the paper presents a design
   and implementation of a coffee commodity trading big data warehouse
   capable of analyzing various essential parameters for supporting
   informed decision-making. First, the designed system can automatically
   collect coffee trading data for New York Arabica coffee futures prices
   from selected worldwide reports and financial data portals. Next, the
   Extract, transform, and load (ETL) process is adopted to ingest coffee
   futures trading crawled data into the 3 layers data warehouse. Finally,
   the analytical system will extract and visualize selected key dimensions
   that influence coffee futures prices within different observation
   windows and perspectives. As a result, we implement a prototype of a
   coffee trading data warehouse on the crawled data from January 2000 to
   October 2022 and visualize trends in coffee futures prices based on the
   collected data for informed decision-making. The construction system is
   capable of stably operating and processing large volumes of transaction
   data. This paper will be valuable documentation for reference and
   decision support for coffee commodity trading enterprises and contribute
   to the development of future forecasting algorithms.
RI Le, Ngoc Bao Van/IXW-9767-2023; Huh, Jun-Ho/AAC-1518-2022; Seo, Yeong-Seok/AAF-2849-2019
OI Le, Ngoc Bao Van/0000-0002-3464-1274; Huh, Jun-Ho/0000-0001-6735-6456;
   Seo, Yeong-Seok/0000-0002-5319-7674
ZR 0
TC 3
ZB 0
Z8 0
ZS 0
ZA 0
Z9 3
U1 6
U2 23
SN 2169-3536
DA 2024-07-23
UT WOS:001269900500001
ER

PT C
AU Oukhouya, Lamya
   El Haddadi, Anass
   Er-Raha, Brahim
   Asri, Hiba
   Laaz, Naziha
BE BenAhmed, M
   Abdelhakim, BA
   Ane, BK
   Rosiyadi, D
TI A Proposed Big Data Architecture Using Data Lakes for Education Systems
SO EMERGING TRENDS IN INTELLIGENT SYSTEMS & NETWORK SECURITY
SE Lecture Notes on Data Engineering and Communications Technologies
VL 147
BP 53
EP 62
DI 10.1007/978-3-031-15191-0_6
DT Proceedings Paper
PD 2023
PY 2023
AB Nowadays, educational data can be defined through the 3Vs of Big Data:
   volume, variety and velocity. Data sources produce massive and complex
   data, which makes knowledge extraction with traditional tools difficult
   for educational organizations. Indeed, the actual architecture of data
   warehouses do not possess the capability of storing and managing this
   huge amount of varied data. The same goes for analytical processes;
   which no longer satisfy business analysts; in terms of data availability
   and speed of execution of queries. These constraints have implied an
   evolution towards more modern architectures, integrating Big Data
   solutions capable of promoting smart learning to students. In this
   context, the present paper proposes a new big data architecture for
   education systems covering multiple data sources. Using this
   architecture, data is organized through a set of layers, starting with
   the management of the different data sources to their final consumption.
   The proposal approach includes data lake as a means of modernizing
   decision-making processes, in particular data warehouses and OLAP
   methods. It will be used as a means for data consolidation for the
   integration of heterogeneous data sources.
CT 5th International Conference on Networks, Intelligent Systems and
   Security (NISS)
CY MAR 30-31, 2022
CL Bandung, INDONESIA
RI EL HADDADI, Anass/ABD-8465-2021; Laaz, Naziha/GSM-8175-2022
ZR 0
ZB 0
Z8 0
ZA 0
TC 1
ZS 0
Z9 3
U1 2
U2 10
SN 2367-4512
BN 978-3-031-15191-0; 978-3-031-15190-3
DA 2023-01-15
UT WOS:000894285000006
ER

PT C
AU Ulbig, Michael
   Merschak, Simon
   Hehenberger, Peter
   Bachler, Johann
BE Noel, F
   Nyffenegger, F
   Rivest, L
   Bouras, A
TI Requirements on and Selection of Data Storage Technologies for Life
   Cycle Assessment
SO PRODUCT LIFECYCLE MANAGEMENT PLM IN TRANSITION TIMES: THE PLACE OF
   HUMANS AND TRANSFORMATIVE TECHNOLOGIES, PLM 2022
SE IFIP Advances in Information and Communication Technology
VL 667
BP 86
EP 95
DI 10.1007/978-3-031-25182-5_9
DT Proceedings Paper
PD 2023
PY 2023
AB The importance of a centralized data storage system for life cycle
   assessment (LCA) will be addressed in this paper. Further, the
   decision-making process for a suitable data storage system is discussed.
   LCA requires a lot of relevant data such as resource/material data,
   production process data and logistics data, originating from many
   different sources, which must be integrated. Therefore, data collection
   for LCA is quite difficult. In practice, relevant data for LCA is often
   not available or is uncertain and has therefore to be estimated or
   generalized. This implies less accuracy of the calculated carbon
   footprint. State of the Art research shows that the LCA data collection
   process can benefit from data engineering approaches. Key of these
   approaches is a suitable and efficient data storage system like a data
   warehouse or a data lake. Depending on the LCA use case, a data storage
   system can also benefit from the combination with other technologies
   such as big data and cloud computing. As a result, in this paper a
   criteria catalog is developed and presented. It can be used to evaluate
   and decide which data storage systems and additional technologies are
   recommended to store and process data for more efficient and more
   precise carbon footprint calculation in life cycle assessment.
CT 19th IFIP WG 5.1 International Conference on Product Lifecycle
   Management (PLM)
CY JUL 10-13, 2022
CL Grenoble, FRANCE
SP IFIP WG 5 1; Univ Grenoble Alpes, Grenoble INP; CNRS; G Sci Concept
   Optimisat Prod; Springer
OI Merschak, Simon/0000-0001-8903-6146; Ulbig, Michael/0009-0009-4574-5974
TC 2
ZA 0
ZB 0
ZS 0
Z8 0
ZR 0
Z9 3
U1 2
U2 10
SN 1868-4238
EI 1868-422X
BN 978-3-031-25181-8; 978-3-031-25182-5
DA 2023-05-03
UT WOS:000968187600009
ER

PT C
AU Ouafiq, El Mehdi
   Saadane, Rachid
   Chehri, Abdellah
   Wahbi, Mohamed
GP IEEE
TI 6G Enabled Smart Environments and Sustainable Cities: an Intelligent Big
   Data Architecture
SO 2022 IEEE 95TH VEHICULAR TECHNOLOGY CONFERENCE (VTC2022-SPRING)
SE IEEE Vehicular Technology Conference VTC
DI 10.1109/VTC2022-Spring54318.2022.9860772
DT Proceedings Paper
PD 2022
PY 2022
AB Nowadays, there is an important need for fault-tolerant and
   energy-efficient self-organization systems, especially within smart
   cities. Internet of Things (IoT) proved capable of observing and
   examining the environment, generating & processing data. IoT is now
   applicable to almost every industry, including transportation and
   logistics, utilities, agriculture, smart cities, and more. In these
   industries, various types of meters, sensors, and trackers are used to
   constantly monitor activities, automate processes and optimize tasks.
   With the help of big data analytics, they can drive decision-making
   systems based on observations. As a result, the cities-management
   challenges are growing. The smart cities requirements are increasing to
   remedy the challenges, which requires a self-organized network composed
   of a sizeable number of nodes distributed across an area of interest.
   The traditional communication systems show limitations, especially when
   dealing with massive data rates, latency, the explosive growth of
   vehicular communication, and dynamic mobility. In this study, we explore
   a way to leverage the capabilities of wireless communication and big
   data analytics in favor of Smart Cities.
CT IEEE 95th Vehicular Technology Conference: (VTC-Spring)
CY JUN 19-22, 2022
CL Helsinki, FINLAND
SP IEEE; Nokia; Huawei; Samsung; Technol Innovat Inst; Pix Moving
RI Wahbi, Mohamed/I-3076-2013; Chehri, Abdellah/X-9516-2019; rachid, saadane/J-4558-2019
OI Chehri, Abdellah/0000-0002-4193-6062; rachid,
   saadane/0000-0002-0197-8313
ZA 0
ZS 0
ZR 0
TC 2
ZB 0
Z8 0
Z9 3
U1 1
U2 4
BN 978-1-6654-8243-1
DA 2022-10-29
UT WOS:000861825802017
ER

PT J
AU Zhang, Wei
   Dai, Zhixiang
   Xia, Taiwu
   Chen, Gangping
   Zhang, Yihua
   Zhou, Jun
   Liu, Cui
TI Multi-Source Heterogeneous Data-Driven Digital Delivery System for Oil
   and Gas Surface Engineering
SO SYSTEMS
VL 13
IS 6
AR 447
DI 10.3390/systems13060447
DT Article
PD JUN 6 2025
PY 2025
AB To address the challenges of data fragmentation, inconsistent standards,
   and weak interactivity in oil and gas field surface engineering, this
   study proposes an intelligent delivery system integrated with
   three-dimensional dynamic modeling. Utilizing a layered collaborative
   framework, the system combines optimization algorithms and anomaly
   detection methods during data processing to enhance the relevance and
   reliability of high-dimensional data. The model construction adopts a
   structured data architecture and dynamic governance strategies,
   supporting multi-project secure collaboration and full lifecycle data
   management. At the application level, it integrates three-dimensional
   visualization and semantic parsing capabilities to achieve interactive
   display and intelligent analysis of cross-modal data. Validated through
   practical engineering cases, the platform enables real-time linkage of
   equipment parameters, documentation, and three-dimensional models,
   significantly improving data integration efficiency and decision-making
   capabilities. This advancement drives the transformation of oil and gas
   field engineering toward intelligent and knowledge-driven practices.
ZS 0
ZR 0
ZB 0
TC 2
ZA 0
Z8 0
Z9 2
U1 4
U2 7
EI 2079-8954
DA 2025-07-01
UT WOS:001516216200001
ER

PT J
AU Abouzaid, Ahmed
   Barclay, Peter J.
   Chrysoulas, Christos
   Pitropakis, Nikolaos
TI Building a modern data platform based on the data lakehouse architecture
   and cloud-native ecosystem
SO DISCOVER APPLIED SCIENCES
VL 7
IS 3
AR 166
DI 10.1007/s42452-025-06545-w
DT Article
PD FEB 22 2025
PY 2025
AB In today's Big Data world, organisations can gain a competitive edge by
   adopting data-driven decision-making. However, a modern data platform
   that is portable, resilient, and efficient is required to manage
   organisations' data and support their growth. Furthermore, the change in
   the data management architectures has been accompanied by changes in
   storage formats, particularly open standard formats like Apache Hudi,
   Apache Iceberg, and Delta Lake. With many alternatives, organisations
   are unclear on how to combine these into an effective platform. Our work
   investigates capabilities provided by Kubernetes and other Cloud-Native
   software, using DataOps methodologies to build a generic data platform
   that follows the Data Lakehouse architecture. We define the data
   platform specification, architecture, and core components to build a
   proof of concept system. Moreover, we provide a clear implementation
   methodology by developing the core of the proposed platform, which are
   infrastructure (Kubernetes), ingestion and transport (Argo Workflows),
   storage (MinIO), and finally, query and processing (Dremio). We then
   conducted performance benchmarks using an industry-standard benchmark
   suite to compare cold/warm start scenarios and assess Dremio's caching
   capabilities, demonstrating a 12% median enhancement of query duration
   with caching.
RI AbouZaid, Ahmed/; Pitropakis, Nikolaos/ACW-7211-2022; Chrysoulas, Christos/AAD-8176-2020
OI AbouZaid, Ahmed/0009-0007-5524-5055; Pitropakis,
   Nikolaos/0000-0002-3392-9970; Chrysoulas, Christos/0000-0001-9817-003X
ZS 0
TC 1
ZB 0
ZA 0
Z8 0
ZR 0
Z9 2
U1 3
U2 6
EI 3004-9261
DA 2025-02-27
UT WOS:001427902800002
ER

PT J
AU Maass, Laura
   Badino, Manuel
   Iyamu, Ihoghosa
   Holl, Felix
TI Assessing the Digital Advancement of Public Health Systems Using
   Indicators Published in Gray Literature: Narrative Review
SO JMIR PUBLIC HEALTH AND SURVEILLANCE
VL 10
AR e63031
DI 10.2196/63031
DT Review
PD 2024
PY 2024
AB Background: Revealing the full potential of digital public health (DiPH)
   systems requires a wide-ranging tool to assess their maturity and
   readiness for emerging technologies. Although a variety of indices exist
   to assess digital health systems, questions arise about the inclusion of
   indicators of information and communications technology maturity and
   readiness, digital (health) literacy, and interest in DiPH tools by the
   society and workforce, as well as the maturity of the legal framework
   and the readiness of digitalized health systems. Existing tools
   frequently target one of these domains while overlooking the others. In
   addition, no review has yet holistically investigated the available
   national DiPH system maturity and readiness indicators using a
   multidisciplinary lens. Objective: We used a narrative review to map the
   landscape of DiPH system maturity and readiness indicators published in
   the gray literature. Methods: As original indicators were not published
   in scientific databases, we applied predefined search strings to the
   DuckDuckGo and Google search engines for 11 countries from all
   continents that had reached level 4 of 5 in the latest Global Digital
   Health Monitor evaluation. In addition, we searched the literature
   published by 19 international organizations for maturity and readiness
   indicators concerning DiPH. Results: Of the 1484 identified references,
   137 were included, and they yielded 15,806 indicators. We deemed 286
   indicators from 90 references relevant for DiPH system maturity and
   readiness assessments. The majority of these indicators (133/286, 46.5%)
   had legal relevance (targeting big data and artificial intelligence
   regulation, cybersecurity, national DiPH strategies, or health data
   governance), and the smallest number of indicators (37/286, 12.9%) were
   related to social domains (focusing on internet use and access, digital
   literacy and digital health literacy, or the use of DiPH tools,
   smartphones, and computers). Another 14.3% (41/286) of indicators
   analyzed the information and communications technology infrastructure
   (such as workforce, electricity, internet, and smartphone availability
   or interoperability standards). The remaining 26.2% (75/286) of
   indicators described the degree to which DiPH was applied (including
   health data architecture, storage, and access; the implementation of
   DiPH interventions; or the existence of interventions promoting health
   literacy and digital inclusion). Conclusions:Our work is the first to
   conduct a multidisciplinary analysis of the gray literature on DiPH
   maturity and readiness assessments. Although new methods for
   systematically researching gray literature are needed, our study holds
   the potential to develop more comprehensive tools for DiPH system
   assessments. We contributed toward a more holistic understanding of
   DiPH. Further examination is required to analyze the suitability and
   applicability of all identified indicators in diverse health care
   settings. By developing a standardized method to assess DiPH system
   maturity and readiness, we aim to foster informed decision-making among
   health care planners and practitioners to improve resource distribution
   and continue to drive innovation in health care delivery.
RI Iyamu, Ihoghosa/IWE-5004-2023; Badino, Manuel/; Holl, Felix/Y-9648-2019; Maaß, Laura/AEX-5567-2022
OI Iyamu, Ihoghosa/0000-0003-0271-9468; Badino, Manuel/0000-0003-2193-2168;
   Holl, Felix/0000-0002-4020-9509; Maaß, Laura/0000-0001-7354-8120
ZR 0
ZS 0
ZB 0
Z8 0
TC 2
ZA 0
Z9 2
U1 5
U2 11
SN 2369-2960
DA 2025-01-07
UT WOS:001388074000001
PM 39566910
ER

PT J
AU Sreepathy, H., V
   Rao, B. Dinesh
   Kumar, J. Mohan
   Rao, B. Deepak
TI Design an efficient data driven decision support system to predict
   flooding by analysing heterogeneous and multiple data sources using Data
   Lake
SO METHODSX
VL 11
AR 102262
DI 10.1016/j.mex.2023.102262
EA JUN 2023
DT Article
PD DEC 2023
PY 2023
AB Floods are the most common natural disaster in several countries
   throughout the world. Flooding has a major impact on people's lives and
   livelihoods. The impact of flood disasters on human lives can be
   mitigated by developing effective flood forecasting and prediction
   models. The majority of flood prediction models do not take all
   flood-causing factors into account when they are designed. It is
   difficult to collect and handle some of these flood-causing variables
   since they are heterogeneous in nature. This paper presents a new big
   data architecture called Data Lake, which can ingest and store all
   important flood-causing heterogeneous data sources in their raw format
   for machine learning model creation. The statistical relevance of
   important flood producing factors on flood prediction outcome is
   determined utilizing inferential statistical approaches. The outcome of
   this research is to create flood warning systems that can alert the
   public and government officials so that they can make decisions in the
   event of a severe flood, reducing socioeconomic loss. & BULL; Flood
   causing factors are from heterogeneous sources, so there is no big data
   architecture for handling variety of data sources. & BULL; To provide
   data architectural solution using data lake for collecting and analysing
   heterogeneous flood causing factors. & BULL; Uses inferential
   statistical approach to determine importance of different flood causing
   factors in design of efficient flood prediction models.
OI Jayasubramanian, Mohan Kumar/0000-0002-7559-0071
ZB 0
Z8 0
ZA 0
ZS 0
TC 2
ZR 0
Z9 2
U1 0
U2 15
EI 2215-0161
DA 2023-09-16
UT WOS:001060254000001
PM 37448950
ER

PT J
AU Patil, Avinash M.
   Lagad, Priyanka M.
   Soge, Bhavana
   Meshram, Rohan
   Lokhande, Mahendra N.
   Lokhande, Pradeep D.
TI Ammonium chloride mediated synthesis of 2-aryl-phthalazinone from
   O-formyl benzoic acid and in silico applications
SO ARKIVOC
SI SI
BP 1
EP 11
DI 10.24820/ark.5550190.p011.972
PN 7
DT Article
PD 2023
PY 2023
AB Ammonium chloride mediated cyclization reaction leading to one-pot
   synthesis of 2-arylphthalazinone from 2 -carboxyl benzoic acid and aryl
   hydrazine in methanol was developed. This method was found to be
   tolerant of a broad range of functional groups. This novel protocol
   features mild reaction conditions, operational simplicity, and easy
   availability of starting material and very high yields. The molecular
   docking data indicates that compound have comparable free energy with
   the standard compound. They interact only with some conserved residues
   such as Leu387, Trp387, Phe381, Tyr385. Therefore, this compound can be
   considered for further analysis and they have enormous potential to be
   tested experimentally
OI N Patil, Ashish/0000-0001-7807-2686
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
TC 2
Z9 2
U1 0
U2 1
SN 1551-7004
EI 1551-7012
DA 2023-06-03
UT WOS:000994652600001
ER

PT C
AU Sousa, Vania
   Barros, Daniela
   Guimaraes, Pedro
   Santos, Antonina
   Santos, Maribel Yasmina
BE Cabanillas, C
   Perez, F
TI Conceptual Formalization of Massive Storage for Advancing
   Decision-Making with Data Analytics
SO INTELLIGENT INFORMATION SYSTEMS, CAISE FORUM 2023
SE Lecture Notes in Business Information Processing
VL 477
BP 121
EP 128
DI 10.1007/978-3-031-34674-3_15
DT Proceedings Paper
PD 2023
PY 2023
AB Data Lakes have been widely used to handle massive amounts of data
   arriving at high velocity and variety. However, if proper data
   management concerns are not addressed, this massive data storage can
   easily turn Data Lakes into Data Swamps. Furthermore, data must be
   associated with the data artefacts created to extract value from it,
   such as pipelines used to collect, treat, or process data and analytical
   artefacts such as analytical dashboards and machine learning models.
   This paper proposes a more comprehensive view of a Data Lake, in which
   all of these resources can be stored and managed. To that end, the
   conceptual meta-model incorporates a data catalog, data at various
   stages of maturity, pipelines, dashboards, and machine learning models.
   The proposed meta-model was instantiated in the ADM.IN (Advanced
   Decision Making in Productive Systems through Intelligent Networks)
   project, showing how vast amounts of data and their related artefacts
   can be managed to support decision-making processes with data analytics.
CT 35th CAiSE Conference on Cyber-Human Systems
CY JUN 12-16, 2023
CL Zaragoza, SPAIN
SP San Jorge Univ, SVIT Res Grp
RI Guimarães, Peo/; Santos, Maribel Yasmina/M-5214-2013; Sousa, Vânia/
OI Guimarães, Peo/0000-0003-3390-8528; Santos, Maribel
   Yasmina/0000-0002-3249-6229; Sousa, Vânia/0009-0002-1279-6651
TC 2
Z8 0
ZR 0
ZA 0
ZB 0
ZS 0
Z9 2
U1 0
U2 0
SN 1865-1348
EI 1865-1356
BN 978-3-031-34673-6; 978-3-031-34674-3
DA 2024-09-15
UT WOS:001284384200015
ER

PT J
AU Ritchi, Hamzah
   Andriani, Gina
   Zulkarnaen, Reza
   Zaidaan, Akmal
TI "The state of implementing big data in banking business processes: An
   Indonesian perspective"
SO BANKS AND BANK SYSTEMS
VL 17
IS 3
DI 10.21511/bbs.17(3).2022.10
DT Article
PD 2022
PY 2022
AB Notwithstanding the perceived global potentiality, how big data enhances
   decision- making quality prompts an intriguing inquiry, especially in an
   increasingly competitive banking environment in developing economies.
   Building on an industry data-driven framework, this study strives to
   understand the state of implementing big data in the Indonesian banking
   sector. A deductively organized descriptive method employing indepth
   interviews was conducted with subject matter experts representing
   Indonesian banking-related areas. The result and the following analysis
   show the modest status of big data implementation across three major
   banks and two complementary companies, as indicated by many elements of
   the framework phases that were found during the early adoption stage.
   This denotes a steady buy-in across banking business processes as
   particularly reflected in the framework's four phases - continuing push
   to meet the variety aspect (intelligence), structured data architecture
   domination (design), limited choice of performance indicator for big
   data value (choice), and customer-corporate vision decoupling
   (implementation). While Indonesian banks have evidently initiated the
   big data implementation, further improvement remains imperative for the
   decision-making process. Accordingly, big data should be tightly coupled
   with a strong data-driven vision that drives decision-making across
   intra-firm actors. Handling data omnipresence shall be viewed as the
   embodiment of a data-driven vision.
RI Zaidaan, Akmal/; Ritchi, Hamzah/O-3531-2017
OI Zaidaan, Akmal/0000-0003-3714-3155; Ritchi, Hamzah/0000-0002-9374-9357
ZA 0
Z8 0
ZR 0
ZS 0
ZB 0
TC 2
Z9 2
U1 0
U2 4
SN 1816-7403
EI 1991-7074
DA 2022-01-01
UT WOS:001297163400010
ER

PT J
AU Zerega-Prado, Jose
   Llerena-Izquierdo, Joe
TI Information consolidation architecture for health insurance using Big
   Data
SO MEMORIA INVESTIGACIONES EN INGENIERIA
IS 23
BP 18
EP 31
DI 10.36561/ING.23.3
DT Article
PD 2022
PY 2022
AB The identification of data that is in various sources of information and
   its consolidation to deliver it as useful is achieved with Big Data. The
   overall objective of this work is to develop an information
   consolidation architecture design for health insurance using Big Data.
   For this research proposal, the analytical empirical method is used, of
   a quasi-experimental type with a quantitative approach, through the
   analysis of relevant references and specification of the architecture
   components. The results of this research allow categorizing different
   computational architectures for health insurance through a review of
   relevant literature, developing an architectural model of a
   computational system for an Ecuadorian health insurance company oriented
   to the consolidation of information, and evaluating the study
   methodology used to establish feasible factors of the model. The
   contribution of this work allows us to determine the applicability of
   the model to national or foreign health insurance companies by
   contrasting feasible factors in a specific company of the environment.
   It is concluded that the different sources of information or types of
   data used in the field of health insurance allow to know several edges
   of data analysis through a Big Data architecture, in addition to
   obtaining indicators to improve decision making; 73% of the established
   factors are viable in an Ecuadorian health insurance company.
RI Llerena Izquierdo, Joe/B-5941-2014
OI Llerena Izquierdo, Joe/0000-0001-9907-7048
Z8 0
ZA 0
ZR 0
ZS 0
ZB 0
TC 0
Z9 2
U1 0
U2 7
SN 2301-1092
EI 2301-1106
DA 2023-01-22
UT WOS:000906769400002
ER

PT J
AU Geva, Gil A.
   Ketko, Itay
   Nitecki, Maya
   Simon, Shoham
   Inbar, Barr
   Toledo, Itay
   Shapiro, Michael
   Vaturi, Barak
   Votta, Yoni
   Filler, Daniel
   Yosef, Roey
   Shpitzer, Sagi A.
   Hir, Nabil
   Markovich, Michal Peri
   Shapira, Shachar
   Fink, Noam
   Glasberg, Elon
   Furer, Ariel
TI Data Empowerment of Decision-Makers in an Era of a Pandemic:
   Intersection of "Classic" and Artificial Intelligence in the Service of
   Medicine
SO JOURNAL OF MEDICAL INTERNET RESEARCH
VL 23
IS 9
AR e24295
DI 10.2196/24295
DT Article
PD SEP 10 2021
PY 2021
AB Background: The COVID-19 outbreak required prompt action by health
   authorities around the world in response to a novel threat. With
   enormous amounts of information originating in sources with uncertain
   degree of validation and accuracy, it is essential to provide
   executive-level decision-makers with the most actionable, pertinent, and
   updated data analysis to enable them to adapt their strategy swiftly and
   competently.
   Objective: We report here the origination of a COVID-19 dedicated
   response in the Israel Defense Forces with the assembly of an
   operational Data Center for the Campaign against Coronavirus.
   Methods: Spearheaded by directors with clinical, operational, and data
   analytics orientation, a multidisciplinary team utilized existing and
   newly developed platforms to collect and analyze large amounts of
   information on an individual level in the context of SARS-CoV-2
   contraction and infection.
   Results: Nearly 300,000 responses to daily questionnaires were recorded
   and were merged with other data sets to form a unified data lake. By
   using basic as well as advanced analytic tools ranging from simple
   aggregation and display of trends to data science application, we
   provided commanders and clinicians with access to trusted, accurate, and
   personalized information and tools that were designed to foster
   operational changes and mitigate the propagation of the pandemic. The
   developed tools aided in the in the identification of high-risk
   individuals for severe disease and resulted in a 30% decline in their
   attendance to their units. Moreover, the queue for laboratory
   examination for COVID-19 was optimized using a predictive model and
   resulted in a high true-positive rate of 20%, which is more than twice
   as high as the baseline rate (2.28%, 95% CI 1.63%-3.19%).
   Conclusions: In times of ambiguity and uncertainty, along with an
   unprecedented flux of information, health organizations may find
   multidisciplinary teams working to provide intelligence from diverse and
   rich data a key factor in providing executives relevant and actionable
   support for decision-making.
OI Geva, Gil/0000-0002-0322-8348; Shapiro, Michael/0000-0001-5943-6974;
   Filler, Daniel/0000-0002-0070-816X; Simon, Shoham/0000-0003-2544-1550;
   Ketko, Itay/0000-0001-7435-4424; Nitecki, Maya/0000-0003-1127-4552;
   Inbar, Barr/0000-0002-1978-1826
ZB 0
TC 2
Z8 0
ZA 0
ZS 0
ZR 0
Z9 2
U1 1
U2 19
SN 1439-4456
EI 1438-8871
DA 2021-09-10
UT WOS:000695740200002
PM 34313589
ER

PT C
AU Neves, Ricardo A.
   Cruvinel, Paulo E.
GP IEEE
TI Ontology for Structuring a Digital Databases for Decision Making in
   Grain Production
SO 2021 IEEE 15TH INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC
   2021)
SE IEEE International Conference on Semantic Computing
BP 386
EP 392
DI 10.1109/ICSC50631.2021.00071
DT Proceedings Paper
PD 2021
PY 2021
AB This paper presents an ontology for the structuring of digital databases
   with the objective of acting in a cloud environment and meeting big data
   sources in the agricultural context of grain production. Its conception
   is structured in three stages: the first stage presents an ontological
   architecture aimed at public and private cloud environments, the second
   stage deals with a semantic model at process level, and a pseudocode for
   ontological application is elaborated in the third stage, considering
   the technologies applied to the cloud. This work combines advanced
   features to support decision making from Data Lake storage solutions,
   semantic treatment of big data, as well as the presentation of
   strategies based on machine learning and data quality analysis to obtain
   data and metadata organized for application in a decision model. The
   configuration of the ontology presented meets the diversity of big data
   projects in the grain production context, the characteristics of which
   are based on interoperability in the use of heterogeneous data and its
   integration, elasticity of computational resources, and high
   availability of cloud access.
CT 15th IEEE International Conference on Semantic Computing (ICSC)
CY JAN 27-29, 2021
CL ELECTR NETWORK
SP IEEE; IEEE Comp Soc
RI Cruvinel, Paulo/C-7687-2015
ZS 0
Z8 0
ZA 0
ZB 1
ZR 0
TC 2
Z9 2
U1 0
U2 8
SN 2325-6516
BN 978-1-7281-8899-7
DA 2021-08-04
UT WOS:000668692000067
ER

PT C
AU Sosa, David
   Paciello, Julio
BE Teran, L
   Pincay, J
   Portmann, E
TI Data Lake: A Case of Study of a Big Data Analytics Architecture for
   Public Procurements
SO 2021 EIGHT INTERNATIONAL CONFERENCE ON EDEMOCRACY & EGOVERNMENT (ICEDEG)
SE International Conference on eDemocracy and eGovernment ICEDEG
BP 194
EP 198
DI 10.1109/ICEDEG52154.2021.9530976
DT Proceedings Paper
PD 2021
PY 2021
AB Big Data technologies are facing problems of volume, velocity, variety
   and veracity of data, attending to the wide expansion of emerging
   technologies like IoT and IoE. Cyberocracy proposes a decision-making
   process of a Government based on the effective use of information. An
   important effort in this line, focusing on government public
   procurement, has been carried out by the Open Contracting Partnership
   (OCP), promoting the publication of more volumes of public procurement
   data in non-relational and machine processable formats every day. This
   work analyzes the underlying Big Data infrastructure for the analysis of
   public procurement data through a comparative case of study between a
   technology proposed by the OCP called KingFisher and emergent
   technologies based on Data Lakes. With an emphasis on storage
   requirements to support a high volume of payloads, also considering
   criteria of velocity and RAM use. Preliminary results show encouraging
   findings especially in terms of volume required by a Data Lake, even for
   different payload scenarios, up to 10 times less storage than the
   relational database-based model.
CT 8th International Conference on eDemocracy and eGovernment (ICEDEG)
CY JUL 28-30, 2021
CL ELECTR NETWORK
SP Escuela Super Politecnica Litoral; Escuela Politecnica Nacl; Inst Altos
   Estudios Nacl; Univ Amer; Univ Fuerzas Armadas; Univ Tecnica Ambato;
   Univ Fribourg; Univ San Francisco Quito; IEEE Comp Soc; IEEE Reg 9; IEEE
   Comp Soc eGovernment Special Tech Community
ZS 0
ZA 0
ZB 0
TC 1
Z8 0
ZR 0
Z9 2
U1 0
U2 4
SN 2573-2005
EI 2573-1998
BN 978-1-6654-2513-1
DA 2022-11-30
UT WOS:000847020200026
ER

PT C
AU Abdelhedi, Fatma
   Jemmali, Rym
   Zurfluh, Gilles
GP IEEE
TI Medical data lake query assistance
SO 2023 20TH ACS/IEEE INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND
   APPLICATIONS, AICCSA
SE International Conference on Computer Systems and Applications
DI 10.1109/AICCSA59173.2023.10479336
DT Proceedings Paper
PD 2023
PY 2023
AB In today's world, there is a growing need to analyze data stored in a
   Data Lake, which is a collection of large, heterogeneous databases. Our
   work is part of a medical application that aims to help healthcare
   professionals analyze complex data for decision-making. We propose
   mechanisms that promote data accessibility. The data are stored in a
   Data Warehouse (DW) that is periodically built from a data lake.
   Depending on the needs of the decision-maker, data are extracted from
   the DW and transferred to a Data Mart (DM) for querying. In this paper,
   we present a schema recommendation system based on the principle of
   collaborative filtering. This system can predict the DM schemas that
   were developed in the past that best match the data need expressed by a
   decision-maker. It does this by comparing the attributes present in the
   schemas with the attributes deduced from the need to propose a list of
   predictions for the most suitable schemas. The technique used is simple,
   while allowing us to solve the problem of periodic updates to the source
   data. An experiment was conducted for a medical application.
CT 20th ACS/IEEE International Conference on Computer Systems and
   Applications (AICCSA)
CY DEC 04-07, 2023
CL Giza, EGYPT
SP IEEE; ACS
RI Abdelhedi, Fatma/AAT-3786-2021
ZB 0
ZR 0
ZA 0
Z8 0
ZS 0
TC 0
Z9 1
U1 0
U2 0
SN 2161-5322
BN 979-8-3503-1943-9
DA 2024-07-06
UT WOS:001222477900102
ER

PT C
AU Kulkarni, Apurva
   Bassin, Pooja
   Parasa, Niharika Sri
   Venugopal, Vinu E.
   Srinivasa, Srinath
   Ramanathan, Chandrashekar
BE Sachdeva, S
   Watanobe, Y
   Bhalla, S
TI Ontology Augmented Data Lake System for Policy Support
SO BIG DATA ANALYTICS IN ASTRONOMY, SCIENCE, AND ENGINEERING, BDA 2022
SE Lecture Notes in Computer Science
VL 13830
BP 3
EP 16
DI 10.1007/978-3-031-28350-5_1
DT Proceedings Paper
PD 2023
PY 2023
AB Analytics of Big Data in the absence of an accompanying framework of
   metadata can be a quite daunting task. While it is true that statistical
   algorithms can do large-scale analyses on diverse data with little
   support from metadata, using such methods on widely dispersed, extremely
   diverse, and dynamic data may not necessarily produce trustworthy
   findings. One such task is identifying the impact of indicators for
   various Sustainable Development Goals (SDGs). One of the methods to
   analyze impact is by developing a Bayesian network for the policymaker
   to make informed decisions under uncertainty. It is of key interest to
   policy-makers worldwide to rely on such models to decide the new
   policies of a state or a country (https://sdgs.un.org/2030agenda). The
   accuracy of the models can be improved by considering enriched data -
   often done by incorporating pertinent data from multiple sources.
   However, due to the challenges associated with volume, variety,
   veracity, and the structure of the data, traditional data lake systems
   fall short of identifying information that is syntactically diverse yet
   semantically connected. In this paper, we propose a Data Lake (DL)
   framework that targets ingesting & processing of data like any
   traditional DL, and in addition, is capable of performing data retrieval
   for applications such as Policy Support Systems (where the selection of
   data greatly affect the output interpretations) by using ontologies as
   the intermediary. We discuss the proof of concept for the proposed
   system and the preliminary results (IIITB Data Lake project Website
   link: http://cads.iiitb.ac.in/wordpress/) based on the data collected
   from the agriculture department of the Government of Karnataka (GoK).
CT 10th International Conference on Big Data Analytics (BDA)
CY DEC 05-07, 2022
CL Univ Aizu, ELECTR NETWORK
HO Univ Aizu
SP Natl Inst Technol Delhi; Indian Inst Technol Delhi
RI Ellampallil Venugopal, Vinu/; Srinivasa, Srinath/AAT-8414-2020; Kulkarni, Apurva/; Bassin, Pooja/; Ramanathan, Chanashekar/
OI Ellampallil Venugopal, Vinu/0000-0003-4429-9932; Kulkarni,
   Apurva/0000-0002-9215-2049; Bassin, Pooja/0000-0002-0611-8734;
   Ramanathan, Chanashekar/0000-0002-3330-8365
Z8 0
TC 1
ZR 0
ZA 0
ZB 0
ZS 0
Z9 1
U1 1
U2 4
SN 0302-9743
EI 1611-3349
BN 978-3-031-28349-9; 978-3-031-28350-5
DA 2023-07-13
UT WOS:001004046900001
ER

PT C
AU Bianchini, Devis
   De Antonellis, Valeria
   Garda, Massimiliano
   Melchiori, Michele
BE Hartmann, S
   Kung, J
   Kotsis, G
   Tjoa, AM
   Khalil, I
TI Contextual Preferences to Personalise Semantic Data Lake Exploration
SO DATABASE AND EXPERT SYSTEMS APPLICATIONS, DEXA 2020, PT II
SE Lecture Notes in Computer Science
VL 12392
BP 322
EP 332
DI 10.1007/978-3-030-59051-2_22
DT Proceedings Paper
PD 2020
PY 2020
AB In the latest years, the availability of data collected within Smart
   Cities is enabling citizens to take decisions about their daily life in
   an autonomous way. In this landscape, data aggregation according to
   different analysis dimensions may help users to take decisions,
   leveraging indicators as powerful tools for meaningful exploration.
   However, due to the volume and heterogeneity of Smart City data, data
   lakes have to be used as flexible repositories for enabling data storage
   and organisation. Despite they are usually based on centralisation of
   data storage, data lakes compel to consider pay-as-you-go or on-demand
   solutions, where integration is progressively carried out, to cope with
   the cumbersome nature of Big Data. Given the variety of interested
   users, their goals and preferences on available data, personalised data
   access, as well as representation and use of preferences, are required
   and need to be adapted to the unique characteristics of data lakes. In
   this paper, we describe an approach to model preferences on Smart City
   indicators built on top of a data lake. Preferences are used for
   personalised data exploration. Main contributions of this paper concern:
   (a) the definition of users' preferences and preference constructors
   over the semantic representation of indicators; (b) the definition of
   users' contexts and contextual preferences; (c) preference-based
   personalised exploration of Smart City data.
CT 31st International Conference on Database and Expert Systems
   Applications (DEXA)
CY SEP 14-17, 2020
CL Comenius Univ Bratislava, ELECTR NETWORK
HO Comenius Univ Bratislava
SP Software Competence Ctr Hagenberg; JVU, Inst Telecooperaat; Informat
   Integrat & Web Based Applicat & Serv
RI Melchiori, Michele/AAH-3714-2019; Garda, Massimiliano/
OI Garda, Massimiliano/0009-0006-5823-6595
Z8 0
ZR 0
ZA 0
ZB 0
TC 1
ZS 0
Z9 1
U1 0
U2 3
SN 0302-9743
EI 1611-3349
BN 978-3-030-59051-2; 978-3-030-59050-5
DA 2021-11-21
UT WOS:000716716900022
ER

PT C
AU Hou, Jie
   Zhang, Xi-kun
   Wang, Yao-gang
BE Cai, N
TI SVM-Based Clinical Decision Support Algorithm under Medical Big Data
   Architecture
SO COMPUTER SCIENCE AND TECHNOLOGY (CST2016)
BP 936
EP 945
DT Proceedings Paper
PD 2017
PY 2017
AB Big Data technology has experienced rapid development in recent years
   and has demonstrated its effectiveness when implemented inclinical
   diagnostic decision support. Current research of big data focuses
   largely on data storage architecture, the exploration on big clinical
   data mining and decision making strategy is relatively less. This paper
   discusses the parallel big medical data mining method under Spark
   architecture and proposes the optimized support vector machine (PCSVM)
   algorithm to provide qualitative data for clinical diagnostic decision
   support.
CT International Conference on Computer Science and Technology (CST)
CY JAN 08-10, 2016
CL Shenzhen, PEOPLES R CHINA
TC 1
ZA 0
ZR 0
ZS 0
Z8 0
ZB 0
Z9 1
U1 1
U2 6
BN 978-981-314-642-6; 978-981-3146-41-9
DA 2018-09-12
UT WOS:000443429900105
ER

PT J
AU Iglesias, Felix
   Ros, Frederic
   Thuy, Lynh Hoang Vy
   Gourcy, Laurence
   Moquet, Jean-Sebastien
   Daele, Veronique
   Dupraz, Sebastien
TI A conceptual architecture for AI-assisted Digital Twins in natural
   resource management
SO ECOLOGICAL INFORMATICS
VL 94
AR 103635
DI 10.1016/j.ecoinf.2026.103635
EA JAN 2026
DT Article
PD MAR 2026
PY 2026
AB The management of natural resources is increasingly critical and
   challenging due to complex interactions among environmental, industrial,
   and societal processes. Traditional approaches often fail to integrate
   heterogeneous data, limiting predictive and decision-support
   capabilities. This study presents a conceptual architecture for an
   Artificial Intelligence (AI)-assisted Digital Twin (DT) of the
   Centre-Val de Loire region, designed to unify time-dependent
   multi-source data. Based on the ENVRI Reference Model, it covers
   Science, Information, Computational, Engineering, and Technology layers,
   defining standardized data exchange, communication protocols, and
   prototype functionalities. A proof of concept FIWARE implementation
   supports ingestion, monitoring and analytical services for piezometric
   and meteorological data, exemplified through groundwater dynamics in the
   Beauce aquifer. It integrates daily observations from 53 piezometric
   stations over more than five years, managing approximately 2.8 million
   records in a containerized environment. Results show that the proposed
   DT architecture can enhance sustainability-oriented decision making,
   integrating heterogeneous data and predictive analyses while enabling
   collaboration across scientific and technical domains. Its modular
   design offers a replicable template for future AI-assisted environmental
   DTs, scalable to larger regions. Hence, this work illustrates how DTs
   can improve environmental monitoring and understanding, providing a
   pathway toward resilient, data-driven management of natural resources.
RI ROS, Frédéric/V-2884-2019; Gourcy, Laurence/AAJ-6717-2020
Z8 0
ZR 0
ZB 0
TC 0
ZA 0
ZS 0
Z9 0
U1 0
U2 0
SN 1574-9541
EI 1878-0512
DA 2026-02-13
UT WOS:001681983600001
ER

PT J
AU Bahmutsky, Sofia
   Turner, Ian
   Arulnathan, Vivek
   Pelletier, Nathan
TI Advancing life cycle assessment through data science: A critical review
   of algorithms, tools, and data challenges
SO SUSTAINABLE PRODUCTION AND CONSUMPTION
VL 61
BP 25
EP 36
DI 10.1016/j.spc.2025.10.007
EA DEC 2025
DT Article
PD DEC 2025
PY 2025
AB A well-executed life cycle assessment requires thorough data collection
   across all relevant processes, combined with advanced data analysis.
   Common data-related issues in life cycle assessment research include the
   absence of necessary data, low data quality, inconsistencies,
   uncertainty, and failure to account for variations over time and
   location. In this context, data science, the discipline of extracting
   meaningful insights from data, has the potential to address these
   challenges. While the integration of data science with life cycle
   assessment holds significant potential, best use cases depend on the
   goal of the study, as well as the data type and volume required,
   underscoring the necessity of reviewing the intersection of data science
   and life cycle assessment. This study used the Preferred Reporting Items
   for Systematic Reviews and Meta-Analysis (PRISMA) method to identify
   literature addressing the use of data science elements to support life
   cycle assessment. It evaluated which data science techniques are
   appropriate for specific life cycle assessment stages or problem areas
   and the strengths and weaknesses of current data science applications in
   life cycle assessment. Key opportunities identified revolve around
   solutions for dealing with missing or poor-quality data,
   expensive/prohibitive data collection, and improving the accuracy of
   life cycle assessment results. The currently most feasible pathways
   appear to involve use of machine learning techniques, as these types of
   studies were the most conducted and generated tangible results. Extreme
   gradient boosting, random forest, and artificial neural networks were
   particularly prominent algorithm choices. Data collection and
   transferability using ontologies and semantic tools were also
   highlighted as important strategies for improving data flow in life
   cycle assessment, including the integration of a wide variety of
   databases and non-life cycle assessment data.
RI Pelletier, Nathan/U-9312-2019
Z8 0
ZS 0
ZA 0
TC 0
ZR 0
ZB 0
Z9 0
U1 14
U2 14
SN 2352-5509
DA 2025-11-09
UT WOS:001608191100001
ER

PT P
AU CHEN W
TI Method for processing data based on artificial            intelligence
   and intelligent car park, involves using            online learning or
   increment learning technology for            periodically re-training
   each artificial intelligence            model and adjusting parameter
PN CN121096164-A
AE TIANJIN RUIYI TECHNOLOGY CO LTD
AB 
   NOVELTY - The method involves collecting multi-source               
   heterogeneous data in real time by multiple                internet of
   things sensing devices arranged in a                car park. The data
   is cleaned, formatted and                space-time aligned to form a
   uniform data lake. An                artificial intelligent algorithm is
   used to perform                depth analysis and model training based
   on the data                lake. An intelligent decision model library
   is                constructed. An analysis result is converted into a   
   specific application service and control                instruction
   based on the intelligent decision model                library. Actual
   effect data of the application                service is taken as
   feedback. Online learning or                increment learning
   technology is used for                periodically re-training each AI
   model and                adjusting a parameter such that prediction     
   precision and decision-making ability of the model                are
   continuously improved along with accumulation                of the data
   to form a closed-loop system from data                analysis to
   application to feedback to                optimization.
   USE - Method for processing data based on artificial               
   intelligence and intelligent car park.
   ADVANTAGE - The method enables periodically performing               
   re-training and parameter optimization on each AI                model,
   so that the prediction precision and                decision ability of
   the model are continuously                improved along with the
   accumulation of the data,                thus forming a               
   data-analysis-application-feedback-optimized closed                loop
   system.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow diagram
   illustrating                a method for processing data based on
   artificial                intelligence and intelligent car park.
   (Drawing                includes non-English language text).
Z9 0
U1 0
U2 0
DA 2026-01-10
UT DIIDW:2025C1698L
ER

PT P
AU BEULAH M E
   JEHAN C
   SARAVANAN R
TI Big data-powered internet of things (IoT) platform            for
   implementing intelligent predictive maintenance and           
   optimization method (IPMOM), has edge-cloud            collaborative
   framework that enables low latency            anomaly detection and
   cloud-based model training
PN IN202541112952-A
AE VELTECH MULTI TECH RANGARAJAN SAKUNTHALA
AB 
   NOVELTY - The platform has an IoT sensing layer, an edge               
   analytics layer, a big data processing engine, a               
   predictive maintenance module, a process                optimization
   engine, and a feedback control                integrator. 2. The
   predictive maintenance module                utilizes the hybrid big
   data-driven predictive                analytics technique (HBD-PAT)
   comprising                convolutional neural network (CNN), long
   short-term                memory (LSTM) and ensemble models. The process
   optimization engine employs reinforcement learning                for
   real-time adjustment of industrial parameters.                An
   edge-cloud collaborative framework enables low                latency
   anomaly detection and cloud-based model                training. The
   sensing layer includes heterogeneous                sensors such as
   vibration, acoustic, thermal,                current, voltage, pressure,
   humidity, and optical                sensors. The IoT gateway and edge
   analytics layer                performs local data aggregation and
   filtering ,                noise removal and feature extraction.
   USE - Big data-powered internet of things (IoT)                platform
   for implementing intelligent predictive                maintenance and
   optimization method (IPMOM).
   ADVANTAGE - The platform enables real-time condition               
   monitoring, failure prediction, and intelligent                process
   optimization, develops a unified                IoT-enabled industrial
   platform for continuous,                high-frequency data acquisition,
   provides a                scalable big data architecture supporting     
   high-volume, high-velocity data, introduces                intelligent
   predictive maintenance and optimization                method (IPMOM)
   for intelligent, real-time                predictive maintenance and
   optimization, introduces                hybrid big data-driven
   predictive analytics                technique (HBD-PAT) for accurate
   failure prediction                and RUL estimation, enables autonomous
   decision-making for process adjustment and                optimization,
   reduces downtime, improves safety,                and increases
   productivity and supports hybrid                edge-cloud deployment
   for efficient                computation.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a method    
          for predictive maintenance and optimization                IPMOM.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow diagram of a method
        for predictive maintenance and optimization                (IPMOM).
Z9 0
U1 0
U2 0
DA 2025-12-29
UT DIIDW:2025B9645N
ER

PT P
AU ILLOUZ A
   SHEMESH E
   RISE L
   WEINTRAUB G
TI Method for performing integrity verification of            data obtained
   from cloud data lake, involves            calculating combined hash
   value based on partition hash            values, and calculating
   verified combined hash value            based on hash values obtained
   from metadata table            corresponding to each of partitions
PN US2025363089-A1; US12547606-B2
AE INT BUSINESS MACHINES CORP
AB 
   NOVELTY - The method involves transmitting (602) a               
   request for a data set to the cloud data lake, and               
   receiving (604) multiple file names from the cloud                data
   lake in response to the request. Multiple                partitions of
   the cloud data lake that stores a set                of files that
   satisfy the request are extracted                (606) from the file
   names. A partition hash value                for each of the partitions
   is calculated (608). A                metadata table created by a data
   owner of the set                of files is obtained (610), and the
   metadata table                is verified based on a digital signature
   of the                metadata table corresponding to the data owner.
   The                verified partition hash values are obtained (612)    
   from the metadata table. A combined hash value is               
   calculated based on the partition hash values, and                a
   verified combined hash value is calculated based                on hash
   values obtained from the metadata table                corresponding to
   each of the partitions.
   USE - Method for performing integrity verification                of
   data obtained from cloud data lake used as                primary
   sources for analytics and machine learning                models for
   data-driven decision-making.
   ADVANTAGE - The cloud data lake is a cloud-hosted               
   centralized repository that provides nearly                unlimited
   capacity and scalability for storing                large-scale
   structured and unstructured data. The                control functions
   and the forwarding functions of                network module are
   performed on physically separate                devices, such that the
   control functions manage                multiple different network
   hardware devices.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for:(1) a
   computing system having a memory having                computer readable
   instructions and multiple                processors for executing the
   computer readable                instructions;(2) a computer program
   product comprising a                computer readable storage medium
   having program                instructions.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow diagram of a method
   for performing integrity verification of data                obtained
   from cloud data lake.602Transmitting a request for a data set to        
   the cloud data lake604Receiving multiple file names from the            
   cloud data lake in response to the request606Extracting multiple
   partitions of the                cloud data lake that stores a set of
   files that                satisfy the request from the file
   names608Calculating partition hash value for each                of the
   partitions610Obtaining metadata table created by a data               
   owner of the set of files612Obtaining verified partition hash values    
              from the metadata table
Z9 0
U1 0
U2 0
DA 2025-12-16
UT DIIDW:2025B22079
ER

PT J
AU Santos-Dominguez, Martin
   Hernandez Flores, Nicasio
   Parra-Ramirez, Isaac Alberto
   Arroyo-Figueroa, Gustavo
TI AI-Big Data Analytics Platform for Energy Forecasting in Modern Power
   Systems
SO BIG DATA AND COGNITIVE COMPUTING
VL 9
IS 11
AR 272
DI 10.3390/bdcc9110272
DT Article
PD OCT 31 2025
PY 2025
AB Big Data Analytics is vital for power grids, as it empowers informed
   decision-making, anticipates potential operational and maintenance
   issues, optimizes grid management, supports renewable energy
   integration, ultimately reduces costs, improves customer service,
   monitors consumer behavior, and offers new services. This paper
   describes the AI-Big Data Analytics Architecture based on a data lake
   architecture that uses a reduced and customized set of Hadoop and Spark
   as a cost-effective, on-premises alternative for advanced data analytics
   in power systems. As a case study, a comparative analysis of electricity
   price forecasting models in the day-ahead market for nodes of the
   Mexican national electrical system using statistical, machine learning,
   and deep learning models, is presented. To build and select the best
   forecasting model, a data science and machine learning methodology is
   used. The results show that the Gradient Boosting and Support Vector
   Regression models presented the best performance, with a Mean Absolute
   Percentage Error (MAPE) between 1% and 4% for five-day-ahead electricity
   price forecasting. The implementation of the best forecasting model into
   the Big Data Analytics Platform allows the automation of the calculation
   of the local electricity price forecast per node (every 24, 72, or 120
   h) and its display in a comparative dashboard with actual and forecasted
   data for decision-making on demand. The proposed architecture is a
   valuable tool that allows the future implementation of intelligent
   energy forecasting models in power grids, such as load demand, fuel
   prices, power generation, and consumption, among others.
RI Arroyo Figueroa, Gustavo/O-4911-2016
OI Arroyo Figueroa, Gustavo/0000-0003-0764-045X
ZA 0
Z8 0
ZS 0
ZR 0
ZB 0
TC 0
Z9 0
U1 1
U2 1
EI 2504-2289
DA 2025-12-01
UT WOS:001624040600001
ER

PT J
AU Ait Errami, Soukaina
   Hajji, Hicham
   Ait El Kadi, Kenza
   Badir, Hassan
TI Leveraging Space Filling Curves for Efficient Storage and Processing of
   Spatial Data in the Data LakeHouse
SO TRANSACTIONS IN GIS
VL 29
IS 7
AR e70137
DI 10.1111/tgis.70137
DT Article
PD OCT 28 2025
PY 2025
AB The rapid growth of data-driven decision making has led to an increasing
   need for efficient and scalable data processing architectures. Data
   Lakehouse has emerged as a solution for nowadays data workload needs.
   It's a paradigm that combines the benefits of data lakes and data
   warehouses and provides a unified platform for a variety of operational
   workloads, including business intelligence, analytics, data science, and
   AI. In this paper, we present the concept of space filling curves,
   particularly the three most known curves, namely: Z-order, Hilbert, and
   Gray code curves. We investigate how they improve both data locality and
   access patterns in the context of spatial big data in Data Lakehouse.
   This improvement has a direct impact on storage optimization and query
   performance. As a practical use case, the paper covers the
   implementation of the Z-order curve, along with a discussion of the main
   algorithm's components and how it fits into the current Data Lakehouse
   system. We show that these optimizations significantly enhance the
   capabilities of Data Lakehouse architectures, ensuring better resource
   utilization across various spatial workloads.
RI Hassan, BADIR/R-6226-2019
ZA 0
Z8 0
ZS 0
ZB 0
ZR 0
TC 0
Z9 0
U1 2
U2 2
SN 1361-1682
EI 1467-9671
DA 2025-11-03
UT WOS:001602062200001
ER

PT C
AU Puertas, Enrique
   Bemposta, Sergio
   Monsalve, Borja
   Lopez, Jose M.
   Corrales-Paredes, Ana
TI Big Data System for Traffic Monitoring and Management at Roundabouts
   using Drones and Artificial Intelligence
SO IFAC PAPERSONLINE
VL 59
IS 10
BP 1534
EP 1539
DI 10.1016/j.ifacol.2025.09.258
EA SEP 2025
DT Proceedings Paper
PD 2025
PY 2025
AB This paper proposes a vehicle detection system for roundabouts based on
   images captured by a drone. This system runs on a Big Data architecture
   to ensure scalability and real-time processing. The system architecture
   is divided into two parts: a detection part, based on drones and
   computer vision, and a communication and processing part, based on a Big
   Data architecture deployed in the cloud. The system is able to
   accurately detect both roundabouts and the vehicles driving on them,
   providing valuable information on traffic conditions. The Big Data
   architecture allows real-time traffic information to be processed and
   analyzed, facilitating informed decision-making to improve traffic flow
   and safety. The evaluation of the system, carried out through
   simulations, has demonstrated its robustness and ability to handle large
   volumes of data in real time. Copyright (C) 2020 The Authors. Published
   by Elsevier B.V. This is an open access article under the CC BY-NC-ND
   license (http://creativecommons.org/licenses/by-nc-nd/4.0/)
CT 11th IFAC Conference on Manufacturing Modelling, Management and Control
   (MIM)
CY JUN 30-JUL 03, 2025
CL Trondheim, NORWAY
SP Int Federat Automat Control, TC 5 2 Management & Control Mfg & Logist;
   Int Federat Automat Control, TC 1 3 Discrete Event & Hybrid Syst; Int
   Federat Automat Control, TC 3 2 Computat Intelligence Control; Int
   Federat Automat Control, TC 5 1 Mfg Plant Control; Int Federat Automat
   Control, TC 7 4 Transportat Syst; Int Federat Automat Control, TC 9 1
   Econ, Business, & Financial Syst
RI Puertas, Enrique/L-5656-2014; Corrales Paredes, Ana/AAD-4733-2022
Z8 0
ZR 0
ZS 0
ZA 0
TC 0
ZB 0
Z9 0
U1 2
U2 2
SN 2405-8963
DA 2025-11-28
UT WOS:001583825700257
ER

PT J
AU ORDÓÑEZ PALACIOS, LUIS EDUARDO
   BUCHELI GUERRERO, VÍCTOR
   CAICEDO BRAVO, EDUARDO
TI E-solar: una herramienta para la evaluación del recurso solar basada en
   una arquitectura big data sobre un ambiente PySpark
X1 E-solar: a tool for solar resource assessment based on a Big Data
   architecture in a PySpark environment
SO Ingeniería y Desarrollo
VL 43
IS 1
BP 6
EP 23
DI 10.14482/inde.43.01.456.089
DT research-article
PD 2025-06
PY 2025
AB Abstract Over time, diverse researchers have created mathematical,
   statistical, and predictive models to evaluate solar resources. However,
   their implementation in technical tools restricts their usability for
   non-technical users. Additionally, data processing to estimate solar
   radiation often necessitates powerful hardware. This study introduces a
   Big Data based tool that employs flat files and satellite images to
   estimate solar radiation in Colombia. A model was developed using
   machine learning techniques and various programming languages. It
   operates within MapR, a distribution of the Hadoop ecosystem with an
   extensive array of Big Data capabilities and utilizes the PySpark API
   for parallel data processing within a computer cluster. The E-Solar
   tool, deployed on a web server, underwent assessment by professionals
   within the energy sector. Usability was analyzed, compliance with recent
   programming standards was confirmed, and profiles of interested users
   were identified. The solar radiation data generated by the tool are
   pivotal for solar projects. Furthermore, the tool lends support to
   researchers and organizations in decision-making for the implementation
   of photovoltaic systems, as it offers pertinent information regarding
   the behavior of solar resources in Colombia.
X4 Resumen Con el tiempo, diversos investigadores han creado modelos
   matemáticos, estadísticos y predictivos para evaluar el recurso solar.
   Sin embargo, su implementación en herramientas técnicas limita su
   utilización por usuarios no técnicos. Además, el procesamiento de datos
   para estimar la radiación solar suele requerir hardware potente. Este
   estudio presenta una herramienta basada en Big data que utiliza archivos
   planos e imágenes de satélite para estimar la radiación solar en
   Colombia. Se desarrolló un modelo con técnicas de aprendizaje automático
   y varios lenguajes de programación. Se ejecuta en MapR, una distribución
   del ecosistema Hadoop con un amplio conjunto de capacidades big data y
   emplea la API de PySpark para procesar datos en paralelo en un clúster
   de computadoras. La herramienta E-solar implementada en un servidor web
   fue evaluada por profesionales del sector energético. Se analizó la
   usabilidad, se verificó la conformidad con estándares de programación
   recientes y se identificaron perfiles de usuarios interesados. Los datos
   de radiación solar generados por la herramienta son fundamentales para
   proyectos solares. Además, la herramienta proporciona apoyo a
   investigadores y organizaciones; y facilita la toma de decisiones en la
   implementación de sistemas fotovol-taicos al ofrecer información
   relevante sobre el comportamiento del recurso solar en Colombia.
ZS 0
TC 0
ZA 0
ZB 0
ZR 0
Z8 0
Z9 0
U1 0
U2 0
SN 2145-9371
DA 2025-08-21
UT SCIELO:S0122-34612025000100006
ER

PT P
AU JYOTHY C R
   ABRAHAM S
   RAVEENDRANATH R
   GOPIKA G
   SHIRIN A
TI Artificial intelligence-driven decision support            system for
   digital transformation in traditional            manufacturing
   enterprises, has secure deployment            architecture that supports
   on-premise or cloud-based            environments
PN IN202541041001-A
AE MANGALAM ENG COLLEGE
AB 
   NOVELTY - The system has a data integration layer for               
   collecting operational and enterprise data from               
   enterprise resource planning (ERP), manufacturing               
   execution system (MES), supervisory control and                data
   acquisition (SCADA) and Internet of things                (IoT) systems.
   An artificial intelligence (AI)                engine performs
   predictive, prescriptive and                diagnostic analytics on
   manufacturing data. A                modular user interface (UI) is
   provided with                role-based dashboards and recommendation   
   visualization. A digital twin simulation module is               
   provided for scenario testing. A secure deployment               
   architecture supports on-premise or cloud-based               
   environments.
   USE - AI-driven decision support system for digital               
   transformation in traditional manufacturing                enterprises.
   ADVANTAGE - The system bridges the gap between traditional              
   manufacturing systems and advanced digital                technologies
   using an incremental and modular                approach, avoids a
   complete overhaul of existing                systems, preserves capital
   investment, provides                AI-powered insights to allow good
   decision-making                across maintenance, quality control,
   energy                management and inventory planning, scales across  
   industries and plant sizes, is cloud compatible,                tailored
   with key performance indicators (KPIs)                relevant to roles
   and deployed in low-connectivity                environments using edge
   computing strategies,                empowers mid-sized manufacturers to
   harness digital                tools for competitiveness, flexibility,
   and                sustainable growth, combines predictive analytics,   
   real-time monitoring, and data visualization to                assist
   plant managers, engineers, and executives in                process
   optimization, machine utilization, and                operational
   forecasting, contributes to the                practical adoption of
   Industry 4.0 technologies                within brownfield industrial
   ecosystems, operates                on legacy systems with limited
   connectivity,                fragmented data sources and outdated       
   decision-making processes, increases data centric               
   economy, guides traditional manufacturing                enterprises
   through the process of digital                transformation, enhances
   existing enterprise                software e.g. ERP, MES, and SCADA
   systems using AI                for analytics, forecasting and
   optimization,                aggregates structured and unstructured data
   from                multiple operational silos comprising machine logs, 
   energy meters, maintenance schedules and supply                chain
   flows, processes data to identify                inefficiencies,
   suggests process adjustments,                predicts machine failures,
   offers role specific                dashboards and actionable
   recommendations,                simulates operational scenarios for
   risk-free                experimentation, supports local deployment for 
   data-sensitive industries and secure cloud                deployment or
   on- premise hosting and uses data                encryption and access
   control mechanisms for                cybersecurity compliance, achieves
   modularity,                ensures that manufacturers adopts components 
   incrementally without overhauling their                infrastructure,
   reduces the barrier to Industry 4.0                adoption by merging
   real-time intelligence,                historical context, and strategic
   insight into a                unified decision support system, empowers 
   manufacturers to remain competitive and agile,                augments
   industrial operations without disrupting                core processes,
   collects and aggregates operational                data from IoT
   sensors, machine controllers, energy                meters, and
   maintenance logs in real time into a                central data lake,
   pre-processes data using                techniques e.g. normalization,
   anomaly detection                and imputation to ensure quality,
   identifies                operational bottlenecks, predicts component
   wear,                classifies machine efficiency zones, generates     
   prescriptive suggestions e.g. optimal machine                scheduling,
   energy saving strategies or proactive                inventory ordering,
   features interactive dashboards                for plant managers,
   supervisors and executives and                allows simulation of
   scenarios before implementing                real-world changes.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of the    
              AI-driven decision support system.
Z9 0
U1 0
U2 0
DA 2025-06-21
UT DIIDW:202557041V
ER

PT P
AU FANG Y
   LUO Y
   SHEN S
TI Multi-layer data lake based dual-model operation            and
   maintenance management method for information            technology (IT)
   informatization, involves receiving            data by Kafka operation
   and maintenance cluster, when            collecting IT operation and
   maintenance related data            from multiple data sources in real
   time
PN CN119323367-A; CN119323367-B
AE ZHUHAI ZHILIAN SIXUN TECHNOLOGY CO LTD
AB 
   NOVELTY - The method involves inputting (S4) the several               
   key performance evaluation state quantity sets into               
   operation and maintenance identification model to               
   identify potential factors that cause system                problems and
   performance bottlenecks. The                information technology (IT)
   resource configuration                is adjusted (S5) through operation
   and maintenance                adjustment model based on potential
   factors to                optimize system performance and improve
   resource                utilization. The identification results and     
   adjustment results are displayed (S6) by                associating
   operation and maintenance                identification model with
   operation and maintenance                adjustment model to support
   operation and                maintenance decision-making. The data is
   received                by Kafka(RTM: network communication platform)   
   operation and maintenance cluster, when collecting                IT
   operation and maintenance related data from                multiple data
   sources, and data receiving groups                are divided and nodes
   are configured to complete                Hadoop distributed file system
   (HDFS)                storage.
   USE - Multi-layer data lake based dual-model                operation
   and maintenance management method for                information
   technology (IT) informatization.
   ADVANTAGE - The method automatically adjusts IT resource               
   configuration based on potential factors through               
   operation and maintenance adjustment model to                optimize
   system performance and improves resource                utilization;
   dynamically display identification                results and adjustment
   results. The method                significantly improves operation and
   maintenance                efficiency and system stability.
   DETAILED DESCRIPTION - The IT operation and maintenance related data    
   is collected (S1) from multiple data sources in                real
   time, and a multi-layer operation and                maintenance data
   network is formed after                correlation processing. The
   multi-layer operation                and maintenance data network is
   integrated (S2)                into the data lake with layered
   technology to form                a multi-layer operation and
   maintenance data lake.                The multi-layer interface of the
   multi-layer                operation and maintenance data lake is used
   to                quickly access and retrieve large-scale operation     
   and maintenance data. The big data analysis is                performed
   (S3) on the retrieved large-scale                operation and
   maintenance data, accurate filtering                of data is
   completed, key features and deep                integration are
   extracted, and several key                performance evaluation state
   quantity sets are                obtained.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow chart of
   multi-layer                data lake based dual-model operation and     
   maintenance management method for IT                informatization.
   (Drawing includes non-English                language text)S1Step for
   collecting the IT operation and                maintenance related data
   from multiple data sources                in real time, and forming a
   multi-layer operation                and maintenance data network after
   correlation                processingS2Step for integrating the
   multi-layer                operation and maintenance data network into
   the                data lake with layered technology to form a          
   multi-layer operation and maintenance data lake,                and
   using the multi-layer interface of the                multi-layer
   operation and maintenance data lake to                quickly access and
   retrieve large-scale operation                and maintenance dataS3Step
   for performing the big data analysis                on the retrieved
   large-scale operation and                maintenance data, completing
   accurate filtering of                data, extracting key features and
   deep integration,                and obtaining several key performance
   evaluation                state quantity setsS4Step for inputting the
   several key                performance evaluation state quantity sets
   into the                operation and maintenance identification model
   to                identify potential factors that may cause system      
   problems and performance bottlenecksS5Step for adjusting the IT resource
   configuration automatically through the operation                and
   maintenance adjustment model based on the                potential
   factors to optimize system performance                and improve
   resource utilizationS6Step for displaying the identification            
   results and adjustment results dynamically by                associating
   the operation and maintenance                identification model with
   the operation and                maintenance adjustment model to support
   operation                and maintenance decision-making
Z9 0
U1 0
U2 0
DA 2025-02-24
UT DIIDW:202512162L
ER

PT P
AU NANDHAKUMAR N
   GANDI S
   ANNIE T
   MOHAN M
   MOHANAPRAKASH T A
   MANIRAJ S P
TI System for storing and analyzing large data in            cloud-based
   data lake as various formats e.g.            structured data, has data
   ingestion module for            ingesting data from multiple sources
   into data lake in            real-time, and analytics module for
   analyzing processed            data using advanced analytics tools
PN IN202441102919-A
AE NANDHAKUMAR N; GANDI S; ANNIE T; MOHAN M; MOHANAPRAKASH T A; MANIRAJ S P
AB 
   NOVELTY - The system has a cloud-based storage module               
   provided for storing large volumes of unprocessed                data in
   various formats such as structured data                i.e. relational
   databases, semi-structured data                i.e. XML files, and
   unstructured data i.e. audio,                video, images, and text. A
   data ingestion module                ingests data from multiple sources
   into a data lake                in real-time. An analytics module
   analyzes the                processed data using advanced analytics
   tools to                extract actionable insights from the data. A    
   visualization module generates visual reports from                the
   analyzed data for decision-making purposes. A                main body
   enables large-scale data analytics using                a cloud-based
   data lake without requirement for                on-premises
   infrastructure.
   USE - System for storing and analyzing large data in                a
   cloud-based data lake as various formats such as               
   structured data, semi-structured data and                unstructured
   data.
   ADVANTAGE - The system utilizes the cloud-based solutions               
   of organizations to extract actionable insights,                provide
   informed decisions, and gain competitive                advantages
   across industries by enabling efficient                large data
   analytics, ensures better data handling                within the data
   lake aligns with legal and                industry-specific
   requirements, enhances                scalability, flexibility, and
   processing power                required to handle the complex data
   environments,                and reduces the latency by enabling
   real-time                decision-making.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for a method    
   for performing large data analytics using a                cloud-based
   data lake.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of a
   system                for storing and analyzing large data in a         
         cloud-based data lake.
Z9 0
U1 0
U2 0
DA 2025-03-20
UT DIIDW:2025056345
ER

PT C
AU Azeroual, Otmane
   Fabre, Renaud
   Stoerl, Uta
BE Coenen, F
   Fred, A
   Aveiro, D
   Dietz, J
   Poggi, A
   Gruenwald, L
   Masciari, E
   Bernardino, J
TI Revolutionary Synergy: The Fusion of Data Mesh and Data Fabric for
   Strategy Analytics in GRAPHYP Knowledge Graph
SO KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT,
   IC3K 2023
SE Communications in Computer and Information Science
VL 2454
BP 277
EP 295
DI 10.1007/978-3-031-87569-4_13
DT Proceedings Paper
PD 2025
PY 2025
AB In today's world, big data has rapidly evolved, presenting organizations
   with a multitude of challenges in managing, integrating, and leveraging
   their most valuable resource. As data volumes and complexity continue to
   grow, the question arises: How can organizations effectively and
   efficiently manage their data to extract valuable insights? Two
   approaches, data mesh and data fabric, have emerged with the potential
   to revolutionize the current state of data architecture and help
   organizations redefine their data strategy. Although data mesh and data
   fabric are often viewed as contrasting approaches, they ultimately share
   the same goal of improving data management. While data mesh emphasizes
   decentralized responsibility and collaboration, data fabric focuses on
   unified infrastructure and data integration. Our paper aims to
   demonstrate how these two concepts challenge traditional paradigms and
   enable organizations to optimize their data utilization. By integrating
   their respective capabilities through "fusion analytics" GRAPHYP KG
   introduces, for the first time, a geometric interactive mapping of
   disputed knowledge categorizations processed from search logs. This
   novel framework gives rise to innovative "challenging options analytics"
   services, embracing web augmentation on mobile devices and facilitating
   innovative strategic management on an unprecedented scale.
CT 15th International Joint Conference on Knowledge Discovery, Knowledge
   Engineering and Knowledge Management-IC3K
CY NOV 13-15, 2023
CL Rome, ITALY
RI Azeroual, Dr. Otmane/B-7260-2018; Fabre, Renaud/
OI Fabre, Renaud/0000-0003-4170-324X
TC 0
ZR 0
ZB 0
ZS 0
Z8 0
ZA 0
Z9 0
U1 0
U2 0
SN 1865-0929
EI 1865-0937
BN 978-3-031-87568-7; 978-3-031-87569-4
DA 2025-09-25
UT WOS:001553035000013
ER

PT C
AU El Falah, Zineb
   Abouchabaka, Jaafar
   Rafalia, Najat
BE Koubaa, A
   Mnaouer, AB
   Boulila, W
   Raghay, S
TI An Intelligent Big Data Analysis Approach for Real-Time Data Processing:
   A Case Study on META Stock Price Prediction Using LSTM Model
SO INTERNATIONAL CONFERENCE ON SMART SYSTEMS AND EMERGING TECHNOLOGIES,
   2024
SE Lecture Notes in Networks and Systems
VL 1401
BP 279
EP 291
DI 10.1007/978-3-031-91235-1_25
DT Proceedings Paper
PD 2025
PY 2025
AB Technological progress has made Big Data a major trend, posing
   significant challenges in managing vast datasets through digital
   technologies. These challenges include integrating diverse data,
   ensuring timely processing, and providing effective analysis and
   visualization. Big Data analytics uses AI, deep learning, and machine
   learning to uncover patterns and trends, improving decision-making and
   predictions. Real-time data processing faces additional difficulties
   related to handling high data velocity and volume, requiring robust and
   scalable infrastructure. This paper proposes an intelligent Big Data
   architecture for real-time data processing using Apache Kafka, the
   Elastic Stack, and Apache Spark. The approach is demonstrated through a
   case study predicting META stock prices using a Long Short-Term Memory
   (LSTM) model. By integrating deep learning, the architecture effectively
   addresses Big Data challenges, improving decision-making efficiency. The
   analysis uses stock data from Yahoo Finance, and the model's performance
   was assessed using R-squared (R-2) and Mean Absolute Error (MAE). The
   LSTM model achieved an R-2 score of 0.99 and an MAE of 0.04, showing
   significant improvement over traditional models, particularly in
   handling volatile stock data.
CT 3rd International Conference on Smart Systems and Emerging
   Technologies-SMARTTECH-Annual
CY NOV 19-21, 2024
CL Cadi Ayyad University of Marrakech, Marrakesh, MOROCCO
HO Cadi Ayyad University of Marrakech
SP Institute of Electrical and Electronics Engineers Inc; Prince Sultan
   University; University of Prince Mugrin; Ibn Tofail University of
   Kenitra
RI ABOUCHABAKA, Jaafar/JTV-1015-2023; EL FALAH, Zineb/KYP-0832-2024
TC 0
ZB 0
ZR 0
ZA 0
Z8 0
ZS 0
Z9 0
U1 0
U2 0
SN 2367-3370
EI 2367-3389
BN 978-3-031-91234-4; 978-3-031-91235-1
DA 2025-12-05
UT WOS:001591611300025
ER

PT J
AU Gartner, Christopher M.
   Sakhare, Rahul Suryakant
   Desai, Jairaj Chetas
   Sturdevant, James
   Bullock, Darcy M.
TI A Scalable Data Model for Signalized Intersection Performance Measures
SO IEEE ACCESS
VL 13
BP 197851
EP 197863
DI 10.1109/ACCESS.2025.3635007
DT Article
PD 2025
PY 2025
AB Traditionally, traffic signal management has been largely tactical and
   operated from the "bottom-up," focusing on individual intersection
   performances influenced by public suggestions, field observation, and in
   some cases high-resolution controller data. Connected vehicle trajectory
   data now enables a scalable, complementary "top-down" approach for
   system-wide performance analysis, even for locations with no detection
   or communication. This paper proposes a data architecture for derived
   performance measures that can be used for both strategic (top-down) and
   tactical (bottom-up) management of traffic signals. To leverage a
   "top-down" approach, large amounts of data must be processed into
   smaller datasets. For efficiency and interoperability between
   performance measures and the tools used to derive the same, a scalable
   data management architecture is essential. This paper discusses and
   demonstrates a framework developed for the Indiana Department of
   Transportation, which contains the derived information from over 177
   billion records per year for the state, covering more than 2,500
   signalized intersections in just 80,000 or so rows of derived
   performance measures. This framework collects data using a combination
   of a fixed time period, date, movement, approach, and intersection
   identifier. The structured model of derived performance measures
   supports both tactical applications, such as green-time allocation, and
   top-down, strategic management applications such as identifying
   capacity-constrained signals that are candidates for capital
   improvements. This framework is applicable to other tools used to derive
   performance measures, such as high-resolution or LiDAR datasets.
RI Gartner, Christopher/LGY-8902-2024; Bullock, Darcy/; Sakhare, Rahul Suryakant/IVV-7297-2023
OI Gartner, Christopher/0009-0008-8448-2356; Bullock,
   Darcy/0000-0002-7365-1918; Sakhare, Rahul Suryakant/0000-0001-7843-5707
ZA 0
Z8 0
TC 0
ZB 0
ZR 0
ZS 0
Z9 0
U1 0
U2 0
SN 2169-3536
DA 2025-12-10
UT WOS:001626884300009
ER

PT B
AU Hermanus, Danny
Z2  
TI Strategies for Migrating Data Warehouses to Data Lakehouses Using Public
   Cloud Computing
DT Dissertation/Thesis
PD Jan 01 2025
PY 2025
ZA 0
ZR 0
Z8 0
ZS 0
ZB 0
TC 0
Z9 0
U1 1
U2 1
BN 9798315718598
UT PQDT:123519540
ER

PT J
AU Kretzer, Arthur Raulino
   Barreto Vavassori Benitti, Fabiane
   Siqueira, Frank
TI Challenges and Opportunities in Big Data Analytics for Industry 4.0: A
   Systematic Evaluation of Current Architectures
SO IEEE ACCESS
VL 13
BP 183419
EP 183447
DI 10.1109/ACCESS.2025.3624558
DT Article
PD 2025
PY 2025
AB The current efforts to integrate Big Data Analytics (BDA) into Industry
   4.0 manufacturing systems, despite their usefulness for enhancing
   data-driven decision-making, are constrained by the lack of
   architectural standards for data management. This systematic mapping
   study analyzes many BDA architectures proposed in the literature,
   revealing a fragmented landscape in which the proposed architectures are
   largely conceptual with limited industrial validation. Our analysis
   identifies dominant technological patterns, such as Apache Kafka for
   ingestion, Spark for processing, and Hadoop and Hive for storage, with
   the majority of implementations favoring open-source solutions. Despite
   their theoretical importance, real-time analytics capabilities remain
   underutilized in practice. This study synthesizes a unified conceptual
   reference architecture with eight fundamental layers to provide a
   framework for comparative analysis. We document an imbalance in layer
   development: storage and processing receive comprehensive attention
   while querying, infrastructure management, and monitoring layers remain
   underdeveloped. Implementation approaches show distinct patterns in
   deployment strategies and data handling, with structured and
   semi-structured data well supported, whereas unstructured data
   integration presents ongoing challenges. Future research should focus on
   developing standardized modular frameworks, benchmarking methodologies,
   and integrating modern data lakehouse architectures to bridge the gap
   between theoretical proposals and production-ready systems.
RI Siqueira, Frank/ABB-8351-2021; Raulino Kretzer, Arthur/; Benitti, Fabiane/
OI Raulino Kretzer, Arthur/0000-0003-1656-9464; Benitti,
   Fabiane/0000-0003-2747-9931
ZB 0
Z8 0
ZA 0
ZR 0
TC 0
ZS 0
Z9 0
U1 4
U2 4
SN 2169-3536
DA 2025-11-12
UT WOS:001606717700016
ER

PT C
AU Rossi, A.
   Santos, K.
   Treinta, F.
   Pontes, J.
BE Zimmermann, R
   Rodrigues, JC
   Simoes, A
   Dalmarco, G
TI Proposal for a Decision-Making Dashboard Enhanced by Big Data: An
   Application in the Portuguese Furniture Industry
SO HUMAN-CENTRED TECHNOLOGY MANAGEMENT FOR A SUSTAINABLE FUTURE, VOL 2,
   IAMOT
SE Springer Proceedings in Business and Economics
BP 407
EP 416
DI 10.1007/978-3-031-72494-7_40
DT Proceedings Paper
PD 2025
PY 2025
AB Big data analysis in strategic management significantly aids
   decision-making processes, enhancing their effectiveness. Investigating
   key themes in this area allows for trend identification, process
   optimization, and proactive issue prediction, thereby boosting
   competitiveness. This study aims to develop a visual tool for
   decision-making support regarding sales behaviour in the operations
   department of a service industry, utilizing big data analysis within
   Industry 4.0. The research methodology used was the Design Science,
   identifying 5 main phases to accomplish the objective. It was applied
   the IDC model to centralizes the management of data and establish
   decision-making requirements. Subsequently, the DMN method for
   describing and modeling repeatable decisions within organizations and
   data architecture were applied, facilitating the comprehension of the
   significance and scope of the studied topic, along with its main themes.
   Utilizing Power Query, data analysis and processing were automated, and
   M language codes were programmed. It was concluded that data quality's
   relevance significantly impacts decision-making within strategic
   management, thus enabling the development of digital transformation
   within the organization.
CT 33rd International Association for the Management of Technology
   Conference
CY JUL 08-11, 2024
CL Porto, PORTUGAL
ZB 0
Z8 0
ZS 0
ZA 0
ZR 0
TC 0
Z9 0
U1 0
U2 1
SN 2198-7246
EI 2198-7254
BN 978-3-031-72496-1; 978-3-031-72494-7; 978-3-031-72493-0
DA 2025-04-25
UT WOS:001454289900040
ER

PT J
AU Silva, Danilo
   Moir, Monika
   Dunaiski, Marcel
   Blanco, Natalia
   Murtala-Ibrahim, Fati
   Baxter, Cheryl
   de Oliveira, Tulio
   Xavier, Joicymara S.
CA INFORM Africa Res Study Grp
TI Review of open-source software for developing heterogeneous data
   management systems for bioinformatics applications
SO BIOINFORMATICS ADVANCES
VL 5
IS 1
AR vbaf168
DI 10.1093/bioadv/vbaf168
DT Review
PD 2025
PY 2025
AB In a world where data drive effective decision-making, bioinformatics
   and health science researchers often encounter difficulties managing
   data efficiently. In these fields, data are typically diverse in format
   and subject. Consequently, challenges in storing, tracking, and
   responsibly sharing valuable data have become increasingly evident over
   the past decades. To address the complexities, some approaches have
   leveraged standard strategies, such as using non-relational databases
   and data warehouses. However, these approaches often fall short in
   providing the flexibility and scalability required for complex projects.
   While the data lake paradigm has emerged to offer flexibility and handle
   large volumes of diverse data, it lacks robust data governance and
   organization. The data lakehouse is a new paradigm that combines the
   flexibility of a data lake with the governance of a data warehouse,
   offering a promising solution for managing heterogeneous data in
   bioinformatics. However, the lakehouse model remains unexplored in
   bioinformatics, with limited discussion in the current literature. In
   this study, we review strategies and tools for developing a data
   lakehouse infrastructure tailored to bioinformatics research. We
   summarize key concepts and assess available open-source and commercial
   solutions for managing data in bioinformatics.Availability and
   implementation Not applicable.
RI de Castro Silva, Danilo/; Santos Xavier, Joicymara/; Moir, Monika/AAU-6520-2021; Dunaiski, Marcel/AAC-9387-2022
OI de Castro Silva, Danilo/0000-0001-5740-3968; Santos Xavier,
   Joicymara/0000-0002-4649-6270; Moir, Monika/0000-0003-1095-1910; 
ZS 0
ZR 0
TC 0
Z8 0
ZB 0
ZA 0
Z9 0
U1 3
U2 3
EI 2635-0041
DA 2025-08-12
UT WOS:001543196800001
PM 40761326
ER

PT P
AU CHENG Y
   SUN Z
   XU K
TI Data governance task running method based on big            data used in
   data processing, involves processing and            obtaining governance
   judgment results of engineering            data based on governance
   metric values of engineering            data and data governance
   comparison information of            affiliated engineering projects
PN CN117971818-A
AE CHINA NAT INST STANDARDIZATION
AB 
   NOVELTY - The method involves receiving (S1) the               
   engineering data by data governance supervision                center.
   The engineering data is converted into a                data set in
   javascript object notation (JSON)                format. The data lake
   receives (S2) the engineering                transformation data set and
   analyzes and processes                to obtain the governance
   measurement values of the                engineering data. Information
   of subordinate                engineering projects are extracted (S3)
   from the                engineering transformation data set, and        
   synchronously matched to obtain data management                control
   information of the subordinate engineering                projects. The
   governance judgment results of the                engineering data is
   processed and obtained (S4)                based on the governance
   metric values of the                engineering data and the data
   governance comparison                information of the affiliated
   engineering projects,                and the response processing
   interval of the                engineering data is comprehensively
   automatically                adjust and controlled.
   USE - Data governance task running method based on                big
   data used in field of data processing.
   ADVANTAGE - The engineering data is efficiently manage and              
   processed. The accuracy and reliability of data is               
   ensured, thus improving the data utilization value                and
   decision-making effect by measuring data                quality. An
   efficient data governance mechanism is                established and
   the timeliness and availability of                data governance is
   ensured by adjusting and                controlling the time of
   engineering data                processing.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flow diagram
   illustrating                the data governance task running method
   based on                big data. (Drawing includes non-English language
   text)S1Step for receiving the engineering data by                data
   governance supervision centerS2Step for receiving the engineering       
   transformation data set by data lakeS3Step for extracting information of
   subordinate engineering projects from the                engineering
   transformation data setS4Step for processing and obtaining              
   governance judgment results of the engineering data                based
   on the governance metric values of the                engineering data
   and the data governance comparison                information of the
   affiliated engineering                projects
Z9 0
U1 0
U2 0
DA 2025-03-20
UT DIIDW:202448524T
ER

PT B
AU Basso, Denzel
Z2  
TI Enhancing Data Extraction and Transformation for Business Intelligence:
   Integrating Database Sources with Cloud Storage for Streamlined
   Reporting
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
ZA 0
Z8 0
ZB 0
TC 0
ZR 0
ZS 0
Z9 0
U1 1
U2 1
BN 9798346835899
UT PQDT:120586072
ER

PT C
AU Benhissen, Redha
   Bentayeb, Fadila
   Boussaid, Omar
BE Gusikhin, O
   Hammoudi, S
   Cuzzocrea, A
TI Temporal and Flexible Data Warehouses
SO DATA MANAGEMENT TECHNOLOGIES AND APPLICATIONS, DATA 2023
SE Communications in Computer and Information Science
VL 2105
BP 25
EP 49
DI 10.1007/978-3-031-68919-2_2
DT Proceedings Paper
PD 2024
PY 2024
AB The present trend among companies involves a significant revamp of their
   data architecture, aiming to streamline data processes and phase out
   outdated systems. The advent of big data has profoundly influenced
   businesses, empowering them to adeptly manage and analyze vast datasets.
   In the realm of business intelligence, particularly in decision-making,
   data warehouses play a crucial role, leveraging OLAP technology for the
   efficient analysis of structured data. Constructed by amalgamating data
   from diverse sources, a data warehouse faces the challenge of
   accommodating big data-comprising unstructured, semi-structured, or
   structured data from myriad sources-where alterations in content and
   structure are frequent. To address this, our paper introduces a temporal
   multidimensional model utilizing a graph formalism for multi-version
   data warehouses, adept at assimilating changes from data sources. This
   approach relies on multi-version evolution for schema modifications and
   employs bi-temporal labeling for entities and their relationships to
   capture data evolution. Our proposal enhances data warehouse evolution
   flexibility, broadening analysis possibilities within the decision
   support system, and enabling adaptable temporal queries to yield
   consistent results. Building upon our prior work [6], where we presented
   the GAMM model emphasizing evolutionary data treatment, including
   dimensional changes, this study expands on the temporal labeling
   principle in our approach. It delves into various functions governing
   the evolution of temporal data, offering illustrative examples. We
   validate our approach through a case study demonstrating temporal
   queries and conduct runtime performance tests on graph data warehouses.
CT 12th International Conference on Data Management Technologies and
   Applications (DATA)
CY JUL 11-13, 2023
CL Rome, ITALY
RI BOUSSAID, OMAR/AAF-2540-2020; benhissen, redha/
OI BOUSSAID, OMAR/0000-0001-6388-3152; benhissen, redha/0000-0002-6974-0838
TC 0
ZR 0
ZS 0
ZB 0
Z8 0
ZA 0
Z9 0
U1 0
U2 2
SN 1865-0929
EI 1865-0937
BN 978-3-031-68918-5; 978-3-031-68919-2
DA 2024-11-23
UT WOS:001331179000002
ER

PT B
AU Boga, Cristina Isabel Palma Caeiro
Z2  
TI Sistema Para Auxiliar na Tomada de Decisão de Arquitetura Big DataSystem
   to assist in the decision making of Big Data architecture
DT Dissertation/Thesis
PD Jan 01 2024
PY 2024
Z8 0
ZS 0
ZR 0
TC 0
ZB 0
ZA 0
Z9 0
U1 0
U2 0
BN 9798311963046
UT PQDT:123794626
ER

PT C
AU Harby, Ahmed A.
   ElKhodary, Eyad
   Almeida, Ronan
   Sharma, Drishti
   Zulkernine, Farhana
   Alaca, Furkan
   Elganar, Khalid
   Almarzouqi, Amina
   Al-Yateem, Nabeel
   Rahman, Syed Aziz
BE Shahriar, H
   Ohsaki, H
   Sharmin, M
   Towey, D
   Majumder, AKMJA
   Hori, Y
   Yang, JJ
   Takemoto, M
   Sakib, N
   Banno, R
   Ahamed, SI
TI Revolutionizing Healthcare Management: Architecture of a Web-based
   Medical Triage Service
SO 2024 IEEE 48TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE,
   COMPSAC 2024
SE IEEE Annual International Computer Software and Applications Conference
BP 1887
EP 1894
DI 10.1109/COMPSAC61105.2024.00299
DT Proceedings Paper
PD 2024
PY 2024
AB During the COVID-19 pandemic, the traditional emergency healthcare
   systems faced unprecedented strain due to the sharp rise in demands for
   urgent care, scarcity of resources, and increased risks of people
   getting infected while waiting at the emergency care facility. We
   present Triage-Bot, an online medical triage provisioning service, that
   can revolutionize emergency care by decreasing the load on emergency
   departments (ED), reducing healthcare expenses, and improving the
   quality of care. Empowered by artificial intelligence and natural
   language processing, the Triage-Bot service assesses and prioritizes
   patients' needs based on symptoms, medical history, and perceived
   conditions from multimodal video, audio, and text data captured during
   patients' interactions. The captured summarized information with a
   severity ranking is sent to a human expert to suggest the next action on
   the user's part. The diverse data types used by the Triage-Bot in
   communication, authentication, data collection, storage, and analytics
   requires a robust and scalable system architecture for online service
   provisioning. In this paper, we specifically focus on the system design
   and architecture of the Triage-Bot for emergency healthcare settings.
   With integrated electronic medical records (EMR) and online platforms,
   the bot fosters collaboration among healthcare professionals and enables
   swift and informed decision-making even in the face of crises. By
   partially automating and offering a hybrid triage process, the
   Triage-Bot improves resource allocation, reduces healthcare management
   costs for emergency care, minimizes patient waiting times, and improves
   wellbeing. To address the complexities and demands of healthcare data
   management, our proposed system incorporates MongoDB database for
   flexibility, scalability, and versatility in supporting different types
   of data. Additionally, we implement a data linking and analytics
   pipeline utilizing a data Lakehouse system to effectively ingest,
   manage, process, and generate knowledge from heterogeneous data sources.
CT 48th Annual IEEE International Computers, Software, and Applications
   Conference (COMPSAC) - Digital Development for a Better Future
CY JUL 02-04, 2023
CL Osaka Univ, Nakanoshima Ctr, Osaka, JAPAN
HO Osaka Univ, Nakanoshima Ctr
SP IEEE; IEEE Comp Soc
RI Al-Yateem, Nabeel/GQZ-2152-2022; Rahman, Syed/
OI Rahman, Syed/0000-0002-2583-6037
ZR 0
TC 0
ZS 0
Z8 0
ZB 0
ZA 0
Z9 0
U1 0
U2 1
SN 2836-3787
BN 979-8-3503-7697-5; 979-8-3503-7696-8
DA 2024-12-03
UT WOS:001308581200291
ER

PT C
AU Sun, Susan
   Ye, Jeff
   Schwarthoff, Hubert
   Rosin, Jon
   Vakkalagadda, Varalakshmi
   Chang, Jimmy
   Ubbara, Sesidhar Reddy
   Chinthakindi, Anil
GP IEEE
TI Cloud Big Data Lake for Advanced Analytics in Semiconductor
   Manufacturing
SO 2024 35TH ANNUAL SEMI ADVANCED SEMICONDUCTOR MANUFACTURING CONFERENCE,
   ASMC
SE Advanced Semiconductor Manufacturing Conference and Workshop-Proceedings
DI 10.1109/ASMC61125.2024.10545365
DT Proceedings Paper
PD 2024
PY 2024
AB Data driven business intelligence is changing how semiconductor
   manufacturing thrives in the long term. A cloud big data lake is
   designed and implemented based on state-of-the-art cloud architecture
   providing complete services for data ingestion, storage, processing,
   advanced analytics, and machine learning with a high level of security.
   Efficient and effective use of this big data lake and data science
   enables problem solving and decision making to improve productivity and
   performance.
CT 35th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)
CY MAY 13-16, 2024
CL Albany, NY
SP IEEE
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
TC 0
Z9 0
U1 1
U2 4
SN 1078-8743
BN 979-8-3503-8456-7; 979-8-3503-8455-0
DA 2024-07-27
UT WOS:001245033700005
ER

PT C
AU Ahmad, Bashar
BE Pesquita, C
   Skaf-Molli, H
   Efthymiou, V
   Kirrane, S
   Ngonga, A
   Collarana, D
   Cerqueira, R
   Alam, M
   Trojahn, C
   Hertling, S
TI A Distributed and Parallel Processing Framework for Knowledge Graph OLAP
SO SEMANTIC WEB: ESWC 2023 SATELLITE EVENTS
SE Lecture Notes in Computer Science
VL 13998
BP 288
EP 297
DI 10.1007/978-3-031-43458-7_47
DT Proceedings Paper
PD 2023
PY 2023
AB Business intelligence and analytics refers to the ensemble of tools and
   techniques that allow organizations to obtain insights from big data for
   better decision making. Knowledge graphs are increasingly being
   established as a central data hub and prime source for BI and analytics.
   In the context of BI and analytics, KGs may be used for various
   analytical tasks; the integration of data and metadata in a KG
   potentially facilitates interpretation of analysis results. Knowledge
   Graph OLAP (KG-OLAP) adapts the concept of online analytical processing
   (OLAP) from multidimensional data analysis for the processing of KGs for
   analytical purposes. The current KG-OLAP implementation is a monolithic
   system, which greatly inhibits scalability. We propose a research plan
   for the development of a framework for distributed and parallel data
   processing for KG-OLAP over big data. In particular, we propose a
   framework for KG-OLAP over big data based on the data lakehouse
   architecture, which leverages existing frameworks for parallel and
   distributed data processing. We are currently at an early stage of our
   research.
CT 20th European Semantic Web Conference-ESWC-Annual
CY MAY 28-JUN 01, 2023
CL Khersonisos, GREECE
SP Springer Nature; IOS Press
Z8 0
ZS 0
ZB 0
ZA 0
ZR 0
TC 0
Z9 0
U1 1
U2 1
SN 0302-9743
EI 1611-3349
BN 978-3-031-43457-0; 978-3-031-43458-7
DA 2023-01-01
UT WOS:001560618200047
ER

PT C
AU Bianchini, Devis
   Garda, Massimiliano
BE Zhang, F
   Wang, H
   Barhamgi, M
   Chen, L
   Zhou, R
TI A Methodological Approach for Data-Intensive Web Application Design on
   Top of Data Lakes
SO WEB INFORMATION SYSTEMS ENGINEERING - WISE 2023
SE Lecture Notes in Computer Science
VL 14306
BP 349
EP 359
DI 10.1007/978-981-99-7254-8_27
DT Proceedings Paper
PD 2023
PY 2023
AB Data exploration and decision making may benefit from the availability
   of data-intensive web applications, that enable domain experts to
   navigate across massive, dynamic and heterogeneous data sources, stored
   in the so-called Data Lakes. However, traditional design strategies for
   this kind of applications require in the background well-defined and
   cleaned data structures. Conceptual modelling may be fruitfully employed
   to provide web developers with a comprehensive vision over Data Lake
   sources, on which web applications are designed. Nevertheless, the
   cumbersome nature of Data Lakes turns the conceptual model into a
   dynamic entity, which must be properly managed. In this paper, we
   propose a methodological approach to design data-intensive web
   applications on top of a Data Lake. A conceptual data model, weaved over
   Data Lake sources, is leveraged to identify the relevant information to
   be included in the web application. The methodology makes the model
   evolve both with new data sources content emerging from the Data Lake,
   through a zone-based operations pipeline that prepares a curated version
   of the raw data (bottom-up), and with additional domain knowledge
   provided by web developers derived from the data-intensive web
   application design (top-down). The approach, independent from any
   specific implementation technology, is declined in the context of a real
   case study regarding an ongoing research project in the cultural
   heritage domain.
CT 24th International Conference on Web Information Systems
   Engineering-WISE-Annual
CY OCT 25-27, 2023
CL Melbourne, AUSTRALIA
OI Garda, Massimiliano/0009-0006-5823-6595
ZS 0
ZB 0
ZR 0
ZA 0
TC 0
Z8 0
Z9 0
U1 0
U2 0
SN 0302-9743
EI 1611-3349
BN 978-981-99-7253-1; 978-981-99-7254-8
DA 2023-01-01
UT WOS:001547081100026
ER

PT C
AU Krtalic, A.
   Divjak, A. Kuvezdic
   Miletic, A.
BE El-Sheimy, N
   Abdelbary, AA
   El-Bendary, N
   Mohasseb, Y
TI TOWARD DATA LAKES FOR CRISIS MANAGEMENT
SO GEOSPATIAL WEEK 2023, VOL. 48-1
SE International Archives of the Photogrammetry, Remote Sensing and Spatial
   Information Sciences
BP 539
EP 546
DI 10.5194/isprs-archives-XLVIII-1-W2-2023-539-2023
DT Proceedings Paper
PD 2023
PY 2023
AB The content of the data lake comes (is filled) from different sources,
   and different users (experts in various fields) of the same data can
   download and analyse the same data for their (different) needs and
   analysis. Big Data about the human environment and the effect of natural
   and human-caused disasters (in this case: heat islands, earthquakes and
   lava flows, and landmine contamination) on that environment have been
   available to many people for years and are the subject of discussions,
   but there are still numerous research challenges in the form of
   structuring and storing data and analysis results. This implies certain
   requirements for efficient integration, access and querying of the
   various data in the data repository for the described purpose. Data
   lakes and data warehouses are offered as solutions to this problem.
   Well-designed data lakes can be a basic building block for different
   solutions in the analysis of the effects of disasters on the
   environment, and high-quality data warehouses for modelling future
   potential disasters in the same area. This paper presents certain
   personal observations and certain proposals for the creation of
   efficient data lakes and data warehouses (based on many years of work on
   problems in areas: humanitarian demining, heat islands and volcanic
   activity) for the needs of decision-making in crisis based on examples
   from practice. The goal is to influence the development of a unique
   framework for the creation and maintenance of a data lake, in terms of
   its better utilization so that it does not become a data swamp.
CT 5th International-Society-for-Photogrammetry-and-Remote-Sensing (ISPRS)
   Geospatial Week (GSW)
CY SEP 02-07, 2023
CL Cairo, EGYPT
SP Int Soc Photogrammetry & Remote Sensing
RI Kuveždić Divjak, Ana/AAB-8293-2019; Krtalić, Andrija/AAG-4439-2019; Miletić, Anea/KXR-9745-2024
OI Kuveždić Divjak, Ana/0000-0003-1059-8395; Miletić,
   Anea/0000-0002-3324-201X
TC 0
ZR 0
ZA 0
Z8 0
ZB 0
ZS 0
Z9 0
U1 0
U2 0
SN 1682-1750
EI 2194-9034
BN *****************
DA 2024-04-18
UT WOS:001185682000074
ER

PT B
AU Machado, Ricardo Jesus
Z2  
TI The Growing Importance of Data Semantics in Large Organizations: A Case
   Study of Nokia Network and Solutions
DT Dissertation/Thesis
PD Jan 01 2023
PY 2023
Z8 0
ZR 0
ZB 0
ZS 0
ZA 0
TC 0
Z9 0
U1 0
U2 0
BN 9798383899830
UT PQDT:118785324
ER

PT B
AU Severiano, Renato Alexandre Pires
   Neto, Miguel Castro
   Jardim, Bruno
Z2  
TI [not available]
DT Dissertation/Thesis
PD Oct 13 2024
PY 2024
ZB 0
ZA 0
TC 0
ZS 0
ZR 0
Z8 0
Z9 0
U1 0
U2 2
BN 9798384207801
UT PQDT:100694316
ER

PT P
AU LI Y
   ZHANG J
   MENG F
   LIU Y
TI Parking operation management system with layered            cloud
   architecture for real-time parking state of car            park, has
   parking operation management system that is            configured to
   monitor real-time parking status and            income of multiple
   parking lots, and parking space is            predicted, through big
   data
PN CN115472034-A
AE CHINA COMMUNICATIONS INFORMATION TECHNOL
AB 
   NOVELTY - The system has a parking data communication               
   module that is adapted to the protocol of                Modbus(RTM:
   Data communications protocol), socket,                hypertext transfer
   protocol (HTTP), serial port, MQ                telemetry transport
   (MQTT) parking equipment. The                cloud architecture of the
   parking operation                management system is used for
   transmission                integration. The management of different
   databases                stored in the data lake of the parking
   operation                management system, according to the type of
   data.                The data lake of the parking operation management  
   system communicates with the cloud server of the                cloud
   architecture of the parking operation                management system.
   The integrated data of the cloud                server is used as a data
   base. The parking-related                data is managed to ensure data
   operation. The                parking operation management system is
   used to                monitor the real-time parking status and income
   of                multiple parking lots, and the parking space is       
           predicted, through the big data.
   USE - Parking operation management system with                layered
   cloud architecture for real-time parking                state of car
   park.
   ADVANTAGE - The system realizes the communication between               
   Modbus, Socket, HTTP, serial port (485/232), MQTT               
   protocol and cloud server database during parking,                and
   effectively guarantees the rapid communication                between
   each data and cloud server. The system                provides the
   required analysis and decision-making                for the overall
   operation of the parking lot, with                the cloud server as
   the service framework, based on                data communication,
   combined with the cloud module                to effectively transmit
   and integrate data. The                system provides effective basis
   for improving                occupancy of parking space, improving
   comprehensive                treatment level of urban comprehensive
   treatment,                and a parking space scheduling management
   module                communicates with each supporting reservation of  
            the car park, when there is spare parking                space.
   DESCRIPTION Of DRAWING(S) - The drawing shows a schematic view of
   parking                operation management system with layered cloud   
   architecture. (Drawing includes non-English                language
   text)
Z9 0
U1 0
U2 0
DA 2025-03-20
UT DIIDW:2022F6232N
ER

PT P
AU LI X
   WANG J
   GUO W
   YIN W
   ZHANG J
   GUO K
   QI Y
   ZHANG Y
   ZHANG K
   LI Z
   CHEN W
   GUO F
   ZHANG Z
   ZHAN J
   LIN G
   GAO H
   YIN H
TI Post-based online training method for electric            power Internet
   majors used in digital cross-over            development of state grid
   company, involves            constructing post capability learning
   resource system            and data statistics module is used to
   coordinate and            analyze data
PN CN115357561-A
AE STATE GRID CORP CHINA; SHANDONG ELECTRIC POWER COLLEGE; STATE GRID CORP
   CHINA TECH COLLEGE BRANC
AB 
   NOVELTY - The method involves constructing a post               
   capability learning resource system. The general               
   functional modules are designed to enable Internet                majors
   to learn corresponding learning resources                independently.
   The job-based Internet professional                modules are designed
   and include digital                technology, digital infrastructure,
   and data                according to different departments of the
   Internet.                The data statistics module is used to
   coordinate                and analyze data including resource usage,
   post                personnel, training implementation, and talent      
   evaluation. The smart big screen is provided to                build an
   independent operation decision-making                platform based on
   the big data architecture.
   USE - Post-based online training method for electric               
   power Internet majors used in digital cross-over               
   development of state grid company.
   ADVANTAGE - The master-slave relationship is clear               
   integrated post capability training resource                system, the
   satisfy of the student, training has                pertinence,
   improving the training effect,                realizing maximum
   utilization of training resource.                The learning resource
   system can realize the                autonomous learning or training
   based on the                working post, it can provide the decision
   service                for the course training, teaching resource       
           management and so on.
   DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for an          
   electric power Internet professional online                training
   system based on a job position.
   DESCRIPTION Of DRAWING(S) - The drawing shows a flowchart of the        
   post-based online training method for electric                power
   Internet majors. (Drawing includes                non-English language
   text).
Z9 0
U1 0
U2 0
DA 2025-03-20
UT DIIDW:2022E67059
ER

PT J
AU Tshingomba, Urcel Kalenga
   Djibo, Bassira
   Sautot, Lucile
   Teisseire, Maguelonne
   Jouven, Magali
TI A spatialised information system to support decisions regarding grazing
   management in mountainous and Mediterranean rangelands
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
VL 198
AR 107100
DI 10.1016/j.compag.2022.107100
EA JUN 2022
DT Article
PD JUL 2022
PY 2022
AB Agro-sylvo-pastoral systems are common around the Mediterranean Basin,
   where they provide a variety of goods and services to the local
   populations. Their sustainability relies on efficient grazing
   management, especially in Mediterranean rangelands. The diversity of
   pastoral resources, combined with the variety of grazing management
   techniques and farming objectives, has slowed down the development of
   digital tools to assist grazing management in these conditions. However,
   digital technologies could serve agro-sylvo-pastoral farms by improving
   the efficiency of grazing management and reducing the difficulty of the
   associated work. In this objective, and to take into account the variety
   of situations, we suggest developing an information system (IS) based on
   a variety of (contextualised) complementary data. For southern France,
   the following data can be combined: Sentinel 2 images, Registre
   Parcellaire Graphique (RPG), OSO land use and cover, RGE Alti altimetry
   data, pastoral technical references, herd GPS location and feedback from
   farmers. However, designing and implementing such an IS requires
   overcoming methodological and technical limitations concerning the
   integration of heterogeneous structured and unstructured data and the
   definition of meaningful ways to combine them to produce relevant
   insights for decision-making. In this article, we describe an approach
   to produce a spatialised IS aimed at providing farmers with relevant
   information to support decisions regarding grazing management in
   mountainous and Mediterranean rangelands. The IS was codesigned with
   stakeholders, including farmers, to best match their needs and to
   facilitate its integration into farm management. The various
   stakeholders were involved in choosing the types of data to be
   associated and, defining the functions and the conceptual model of the
   IS. We propose to structure the IS as a spatial data lake, designed to
   integrate and associate the identified heterogeneous data, and to
   produce decision-making insights for grazing management in mountainous
   and Mediterranean rangelands.
RI Teisseire, Maguelonne/A-6576-2011; Sautot, Lucile/
OI Sautot, Lucile/0000-0002-4204-7427
ZS 0
ZA 0
ZB 0
Z8 0
ZR 0
TC 0
Z9 0
U1 2
U2 16
SN 0168-1699
EI 1872-7107
DA 2022-06-26
UT WOS:000809781200005
ER

PT C
AU Abdelhedi, Fatma
   Jemmali, Rym
   Zurfluh, Gilles
BE Filipe, J
   Smialek, M
   Brodsky, A
   Hammoudi, S
TI Data Ingestion from a Data Lake: The Case of Document-oriented NoSQL
   Databases
SO ICEIS: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON ENTERPRISE
   INFORMATION SYSTEMS - VOL 1
BP 226
EP 233
DI 10.5220/0011068300003179
DT Proceedings Paper
PD 2022
PY 2022
AB Nowadays, there is a growing need to collect and analyze data from
   different databases. Our work is part of a medical application that must
   allow health professionals to analyze complex data for decision making.
   We propose mechanisms to extract data from a data lake and store them in
   a NoSQL data warehouse. This will allow us to perform, in a second time,
   decisional analysis facilitated by the features offered by NoSQL systems
   (richness of data structures, query language, access performances). In
   this paper, we present a process to ingest data from a Data Lake into a
   warehouse. The ingestion consists in (1) transferring NoSQL DBs
   extracted from the Data Lake into a single NoSQL DB (the warehouse), (2)
   merging so-called "similar" classes, and (3) converting the links into
   references between objects. An experiment has been performed for a
   medical application.
CT 24th International Conference on Enterprise Information Systems (ICEIS)
CY APR 25-27, 2022
CL ELECTR NETWORK
SP INSTICC
RI , Fatma/; Jemmali, Rym/; Abdelhedi, Fatma/AAY-3404-2020
OI , Fatma/0000-0003-1658-8067; Jemmali, Rym/0000-0003-1276-7658; 
ZR 0
TC 0
ZA 0
Z8 0
ZS 0
ZB 0
Z9 0
U1 1
U2 6
BN 978-989-758-569-2
DA 2022-07-03
UT WOS:000814767200024
ER

PT C
AU Ben Rhaiem, Mohamed Amine
   Selmi, Mouna
   Farah, Imed Riadh
   Bouzeghoub, Amel
GP IEEE
TI A big spatiotemporal streaming data architecture for smart city crisis
   monitoring using VGI
SO 2022 2ND INTERNATIONAL CONFERENCE OF SMART SYSTEMS AND EMERGING
   TECHNOLOGIES (SMARTTECH 2022)
BP 107
EP 111
DI 10.1109/SMARTTECH54121.2022.00035
DT Proceedings Paper
PD 2022
PY 2022
AB The exponential growth of human activities and the climate change put
   cities around the world in face of multiple risks and threats that led
   eventually to the emergence of a new urban model, which is the smart
   city resilience. Although being equipped with a myriad of connected
   smart devices and sensors, the smart city is still physically made up of
   buildings, roads, parks, industrial sites, shopping centers, etc.
   Therefore, location-based crisis management endorses a geospatial
   modeling strategy approach for major hazard data management in a smart
   city. Hence, spatial data remains always at the center of risk
   management processes. However, smart and resilient cities still strive
   to solve the imparity between the huge amounts of geospatial data
   generated mostly in real time in particular geographic user content
   contributions also known as Volunteered Geographic Information (VGI) and
   the delayed decision-making. In this paper, we reviewed major studies
   using VGI in big spatiotemporal data analytics in supporting smart city
   resilience. Then, we propose a vision of big spatiotemporal data
   architecture perquisites leveraging big data technologies, VGI and deep
   learning techniques for smart hazard management.
CT 2nd IEEE International Conference on Smart Systems and Emerging
   Technologies (SMARTTECH)
CY MAY 09-11, 2022
CL Prince Sultan Univ, Riyadh, SAUDI ARABIA
HO Prince Sultan Univ
SP IEEE Comp Soc; IEEE; Res & Initiat Ctr; Robot & Internet Things; Prince
   Sultan Univ, IEEE Student Branch; Prince Sultan Univ, Coll Comp &
   Informat Sci; IEEE Saudi Arabia Sect; IEEE Reg 8
RI farah, imed/AAL-7809-2021
ZS 0
ZB 0
ZR 0
TC 0
Z8 0
ZA 0
Z9 0
U1 1
U2 13
BN 978-1-6654-0973-5
DA 2022-09-28
UT WOS:000855229000020
ER

PT C
AU Cakir, Altan
   Ozkaya, Emre
   Akkus, Fatih
   Kucukbas, Ezgi
   Yilmaz, Okan
BE Kahraman, C
   Tolga, AC
   Onar, SC
   Cebi, S
   Oztaysi, B
   Sari, IU
TI Real Time Big Data Analytics for Tool Wear Protection with Deep Learning
   in Manufacturing Industry
SO INTELLIGENT AND FUZZY SYSTEMS: DIGITAL ACCELERATION AND THE NEW NORMAL,
   INFUS 2022, VOL 2
SE Lecture Notes in Networks and Systems
VL 505
BP 148
EP 155
DI 10.1007/978-3-031-09176-6_18
DT Proceedings Paper
PD 2022
PY 2022
AB Industry 4.0 is a motivation that represents the transformation by
   data-driven industrial operations and decision making by digitization of
   manufacturing processes to gain operational advantages in the market.
   Considering how the manufacturing sector is adopting data-driven
   operations is challenging, given that there is not a straightforward
   definition of machine traceability, receiving and storing raw data from
   manufacturing lines, gives an opportunity to analyse the processes in
   real time nature. Thanks to big data management platforms and artificial
   intelligence decision support algorithms, it gives the ability to deeply
   understand the complexity of the processes and, accordingly, to
   eliminate or minimise false methods and reduce the costs that are
   insufficient for production. In addition, one of the biggest preventable
   costs for metal machining processes is the tool breakage and tool
   wearing problems. The motivation of this paper is to discuss data-driven
   decision making possibilities of the tool wearing and optimise breakage
   costs with using artificial intelligence. Furthermore, the analysis
   provides a proof-of-concept that the existence of a digital
   infrastructure combined with the analytical capabilities, such as
   real-time data management and monitoring, and having a highly accurate
   LSTM based time-series integrated artificial intelligent predictive
   model, to deal with inefficiencies in production processes. To this end,
   in this context, by developing the latest advancements in big data
   analytics, we propose a scalable predictive and preventive maintenance
   architecture for metal machining processes domain. We also show the
   opportunities and challenges of utilizing the big data architecture in
   the manufacturing domain.
CT 4th International Conference on Intelligent and Fuzzy Systems (INFUS)
CY JUL 19-21, 2022
CL Bornova, TURKEY
RI Akkus, Mehmet Fatih/; Cakir, Altan/ABD-4450-2020
OI Akkus, Mehmet Fatih/0000-0002-3628-5656; 
TC 0
ZR 0
ZS 0
Z8 0
ZA 0
ZB 0
Z9 0
U1 1
U2 7
SN 2367-3370
EI 2367-3389
BN 978-3-031-09176-6; 978-3-031-09175-9
DA 2022-12-10
UT WOS:000889132600018
ER

PT J
AU Vasquez-Morales, Felipe
   Cravero-Leal, Ania
TI Big Data Architecture for Forest Fire Management Support in the Region
   of Araucania
SO REVISTA CIENTIFICA
VL 42
IS 3
BP 304
EP 314
DI 10.14483/23448350.18349
DT Article
PD SEP-DEC 2021
PY 2021
AB Wildfires have been a growing problem in the last decades. In recent
   years, Big Data technology has been used to process large volumes of
   data from sensors, photos, satellite and images, as well as valuable
   data from field experience. In Chile, there are no Big Data systems to
   support forest fire management. This work aims to propose a Big Data
   architecture for managing the volume of data provided by satellite
   images and supporting fire management in Chile. This architecture was
   tested through a prototype implemented with Cloud Computing tools, which
   processes satellite images and is focused on the analysis of controlled
   burns in the region of La Araucania. The results show that the resulting
   images are valuable for decision-making in the management of burns
   within the region. Although there is much to improve, the results are
   encouraging in terms of the value generated by the resulting images and
   the improvement of this prototype and the architecture itself.
RI Cravero, Ania/MTD-8173-2025
OI Cravero, Ania/0000-0003-0883-7254
TC 0
ZR 0
ZA 0
ZS 0
ZB 0
Z8 0
Z9 0
U1 1
U2 12
SN 0124-2253
EI 2344-8350
DA 2021-10-21
UT WOS:000704485100005
ER

PT P
AU WANG L
   WANG P
   PENG Q
   TIAN J
   XIANG X
   DING Y
   LI F
TI Data lake architecture has data collection layer            that
   collects data which includes unstructured data or           
   multi-structured data, data storage layer that stores            data,
   and data processing layer that processes            data
PN CN112597218-A
AE EVERBRIGHT TECHNOLOGY CO LTD
AB 
   NOVELTY - The data lake architecture has a data               
   collection layer (22) that collects data which                includes
   unstructured data or multi-structured                data. A data
   storage layer (24) stores the data. A                data processing
   layer (26) processes the data. The                data collection layer
   collects the data through                batch processing if the
   throughput of the data is a                key factor in business
   decision-making, and                collects the data in real-time
   collection if the                delay of data is a key factor in
   business                decision-making.
                       USE - Data lake architecture.
   ADVANTAGE - The data is stored and processed through the               
   data lake built on the distributed architecture,                which
   can solve that the data warehouse is only                suitable for
   structured data.
   DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the          
   following:a data processing method;a data processing device;a
   computer-readable storage medium storing                program for data
   processing; andan electronic device.
   DESCRIPTION Of DRAWING(S) - The drawing shows the structural block      
   diagram of the data lake architecture. (Drawing                includes
   non-English language text)22Data collection layer24Data storage
   layer26Data processing layer
Z9 0
U1 0
U2 0
DA 2021-05-01
UT DIIDW:2021361104
ER

PT B
AU Machmouchi, Hassan
   Desper, Deane
   Sambasivam, Samuel
   Calongne, Cynthia
Z2  
TI [not available]
DT Dissertation/Thesis
PD Jun 22 2023
PY 2023
ZA 0
TC 0
ZB 0
Z8 0
ZR 0
ZS 0
Z9 0
U1 1
U2 3
BN 9798534683547
UT PQDT:64705582
ER

PT P
AU LIU R
   ZHANG Q
TI Petroleum big data based integration synergy            management
   application platform, has integrated            collaborative management
   platform provided with            integrated technology research
   platform and different            dynamic tracking analysis platforms
PN CN111027923-A
AE UNIV XIAN SHIYOU
AB 
   NOVELTY - The platform has a big data architecture                system
   and an integrated collaborative management                platform
   bidirectionally connected through a HTTP                protocol. The
   big data architecture system is                provided with a data
   management system, a data                storage system, a data source
   system, a data                acquisition system, a data transmission
   system and                a data monitoring system. The integrated      
   collaborative management platform is provided with                an
   integrated technology research platform,                different
   dynamic tracking analysis platforms, a                knowledge base
   focusing platform, a real-time                monitoring platform and a
   remote decision-making                platform.
   USE - Petroleum big data based integration synergy               
   management application platform.
   ADVANTAGE - The platform realizes data resource sharing,               
   improves petroleum-related field working efficiency                of a
   worker and promotes development of each                enterprise.
   DESCRIPTION Of DRAWING(S) - The drawing shows a block diagram of a      
   petroleum big data based integration synergy                management
   application platform. (Drawing includes                non-English
   language text).
Z9 0
U1 0
U2 0
DA 2025-03-20
UT DIIDW:2020337321
ER

PT C
AU da Silva, Rodrigo Dantas
   Pereira de Araujo, Jean Jar
   Pires de Paiva, Alvaro Ferreira
   de Medeiros Valentim, Ricardo Alexsandro
   Coutinho, Karilany Dantas
   de Paiva, Jailton Carlos
   Roussanaly, Azim
   Boyer, Anne
GP ACM
TI A Big Data Architecture to a Multiple Purpose in Healthcare
   Surveillance: The Brazilian Syphilis Case
SO PROCEEDINGS OF THE 10TH EURO-AMERICAN CONFERENCE ON TELEMATICS AND
   INFORMATION SYSTEMS (EATIS 2020)
DI 10.1145/3401895.3402092
DT Proceedings Paper
PD 2020
PY 2020
AB For many decades society did need to monitor and assess the standard of
   living of the population. In the 1950s, the United Nations (UN) saw this
   need and proposed 12 areas that should be evaluated, the first of which
   is listed under "Health and Demography", which focuses on what is
   expressed as the level of a population's health. Decades have passed and
   great results have been gained from similar initiatives such as reducing
   mortality from infectious diseases and even eradicating some others. In
   the age of the digital society, needs have grown. Monitoring demands
   that once perished from data to become concrete now suffer from the
   opposite effect, the excess of data from everywhere. Healthcare systems
   around the world use many different information systems, collecting and
   generating hundreds of data at unimaginable speed. We are billions of
   people on the planet and most of us are connected to the virtual world,
   sharing information, experiences and events with some kind of cloud. In
   this information age, the ability to aggregate and process this data is
   a major factor in raising public health to a new level. The development
   of tools capable of analyzing a large volume of data in seconds and
   producing knowledge for targeted decision making can help in the fight
   against specific diseases, in the process of continuing education of
   professionals, in the formation of new professionals, in the elaboration
   of new policies. with the specific locoregional look, in the analysis of
   hidden trends in front of so much information faced in everyday life and
   other possibilities. The present work proposes an architecture capable
   of storing and manipulating seeking to standardize the variables in
   order to allow to correlate this large amount of data in a systematic
   way, providing to several services and researchers the possibility of
   consuming health, social, economic and educational data for the
   promotion of public health.
CT 10th Euro-American Conference on Telematics and Information Systems
   (EATIS)
CY NOV 25-27, 2020
CL Aveiro, PORTUGAL
RI Paiva, Jailton/OHU-2520-2025; Anne, Boyer/AAB-8771-2022; Ferreira Pires de Paiva, Álvaro/; Coutinho, Karilany Dantas/; Paiva, Jailton Carlos/; Valentim, Ricardo/HHM-8045-2022
OI Ferreira Pires de Paiva, Álvaro/0000-0003-0708-051X; Coutinho, Karilany
   Dantas/0000-0002-2051-8611; Paiva, Jailton Carlos/0000-0002-2080-9945;
   Valentim, Ricardo/0000-0002-9216-8593
ZB 0
ZS 0
ZR 0
TC 0
Z8 0
ZA 0
Z9 0
U1 0
U2 0
BN 978-1-4503-7711-9
DA 2020-01-01
UT WOS:000717043600058
ER

PT B
AU de Melo, Pedro Junqueira Teixeira Coelho
   Reis, Luís Paulo
   Capa, Francisco
Z2  
TI [not available]
DT Dissertation/Thesis
PD Aug 23 2024
PY 2024
ZR 0
ZB 0
TC 0
ZS 0
Z8 0
ZA 0
Z9 0
U1 0
U2 0
BN 9798383274170
UT PQDT:91337070
ER

PT J
AU Hahm, Yukun
TI Data Integration Strategy in Big Data Era: A Public Sector Case Analysis
Z1 빅데이터 시대의 데이터 통합 전략: 공공부문 사례 분석
SO The Journal of Information Technology and Architecture
S1 정보화연구
VL 14
IS 2
BP 115
EP 128
DT research-article
PD 2017
PY 2017
AB Big data has created new technical and business environment which change
   organizationsin many ways. It is time for organizations to cope with
   huge data volume as well as various data typesand the speed of data
   production and utilization. In this context, research on data
   integration for solvingthese problems falls short of academic and
   industry demand. Especially academic research have notprovided enough
   answers on effective decision making support through big data
   integration. By developinga big data integration framework evaluating
   such techniques as Hadoop, data federation, anddata virtualization as
   well as infrastructure like parallel data warehouse, cloud systems,
   logical datawarehouse and data lake and analyzing a public sector data
   integration case, the paper proposes astrategy to select appropriate big
   data integration approaches in various situations.
AK 빅데이터라는 새로운 기술 및 경영 환경은 데이터가 조직에서 활용되는 방법에 많은 변화를 초래하고 있다. 이는 기업들이 이전과 다른
   데이터의 규모는 물론 다양한 형태, 그리고 데이터 생산에서 활용까지 더욱 빠른 속도에 대응해야하기 때문이다. 그러나 빅데이터의
   부상과 함께 데이터의 규모가 상상을 초월할 정도로 커지지는 환경에서 여러 곳에 흩어져 있는 다양한 종류의 데이터를 어떻게 통합하여
   실시간으로 제공해 의사결정을 더욱 효율적이며 효과적으로 할 수 있는지에 대한 연구는 아직까지매우 초기 수준에 있다. 본 연구는
   빅데이터 환경에서 데이터 통합을 위해 사용될 수 있는 다양한 방법들인 하둡, 데이터 페더레이션, 데이터 가상화, 그리고 이들과
   관련된 인프라인 병렬형 데이터웨어하우스, 논리적 데이터 웨어하우스, 클라우드 시스템, 데이터 호수 등의 특징을 분석해 정리하고
   공공기관의 빅데이터 통합 사례를 통해 비즈니스 상황에 맞는 데이터 통합 방법의 선택 전략을 제시하고자 한다.
ZB 0
Z8 0
ZA 0
ZS 0
ZR 0
TC 0
Z9 0
U1 0
U2 0
SN 1738-382x
DA 2017-01-01
UT KJD:ART002243254
ER

PT C
AU Zheng, Chengyu
   Huang, Liqun
   Huang, Xiaotao
BE Chang, L
   Guiran, C
   Zhen, L
TI An Improved ODS Platform on Large Enterprise-level
SO PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON MECHATRONICS,
   ELECTRONIC, INDUSTRIAL AND CONTROL ENGINEERING
SE AER-Advances in Engineering Research
VL 8
BP 559
EP 562
DT Proceedings Paper
PD 2015
PY 2015
AB With rapid development of big data applications, telecom operators pay
   more attention to the management and analysis of various data.
   Presently, as the telecom operators haven't built a uniform enterprise
   data platform, and application systems and internal data models differ
   from one another, the complexity of interfaces increases gradually,
   which restricts the ability of business systems to perform all their
   business supporting. But now, the ODS increases the maintenance
   efficiency, decreases IT operations and maintenance costs, improves the
   quality of supporting data, assures the operational revenues, improves
   the service quality, provides strong support for operating decision
   making through using the ETOM model, adopting SOA, applying ODS and EDW
   technical framework for full service operation and all professional
   integration according with the general principles, and introducing EAI
   and management mechanism of message control.
CT International Conference on Mechatronics, Electronic, Industrial and
   Control Engineering (MEIC)
CY APR 01-03, 2015
CL Shenyang, PEOPLES R CHINA
ZR 0
Z8 0
ZA 0
ZB 0
TC 0
ZS 0
Z9 0
U1 0
U2 2
SN 2352-5401
BN 978-94-62520-62-2
DA 2015-09-16
UT WOS:000359443600128
ER

PT J
AU Zhang, Li Ping
Z2  
TI The research and accomplishment of basic data service interface for the
   decision-making condition-based maintenance system of power transformers
   based on soa
DT Dissertation/Thesis
PD Jan 01 2011
PY 2011
Z8 0
ZR 0
TC 0
ZA 0
ZS 0
ZB 0
Z9 0
U1 0
U2 0
UT PQDT:67102220
ER

EF