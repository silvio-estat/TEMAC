"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"The Implication of Data Lake in Enterprises: A Deeper Analytics","J. Singh; G. Singh; B. S. Bhati","Computer Science and Engineering, Chandigarh University, Mohali, India; Computer Science and Engineering, Chandigarh University, Mohali, India; Computer Science and Engineering, Chandigarh University, Mohali, India",2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS),"7 Jun 2022","2022","1","","530","534","Everyday enormous amounts of information are produced from computerized advancements and handling these gigantic complex data requires a decent knowledge on the most proficient method to deal with this data. With a purpose to make the most from this multiform data for determined benefits, the data lake emerge as idea for enhanced adaptability and strong data analytics. Data Lake terminology signify a storage space for storing heterogeneous data, both organized as well as unstructured, bringing about an adaptable association that permits data lake customers incorporate data dynamically which they request. Big Data innovation offer help to enterprises in business intelligence process yet there exists lack of empirical study on utilization of data lake technique in enterprises. This paper gives an exploratory review on data lake implication by portraying its concept, functional architecture, development stages involved and numerous research challenges and direction; which will improve the effective utilization of the data lake approach in enterprises.","2575-7288","978-1-6654-0816-5","10.1109/ICACCS54159.2022.9784986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9784986","Data Lake;Data Lake vs Data Warehouse;Data Lake Research Challenges;Data Lake in Enterprise;Stages for Building Data Lake;Need of Data Lake","Technological innovation;Terminology;Communication systems;Focusing;Computer architecture;Companies;Lakes","","15","","22","IEEE","7 Jun 2022","25-26 March 2022","25-26 March 2022","IEEE","IEEE Conferences"
"Embedding AI and Crowdsourcing in the Big Data Lake","D. E. O'Leary",University of Southern California,IEEE Intelligent Systems,"7 Nov 2014","2014","29","5","70","73","Daniel E. O'Leary examines the notion of the Big Data Lake and contrasts it with decision support-based data warehouses. In addition, some of the risks of the emerging Lake concept that ultimately require data governance are analyzed. O'Leary investigates using different AI and crowdsourcing (human intelligence) applications in that lake in order to integrate disparate data sources, facilitate master data management and analyze data quality. Although data governance often is not seen as a technology issue, it is seen as a critical component of making the Big Data Lake ""work.""","1941-1294","","10.1109/MIS.2014.82","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949519","Big Data Lake;data warehouses;artificial intelligence;crowdsourcing;data governance;master data management;intelligent systems","Crowdsourcing;Artificial intelligence;Big data;Data warehouses;Decision support systems;Databases;Business","","79","","19","IEEE","7 Nov 2014","Sept.-Oct. 2014","","IEEE","IEEE Magazines"
"Building a Data Lake for Power BI in the Cloud: A Review on Utilizing Cloud Storage Services for Large Datasets","V. V. Gurbade; P. Verma; S. Gundewar; V. S. Bramhe","Department of Artificial Intelligence and Data Science, Faculty of Engineering and Technology, Datta Meghe Institute of Higher Education & Research (DU), Wardha, Maharashtra, India; Department of Artificial Intelligence and Machine Learning, Faculty of Engineering and Technology, Datta Meghe Institute of Higher Education & Research (DU), Wardha, Maharashtra, India; Department of Artificial Intelligence and Machine Learning, Faculty of Engineering and Technology, Datta Meghe Institute of Higher Education & Research (DU), Wardha, Maharashtra, India; School of Computing Science and Engineering, VIT Bhopal University, Sehore, Madhya Pradesh, India","2024 2nd DMIHER International Conference on Artificial Intelligence in Healthcare, Education and Industry (IDICAIEI)","20 Jan 2025","2024","","","1","6","A data lake is a centralized repository where you may store both structured and unstructured data at any scale. Unlike typical data warehouses, which need data structure for storage, data lakes allow you to store raw data in its natural state. This adaptability makes data lakes suitable for storing large volumes of various data kinds, including photographs, videos, log files, sensor data, and others. When integrating a data lake with Power Business Intelligence (BI), organizations can harness the power of both technologies to gain valuable insights from their data. In the realm of data-driven decision-making, organizations face the challenge of managing and extracting insights from vast and diverse datasets, a task conventional on-premises storage solutions often struggle with due to the exponential growth of data. Thus, the adoption of more scalable and flexible alternatives becomes imperative. Cloud-based data lakes emerge as transformative solutions, offering unparalleled scalability, accessibility, cost-effectiveness, and advanced security protocols. This paper discuss the concept of constructing a cloud-based data lake optimized for Power BI, leveraging leading cloud storage services like Azure Data Lake Storage (ADLS) and Amazon S3. By seamlessly integrating Power BI with the cloud data lake, organizations can overcome traditional storage limitations and reap numerous benefits. The practical applications in advanced analytics, customer insights, IoT data management, and data discovery underscore the real-world utility of cloud data lakes. The integration of Power BI with a cloud data lake augments efficient data analysis and self-service analytics potential, offering organizations a comprehensive solution for deriving actionable insights from their data assets.","","979-8-3315-2871-3","10.1109/IDICAIEI61867.2024.10842802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10842802","Data Lake;Cloud storage;Power BI;Cloud data integration;Data flows","Cloud computing;Scalability;Decision making;Buildings;Organizations;Big Data applications;Security;Data mining;Business intelligence;Self-service","","","","15","IEEE","20 Jan 2025","29-30 Nov. 2024","29-30 Nov. 2024","IEEE","IEEE Conferences"
"Leveraging Scalable Cloud Infrastructure for Autonomous Driving Data Lakes and Real-Time Decision Making","J. Chen","Graduate School of Arts and Sciences, Columbia University, New York, United States",2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA),"1 Jul 2025","2025","","","1750","1753","Autonomous driving technology relies heavily on the effective management of vast datasets generated by various sensors and vehicle systems. As such, leveraging scalable cloud infrastructure becomes paramount for improving data handling and decision-making capabilities. In this paper, we introduce the Autonomous Driving Data Lakes (ADDL) framework, designed to streamline the storage, retrieval, and processing of extensive driving data in real-time. By utilizing cloud technology, ADDL ensures tight integration of data from diverse sources to enhance situational awareness for autonomous systems. Our architecture features robust data pipelines that support real-time analytics and machine learning applications, which are crucial for timely and accurate decision-making. Extensive experiments with large-scale datasets demonstrate how our approach significantly boosts processing efficiency, data accessibility, and decision-making reliability. The findings highlight advancements in autonomous driving technologies, addressing the challenges associated with data management and enhancing operational effectiveness in changing driving environments.","","979-8-3315-0976-7","10.1109/AIITA65135.2025.11048068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048068","Cloud Infrastructure;Autonomous Driving;Decision Making","Decision making;Pipelines;Machine learning;Big Data applications;Real-time systems;Sensor systems;Telemetry;Reliability;Autonomous vehicles;Intelligent sensors","","","","18","IEEE","1 Jul 2025","28-30 March 2025","28-30 March 2025","IEEE","IEEE Conferences"
"Building a Data Lake for Smart Building Data: Architecture for Data Quality and Interoperability","J. L. Hernández; S. Martín; P. Kapsalis; K. Katsigarakis; E. Sarmas; V. Marinakis","Energy Division, CARTIF Technology Centre, Boecillo, Valladolid, Spain; Energy Division, CARTIF Technology Centre, Boecillo, Valladolid, Spain; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece; Faculty of the Built Environment, University College of London, London, United Kindom; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece","2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)","15 Dec 2023","2023","","","1","8","Building data is growing, where sources are heterogeneous and still treated as silos from different building domains (energy, architecture elements or automation networks, among others). This leads to a lock-in when providing capabilities of data exploitation, such as added-value services, artificial intelligence services or machine-learning activities. Assuring data integration via interoperability mechanisms becomes then pivotal in building data management schemas. Under this perspective, this paper presents an architecture of a data lake that integrates heterogeneous data sources from diverse building domains with the aim of homogenising data-sets and creating data-quality procedures to ensure high-quality services to make better decisions. Based on enriched data between static and dynamic data-sets, the data lake ultimate develops business intelligence mechanism to extract knowledge and information.","","979-8-3503-1806-7","10.1109/IISA59645.2023.10345892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10345892","data lake;data quality;interoperability;digitalisation;smart buildings","Smart buildings;Architecture;Data integrity;Soft sensors;Buildings;Pipelines;Metadata","","5","","16","IEEE","15 Dec 2023","10-12 July 2023","10-12 July 2023","IEEE","IEEE Conferences"
"Cloud Big Data Lake for Advanced Analytics in Semiconductor Manufacturing","S. Sun; J. Ye; H. Schwarthoff; J. Rosin; V. Vakkalagadda; J. Chang; S. R. Ubbara; A. Chinthakindi","Data Science, Micron Technology Inc., Manassas, VA, USA; Process Integration Micron Technology Inc., Manassas, VA, USA; Smart Mfg Tech Solutions Micron Technology Inc., Boise, ID, USA; Information Technology Micron Technology Inc., Manassas, VA, USA; Data Science, Micron Technology Inc., Manassas, VA, USA; Smart Mfg Tech Solutions Micron Technology Inc., Boise, ID, USA; Smart Mfg Tech Solutions Micron Technology Inc., Boise, ID, USA; Front-end Central Quality Micron Technology Inc., Manassas, VA, USA",2024 35th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC),"6 Jun 2024","2024","","","1","5","Data driven business intelligence is changing how semiconductor manufacturing thrives in the long term. A cloud big data lake is designed and implemented based on state-of-the-art cloud architecture providing complete services for data ingestion, storage, processing, advanced analytics, and machine learning with a high level of security. Efficient and effective use of this big data lake and data science enables problem solving and decision making to improve productivity and performance.","2376-6697","979-8-3503-8455-0","10.1109/ASMC61125.2024.10545365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545365","Cloud;Data Lake;Semiconductor Manufacturing;Big Data Analytics","Cloud computing;Soft sensors;Scalability;Machine learning;Lakes;Big Data;Semiconductor device manufacture","","","","5","IEEE","6 Jun 2024","13-16 May 2024","13-16 May 2024","IEEE","IEEE Conferences"
"The Significance of using Data Extraction Methods for an Effective Big Data Mining Process","M. Sharma; R. Gupta","dept. Computer Science Engoneering, Graphic Era deemed to be University, Dehradun, India; dept. Computer Science Engoneering, Graphic Era hill University, Dehradun, India",2023 2nd International Conference for Innovation in Technology (INOCON),"19 Apr 2023","2023","","","1","4","Data is identified as the fuel of modern society for its versatility of use and effectiveness of use. In addition, modern businesses are making a decline based on analysis of historical data and patterns of the data. Such dependency on data analysis makes the process of data analysis important for data mining. Therefore the overall study has shed light on the significance of the data mining process and extraction process of data in order to make a data-driven decision. Additionally, the problems related to the process of data extraction and data mining are mentioned in the study which helps to achieve an overall concept for the data extraction and data mining process. Additionally, the significance of the process is mentioned in the study. Additionally, there are tables constructed that represent problems of the data extraction process and mining and the significance of the stems of mining. The study concludes in a way that helps in the implication of data extraction methods for business.","","979-8-3503-2092-3","10.1109/INOCON57975.2023.10101236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10101236","Big data mining;Data extraction methods;Data Mining process;Data warehouse;Data lake;Data analysis;Decision making;Artificial intelligence;Business intelligence;data-driven decision-making","Technological innovation;Data analysis;Decision making;Big Data;Data mining;Fuels;Business","","4","","20","IEEE","19 Apr 2023","3-5 March 2023","3-5 March 2023","IEEE","IEEE Conferences"
"Research on Marketing and Data Analysis System Based on Computer Big Data","X. Wu",Macau University of Science and Technology,"2022 4th International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)","22 May 2023","2022","","","286","289","This paper establishes a set of enterprise marketing decision-making system based on computer big data calculation. According to the characteristics of marketing data collection and sorting, this paper proposes a mashup data architecture and a data application functional architecture. The author describes the overall functional structure of the system and the design and implementation of key processes such as the generation of marketing activities, the production of marketing activities, and the execution of marketing activities among the modules of the system. At the same time, it expounds the main functions and technical realization modes of the CRM shopping guide module, product unified management module, grid management module, marketing management module, production scheduling management module, and work division management module. This paper mines feature from the three dimensions of users, merchants, and the relationship between users and merchants in the marketing system. A total of 121 features are constructed from multiple perspectives under each dimension. In this paper, the improved Relief algorithm is used to select features with stronger discriminative ability for minority class samples and build a single model to predict the repeated purchase behavior of users. The experimental results show that after using the improved Relief algorithm to select features, the predicted effect of the model is better.","","979-8-3503-3394-7","10.1109/MLBDBI58171.2022.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10125444","computer;big data;marketing;user repeat purchase behavior;marketing analysis system","Computational modeling;Mashups;Decision making;Production;Computer architecture;Predictive models;Prediction algorithms","","","","8","IEEE","22 May 2023","28-30 Oct. 2022","28-30 Oct. 2022","IEEE","IEEE Conferences"
"Enhancing COVID-19 Data Analysis through HCI-Driven AI and IoT Integration","F. Mehdipour; A. Aharari","Department of Information Technology, Otago Polytechnic – Auckland International Campus, Auckland, New Zealand; Faculty of Computer and Information Sciences, SOJO University, Kumamoto, Japan",2024 IEEE 13th Global Conference on Consumer Electronics (GCCE),"28 Nov 2024","2024","","","840","843","This paper explores the integration of Artificial Intelligence (AI), the Internet of Things (IoT), and Human-Computer Interaction (HCI) to enhance data analysis and decision-making in healthcare, particularly during the COVID-19 pandemic. Through a mixed-methods approach, including a literature review and case study analysis, the study highlights how AI-driven analytics and IoT data streams, exemplified by the COVID-19 Data Lake and WHO Health Alert platform, provide real-time insights and improve decision-making efficiency. The success of these systems relies on effective HCI integration, robust data validation, and comprehensive user training. Challenges such as data accuracy and system adaptability are identified, with future research directions focusing on advanced AI techniques and the development of sophisticated HCI frameworks. By addressing these challenges, the integration of AI, IoT, and HCI can further transform healthcare and enhance public health outcomes.","2693-0854","979-8-3503-5507-9","10.1109/GCCE62371.2024.10760844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10760844","Artificial Intelligence (AI);Internet-of-Things (IoT);Human-Computer Interaction (HCI);Healthcare Data Management","COVID-19;Training;Data analysis;Decision making;Transforms;Real-time systems;Internet of Things;Artificial intelligence;Public healthcare;Streams","","1","","14","IEEE","28 Nov 2024","29 Oct.-1 Nov. 2024","29 Oct.-1 Nov. 2024","IEEE","IEEE Conferences"
"AI-Driven Secure and Scalable Data Architecture with Multi-Domain MDM and Cybersecurity for Real-Time Fintech Decision-Making","C. Bonthu; G. Malik; M. R. Dhanagari","Eversana, USA; The Goldman Sachs Group, Inc., Dallas, Texas, USA; Software Development & Engineering, Charles Schwab, USA",2025 Tenth International Conference on Science Technology Engineering and Mathematics (ICONSTEM),"18 Feb 2026","2025","","","1","7","In this paper, AI-based data integration methods can be used to improve real-time decision-making in FinTech settings. In particular, it dwells upon the automatic processing and cleaning of financial data across numerous sources by making use of machine learning algorithms. With the assistance of AI integration, anomalies, inconsistencies, and possible fraud can be identified in real-time, which is essential to make precise financial decisions. Based on Apache Kafka as a real-time data streaming tool, this solution will provide the opportunity to ensure a smooth stream of information between systems and analyze it in seconds with high accuracy. Machine learning models also examine the streams of data to give a financial direction so that the system is adaptive and responsive to the market. This approach enhances the efficiency and scalability of financial processes because it allows making decisions in real-time, using accurate and clean data. Combining the AI with the real-time data processing and such tools as Apache Kafka provides a powerful solution to the application of modern, data-driven FinTech.","2996-2986","979-8-3315-6187-1","10.1109/ICONSTEM65670.2025.11374416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11374416","AI-driven;data integration;machine learning;real-time decision-making;financial data;anomaly detection;Apache Kafka","Accuracy;Fintech;Scalability;Decision making;Data integration;Machine learning;Real-time systems;Data models;Cleaning;Load modeling","","","","15","IEEE","18 Feb 2026","6-7 Nov. 2025","6-7 Nov. 2025","IEEE","IEEE Conferences"
"A Comprehensive Approach to Real-Time and Batch Processing for Energy-Efficient IoT Homes: Leveraging Lambda Architecture and Data Lakes","F. Serepas; I. Papias; N. Bellos; V. Marinakis","Holistic IKE, Athens, Greece; Decision Support Systems Laboratory, School of Electrical & Computer Engineering, National Technical University of Athens, Athens, Greece; Decision Support Systems Laboratory, School of Electrical & Computer Engineering, National Technical University of Athens, Athens, Greece; Decision Support Systems Laboratory, School of Electrical & Computer Engineering, National Technical University of Athens, Athens, Greece","2024 15th International Conference on Information, Intelligence, Systems & Applications (IISA)","18 Dec 2024","2024","","","1","6","The incorporation of IoT technology into energy-efficient home systems has resulted in a surge in data volume, prompting the need for sophisticated storage and processing solutions. This paper proposes a system that integrates the Lambda Architecture with data lakes to address real-time and batch processing needs in the context of energy-efficient homes. By leveraging technologies such as TimescaleDB for short-term storage and Apache Hudi for long-term storage, coupled with Kafka for data streaming, the system ensures efficient data management and analysis. Real-time insights are provided through GraphQL-powered visualizations, while batch processing facilitates advanced analytics and machine learning model training. The proposed system addresses the dual demands of end-users seeking real-time insights and data scientists requiring extensive datasets for analysis.","","979-8-3503-6883-3","10.1109/IISA62523.2024.10786715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786715","Data Lake;Data Analytics;Smart Homes;IoT Devices;Big Data;MQTT;Apache Hudi;Apache Kafka;TimescaleDB;Time Series","Training;Analytical models;Batch production systems;Data visualization;Machine learning;Big Data applications;Real-time systems;Energy efficiency;Surges","","5","","27","IEEE","18 Dec 2024","17-19 July 2024","17-19 July 2024","IEEE","IEEE Conferences"
"Business Intelligence with Databricks SQL: Concepts, tools, and techniques for scaling business intelligence on the data lakehouse","V. Gupta",NA,"Business Intelligence with Databricks SQL: Concepts, tools, and techniques for scaling business intelligence on the data lakehouse","","2022","","","","","Master critical skills needed to deploy and use Databricks SQL and elevate your BI from the warehouse to the lakehouse with confidenceKey FeaturesLearn about business intelligence on the lakehouse with features and functions of Databricks SQLMake the most of Databricks SQL by getting to grips with the enablers of its data warehousing capabilitiesA unique approach to teaching concepts and techniques with follow-along scenarios on real datasetsBook DescriptionIn this new era of data platform system design, data lakes and data warehouses are giving way to the lakehouse – a new type of data platform system that aims to unify all data analytics into a single platform. Databricks, with its Databricks SQL product suite, is the hottest lakehouse platform out there, harnessing the power of Apache Spark™, Delta Lake, and other innovations to enable data warehousing capabilities on the lakehouse with data lake economics. This book is a comprehensive hands-on guide that helps you explore all the advanced features, use cases, and technology components of Databricks SQL. You’ll start with the lakehouse architecture fundamentals and understand how Databricks SQL fits into it. The book then shows you how to use the platform, from exploring data, executing queries, building reports, and using dashboards through to learning the administrative aspects of the lakehouse – data security, governance, and management of the computational power of the lakehouse. You’ll also delve into the core technology enablers of Databricks SQL – Delta Lake and Photon. Finally, you’ll get hands-on with advanced SQL commands for ingesting data and maintaining the lakehouse. By the end of this book, you’ll have mastered Databricks SQL and be able to deploy and deliver fast, scalable business intelligence on the lakehouse.What you will learnUnderstand how Databricks SQL fits into the Databricks Lakehouse PlatformPerform everyday analytics with Databricks SQL Workbench and business intelligence toolsOrganize and catalog your data assetsProgram the data security model to protect and govern your dataTune SQL warehouses (computing clusters) for optimal query experienceTune the Delta Lake storage format for maximum query performanceDeliver extreme performance with the Photon query execution engineImplement advanced data ingestion patterns with Databricks SQLWho this book is forThis book is for business intelligence practitioners, data warehouse administrators, and data engineers who are new to Databrick SQL and want to learn how to deliver high-quality insights unhindered by the scale of data or infrastructure. This book is also for anyone looking to study the advanced technologies that power Databricks SQL. Basic knowledge of data warehouses, SQL-based analytics, and ETL processes is recommended to effectively learn the concepts introduced in this book and appreciate the innovation behind the platform.","","9781803237596","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163377.pdf&bkn=10163377&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Secured AI guided Architecture for D2D Systems of Massive MIMO deployed in 5G Networks","A. Vijay; K. Umadevi","Department of Electronics and Communication Engineering, Ambal Professional Group of Institutions, Palladam, Tamil Nadu, India; Sengunthar Engineering College, Tiruchengode, Tamil Nadu, India",2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI),"11 Oct 2019","2019","","","468","472","Security issues arises with the massive elevation in quantity of mobile users along with high data rate services proposed by 5G networks. D2D communication technique is an optimized method to support various demands on massive data transfer rates among the users in 5G networks. Massive MIMO (Multiple-input and Multiple-output) based antenna systems are deployed to achieve these huge data demands in 5G technology. However, the drawbacks owing to expanding computational overhead in methods of allocating resource, reducing interference, energy optimization and several other problems in D2D networks are compromised with the help of emerging technology of Explainable Artificial Intelligence (XAI). Furthermore, a novel approach based on AI is implemented with an Architectural design for D2D network in decision making over the implementation of techniques based on the persisting situation in the D2D network. Finally, Security protocols based on network demands are implemented through AI in D2D Communications of Massive MIMO based 5G Networks.","","978-1-5386-9439-8","10.1109/ICOEI.2019.8862712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862712","Explainable Artificial Intelligence;Massive MIMO;Big Data Lake;Software-Defined Radio;Cloud Server;COBRA Technology","Device-to-device communication;Artificial intelligence;5G mobile communication;Protocols;Security;Servers","","9","","36","IEEE","11 Oct 2019","23-25 April 2019","23-25 April 2019","IEEE","IEEE Conferences"
"TAIRA-BSC - Trusting AI in Recruitment Applications through Blockchain Smart Contracts","M. Aleisa; M. Alshahrani; N. Beloff; M. White","Dept. of Informatics, University of Sussex, Brighton, United Kingdom; Dept. of Informatics, University of Sussex, Brighton, United Kingdom; Dept. of Informatics, University of Sussex, Brighton, United Kingdom; Dept. of Informatics, University of Sussex, Brighton, United Kingdom",2022 IEEE International Conference on Blockchain (Blockchain),"19 Sep 2022","2022","","","376","383","Artificial intelligence (AI) and blockchain technology (BCT) are considered two of the most trending and disruptive technologies. BCT, although commonly associated with cryptocurrencies, has shown a tremendous impact among many other distributed applications domains. BCT characteristics, such as the distribution of data storage among independent nodes and the use of consensus algorithms offer immutability and transparency and remove the need for a central authority making BCT trustworthy. However, decision-makers and stakeholders currently lack the confidence to overcome uncertainty related to AI technology, which affects the acceptance of AI technology in wider application domains, such as the recruitment process. Furthermore, current research literature does not adequately investigate the role of trust as an integral part of an AI-based recruitment application. Therefore, this paper aims to investigate how emerging BCT and AI technologies can improve decision making and stakeholder trust in a job recruitment system that is traditionally focused on just human expert decision-making. In this paper we propose the design of a new solution for trusting AI in recruitment applications through the use of Blockchain Smart Contracts (TAIRA-BSC). TAIRA-BSC integrates Blockchain Smart Contracts (BSC) with the Data Lake (DL), Machine Learning (ML) and AI technologies in our AI Recruitment Model (AIRM) architecture. TAIRA-BSC improves transparency and interoperability in the recruitment process while protecting sensitive job candidate data and ensures data integrity delivery and traceability in the recruiting process through a verifiable decentralized ledger, i.e., the blockchain and associated smart contracts. The paper presents a discussion on the state-of-the-art of integrating AI with BCT focusing on how BCT can be used to bridge trust concerns with AI systems. We also present a conceptual architecture TAIRA-BSC proof of concept that is developed to serve as a foundation for future studies focused on enhancing trust in AI applications through the integration of BCT.","","978-1-6654-6104-7","10.1109/Blockchain55522.2022.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881829","Artificial intelligence (AI);Blockchain technology (BCT);recruiting;recruiting workflow;smart contracts;data exchange;secure;distributed ledger technology;transparency;AI trust;Data Lake (DL)","Uncertainty;Smart contracts;Decision making;Memory;Machine learning;Lakes;Blockchains","","2","","31","IEEE","19 Sep 2022","22-25 Aug. 2022","22-25 Aug. 2022","IEEE","IEEE Conferences"
"A big spatiotemporal streaming data architecture for smart city crisis monitoring using VGI","M. A. Ben Rhaiem; M. Selmi; I. R. Farah; A. Bouzeghoub","RIADI Laboratory, University Manouba, Manouba, Tunisia; RIADI Laboratory, University Manouba, Manouba, Tunisia; RIADI Laboratory, University Manouba, Manouba, Tunisia; Samovar Telecom SudParis, Institut Polytechnique de Paris, Paris",2022 2nd International Conference of Smart Systems and Emerging Technologies (SMARTTECH),"4 Aug 2022","2022","","","107","111","The exponential growth of human activities and the climate change put cities around the world in face of multiple risks and threats that led eventually to the emergence of a new urban model, which is the smart city resilience. Although being equipped with a myriad of connected smart devices and sensors, the smart city is still physically made up of buildings, roads, parks, industrial sites, shopping centers, etc. Therefore, location-based crisis management endorses a geospatial modeling strategy approach for major hazard data management in a smart city. Hence, spatial data remains always at the center of risk management processes. However, smart and resilient cities still strive to solve the imparity between the huge amounts of geospatial data generated mostly in real time in particular geographic user content contributions also known as Volunteered Geographic Information (VGI) and the delayed decision-making. In this paper, we reviewed major studies using VGI in big spatiotemporal data analytics in supporting smart city resilience. Then, we propose a vision of big spatiotemporal data architecture perquisites leveraging big data technologies, VGI and deep learning techniques for smart hazard management.","","978-1-6654-0973-5","10.1109/SMARTTECH54121.2022.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842436","Smart city resilience;Big spatiotemporal data;VGI;IoT;streaming processing","Smart cities;Roads;Urban planning;Hazards;Spatial databases;Spatiotemporal phenomena;Geospatial analysis;Climate change","","1","","24","IEEE","4 Aug 2022","9-11 May 2022","9-11 May 2022","IEEE","IEEE Conferences"
"Seamless Decision-Making in the Big Data Era: A Modular Approach to Integrating IoT, Cloud Computing, and Data Lakes","M. Zemmouri; F. Z. Laalam; O. Kazar; Y. Himeur; A. Oulefki; C. Toumi; W. Mansoor; S. Attala","Artificial Intelligence and Information Technologies Laboratory, Faculty of New Information and Communication Technologies, Kasdi Merbah Ouargla University, Ouargla, Algeria; Artificial Intelligence and Information Technologies Laboratory, Faculty of New Information and Communication Technologies, Kasdi Merbah Ouargla University, Ouargla, Algeria; Department of Computer Science - LINFI Laboratory, Mohamed Khider University, Biskra, Algeria; College of Engineering and Information Technology, University of Dubai, Dubai, UAE; Department of Computer Science, University of Sharjah, Sharjah, United Arab Emirates; Artificial Intelligence and Information Technologies Laboratory, Faculty of New Information and Communication Technologies, Kasdi Merbah Ouargla University, Ouargla, Algeria; College of Engineering and Information Technology, University of Dubai, Dubai, UAE; College of Engineering and Information Technology, University of Dubai, Dubai, UAE","2023 International Conference on Electrical, Communication and Computer Engineering (ICECCE)","27 Feb 2024","2023","","","1","6","The integration of big data with cutting-edge technologies like IoT and Cloud Computing has profoundly influenced various aspects of modern life, including everyday service processes. To facilitate data-driven decision-making, big data analytics—focused on identifying patterns, trends, and correlations in large data sets—is indispensable. While traditional statistical techniques are useful, new tools and infrastructures such as Hadoop, Spark, and NoSQL are essential to tackle big data challenges. However, modifying the existing environment can be impractical, especially in production settings, due to the need for significant investment and specialized expertise. This article presents a novel computational paradigm that adds a decision-making layer atop existing systems for data analysis, eliminating the need to alter the environment. The approach treats the current information system as a data lake and introduces a new data recovery layer through web services, drawing inspiration from big data technologies like MapReduce. This system offers the advantage of being modular, reusable, and universally compatible, making it an independent decisional framework that can work with any information system or data source.","","979-8-3503-6969-4","10.1109/ICECCE61019.2023.10442390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10442390","Big Data;Data Analysis;Data Science;Paradigm;Design Pattern","Cloud computing;Web services;Decision making;Big Data applications;Time factors;Task analysis;Information systems","","","","31","IEEE","27 Feb 2024","30-31 Dec. 2023","30-31 Dec. 2023","IEEE","IEEE Conferences"
"Participatory AI: Reducing AI Bias and Developing Socially Responsible AI in Smart Cities","G. Falco","Cyber Policy Center, Stanford University, Stanford, USA",2019 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC),"5 Dec 2019","2019","","","154","158","As smart cities evolve, artificial intelligence (AI) will increasingly be used to manage decisions for how cities operate. For everything from incarceration sentencing, city pension appropriation, surveillance and infrastructure management, AI will play a role. The author argues that implementing AI for a smart city should be decided similarly to how cities decide on major infrastructural planning projects. For both, there are social and ethical implications of deployment. A protocol is proposed for smart city AI so that AI can be seen as an ethical and trustworthy city asset rather than an adversary fraught with controversy and bias. This is achieved through participatory AI - the marriage of a fully transparent data architecture, such as the blockchain, and the urban planning practice of participatory planning. The diversity of opinions that participatory AI affords enables cities to facilitate socially responsible AI outcomes.","","978-1-7281-1664-8","10.1109/CSE/EUC.2019.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919542","Responsible AI, AI Bias, Participatory Planning, Blockchain, Smart Cities","Artificial intelligence;Planning;Smart cities;Surveillance;Autonomous agents;Decision making","","18","","18","IEEE","5 Dec 2019","1-3 Aug. 2019","1-3 Aug. 2019","IEEE","IEEE Conferences"
"AI-Powered Data Governance Models for Automated Compliance in Big Data Architectures","E. Sumalatha; B. K. Gudepu; S. Yadav","AuditSubbaraoVamanan &Co, Hyderabad, Telangana; Department of Information Technology, Developer 4, Systems Software at Kemper, USA; Shri Krishan Institute of Engineering and Technology, Kurukshetra University, Kurukshetra, India",2025 International Conference on Recent Innovation in Science Engineering and Technology (ICRISET),"28 Nov 2025","2025","","","1","6","The following paper presents a discussion of developing AI-Powered Data Governance Models of Automated Compliance in Big Data Architectures through Hybrid AI Models with Reinforcement Learning (RL) to be able to adapt in real-time. Taking advantage of the IBM Watson OpenScale, the study suggests a dynamic approach to best deal with the increased risks encountered in large-scale and complex data environments related to data governance and automation of data compliance. This hybrid AI model is also an integration of unsupervised and supervised learning that will allow the system to evolve along with the change of the regulations and streamline these processes of compliance with no manual work. The reinforcement learning constantly updates the model and therefore the compliance measures are always up to date with the regulations that keep changing. IBM Watson OpenScale improves the level of transparency in a system with the help of explainable AI, which enables trust and responsibility in the decision-making process. Compared to the existing solutions, the proposed idea shows considerable scalability gains, processing performance, and near-real-time adaptation, which makes it a fit possible solution to industries, where data compliance is essential, including finance, healthcare, and IoT.","","979-8-3315-5833-8","10.1109/ICRISET64803.2025.11252324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11252324","AI-powered data governance;automated compliance;hybrid AI models;reinforcement learning;real-time adaptation;IBM Watson OpenScale;big data architectures","Industries;Adaptation models;Biological system modeling;Reinforcement learning;Computer architecture;Big Data;Data models;Real-time systems;Regulation;Data governance","","","","16","IEEE","28 Nov 2025","1-2 Aug. 2025","1-2 Aug. 2025","IEEE","IEEE Conferences"
"Ontology for Structuring a Digital Databases for Decision Making in Grain Production","R. A. Neves; P. E. Cruvinel","Federal Institute of São Paulo, São João da Boa Vista, SP, Brazil; Post-Graduation Program in Computer Science - Federal University of São Carlos, SP, Brazil",2021 IEEE 15th International Conference on Semantic Computing (ICSC),"3 Mar 2021","2021","","","386","392","This paper presents an ontology for the structuring of digital databases with the objective of acting in a cloud environment and meeting big data sources in the agricultural context of grain production. Its conception is structured in three stages: the first stage presents an ontological architecture aimed at public and private cloud environments, the second stage deals with a semantic model at process level, and a pseudocode for ontological application is elaborated in the third stage, considering the technologies applied to the cloud. This work combines advanced features to support decision making from Data Lake storage solutions, semantic treatment of big data, as well as the presentation of strategies based on machine learning and data quality analysis to obtain data and metadata organized for application in a decision model. The configuration of the ontology presented meets the diversity of big data projects in the grain production context, the characteristics of which are based on interoperability in the use of heterogeneous data and its integration, elasticity of computational resources, and high availability of cloud access.","2325-6516","978-1-7281-8899-7","10.1109/ICSC50631.2021.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364425","Ontology;Agriculture;Digital Database;Cloud Computing;Big Data;Decision Making","Cloud computing;Databases;Semantics;Decision making;Production;Ontologies;Big Data","","1","","33","IEEE","3 Mar 2021","27-29 Jan. 2021","27-29 Jan. 2021","IEEE","IEEE Conferences"
"A Big Data Architecture for Digital Twin Creation of Railway Signals Based on Synthetic Data","G. Salierno; L. Leonardi; G. Cabri","Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy; Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy; Department of Physics, Informatics and Mathematics, University of Modena and Reggio Emilia, Modena, Italy",IEEE Open Journal of Intelligent Transportation Systems,"18 Jul 2024","2024","5","","342","359","Industry 5.0 has introduced new possibilities for defining key features of the factories of the future. This trend has transformed traditional industrial production by exploiting Digital Twin (DT) models as virtual representations of physical manufacturing assets. In the railway industry, Digital Twin models offer significant benefits by enabling anticipation of developments in rail systems and subsystems, providing insight into the future performance of physical assets, and allowing testing and prototyping solutions prior to implementation. This paper presents our approach for creating a Digital Twin model in the railway domain. We particularly emphasize the critical role of Big Data in supporting decision-making for railway companies and the importance of data in creating virtual representations of physical objects in railway systems. Our results show that the Digital Twin model of railway switch points, based on synthetic data, accurately represents the behavior of physical railway switches in terms of data points.","2687-7813","","10.1109/OJITS.2024.3412820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554659","Big data;digital twin;machine learning;synthetic data;railway industry;artificial intelligence","Rail transportation;Switches;Digital twins;Big Data;Data models;Computer architecture;Synthetic data;Machine learning;Artificial intelligence;Computer architecture","","10","","30","CCBY","11 Jun 2024","2024","","IEEE","IEEE Journals"
"6G Enabled Smart Environments and Sustainable Cities: an Intelligent Big Data Architecture","E. M. Ouafiq; R. Saadane; A. Chehri; M. Wahbi","SIRC/LaGeS-EHTP, EHTP Km 7 Route, El Jadida, Morocco; SIRC/LaGeS-EHTP, EHTP Km 7 Route, El Jadida, Morocco; University of Quebec in Chicoutimi, Chicoutimi, QC, Canada; SIRC/LaGeS-EHTP, EHTP Km 7 Route, El Jadida, Morocco",2022 IEEE 95th Vehicular Technology Conference: (VTC2022-Spring),"25 Aug 2022","2022","","","1","5","Nowadays, there is an important need for fault-tolerant and energy-efficient self-organization systems, especially within smart cities. Internet of Things (IoT) proved capable of observing and examining the environment, generating & processing data. IoT is now applicable to almost every industry, including transportation and logistics, utilities, agriculture, smart cities, and more. In these industries, various types of meters, sensors, and trackers are used to constantly monitor activities, automate processes and optimize tasks. With the help of big data analytics, they can drive decision-making systems based on observations. As a result, the cities-management challenges are growing. The smart cities requirements are increasing to remedy the challenges, which requires a self-organized network composed of a sizeable number of nodes distributed across an area of interest. The traditional communication systems show limitations, especially when dealing with massive data rates, latency, the explosive growth of vehicular communication, and dynamic mobility. In this study, we explore a way to leverage the capabilities of wireless communication and big data analytics in favor of Smart Cities.","2577-2465","978-1-6654-8243-1","10.1109/VTC2022-Spring54318.2022.9860772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9860772","Big Data;Data Science;Smart City;Smart Farming;Wireless Network;5G;6G","Temperature sensors;Temperature measurement;Wireless sensor networks;Smart cities;Big Data;Agriculture;Internet of Things","","9","","18","IEEE","25 Aug 2022","19-22 June 2022","19-22 June 2022","IEEE","IEEE Conferences"
"Model for Semantic Base Structuring of Digital Data to Support Agricultural Management","R. A. Neves; P. E. Cruvinel","Embrapa Instrumentation S??o Carlos, SP, Brazil; Embrapa Instrumentation S??o Carlos, SP, Brazil",2020 IEEE 14th International Conference on Semantic Computing (ICSC),"12 Mar 2020","2020","","","337","340","This article presents a semantic model for structuring digital databases to function in a cloud environment and connect to data sources originating from Big Data. The work examines the process of receiving structured, semi-structured and unstructured data for use in agricultural risk management. It is conceived as an architecture that combines Data Mart, Data Warehouse (NoSQL), and Data Lake resources to support decision making, through knowledge discovery and applies algorithms for data mining by machine learning resources. The configuration presented addresses scenarios involving agricultural data, obtained from sensors operating in multiple modes.","2325-6516","978-1-7281-6332-1","10.1109/ICSC.2020.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031490","semantic model, agricultural management, cloud, structuring digital databases","Semantics;Databases;Unified modeling language;Data models;Big Data;Data mining;Computer architecture","","4","","16","IEEE","12 Mar 2020","3-5 Feb. 2020","3-5 Feb. 2020","IEEE","IEEE Conferences"
"AI-optimized data Lakes for Real-Time Big Data Management and Autonomous Query Optimization","G. Ramesh; N. V. Sivareddy; L. H. Jasim; P. Murugeswari; B. Kumaraswamy; M. L","Department of CSE, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, Telangana, India; Department of Computer Science and Engineering, CMR Institute of Technology, Hyderabad; Department of Computers Techniques Engineering, College of Technical Engineering, The Islamic University, Najaf, Iraq, Al Diwaniyah, Iraq; Department of Electrical Communication Engineering, Sethu Institute of Technology, Pulloor, Kariapatti, Tamil Nadu, India; Department of CS & IT, Kalinga University, Raipur, India; Department of Mathematics, Saveetha Institute of Medical and Technical Sciences, Chennai, Tamilnadu, India",2025 International Conference on Metaverse and Current Trends in Computing (ICMCTC),"17 Oct 2025","2025","","","1","5","Due to the massive explosion of big data, efficient data lakes with ‘real-time’ data management and ‘autonomous’ query optimization have become inevitable. One of the problems attached to traditional data lakes is the difficulty of retrieving data, which is slow to query, inefficiently, and with high complexities of schema evolution the ability of the data lake to optimize workloads dynamically. To overcome these problems, the work presented in this paper brings forward the concept of an AI-optimized data lake framework that exploits machine learning and deep learning for intelligent data ingestion, adaptive indexing as well as self-optimizing query execution. The system is proposed to incorporate hierarchical storage management with AI-driven, self-studying indexing mechanisms, and reinforcement learning-aided query optimization to improve data retrieval efficiency. Furthermore, through an integrated AI-powered anomaly detection system, data processing is made robust and reliable in real time. On top of that the framework also involves autonomous governance and security that can use explainable AI for compliance auditing and a dynamic role-based access control (RBAC). Experimental evaluations show that, with up to a 90% time saving, and with real-time decision-making capabilities, it improves over both aspects in a variety of data workloads. This research brings forth the integration of AI-based optimizations for the development of a broad and flexible framework for intelligently and scaleably building large data lake architectures, thus becoming the future-ready solution for any big data ecosystem within healthcare, financial, or IoT-based smart systems.","","979-8-3315-3821-7","10.1109/ICMCTC62214.2025.11196397","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11196397","Role-based access control;AI-driven;Healthcare;Hadoop Distributed File System","Access control;Data ingestion;Accuracy;Query processing;Storage management;Medical services;Big Data applications;Real-time systems;Anomaly detection;Indexing","","","","14","IEEE","17 Oct 2025","10-11 April 2025","10-11 April 2025","IEEE","IEEE Conferences"
"Machine Learning Techniques for Enhancing Maritime Surveillance Based on GMTI Radar and AIS","K. Dästner; B. von Haßler zu Roseneckh-Köhler; F. Opitz; M. Rottmaier; E. Schmid","AIRBUS, Wörthstraße 85, Ulm, Germany; AIRBUS, Wörthstraße 85, Ulm, 89077, Germany; AIRBUS, Wörthstraße 85, Ulm, Germany; AIRBUS, Wörthstraße 85, Ulm, Germany; AIRBUS, Wörthstraße 85, Ulm, Germany",2018 19th International Radar Symposium (IRS),"30 Aug 2018","2018","","","1","10","Classical maritime surveillance systems are enhanced with disruptive elements comingf om big data and machine learning. Available receiver networks deliver a huge amount of worldwide maritime traffc data. The information includes the position as well as signifcant attributes of all vessels, which are equipped with AIS. The processing of this data lake with modern machine learning and big data techniques offer improved decision support for the user. This is especially the case, when AIS is not available and only sensor information, e.g., GMTI is gathered. New design concepts – e.g. the lambda architecture offer the modular integration of these new assets within existing surveillance systems.","2155-5753","978-3-7369-9545-1","10.23919/IRS.2018.8447961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447961","","Marine vehicles;Surveillance;Machine learning;Clustering algorithms;Big Data;Radar","","12","","20","","30 Aug 2018","20-22 June 2018","20-22 June 2018","IEEE","IEEE Conferences"
"8 Smart grid–based big data analytics using machine learning and artificial intelligence: a survey","S. Koshy; S. Rahul; R. Sunitha; E. P. Cheriyan",NA; NA; NA; NA,Artificial Intelligence and Internet of Things for Renewable Energy Systems,"","2022","","","241","278","Exhilarating developments in the renewable energy generation portfolio and the widespread introduction of microgrids have contributed to significant reforms in the existing power grid’s power flow patterns. Power grids around the world have upgraded to smart grid (SG) by introducing advanced monitoring technologies such as Advanced Metering Infrastructure (AMI), smart meters and Phasor Measurement Units (PMUs), which collect high-resolution electrical measurements across the system. This has brought in a massive amount of data, termed big data, that needs to be efficiently processed to derive valuable insights. Specifically, technical sophistication, security, and integration of datasets are the main concerns that need to be tackled to transform the massive dataset into useful insights. This chapter surveys big data analytics (BDA) and its related benefits, challenges, and advancements in SG’s perspective. BDA in combination with visualization tools, help in the predictive decision-making process in the SG. Thus, data analytics play a significant part in the efficient monitoring of the SG. Powered with the integration of information and communication technologies, an information layer has been introduced to the traditional power systems to collect, store, and process data from smart meters and sensor implementations. Big data architecture involves data aggregation, storing, and analytics, which integrates the SG’s need for a range of frameworks with outstanding computational skills to respond to the customer’s needs. Characterization of big data, SGs, and massive volumes of data processing is first addressed as a preface to demonstrate the motivation and possible benefits of integrating advanced data mining in smart grids. Specific principles and standard data analytics techniques for general concerns are also discussed. The chapter’s key section discusses the advanced uses of various data analytics in SG, leveraging machine learning (ML) and artificial intelligence (AI). SG is benefited from the inherent capacity of ML to generalize, delivering reliable and quick power flow predictions from dispersed measurement units, with superior computing performance and interoperability. The chapter explores numerous literary works that utilize various ML methods to enhance SG activity and management. We will present big data analytics and cloud infrastructure in this chapter and address their importance to SG. Specifically, we would concentrate on relevant computational concerns and solutions linked to SG cyber-physical protection and safety.","","9783110714159","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10789589.pdf&bkn=10783464&pdfType=chapter","","Big Data;Power system reliability;Monitoring;Renewable energy sources;Real-time systems;Electrical engineering;Telecommunication network reliability;Smart grids;Power system stability;Load flow","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"Omnichannel Retail Analytics: A Scalable Big Data Architecture Using Data Vault 2.0 and Apache Spark for Retail Intelligence","U. Kumar; D. Krishnamoorthy; R. Ghadiyaram",NA; NA; NA,2025 IEEE Conference on Cloud and Big Data Computing (CBDCom),"23 Jan 2026","2025","","","207","212","Retailers often struggle to integrate data from disparate sources such as their eCommerce platforms, physical stores, and inventory systems. This fragmentation hampers timely decision-making, creates inconsistent customer experiences, and complicates regulatory compliance. To address these challenges, this paper proposes a scalable, intelligent data warehousing architecture for retail applications utilizing Data Vault 2.0 in conjunction with Apache Spark. This innovative framework facilitates the aggregation, management, and analysis of omnichannel data, ensuring flexibility, traceability, and scalability. A synthetic simulation, based on representative retail data, validates the architecture's performance and adaptability. The integration of Data Vault 2.0 and Apache Spark provides a powerful solution for managing and analyzing retail data, empowering retailers to derive rapid insights and respond swiftly to market dynamics.","","979-8-3315-9094-9","10.1109/CBDCom68404.2025.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11344184","Data Vault 2.0;Apache Spark;Data Warehousing;eCommerce;Retail;POS;ETL;Omnichannel;Big Data;Intelligent Systems;Retail Analytics","Scalability;Warehousing;Decision making;Cluster computing;Computer architecture;Big Data;Electronic commerce;Intelligent systems","","","","16","IEEE","23 Jan 2026","21-24 Oct. 2025","21-24 Oct. 2025","IEEE","IEEE Conferences"
"Implementation of RAG-LLM Based AI Agents for Public Service Innovation: RAG System Architecture Analysis and A Cross-National Case Study","J. Ryu; Y. Woo; K. Lee","Ph.D. Candidate of the Graduate Program in IT Policy and Management, Soongsil University, Seoul, Republic of Korea; School of Public Administration, Soongsil University, Seoul, Republic of Korea; Ph.D. Student of the Graduate Program in IT Policy and Management, Soongsil University","2025 IEEE/ACIS 29th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","28 Nov 2025","2025","","","308","321","The rapid adoption of Retrieval-Augmented Generation (RAG) integrated with Large Language Models (LLMs) is transforming public sector services by addressing the limitations of conventional AI, such as outdated knowledge, hallucination, and regulatory compliance challenges. This study investigates the transformative potential of Retrieval-Augmented Generation integrated with Large Language Models (RAG-LLM) in public service innovation through architectural analysis and cross-national case studies of Estonia, Singapore, and the European Union. By examining RAG-LLM implementations across legal, administrative, and multilingual domains, the research identifies critical success factors in governance models, interoperability frameworks, and data standardization.Key findings reveal that centralized architectures (Estonia’s Kratt ecosystem, Singapore’s AIBots) enable rapid scaling through unified standards, while federated models (EU’s cross-border system) balance sovereignty with collaboration. Hybrid retrieval strategies-combining keyword-based and semantic search-and domain-specific embeddings reduce hallucinations by up to 63%, ensuring compliance and accuracy in high-stakes scenarios. Operational efficiencies are significant: Estonia processes 1.2M monthly queries with 89% resolution rates, Singapore automates 40% more citizen inquiries, and the EU reduces permit processing from six weeks to three days. Citizen satisfaction rates (82–98%) correlate with transparency features (source citations, multilingual support) and inclusive design.The study underscores that RAG-LLM systems act as force multipliers for public sector innovation when supported by adaptive governance, continuous data quality management, and standardized evaluation metrics. Challenges persist in generalizability to less digitized contexts, ethical governance, and evolving regulatory landscapes. Policy recommendations emphasize interoperability frameworks, domain-tuned standardization, and human-AI collaboration to realize scalable, trustworthy, and citizen-centric services.","2693-8421","979-8-3315-1258-3","10.1109/SNPD65828.2025.11252835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11252835","Retrieval-Augmented Generation;public sector AI;interoperability;digital governance;citizen-centric services;cross-national case study","Technological innovation;Law;Large language models;Retrieval augmented generation;Europe;Collaboration;Data models;Multilingual;Artificial intelligence;Interoperability","","","","16","IEEE","28 Nov 2025","25-27 June 2025","25-27 June 2025","IEEE","IEEE Conferences"
"An Novel Approach in Designing a Security Workbench with Deep Learning Capabilities and Process Automation","S. Vijayakumar; K. S. P. Gowtham; N. Nigam; R. V. R. Singh","Hitech DET, TATA Consultancy Services, Coimbatore, India; Hitech DET, TATA Consultancy Services, Coimbatore, India; Hitech DET, TATA Consultancy Services, Lucknow, India; Hitech DET, TATA Consultancy Services, Lucknow, India",TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON),"12 Dec 2019","2019","","","263","268","To start with a proverb “It takes 20 years to build a reputation and few minutes of cyber-incident to ruin it” by Stephane Nappo. The number of cyber security attack over the Internet and Network is growing exponentially every day. The conventional approach of detecting malicious activity through the blacklists and controlling their access at the organization level not going to be effective in the near future. It is necessary to apply novel approaches based on Artificial Intelligence (AI) and Deep Learning (DL) techniques to detect cyber security attack pattern and bring down the time to react with seamless automation process. The challenge is to build a Deep Learning Model to predict the next sequence of attack pattern from different digital sources and zones is not automated traditionally, decision making for the security analysts and right solution recommendation from previous knowledge is a nightmare for large enterprise in the era towards uncompromised “Digital World”. Proposed security workbench will bring in the advanced analytical capabilities, intelligence and automation in cyber security attack detection and security fix process automation.","2159-3450","978-1-7281-1895-6","10.1109/TENCON.2019.8929691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8929691","Cyber Security;Security Workbench;Data Lake;Machine Learning;Deep Learning;Automation","Security;Predictive models;Machine learning;Training;Automation;Computer architecture;Analytical models","","","","11","IEEE","12 Dec 2019","17-20 Oct. 2019","17-20 Oct. 2019","IEEE","IEEE Conferences"
"Developing a Prototype Healthcare Data Platform for Advanced Analytics in Rehabilitation Environments","A. Foschi; D. Pistilli; G. Bondani; F. Rebecchi","R&D, Eustema S.p.A., Rome, Italy; R&D, Eustema S.p.A., Rome, Italy; R&D, Eustema S.p.A., Rome, Italy; R&D, Eustema S.p.A., Rome, Italy",2024 IEEE 8th Forum on Research and Technologies for Society and Industry Innovation (RTSI),"26 Nov 2024","2024","","","369","374","The rapid evolution of digital systems in the healthcare sector presents a significant opportunity to enhance rehabilitation outcomes through advanced analytics and personalized treatments. This advancement enables healthcare professionals to tailor rehabilitation programs to the individual needs of patients, leading to more effective and efficient recovery processes. Considering this, this paper introduces a prototype of data platform specifically designed to harness the potential of digital technology in the rehabilitation domain. The platform concept proposed herein integrates advanced data management tools and machine learning algorithms in order to leverage the vast amounts of data generated by healthcare devices. Specifically, the main purpose of this platform is to improve rehabilitation processes by offering tailored, data-driven insights that support healthcare professionals in making informed decisions. Utilizing open-source components, the prototype aims to demonstrate interoperability, scalability, and efficiency in processing and analyzing complex rehabilitation datasets. This paper concentrates on the architectural design, the plan for implementation, and the expected challenges and their solutions in the development of this platform. Additionally, it outlines the original contributions of the research, including advancements in data management techniques and interoperability standards. The prototype discussed here is developed as part of the “Fit4MedRob” initiative, a scientific project sponsored by the Italian Ministry of University and Research, that aims to overhaul rehabilitative models for individuals with compromised motor and cognitive functions through cutting-edge bio robotic technologies. This initiative spans a total of 44 months and seeks to address the unmet needs of patients and healthcare providers with innovative robotic and digital technologies.","2687-6817","979-8-3503-6213-8","10.1109/RTSI61910.2024.10761573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10761573","healthcare data platform;rehabilitation technology;hl7 fhir;data interoperability;data anonymization;healthcare data lake;clinical trials;decision support system","Technological innovation;Data analysis;Scalability;Prototypes;Medical services;Motors;Protection;Robots;Interoperability;Standards","","","","36","IEEE","26 Nov 2024","18-20 Sept. 2024","18-20 Sept. 2024","IEEE","IEEE Conferences"
"Evaluating the Quality of Social Media Data in Big Data Architecture","A. Immonen; P. Pääkkönen; E. Ovaska","VTT Technical Research Centre of Finland, Oulu, Finland; VTT Technical Research Centre of Finland, Oulu, Finland; VTT Technical Research Centre of Finland, Oulu, Finland",IEEE Access,"20 May 2017","2015","3","","2028","2043","The use of freely available online data is rapidly increasing, as companies have detected the possibilities and the value of these data in their businesses. In particular, data from social media are seen as interesting as they can, when properly treated, assist in achieving customer insight into business decision making. However, the unstructured and uncertain nature of this kind of big data presents a new kind of challenge: how to evaluate the quality of data and manage the value of data within a big data architecture? This paper contributes to addressing this challenge by introducing a new architectural solution to evaluate and manage the quality of social media data in each processing phase of the big data pipeline. The proposed solution improves business decision making by providing real-time, validated data for the user. The solution is validated with an industrial case example, in which the customer insight is extracted from social media data in order to determine the customer satisfaction regarding the quality of a product.","2169-3536","","10.1109/ACCESS.2015.2490723","Tekes and VTT through the DIGILE’s Need for Speed Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299603","architecture;big data;metadata;quality attribute;quality of data;Architecture;big data;metadata;quality attribute;quality of data","Big data;Social network services;Computer architecture;Meta data;Online services","","94","","52","OAPA","16 Oct 2015","2015","","IEEE","IEEE Journals"
"Connection of Dynamic and Static Data: A Data Lake for Building Digitalisation","J. L. Hernández; D. Arévalo; S. Martín; K. Katsigarakis; G. N. Lilis; D. Rovas; I. De Miguel","Energy Division, CARTIF technology centre, Boecillo, Spain; Energy Division, CARTIF technology centre, Boecillo, Spain; Energy Division, CARTIF technology centre, Boecillo, Spain; IEDE University College London, London, UK; IEDE University College London, London, UK; IEDE University College London, London, UK; Universidad de Valladolid, Valladolid, Spain",2024 IEEE International Workshop on Metrology for Living Environment (MetroLivEnv),"6 Aug 2024","2024","","","262","267","The landscape of building data is expanding, with heterogeneous sources that are often treated as isolated silos across different building domains such as energy, architecture elements, or automation networks. This siloed approach creates a lock-in scenario, limiting the potential for effective data exploitation, including the provision of added-value services, artificial intelligence, or machine-learning activities. To overcome this challenge, ensuring data integration through interoperability mechanisms becomes crucial within building data management frameworks. In line with this perspective, this work introduces a data lake that harmonizes heterogeneous data sources from various building domains. The primary goal is to standardize datasets, ensuring the delivery of high-quality services to facilitate better decision-making. These datasets are enriched by interactions between static and dynamic datasets. This holistic approach aims to break down silos and unlock the full potential of building data for informed decision-making processes.","","979-8-3503-8501-4","10.1109/MetroLivEnv60384.2024.10615827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615827","","Soft sensors;Buildings;Semantics;Decision making;Sociology;Data collection;Big Data applications","","","","13","IEEE","6 Aug 2024","12-14 June 2024","12-14 June 2024","IEEE","IEEE Conferences"
"Empowering the Tribal people with the use of big data processing expert system in animal Husbandry and Poultry Farming application","R. Saravanan; V. Nehru; S. Muthuselvi","Department of Computer Science & Engineering, Vel Tech Multi Tech Dr. Rangarajan & Dr. Sakunthala Engineering College, Chennai, Avadi, India; Department of Computer Science & Engineering, Vel Tech Multi Tech Dr. Rangarajan & Dr. Sakunthala Engineering College, Chennai, Avadi, India; Department of Computer Science & Engineering, Vel Tech Multi Tech Dr. Rangarajan & Dr. Sakunthala Engineering College, Chennai, Avadi, India","2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)","3 Jan 2024","2023","","","1","8","The population of the tribal people has been decreased day by day in India due to the lack of awareness in health related issues and there is a series challenges in their sustainable livelihood. The Particularly Vulnerable People from tribal groups (PVTGs) engaged in animal husbandry and poultry farming as their primary source of income, which improves their standard of living. Maintain and safeguard poultry and animals from diseases is a cumbersome process. Providing enough medical facility is still a challenging task due to the geographical location and unavailability of the infrastructure and human resources. The proposed framework uses Apache Kafka-Apache Storm-NoSQL Mongo DB architecture to process enormous volume of sensor data in real time and it receives the sensor data and uses it to create the various disease identification models. The processed data are stored in Mongo DB as a historical data. The system provides a Web-based monitoring system for continuos monitoring the health conditions of cattles and poultry through the Smart Health Care Centre. Smartness in operation is performed through System on Chip (SoC) IoT system, the proposed big data expert system model transcends from the traditional functionalities of disease identification by the real time field visit analysis by the medical professionals. The proposed system is more suitable for the remote hill area. Smart Health Care system improves the disease identification accuracy and provides a powerful Big Data architecture for data analytics and data storage. The big data expert system frame work is underwent successful functional testing of ""SoC-IoT smart devices"" connected with the network and the performance of the network in terms of CPU, memory usage and the network delay is analyzed. Further the frame work uses the big data processing with the machine learning approach ""Hybrid diseases identification Model"" with the combination of DBSCAN for outlier detection together with Random Forest classification, which improves the disease identification accuracy of the various disease attacked the cattles and poultry.","","979-8-3503-0570-8","10.1109/RMKMATE59243.2023.10369174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10369174","Apache Kafka;Apache Storm;Mongo DB;DBSCAN;Random Forest","Animals;Smart healthcare;Big Data;Data models;Real-time systems;Expert systems;Monitoring","","","","9","IEEE","3 Jan 2024","1-2 Nov. 2023","1-2 Nov. 2023","IEEE","IEEE Conferences"
"Artificial Intelligence in Finance: Coffee Commodity Trading Big Data for Informed Decision Making","N. -B. -v. Le; Y. -S. Seo; J. -H. Huh","Department of Data Informatics, National Korea Maritime and Ocean University, Busan, Republic of Korea; School of Computer Science and Engineering, Yeungnam University, Gyeongsan, Republic of Korea; Interdisciplinary Major of Ocean Renewable Energy Engineering, National Korea Maritime and Ocean University, Busan, Republic of Korea",IEEE Access,"10 Jul 2024","2024","12","","91780","91792","Coffee, the second-largest global soft commodity, can take advantage of a comprehensive mining of daily and historical market data for more effective informed trading decisions. Advanced ICT and data mining technologies can change the trading market operation. The existing systems are confronted with certain constraints, including incomplete data, insufficient documentation for storage, and a requirement for a scalable infrastructure for big data analytics, such as a data warehouse or data lakehouse. To address this issue, the paper presents a design and implementation of a coffee commodity trading big data warehouse capable of analyzing various essential parameters for supporting informed decision-making. First, the designed system can automatically collect coffee trading data for New York Arabica coffee futures prices from selected worldwide reports and financial data portals. Next, the Extract, transform, and load (ETL) process is adopted to ingest coffee futures trading crawled data into the 3 layers data warehouse. Finally, the analytical system will extract and visualize selected key dimensions that influence coffee futures prices within different observation windows and perspectives. As a result, we implement a prototype of a coffee trading data warehouse on the crawled data from January 2000 to October 2022 and visualize trends in coffee futures prices based on the collected data for informed decision-making. The construction system is capable of stably operating and processing large volumes of transaction data. This paper will be valuable documentation for reference and decision support for coffee commodity trading enterprises and contribute to the development of future forecasting algorithms.","2169-3536","","10.1109/ACCESS.2024.3409762","National Research Foundation of Korea (NRF); Korea Government (MSIT)(grant numbers:NRF-2023R1A2C1008134); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549867","Coffee big data;data warehouse;coffee commodity trading;ETL process;informed decision-making;data visualization;big data","Data warehouses;Contracts;Data visualization;Predictive models;Data models;Data mining;Big Data;Market research;Pricing;Stock markets;Financial services","","6","","40","CCBYNCND","5 Jun 2024","2024","","IEEE","IEEE Journals"
"Data Engineering with AWS: Learn how to design and build cloud-based data transformation pipelines using AWS","G. Eagar",NA,Data Engineering with AWS: Learn how to design and build cloud-based data transformation pipelines using AWS,"","2021","","","","","The missing expert-led manual for the AWS ecosystem — go from foundations to building data engineering pipelines effortlessly Purchase of the print or Kindle book includes a free eBook in the PDF format.Key FeaturesLearn about common data architectures and modern approaches to generating value from big dataExplore AWS tools for ingesting, transforming, and consuming data, and for orchestrating pipelinesLearn how to architect and implement data lakes and data lakehouses for big data analytics from a data lakes expertBook DescriptionWritten by a Senior Data Architect with over twenty-five years of experience in the business, Data Engineering for AWS is a book whose sole aim is to make you proficient in using the AWS ecosystem. Using a thorough and hands-on approach to data, this book will give aspiring and new data engineers a solid theoretical and practical foundation to succeed with AWS. As you progress, you’ll be taken through the services and the skills you need to architect and implement data pipelines on AWS. You'll begin by reviewing important data engineering concepts and some of the core AWS services that form a part of the data engineer's toolkit. You'll then architect a data pipeline, review raw data sources, transform the data, and learn how the transformed data is used by various data consumers. You’ll also learn about populating data marts and data warehouses along with how a data lakehouse fits into the picture. Later, you'll be introduced to AWS tools for analyzing data, including those for ad-hoc SQL queries and creating visualizations. In the final chapters, you'll understand how the power of machine learning and artificial intelligence can be used to draw new insights from data. By the end of this AWS book, you'll be able to carry out data engineering tasks and implement a data pipeline on AWS independently.What you will learnUnderstand data engineering concepts and emerging technologiesIngest streaming data with Amazon Kinesis Data FirehoseOptimize, denormalize, and join datasets with AWS Glue StudioUse Amazon S3 events to trigger a Lambda process to transform a fileRun complex SQL queries on data lake data using Amazon AthenaLoad data into a Redshift data warehouse and run queriesCreate a visualization of your data using Amazon QuickSightExtract sentiment data from a dataset using Amazon ComprehendWho this book is forThis book is for data engineers, data analysts, and data architects who are new to AWS and looking to extend their skills to the AWS cloud. Anyone new to data engineering who wants to learn about the foundational concepts while gaining practical experience with common data engineering services on AWS will also find this book useful. A basic understanding of big data-related topics and Python coding will help you get the most out of this book but it’s not a prerequisite. Familiarity with the AWS console and core services will also help you follow along.","","9781800569041","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10162399.pdf&bkn=10162399&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"DLAQP: A Data Lake-Based Healthcare Approximate Query Processing Framework","J. Guo; T. Liu; K. Wen; C. Xia; K. Chao; J. Li","Software Engineering College, Henan University, Kaifeng, China; Software Engineering College, Henan University, Kaifeng, China; Software Engineering College, Henan University, Kaifeng, China; Kaifeng 155 Hospital, Kaifeng, China; Software Engineering College, Henan University, Kaifeng, China; Software Engineering College, Henan University, Kaifeng, China",2025 6th International Conference on Computer Vision and Data Mining (ICCVDM),"18 Dec 2025","2025","","","407","413","Efficient exploration of healthcare data is essential for clinical research and data-driven medical decision-making. However, traditional exact query methods often fall short in handling large-scale, complex medical datasets due to performance limitations. Approximate Query Processing (AQP), which improves efficiency by tolerating a bounded error, has shown great promise in this context. Yet, existing AQP techniques often fail to deliver satisfactory accuracy on medical data, largely due to challenges such as skewed distributions and weak attribute correlations that undermine the effectiveness of generalpurpose sampling. To address these issues, we propose DLAQP, a datalake-based approximate query processing system tailored for healthcare data. It employs adaptive sampling to improve sample representativeness and leverages a Variational Autoencoder (VAE) to generate high-quality samples. Experimental results show that, compared to traditional methods, DLAQP reduces query error by an average of 60% while maintaining comparable query latency. The system has been validated on real-world medical datasets, further demonstrating its effectiveness and practical value in actual healthcare data analysis scenarios.","","979-8-3315-6621-0","10.1109/ICCVDM66874.2025.11290516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11290516","Approximate Query Processing;Conditional variational auto-encoder;machine learning;Aggregate Query","Computer vision;Data analysis;Correlation;Query processing;Aggregates;Decision making;Autoencoders;Medical services;Machine learning;Data mining","","","","18","IEEE","18 Dec 2025","12-14 Sept. 2025","12-14 Sept. 2025","IEEE","IEEE Conferences"
"Characterising IoT for Smart development: Anaylsing the challenges","S. Malhotra; V. Agarwal; M. Anjum; A. Parashar","Fortune Institute of International Business, New-Delhi, India; Amity International Business School, Amity University Uttar Pradesh, Noida, India; Amity Institute of Information Technology, Amity University Uttar Pradesh, Noida, India; Amity International Business School, Amity University Uttar Pradesh, Noida, India",2023 3rd International Conference on Innovative Practices in Technology and Management (ICIPTM),"10 May 2023","2023","","","1","5","Industry 4.0 is all about putting industrial data from multiple sources into a data lake and then using analytics, artificial intelligence, machine learning to utilize the data for businesses. The primary reason for that is the advent of the Internet of Things (IoT). IoT has enabled uninterrupted sharing and exchange of data for its users from the consumer to the industrial level. Although still in the nascent stage of evolution, IoT has the potential to significantly impact business outcomes and will be instrumental in bringing a transformation in the way we communicate and exchange information. However, there remains a considerable gap in identifying the challenges in the implementation of IoT platforms and techniques. This paper aims at presenting a comprehensive analysis of the major challenges in the implementation of IoT and classifies them into two broad categories-technological and managerial according to the opinions of the experts. An attempt has been made herein to create a hierarchy depicting the key challenges where the researchers and industry should focus their attention and make better strategic decisions. A multi-criteria decision-making method known as the Best-Worst Method (BWM) has been used to rate the challenges. Results show that power requirement is the major challenge in technological challenges and maintenance is the major challenge in managerial challenges.","","979-8-3503-3623-8","10.1109/ICIPTM57143.2023.10118284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10118284","IoT;Internet of Things;Challenges in Implementation;Best-Worst Method","Industries;Protocols;Biological system modeling;Mashups;Energy resolution;Standardization;Maintenance engineering;Internet of Things;Smart devices;Business","","1","","13","IEEE","10 May 2023","22-24 Feb. 2023","22-24 Feb. 2023","IEEE","IEEE Conferences"
"Data-Driven Transformation in Investment Banks","B. Iraqi; L. Benhiba; M. A. Janati Idrissi","ENSIAS Mohammed V University in Rabat, Rabat, Morocco; ENSIAS Mohammed V University in Rabat, Rabat, Morocco; ENSIAS Mohammed V University in Rabat, Rabat, Morocco",2023 IEEE 6th International Conference on Cloud Computing and Artificial Intelligence: Technologies and Applications (CloudTech),"29 Dec 2023","2023","","","01","09","Digital transformation has become a major concern to all companies, and with data being at the center of this transformation, enterprises are increasingly shifting to a data-driven transformation where decision-making is based on facts and data. In sectors where data has always been in the center of all work processes, such as investment banking, data-driven transformation has even more importance as it allows a more tangible result generation. This paper aims to provide guidance to investment banks on their data-driven transformation journey by providing insights on the target culture, the patterns that could be adopted and phases that should be followed to roadmap this transformation. The paper also discusses when data architecture work starts, its drivers, challenges and risks to mitigate in order to ensure the highest performance levels possible. The objective is to getbetter sense of all dimensions to inspire investment banks to engage in this process.","","979-8-3503-0306-3","10.1109/CloudTech58737.2023.10366132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366132","investment banking;data analytics;data-driven transformation;data-driven enterprise;data architecture","Cloud computing;Data analysis;Digital transformation;Decision making;Computer architecture;Companies;Banking","","1","","19","IEEE","29 Dec 2023","21-23 Nov. 2023","21-23 Nov. 2023","IEEE","IEEE Conferences"
"A Comprehensive Survey on Advanced Data Science Platforms for Cyber-Physical Systems, Digital Twins, and Robotics","R. Kabir; Y. Watanobe; D. Ding; M. Rashedul Islam; K. Naruse","School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Fukushima, Japan; School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Fukushima, Japan; School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Fukushima, Japan; Department of Computer Science and Engineering, University of Asia Pacific, Dhaka, Bangladesh; School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Fukushima, Japan",IEEE Access,"22 Oct 2025","2025","13","","177269","177304","The integration of Cyber-Physical Systems (CPS), Digital Twins (DT), and robotics with Advanced Data Science Platforms (ADSP) is rapidly transforming industrial and research landscapes by enabling real-time data processing, intelligent decision-making, and enhanced automation. Over the past decades, with the growing demand for adaptable, expandable, and secure platforms, numerous groundbreaking studies have emerged in the field of ADSP for CPS, DT, and robotics. However, most existing research addresses isolated aspects of AI, CPS, DTs, or robotics, lacking a holistic view of how ADSP expands and optimizes these technologies. To address this gap, this survey provides a comprehensive and structured review of the existing methodologies, tools, and techniques at each step of the ADSP workflow, focusing on their applications in CPS, DT, and robotics. Firstly, this survey analyzes the data ingestion phase, focusing on raw data collection architecture, advanced data pre-processing techniques, and data lake integration, while identifying integration and scalability challenges. Secondly, the development methodologies and data analysis techniques within experimental workflows are explored by highlighting widely used tools and real-world case studies. Thirdly, a detailed overview of optimization techniques and deployment strategies is presented, including cloud, edge, and hybrid models, supported by practical deployment examples. Finally, the continuous learning mechanisms are investigated for adaptive system updates, challenges in real-time adaptation, and expanding model performance. Additionally, this survey focuses on evaluation metrics, benchmark studies, and performance comparisons to assess platform efficiency across various domains. This study also explores emerging challenges such as data quality & availability, platform expandability, model transparency, and security, offering insights into future research directions. To ensure the rigor and breadth, this survey is conducted on 316 high-quality studies, state-of-the-art methodologies, and platforms that are selected using the PRISMA methodology from over 600 reviewed publications. By presenting a structured overview of ADSPs, this work aims to serve as a valuable resource for researchers, engineers, and industry professionals aiming to utilize data science for innovation in CPS, DT, and robotics.","2169-3536","","10.1109/ACCESS.2025.3619776","Commissioned Research Fund provided by Fukushima Institute for Research, Education, and Innovation (F-REI)(grant numbers:JPFR24010102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11197470","Cyber-physical systems (CPS);digital twins (DT);robotics;advanced data science platforms (ADSP);machine learning (ML);deep learning (DL);artificial intelligence (AI);edge computing;cloud computing;Internet of Things (IoT);real-time data processing;automation;security and privacy;decision-making systems;benchmarking;data-driven optimization;reinforcement learning (RL);performance evaluation;smart manufacturing;industrial automation","Service robots;Real-time systems;Data models;Surveys;Adaptation models;Optimization;Security;Data science;Benchmark testing;Technological innovation","","","","316","CCBY","9 Oct 2025","2025","","IEEE","IEEE Journals"
"The Role of Data Catalog in Advancing Data Monetization Strategy","S. Rosandić",Ericsson Nikola Tesla d.d.,2025 MIPRO 48th ICT and Electronics Convention,"2 Sep 2025","2025","","","1164","1169","For future-oriented organizations, data are a vital asset and key to digital transformation. Still, few truly regard data as a strategic asset using their full potential and creating financial value. In real cases, data are often scattered across systems creating silos that hinder coordination, accessibility, and enterprise data modeling. With data continuously growing, finding the right information at the right time becomes challenging. Information is trapped in specific departments or systems and inconsistent definitions and business knowledge further complicate processes. It is essential, therefore, to understand and align business and data architecture to unlock monetization.","1847-3938","979-8-3315-3597-1","10.1109/MIPRO65660.2025.11131961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11131961","data strategy;data governance;data architecture;data ecosystem;data catalog;metadata;data monetization;data marketplace;situation awareness;single source of truth","Costs;Costing;Digital transformation;Ecosystems;Decision making;Organizations;Metadata;Data governance;Artificial intelligence;Consumer electronics","","","","28","IEEE","2 Sep 2025","2-6 June 2025","2-6 June 2025","IEEE","IEEE Conferences"
"A Two-Stage Method for Ultra-Short-Term PV Power Forecasting Based on Data-Driven","H. Zhou; J. Wang; F. Ouyang; C. Cui; X. Li","Laboratory of Big Data and Artificial Intelligence, College of Information and Engineering, China Jiliang University, Hangzhou, China; Laboratory of Big Data and Artificial Intelligence, College of Information and Engineering, China Jiliang University, Hangzhou, China; Laboratory of Big Data and Artificial Intelligence, College of Information and Engineering, China Jiliang University, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big Data Architecture, Zhejiang Police College, Hangzhou, China; Laboratory of Big Data and Artificial Intelligence, College of Information and Engineering, China Jiliang University, Hangzhou, China",IEEE Access,"1 May 2023","2023","11","","41175","41189","To promote the real-time dispatching of a power grid and balanced decision-making of power producers, accuracy and real-time forecasting are two main problems that need to be solved in ultra-short-term photovoltaic (PV) forecasting. Focusing on the problems of slow model training speed and low forecasting accuracy due to the redundancy of training data samples and insufficient long periodic capture of data in complex weather, this paper proposes a two-stage method for ultra-short-term PV power forecasting based on data-driven. In the meteorological analysis stage, the generation power samples similar to the forecast day were extracted by inputting daily meteorological features and using maximal information coefficient (MIC) weighted grey correlation degree to form the corresponding forecast data set. In the power forecasting stage, the temporal convolutional used network (TCN) extracts local features to maintain the sequence of extracted features. Then the bidirectional gating unit (BiGRU) combined with the Skip connection strategy was used to fully learn the long and the short time sequence of photovoltaic sequences, and the attention mechanism was used to pay adaptive attention to the more important historical states. This study experimented on the measured data from a photovoltaic power station in Southeastern China. The experimental results show that this method is effective in photovoltaic power short-term forecasts. In addition, compared with the latest model, this method has smaller forecasting errors and higher robustness in the time scales of 15 minutes, 30 minutes, 45 minutes, and 60 minutes. Specifically, indicator R2 increased by an average of 5.4%, while indicators RMSE and MAE decreased by 8.6% and 7.3%, respectively.","2169-3536","","10.1109/ACCESS.2023.3267515","Zhejiang Province Public Welfare Technology Application Research Project(grant numbers:LGG22E070003); Ministry of Public Security Open Subjects of the Key Laboratory of Public Security Information Application Based on Big Data Architecture(grant numbers:2021DSJSYS004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103522","Bidirectional gating unit;temporal convolutional network;maximal information coefficient;skip connection;photovoltaic power forecasting","Forecasting;Feature extraction;Predictive models;Photovoltaic systems;Training;Time series analysis;Correlation","","17","","36","CCBYNCND","17 Apr 2023","2023","","IEEE","IEEE Journals"
"Blockchain Technologies for Chain of Custody Authentication","K. Chandramouli; R. Horincar; C. J. Naurois; D. Pallmer; D. Faure; W. M&#xfc;ller; K. Demestichas","Multimedia and Vision Research Group, School of Electronic Engineering and Computer Science, Venaka Media Limited,Queen Mary University of London, London,London, UK,UK; Thales, Courbevoie, France; Thales, Courbevoie, France; Fraunhofer IOSB, Karlsruhe, Germany; Thales, Courbevoie, France; Fraunhofer IOSB, Karlsruhe, Germany; Institute of Communication and Computer Systems, National Technical University of Athens, Athens, Greece",Security Technologies and Social Implications,"","2023","","","262","289","Technological advances are rapidly and radically changing human society, with “smart” sensors and gadgets penetrating almost all facets of daily life. The mass availability of these technologies has resulted in an exponential increase in the quantity of generated data. Together with the simultaneous exponential growth in computing power, this has driven rapid advances in the application of machine learning (ML) and artificial intelligence (AI). These developments in the fields of data availability and AI technologies present even greater challenges for law enforcement and policing, while simultaneously opening huge opportunities. Complementing the benefits of these technologies by the law enforcement authorities, criminals are also equally exploiting technology. A part of the digital world is the increasing abundance of digital evidence; from CCTV footage to emails to phone records, evidence has now gone digital and there is a requirement to ensure it is accessible, readable, and has long‐term integrity when current technology, systems, or formats have been replaced or decommissioned. There is a further requirement for a seamless interface between policing and the criminal justice system to ensure digital evidence can be presented easily and without delay. As the quantity of data being used in criminal investigations becomes increasing larger, there is a critical need to maintain records tracing the origin and processing of evidence collected in digital format to authenticate the validity of the evidence. Addressing this need, the multimedia analysis and correlation engine for organized crime prevention and investigation (MAGNETO) project proposed the use of blockchain technologies for tracking and recording the processing of information within the big‐data architecture of the criminal investigation platform. The novelty of the proposed framework relies on the use of semantic technologies for knowledge formalization and the use of immutable technology based on hashing solutions to prevent evidentiary modifications. The platform addresses the need for mitigating the impact of cognitive bias to ensure the investigation platform offers objectivity in processing evidence.","","9781119834151","10.1002/9781119834175.ch11","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9930735.pdf&bkn=9928039&pdfType=chapter","","Magnetic recording;Europe;Magnetic resonance imaging;Law;Soft sensors;Semantics;Blockchains","","","","","","26 Oct 2022","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Crime Pattern Detection Utilizing Power BI Visualizations on the Microsoft Fabric Data Platform With the Public data.police.uk Dataset","A. Todosijević; P. Dakić; T. Heričko; Ž. Kljajić; V. Todorović","Faculty of Informatics and Computing, Singidunum University, Belgrade, Serbia; Faculty of Informatics and Computing, Singidunum University, Belgrade, Serbia; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia; Faculty of Business Economics, Pan-European University Apeiron, Banja Luka, Bosnia & Herzegovina; Faculty of Business Studies and Law, MB University, Belgrade, Serbia",2025 15th International Conference on Advanced Computer Information Technologies (ACIT),"9 Oct 2025","2025","","","593","598","This paper presents a big data-driven platform for crime pattern detection using Power BI visualizations on Microsoft Fabric, built upon the public data.police.uk dataset. Law enforcement agencies require scalable analytics to extract actionable insights from large, complex datasets. We implemented a Data Lakehouse architecture to process around 8,500 crime data files i n C SV format from multiple regions, with Python-based metadata cataloging for structured access to crime outcomes, stop-and-search records, and street-level incidents. Dataflows and Notebooks in Fabric addressed regional inconsistencies and enabled efficient data transformation. Power BI reports provided intuitive and interactive visualizations for exploring geographic and temporal crime trends. Performance testing demonstrated up to 40% faster query response times compared to traditional warehouses, and regional crime analysis that previously took days was completed within hours. The results indicated that the platform scaled efficiently while maintaining stable performance under growing data volumes. Our approach demonstrates how unified analytics and visualization environments can democratize access to crime data insights, supporting evidence-based policing and public safety decision-making.","2770-5226","979-8-3315-9544-9","10.1109/ACIT65614.2025.11185634","Erasmus; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11185634","Data Platform;Microsoft Fabric;data.police.uk;Crime Analytics;Data Lakehouse Architecture","Law enforcement;Soft sensors;Decision making;Data visualization;Computer architecture;Metadata;Fabrics;Real-time systems;Time factors;Testing","","3","","14","IEEE","9 Oct 2025","17-19 Sept. 2025","17-19 Sept. 2025","IEEE","IEEE Conferences"
"Empowering Data Mesh with Federated Learning","H. Li; S. Toor","Department of Industrial Design, Eindhoven University of Technology, Eindhoven, Netherlands; Department of Information Technology, Uppsala University Scaleout Systems, Uppsala, Sweden",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","2340","2342","The evolution of data architecture has seen the rise of data lakes, aiming to solve the bottlenecks of data management and promote intelligent decision-making. However, this centralized architecture is limited by the proliferation of data sources and the growing demand for timely analysis and processing. A new data paradigm, Data Mesh, is proposed to overcome these challenges. In this decentralized architecture where data is locally preserved by each domain team, traditional centralized machine learning cannot conduct effective analysis across multiple domains, especially for security-sensitive organizations. To this end, we introduce a pioneering approach that incorporates Federated Learning into Data Mesh. This applied research article emphasizes the benefits of combining two distinct domains to achieve the best outcomes for industrial use cases.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825390","Data Mesh;Federated Learning;Domain-Intelligence","Federated learning;Soft sensors;Decision making;Collaboration;Organizations;Big Data applications;Fraud","","3","","8","IEEE","16 Jan 2025","15-18 Dec. 2024","15-18 Dec. 2024","IEEE","IEEE Conferences"
"Prognosis Smart System AI-based Applied to Equipment Health Monitoring in 4.0 Industry Scenario","A. Silva; G. F. M. Souza",University of São Paulo; University of São Paulo,2021 Annual Reliability and Maintainability Symposium (RAMS),"22 Nov 2021","2021","","","1","6","In the age of IIoT - Industrial Internet of Things, data lake, data mining, big data, and cloud computing, the smart manufacturing enables to make more informed decisions in real-time by using the database extracted from sensors in its equipment. During an operational campaign, the Health Monitoring System (HMS) also allows an understanding of how component degradation is affecting the performance of the equipment. Through a structure supported by AI, as data lake and cloud computing, the HMS provides to monitored equipment a fault detection system, early warning alarms to prevent failures and a calculation of the remaining useful life (RUL).The purpose of this paper is to present a prognosis smart system based on AI applied to HMS to support decision-making regarding operational performance of equipment. A Recurrent Neural Network (RNN) procedure is developed to continuously analyze the mass of monitoring data generated during the machine operation. The ability to learn the behavior patterns of the collected signals and in this way to be able to make parameter predictions with high accuracy makes artificial neural networks a powerful tool to carry out an effective prognosis. Machine operational parameters are monitored simultaneously by the prognosis smart system. Then, this information is processed by the neural network and used to characterize the machine operational condition. Upon detecting a failure trend for one or more parameters monitored by recognizing deterioration patterns, the prognosis system calculates the remaining useful life (RUL) and allows maintainers to take early actions before the failure occurrence.The proposed methodology is applied as part of a HMS of a hydro generator based on parameters registered in operator inspections routes designed to identify critical equipment degradation. The registered data representing one operational year are used to train the neural network regarding normal and abnormal machine condition. After training, the neural network is able to predict failure trends for monitored temperature parameters of the hydro-generator lubricating system that is critical to support equipment performance. Comparing prediction data and data collected by the sensors, the developed neural network reached about 0,98 RMSE score. The remaining useful life prognosis proved to be an important tool to avoid hydro generator components unexpected failures which may affect power output and cause penalties to the power generation company.","2577-0993","978-1-7281-8017-5","10.1109/RAMS48097.2021.9605722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605722","artificial intelligence;health monitoring;smart prognosis;remaining useful life","Temperature sensors;Temperature measurement;Degradation;Recurrent neural networks;Neural networks;Tools;Market research","","2","","15","IEEE","22 Nov 2021","24-27 May 2021","24-27 May 2021","IEEE","IEEE Conferences"
"EEG Pattern Recognition using Brain-Inspired Spiking Neural Networks for Modelling Human Decision Processes","Z. G. Doborjeh; M. Doborjeh; N. Kasabov","Knowledge Engineering and Discovery, Research Institute (KEDRI), Auckland, New Zealand; Knowledge Engineering and Discovery, Research Institute (KEDRI), Auckland, New Zealand; Knowledge Engineering and Discovery, Research Institute (KEDRI), Auckland, New Zealand",2018 International Joint Conference on Neural Networks (IJCNN),"14 Oct 2018","2018","","","1","7","This paper proposes a method utilising spiking neural networks (SNN) for modelling, visualising and comparing the brain data under complex mental states. The method was applied to a cognitive task performed by 23 participants while they were making decision on a moral dilemma situation-related task. An SNN evolving spatiotemporal data architecture is used to learn and visualise the neural activity across different brain regions. The model developed allows for studying the patterns of electrical activity of neurons elicited during complex decision making processes such as moral-related tasks. This could be used for predictive analysis of various aspects of human behavior during decision making and for other related cognitive tasks.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489748","Spiking Neural Network;Spatio-temporal brain data;Moral Dilemma judgement;Decision making","Brain modeling;Electroencephalography;Ethics;Data models;Task analysis;Biological neural networks;Analytical models","","4","","22","IEEE","14 Oct 2018","8-13 July 2018","8-13 July 2018","IEEE","IEEE Conferences"
"DATAWiSE: A Scalable Big Data Reference Architecture for Smart Building","E. Stamatopoulos; D. Stoian; H. Neofytou; P. Kouloukakis; A. Sianni; V. Marinakis","Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece","2025 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)","13 Aug 2025","2025","","","1","9","The emergence of Digital Twin technology has dramatically changed operational and managerial practices in intelligent buildings by enabling real-time monitoring, predictive maintenance, and performance improvement. However, the management of large and heterogeneous data produced by Internet of Things (IoT) sensors, Building Information Models (BIM), and environmental systems poses a challenge in terms of interoperability, scalability, and real-time processing capability. This paper presents the DATAWiSE architecture, a modular and scalable big data framework that is designed to integrate disparate building data sources while ensuring both secure and efficient data management. A detailed account of the process followed, from user requirements collection to the design of the proposed reference architecture. The proposed multi-layered architecture combines distributed storage technologies, AI-based analytics, and standardized communication protocols to provide strong data governance while enabling informed decision-making. Explainable AI approaches also assist in increasing system transparency and stakeholder trust. Future development areas include further enhancements in federated learning, edge computing, and harmonization with international data-sharing protocols to increase the architecture's applicability within larger smart city infrastructures.","2693-8855","979-8-3315-8534-1","10.1109/ICE/ITMC65658.2025.11106585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106585","big data architecture;interoperability;building digital twin;AI-driven analytics;smart buildings","Smart buildings;Smart cities;Architecture;Soft sensors;Scalability;Computer architecture;Big Data;Real-time systems;Digital twins;Interoperability","","","","20","IEEE","13 Aug 2025","16-19 June 2025","16-19 June 2025","IEEE","IEEE Conferences"
"Shared Services Common Data Model to Deliver Advanced Analytics","B. Gall; C. Tucker; B. Massey","Strategic Innovations, The Energy Authority, Jacksonville, FL, United States; Strategic Innovations, The Energy Authority, Jacksonville, FL, United States; Strategic Innovations, The Energy Authority, Jacksonville, FL, United States",2022 IEEE International Smart Cities Conference (ISC2),"26 Oct 2022","2022","","","1","5","Smart cities generate large amounts of data from various services and hardware. Data is generated and collected from Advanced Meter Infrastructure (AMI), Weather Stations, SCADA systems, and transportation systems for example. Within each of these data domains cities have many hardware and software vendors to pick from, each with their own proprietary method to store and share data. High resolution data provided by technologies such as AMI meters create the opportunity to deliver new distribution network and customer analysis that were not possible previously; however, the delivery of these advanced analytics projects has been challenging. While the identification of advanced analytics use cases is generally agreed upon across utilities, execution of these services is typically delivered in a case-by-case basis depending on chosen vendors and ability to integrate the necessary systems and data. For smaller utilities this often renders the service costs out of reach. By creating and leveraging a standardized analytical data model focused on delivery of advanced analytics services rather than the vendor's software and hardware needs, economies of scale are realized across large and small utilities, reducing costs and the barrier of entry into advanced analytics and data driven decision making.","2687-8860","978-1-6654-8561-6","10.1109/ISC255366.2022.9922563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9922563","data architecture;common data model;shared services;cloud;data modelling","Meters;Analytical models;Costs;Smart cities;Transportation;SCADA systems;Data models","","","","16","IEEE","26 Oct 2022","26-29 Sept. 2022","26-29 Sept. 2022","IEEE","IEEE Conferences"
"Challenges and Opportunities in Big Data Analytics for Industry 4.0: A Systematic Evaluation of Current Architectures","A. R. Kretzer; F. Barreto Vavassori Benitti; F. Siqueira","Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil; Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil; Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil",IEEE Access,"30 Oct 2025","2025","13","","183419","183447","The current efforts to integrate Big Data Analytics (BDA) into Industry 4.0 manufacturing systems, despite their usefulness for enhancing data-driven decision-making, are constrained by the lack of architectural standards for data management. This systematic mapping study analyzes many BDA architectures proposed in the literature, revealing a fragmented landscape in which the proposed architectures are largely conceptual with limited industrial validation. Our analysis identifies dominant technological patterns, such as Apache Kafka for ingestion, Spark for processing, and Hadoop and Hive for storage, with the majority of implementations favoring open-source solutions. Despite their theoretical importance, real-time analytics capabilities remain underutilized in practice. This study synthesizes a unified conceptual reference architecture with eight fundamental layers to provide a framework for comparative analysis. We document an imbalance in layer development: storage and processing receive comprehensive attention while querying, infrastructure management, and monitoring layers remain underdeveloped. Implementation approaches show distinct patterns in deployment strategies and data handling, with structured and semi-structured data well supported, whereas unstructured data integration presents ongoing challenges. Future research should focus on developing standardized modular frameworks, benchmarking methodologies, and integrating modern data lakehouse architectures to bridge the gap between theoretical proposals and production-ready systems.","2169-3536","","10.1109/ACCESS.2025.3624558","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES) (Research Organization Registry (ROR) identifier: 00x0ma614) for the Article Processing Charge; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11214321","Big data analytics (BDA);Industry 4.0;Industrial Internet of Things (IIoT);smart manufacturing;cyber-physical systems (CPS);data lake","Fourth Industrial Revolution;Manufacturing;Systematics;Computer architecture;Artificial intelligence;Pipelines;Industrial Internet of Things;Big Data applications;Computer science;Focusing","","","","86","CCBY","22 Oct 2025","2025","","IEEE","IEEE Journals"
"Climatic Oracle: Unveiling Future Weather Trends with Data Science","P. JK; S. N. S; G. N; S. R","Department of Computer Science and Engineering, Sri Sai Ram Engineering College, Chennai-44; Department of Computer Science and Engineering, Sri Sai Ram Engineering College, Chennai-44; Department of Computer Science and Engineering, Sri Sai Ram Engineering College, Chennai-44; Department of Computer Science and Engineering, Sri Sai Ram Engineering College, Chennai-44",2024 International Conference on Smart Technologies for Sustainable Development Goals (ICSTSDG),"17 Jun 2025","2024","","","1","7","The Climatic Oracle initiative spearheads a paradigm shift in weather forecasting, seamlessly integrating meteorological expertise with cutting-edge data science. By harnessing real-time data streams, sophisticated analytics and adaptive learning mechanisms, this visionary project delivers unparalleled precision in weather prediction. A robust data architecture, augmented by machine learning algorithms and specialized models for extreme weather events, empowers timely decision-making. Continuous learning, ethical awareness and community-driven insights foster accuracy, transparency and fairness. Global collaboration, secured data exchange and dedicated research propel the Climatic Oracle to the forefront of innovation, redefining weather forecasting as a dynamic, responsive system.","","979-8-3315-1628-4","10.1109/ICSTSDG61998.2024.11026688","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11026688","Climate Change;Data Analysis;Climate Simulation;Parallel Computing","Ethics;Technological innovation;Accuracy;Uncertainty;Weather forecasting;Collaboration;Data science;Real-time systems;Forecasting;Streams","","","","15","IEEE","17 Jun 2025","6-8 Nov. 2024","6-8 Nov. 2024","IEEE","IEEE Conferences"
"Revolutionizing Healthcare Management: Architecture of a Web-based Medical Triage Service","A. A. Harby; E. ElKhodary; R. Almeida; D. Sharma; F. Zulkernine; F. Alaca; K. Elgazzar; A. Almarzouqi; N. Al-Yateem; S. A. Rahman","School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; Faculty of Engineering and Applied Science, Ontario Tech University, Oshawa, Ontario, Canada; University of Sharjah, Sharjah, United Arab Emirates; University of Sharjah, Sharjah, United Arab Emirates; University of Sharjah, Sharjah, United Arab Emirates","2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)","26 Aug 2024","2024","","","1887","1894","During the COVID-19 pandemic, the traditional emergency healthcare systems faced unprecedented strain due to the sharp rise in demands for urgent care, scarcity of resources, and increased risks of people getting infected while waiting at the emergency care facility. We present Triage-Bot, an online medical triage provisioning service, that can revolutionize emergency care by decreasing the load on emergency departments (ED), reducing healthcare expenses, and improving the quality of care. Empowered by artificial intelligence and natural language processing, the Triage-Bot service assesses and prioritizes patients' needs based on symptoms, medical history, and perceived conditions from multimodal video, audio, and text data captured during patients' interactions. The captured summarized information with a severity ranking is sent to a human expert to suggest the next action on the user's part. The diverse data types used by the Triage-Bot in communication, authentication, data collection, storage, and analytics requires a robust and scalable system architecture for online service provisioning. In this paper, we specifically focus on the system design and architecture of the Triage-Bot for emergency healthcare settings. With integrated electronic medical records (EMR) and online platforms, the bot fosters collaboration among healthcare professionals and enables swift and informed decision-making even in the face of crises. By partially automating and offering a hybrid triage process, the Triage-Bot improves resource allocation, reduces healthcare management costs for emergency care, minimizes patient waiting times, and improves wellbeing. To address the complexities and demands of healthcare data management, our proposed system incorporates MongoDB database for flexibility, scalability, and versatility in supporting different types of data. Additionally, we implement a data linking and analytics pipeline utilizing a data Lakehouse system to effectively ingest, manage, process, and generate knowledge from heterogeneous data sources.","2836-3795","979-8-3503-7696-8","10.1109/COMPSAC61105.2024.00299","NSERC Canada; IBM; Mitacs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633674","Database;Triage bot;Healthcare Management;Data Lakehouse","Hospitals;Databases;Soft sensors;Authentication;Systems architecture;Computer architecture;Chatbots","","1","","32","IEEE","26 Aug 2024","2-4 July 2024","2-4 July 2024","IEEE","IEEE Conferences"
"Fuzzy Join for Flexible Combining Big Data Lakes in Cyber-Physical Systems","B. Małysiak-Mrozek; A. Lipińska; D. Mrozek","Institute of Informatics, Silesian University of Technology, Gliwice, Poland; Institute of Informatics, Silesian University of Technology, Gliwice, Poland; Institute of Informatics, Silesian University of Technology, Gliwice, Poland",IEEE Access,"4 Dec 2018","2018","6","","69545","69558","Cyber-physical systems produce large amounts of data that are stored in domain-related data lakes in a variety of formats. By using the big data technologies that enable efficient data processing, the value of the data increases, as these technologies can turn the data into actionable information that influences important decision-making processes. However, a broader view of the operational environment, an investigated phenomena, and challenges related to them can frequently be obtained after combining data from many data sets located in various big data lakes. This requires contact points in both data lakes that must be flexibly joined because in many cases, data sets do not correspond to one another directly. In this paper, we show fuzzy join operation for flexible combining big data lakes. The fuzzy join transforms numerical values of common attributes of joined data sets into fuzzy sets and uses such a representation in the join operation. We propose two variants of the join operation that transforms crisp numerical values of joining attributes into: 1) fuzzy numbers and 2) linguistic terms. The fuzzy join operation is implemented and tested in the declarative U-SQL language that is used for scalable and parallel querying in big data lakes. The ideas presented here are exemplified by a distributed analysis of cardiac disease data on Microsoft Azure cloud. The results of the conducted experiments confirm that the fuzzy join can enrich data sets that are used in making critical decisions and, as a highly scalable cloud-based solution, can be successfully used in processing large volumes of data delivered by cyber-physical systems.","2169-3536","","10.1109/ACCESS.2018.2879829","Microsoft Research; Habilitation Grant of the Rector of the Silesian University of Technology, Gliwice, Poland(grant numbers:02/020/RGH18/0148); Statutory Research Funds of Institute of Informatics, Silesian University of Technology(grant numbers:BK/213/RAU2/2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525267","Cyber-physical systems;big data;fuzzy logic;querying;cloud computing;biomedical data analysis;declarative languages","Lakes;Big Data;Cyber-physical systems;Cloud computing;Sensors;Monitoring;Biomedical monitoring","","17","","51","CCBY","6 Nov 2018","2018","","IEEE","IEEE Journals"
