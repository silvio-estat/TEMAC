"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Big Data Architecture: Designing the Right Solution for Social Network Analysis","I. Agbo; A. Kupriyanov; I. Rytsarev","Department of Technical Cybernetics, Samara National Research University, Samara, Russia; Department of Technical Cybernetics, Samara National Research University, Samara, Russia; Department of Technical Cybernetics, Samara National Research University, Samara, Russia",2020 8th International Symposium on Digital Forensics and Security (ISDFS),"15 Jun 2020","2020","","","1","5","This paper highlights the link between social networks and Big Data, which is generated by its users and how the generated data is used by businesses to improve their products and services as well as to increase their profits. It goes on to give a concise overview of Big Data architecture, the various components involved, challenges faced when developing solutions, the process of retrieving, storing and processing datasets as well as recommendations to follow when designing architectures geared towards social network analysis.","","978-1-7281-6939-2","10.1109/ISDFS49300.2020.9116274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116274","big data;NOSQL;big data architecture;social networks;social network analysis","Social networking (online);Digital forensics;Big Data;Security;Business","","1","","23","IEEE","15 Jun 2020","1-2 June 2020","1-2 June 2020","IEEE","IEEE Conferences"
"Cloud Platform with Big Data Architecture for Intelligent Community-based Elderly Care","Y. Ye; Y. Tang; J. Jiang; Q. Wang","Changsha University of Science & Technology, Changsha, China; Changsha University of Science & Technology, Changsha, China; Changsha University of Science & Technology, Changsha, China; Changsha University of Science & Technology, Changsha, China","2025 IEEE International Conference on Computation, Big-Data and Engineering (ICCBE)","28 Nov 2025","2025","","","307","310","The rapid development of information technologies, especially big data technologies, has promoted smart elderly care services. In this study, we introduced a big data architecture consisting of appropriate technology stacks that are conducive to real-time data processing, scalability, and reliability for constructing such a smart elderly care cloud platform. In the architecture, Apache Flink, Apache Kafka, Apache ZooKeeper, and Apache HBase were employed to process large-scale real-time data efficiently. The multi-task cascaded convolutional network algorithm was also utilized for face recognition to provide security and personalized service. The platform processed user behavioral and business data in real-time with a multi-layer real-time data warehouse. Optimal performance was achieved by utilizing MySQL for structured data and HBase for semi-structured data storage. This solution satisfies the functional and non-functional requirements for elderly care and serves as a basis for modelling intelligent elderly care systems to enhance the quality of service.","","979-8-3315-3244-4","10.1109/ICCBE65177.2025.11255983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11255983","smart elderly care;Big data architecture;real-time data processing;face recognition;cloud platform","Face recognition;Scalability;Computer architecture;Quality of service;Big Data;Data warehouses;Data processing;Real-time systems;Security;Older adults","","","","7","IEEE","28 Nov 2025","27-29 June 2025","27-29 June 2025","IEEE","IEEE Conferences"
"Research on Big Data Architecture, Key Technologies and Its Measures","X. Li; F. Zhang; Y. Wang","Nanjing Artillery Academy of the P.L.A., Nanjing, China; Nanjing Artillery Academy of the P.L.A., Nanjing, China; Nanjing Artillery Academy of the P.L.A., Nanjing, China","2013 IEEE 11th International Conference on Dependable, Autonomic and Secure Computing","26 Jun 2014","2013","","","1","4","Big data require exceptional technologies to efficiently process large quantities of data within tolerable elapsed times, such as capture, curation, storage, search, sharing, transfer, analysis and visualization. Concept, features, construction importance, architecture, run mode, and its key technologies of big data are analyzed in this paper. Information sharing and data security under big data constructin are studied, at last, four measures for building big data are putforward, which can provide good decision-making for big data construction.","","978-1-4799-3381-5","10.1109/DASC.2013.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6844328","Big data processing;data analysis;data security;data architecture;construction measures","Big data;Training;Cloud computing;Computer architecture;Data mining;Databases","","10","","6","IEEE","26 Jun 2014","21-22 Dec. 2013","21-22 Dec. 2013","IEEE","IEEE Conferences"
"Hierarchical Scalable Data Lake Design for Game Engine","M. Yang; P. Zhou; S. Li; R. Pu","State Key Laboratory of Public Big Data, College of Computer Science and Technology Guizhou University, Guiyang, China; School of Mechanical Engineering, Guizhou University, Guiyang, China; State Key Laboratory of Public Big Data, Guizhou University, Guiyang, China; School of Mechanical Engineering, Guizhou University, Guiyang, China",2022 8th International Conference on Big Data and Information Analytics (BigDIA),"9 Sep 2022","2022","","","360","365","With the rapid development of information technology, people are more and more inseparable from smart devices, and people and devices produce a large amount of data all the time. How to store and analyze massive data has become a research hotspot of the times. However, researchers mainly study the high reliability, high availability, high fault tolerance, high throughput, and high concurrent processing of big data systems, but there are few studies on designing hierarchical and scalable data lakes. In this study, a layered and extensible design of the data lake is carried out, which reduces the complexity of implementing business indicators during data analysis, and at the same time improves code reuse, scalability, development efficiency and code security. In addition, in order to avoid the problem of data accumulation or even job execution failure due to the skew of ip dimension table data, this paper designs the ip dimension table rowkey. This paper designs a set of real-time and offline big data analysis data lake architecture based on game engine and applies it to the actual production environment.","2771-6902","978-1-6654-8796-2","10.1109/BigDIA56350.2022.9874158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9874158","Data lake hierarchical scalable design;real-time big data analysis;offline big data analysis;rowkey design","Codes;Scalability;Games;Big Data applications;Throughput;Reliability engineering;Real-time systems","","","","13","IEEE","9 Sep 2022","24-25 Aug. 2022","24-25 Aug. 2022","IEEE","IEEE Conferences"
"Embedding AI and Crowdsourcing in the Big Data Lake","D. E. O'Leary",University of Southern California,IEEE Intelligent Systems,"7 Nov 2014","2014","29","5","70","73","Daniel E. O'Leary examines the notion of the Big Data Lake and contrasts it with decision support-based data warehouses. In addition, some of the risks of the emerging Lake concept that ultimately require data governance are analyzed. O'Leary investigates using different AI and crowdsourcing (human intelligence) applications in that lake in order to integrate disparate data sources, facilitate master data management and analyze data quality. Although data governance often is not seen as a technology issue, it is seen as a critical component of making the Big Data Lake ""work.""","1941-1294","","10.1109/MIS.2014.82","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949519","Big Data Lake;data warehouses;artificial intelligence;crowdsourcing;data governance;master data management;intelligent systems","Crowdsourcing;Artificial intelligence;Big data;Data warehouses;Decision support systems;Databases;Business","","79","","19","IEEE","7 Nov 2014","Sept.-Oct. 2014","","IEEE","IEEE Magazines"
"The Implication of Data Lake in Enterprises: A Deeper Analytics","J. Singh; G. Singh; B. S. Bhati","Computer Science and Engineering, Chandigarh University, Mohali, India; Computer Science and Engineering, Chandigarh University, Mohali, India; Computer Science and Engineering, Chandigarh University, Mohali, India",2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS),"7 Jun 2022","2022","1","","530","534","Everyday enormous amounts of information are produced from computerized advancements and handling these gigantic complex data requires a decent knowledge on the most proficient method to deal with this data. With a purpose to make the most from this multiform data for determined benefits, the data lake emerge as idea for enhanced adaptability and strong data analytics. Data Lake terminology signify a storage space for storing heterogeneous data, both organized as well as unstructured, bringing about an adaptable association that permits data lake customers incorporate data dynamically which they request. Big Data innovation offer help to enterprises in business intelligence process yet there exists lack of empirical study on utilization of data lake technique in enterprises. This paper gives an exploratory review on data lake implication by portraying its concept, functional architecture, development stages involved and numerous research challenges and direction; which will improve the effective utilization of the data lake approach in enterprises.","2575-7288","978-1-6654-0816-5","10.1109/ICACCS54159.2022.9784986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9784986","Data Lake;Data Lake vs Data Warehouse;Data Lake Research Challenges;Data Lake in Enterprise;Stages for Building Data Lake;Need of Data Lake","Technological innovation;Terminology;Communication systems;Focusing;Computer architecture;Companies;Lakes","","15","","22","IEEE","7 Jun 2022","25-26 March 2022","25-26 March 2022","IEEE","IEEE Conferences"
"Big Data Lakes: Models, Frameworks, and Techniques","A. Cuzzocrea","iDEA Lab, University of Calabria Rende, Italy & LORIA, Nancy, France",2021 IEEE International Conference on Big Data and Smart Computing (BigComp),"10 Mar 2021","2021","","","1","4","Nowadays, big data lakes are prominent components of emerging big data architectures. Basically, big data lakes are the natural evolution of data warehousing systems in the big data context, and deal with several requirements deriving from the well-known 3V nature of big data. Along with the emerging of big data lake research initiative, several issues appeared, such as: (i) big data lake models; (ii) big data lake frameworks; (iii) big data lake techniques. In line with this exciting research perspective, this paper proposes an overview of state-of-the-art approaches that are at the foundations of big data lake research, and innovative open problems and issues, which drive future research directions, on advancing the big data lake research trend.","2375-9356","978-1-7281-8924-6","10.1109/BigComp51126.2021.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373107","Big Data;Big Data Lakes;Big Data Representation;Big Data Processing;Big Data Analytics","Warehousing;Semantics;Big Data;Lakes;Market research;Data models;Research initiatives","","34","","32","IEEE","10 Mar 2021","17-20 Jan. 2021","17-20 Jan. 2021","IEEE","IEEE Conferences"
"Data Lake: A Case of Study of a Big Data Analytics Architecture for Public Procurements","D. Sosa; J. Paciello","Polytechnic Faculty, National University of Asuncion, Asuncion, Paraguay; Polytechnic Faculty, National University of Asuncion, Asuncion, Paraguay",2021 Eighth International Conference on eDemocracy & eGovernment (ICEDEG),"13 Sep 2021","2021","","","194","198","Big Data technologies are facing problems of volume, velocity, variety and veracity of data, attending to the wide expansion of emerging technologies like IoT and IoE. Cyberocracy proposes a decision-making process of a Government based on the effective use of information. An important effort in this line, focusing on government public procurement, has been carried out by the Open Contracting Partnership (OCP), promoting the publication of more volumes of public procurement data in non-relational and machine processable formats every day. This work analyzes the underlying Big Data infrastructure for the analysis of public procurement data through a comparative case of study between a technology proposed by the OCP called KingFisher and emergent technologies based on Data Lakes.With an emphasis on storage requirements to support a high volume of payloads, also considering criteria of velocity and RAM use. Preliminary results show encouraging findings especially in terms of volume required by a Data Lake, even for different payload scenarios, up to 10 times less storage than the relational database-based model.","2573-1998","978-1-6654-2512-4","10.1109/ICEDEG52154.2021.9530976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530976","Big Data;IoT;IoE;Data Lake;Cyberocracy;Public Procurements","Procurement;Solid modeling;Government;Decision making;Random access memory;Focusing;Big Data","","2","","17","IEEE","13 Sep 2021","28-30 July 2021","28-30 July 2021","IEEE","IEEE Conferences"
"Cloud DATA LAKE: The new trend of data storage","E. Zagan; M. Danubianu","Faculty of Electrical Engineering and Computer Science, Stefan cel Mare University, Suceava, Romania; Faculty of Electrical Engineering and Computer Science, Stefan cel Mare University, Suceava, Romania","2021 3rd International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)","25 Jun 2021","2021","","","1","4","In databases field, the term Data Lake is increasingly common, which is a new raw data storage technology to undergo further advanced processing and analysis. Today there are for different ways to implement Data Lake architecture, namely: Data Lake On-Premises, Cloud Data Lake, Hybrid Data Lake and Multi-Cloud Data Lake. Each of these architectures has their own advantages and disadvantages, and yet the new trend is to go in Cloud. In this work, we will briefly explain what a Date Lake is, what the for different architectures are, and we will broadly present the major benefits of the Cloud architecture and its shortcomings in order to provide a preliminary guide on the implementation of Data Lake architecture.","","978-1-6654-4058-5","10.1109/HORA52670.2021.9461293","European Social Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9461293","Data Lake;Data Lake architecture;Data Lake On-Premises;Cloud Data Lake;Hybrid Data Lake;Multi-Cloud Data Lake","Human computer interaction;Cloud computing;Databases;Data integrity;Memory;Lakes;Market research","","14","","14","IEEE","25 Jun 2021","11-13 June 2021","11-13 June 2021","IEEE","IEEE Conferences"
"Big Data Architecture for Large Organizations","F. N. Ismail; A. Sengupta; S. Amarasoma","Dept. of Mathematics, State University of New York, Buffalo, USA; School of Computing, University of Otago, Dunedin, New Zealand; Ernst & Young Global Delivery Service, Sri Lanka",2025 10th International Conference on Big Data Analytics (ICBDA),"4 Nov 2025","2025","","","27","32","The exponential growth of big data has transformed how large organisations leverage information to drive innovation, optimise processes, and maintain competitive advantages. However, managing and extracting insights from vast, heterogeneous data sources requires a scalable, secure, and well-integrated big data architecture. This paper proposes a comprehensive big data framework that aligns with organisational objectives while ensuring flexibility, scalability, and governance. The architecture encompasses multiple layers, including data ingestion, transformation, storage, analytics, machine learning, and security, incorporating emerging technologies such as Generative AI (GenAI) and low-code machine learning. Cloud-based implementations across Google Cloud, AWS, and Microsoft Azure are analysed, highlighting their tools and capabilities. Additionally, this study explores advancements in big data architecture, including AI-driven automation, data mesh, and Data Ocean paradigms. By establishing a structured, adaptable framework, this research provides a foundational blueprint for large organisations to harness big data as a strategic asset effectively.","2832-3734","979-8-3315-0393-2","10.1109/ICBDA65366.2025.11211062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11211062","Big Data;Blueprint;Architecture;Google Cloud;AWS;Microsoft Azure","Technological innovation;Data ingestion;Generative AI;Scalability;Standards organizations;Organizations;Machine learning;Big Data;Internet;Security","","1","","14","IEEE","4 Nov 2025","13-15 March 2025","13-15 March 2025","IEEE","IEEE Conferences"
"Cloud Big Data Lake for Advanced Analytics in Semiconductor Manufacturing","S. Sun; J. Ye; H. Schwarthoff; J. Rosin; V. Vakkalagadda; J. Chang; S. R. Ubbara; A. Chinthakindi","Data Science, Micron Technology Inc., Manassas, VA, USA; Process Integration Micron Technology Inc., Manassas, VA, USA; Smart Mfg Tech Solutions Micron Technology Inc., Boise, ID, USA; Information Technology Micron Technology Inc., Manassas, VA, USA; Data Science, Micron Technology Inc., Manassas, VA, USA; Smart Mfg Tech Solutions Micron Technology Inc., Boise, ID, USA; Smart Mfg Tech Solutions Micron Technology Inc., Boise, ID, USA; Front-end Central Quality Micron Technology Inc., Manassas, VA, USA",2024 35th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC),"6 Jun 2024","2024","","","1","5","Data driven business intelligence is changing how semiconductor manufacturing thrives in the long term. A cloud big data lake is designed and implemented based on state-of-the-art cloud architecture providing complete services for data ingestion, storage, processing, advanced analytics, and machine learning with a high level of security. Efficient and effective use of this big data lake and data science enables problem solving and decision making to improve productivity and performance.","2376-6697","979-8-3503-8455-0","10.1109/ASMC61125.2024.10545365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545365","Cloud;Data Lake;Semiconductor Manufacturing;Big Data Analytics","Cloud computing;Soft sensors;Scalability;Machine learning;Lakes;Big Data;Semiconductor device manufacture","","","","5","IEEE","6 Jun 2024","13-16 May 2024","13-16 May 2024","IEEE","IEEE Conferences"
"Implementing Big Data Lake for Heterogeneous Data Sources","H. Mehmood; E. Gilman; M. Cortes; P. Kostakos; A. Byrne; K. Valta; S. Tekes; J. Riekki","University of Oulu, Finland; University of Oulu, Finland; University of Oulu, Finland; University of Oulu, Finland; Dell EMC, Ireland; Draxis Environmental S.A, Greece; Draxis Environmental S.A, Greece; University of Oulu, Finland",2019 IEEE 35th International Conference on Data Engineering Workshops (ICDEW),"1 Jul 2019","2019","","","37","44","Modern connected cities are more and more leveraging advances in ICT to improve their services and the quality of life of their inhabitants. The data generated from different sources, such as environmental sensors, social networking platforms, traffic counters, are harnessed to achieve these end goals. However, collecting, integrating, and analyzing all the heterogeneous data sources available from the cities is a challenge. This article suggests a data lake approach built on Big Data technologies, to gather all the data together for further analysis. The platform, described here, enables data collection, storage, integration, and further analysis and visualization of the results. This solution is the first attempt to integrate a diverse set of data sources from four pilot cities as part of the CUTLER project (Coastal urban development through the lenses of resiliency). The design and implementation details, as well as usage scenarios are presented in this paper.","2473-3490","978-1-7281-0890-2","10.1109/ICDEW.2019.00-37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8750951","data lake, Big Data, Smart City, data analysis","Lakes;Smart cities;Big Data;Sensors;Economics;Monitoring","","44","","44","IEEE","1 Jul 2019","8-12 April 2019","8-12 April 2019","IEEE","IEEE Conferences"
"Managing data lakes in big data era: What's a data lake and why has it became popular in data management ecosystem","H. Fang","Data Center of Air China, Beijing, China","2015 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)","5 Oct 2015","2015","","","820","824","The concept of a data lake is emerging as a popular way to organize and build the next generation of systems to master new big data challenges, but there are lots of concerns and questions for large enterprises to implement data lakes. The paper discusses the concept of data lakes and shares the author's thoughts and practices of data lakes.","","978-1-4799-8730-6","10.1109/CYBER.2015.7288049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7288049","Big Data;Data Lake;Hadoop;data management ecosystem;eneterpirse architecture","Lakes;Data warehouses;Big data;Companies;Ecosystems","","146","","5","IEEE","5 Oct 2015","8-12 June 2015","8-12 June 2015","IEEE","IEEE Conferences"
"SmartLAK: A big data architecture for supporting learning analytics services","T. Rabelo; M. Lama; R. R. Amorim; J. C. Vidal","Faculdade de Ciências Aplicadas e Sociais de Petrolina (FACAPE), Brasil; Centro de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; Depto de Educação, (UNEB/DEDC VII), Universidade do Estado da Bahia, Brasil; Centro de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain",2015 IEEE Frontiers in Education Conference (FIE),"7 Dec 2015","2015","","","1","5","In this paper, we present a big data software architecture that uses an ontology, based on the Experience API specification, to semantically represent the data streams generated by the learners when they undertake the learning activities of a course, e.g., in a course. These data are stored in a RDF database to provide a high performance access so learning analytics services can process the large amount of data generated in a virtual learning environment. These services provide valuable information to teachers and instructors such as predict the learner's performance, discover the real learning paths, extract the learner's behavior patterns and so on. The proposed architecture has been validated in the Educational Technology undergraduate course of the Degree in Pedagogy at the Faculty of Education of the University of Santiago de Compostela.","","978-1-4799-8454-1","10.1109/FIE.2015.7344147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344147","Big data architecture;Learning analytics;Experience API","Computer architecture;Ontologies;Databases;Big data;Education;Semantics;Context","","16","","17","IEEE","7 Dec 2015","21-24 Oct. 2015","21-24 Oct. 2015","IEEE","IEEE Conferences"
"A Step towards Big Data Architecture for Higher Education Analytics","S. Jha; M. Jha; L. O'Brien","Central Queensland University, Sydney, NSW, Australia; Central Queensland University, Sydney, NSW, Australia; Home Affairs, Canberra, ACT, Australia",2018 5th Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE),"3 Oct 2019","2018","","","178","183","Big Data analytics in the higher education sector is used relatively less than in other sectors but its use is growing gradually. Big Data analytics in this sector needs to be combined with business processes to improve institutional operations and support institutions in offering innovative services to students. The retention rate of students can be improved if an early alert system based on Big Data analysis is set up and intervention is appropriately deployed. In this paper we discuss the functional capabilities of Big Data analytics in Higher Education and a step towards Big Data architecture to implement data analytics to benefit the Higher Education institutions and their stakeholders. This paper reports an experimental study with 309 postgraduate students to explore how Big Data Architecture can be used for Higher Education analytics.","","978-1-7281-1390-6","10.1109/APWConCSE.2018.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853675","Big Data Architecture;Big Data in Higher Education;Big Data Analytics;Student Retention;Early Intervention","Big Data;Decision making;Computer architecture;Learning management systems;Australia","","3","","34","IEEE","3 Oct 2019","10-12 Dec. 2018","10-12 Dec. 2018","IEEE","IEEE Conferences"
"Analysis of Blockchain and Interplanetary File System (IPFS) Utilization for Big Data Architecture Optimization","A. P. Ahmad; A. A. Ilham; A. W. Paundu","Department of Informatics, Hasanuddin University Makassar, Indonesia; Department of Informatics, Hasanuddin University Makassar, Indonesia; Department of Informatics, Hasanuddin University Makassar, Indonesia","2023 IEEE International Conference on Communication, Networks and Satellite (COMNETSAT)","7 Feb 2024","2023","","","652","657","Big data is the collection of very complex data sets that are very difficult to process by traditional data processing applications. This data comes from various devices or media that are connected to the internet. Today, big data processing uses Cloud and Hadoop, which are capable of processing large amounts of data. However, as centralized storage paradigms, Cloud and Hadoop are vulnerable to Single Point of Failure, low availability, system failure, or even hacker attacks. In this research, a big data architecture using Blockchain and Interplanetary File System (IPFS) is designed and a comparison is made between big data architecture using Hadoop and big data architecture using Blockchain and IPFS and testing the time and throughput required by each architecture. The final result of this research is a discussion of the comparison of data execution based on time and throughput in each architecture. The comparison result shows that the throughput and time generated by Hadoop’s big data architecture are better with a comparison ratio value for file size 500 MB of 1.7320, file size 700 MB of 1.7915, and file size 1 GB of 1.6975.","","979-8-3503-4110-2","10.1109/COMNETSAT59769.2023.10420785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420785","Big Data;Blockchain;Interplanetary File System (IPFS);Cloud;Hadoop;Single Point of Failure;Throughput","Cloud computing;Computer architecture;Big Data;Throughput;Blockchains;InterPlanetary File System;Testing","","2","","20","IEEE","7 Feb 2024","23-25 Nov. 2023","23-25 Nov. 2023","IEEE","IEEE Conferences"
"Data Lake Management for Educational Analysis","D. Martinez-Mosquera; V. Beltrán; D. Riofrío-Luzcando; J. Carrión-Jumbo","Department of Informatics and Computer Science, Escuela Politécnica Nacional, Digital School, Universidad Internacional SEK, Quito, Ecuador; Digital School, Universidad Internacional SEK, Quito, Ecuador; Digital School, Universidad Internacional SEK, Quito, Ecuador; Digital School, Universidad Internacional SEK, Quito, Ecuador",2022 IEEE Sixth Ecuador Technical Chapters Meeting (ETCM),"9 Nov 2022","2022","","","1","5","This article presents an approach to managing an educational analytical system in a data lake. This solution covers higher education institutions' requirements for managing large volumes generated by their students and teachers. This work deals with the problem of the lack of organization when implementing a data lake due to the fact that there are no well-known or standardized methods for its administration. Our methodology proposes dividing the data lake into three zones: (1) landing tier, (2) staging tier, and (3) consumption tier, and transforming the data for each zone under the guidance of the Common Data Model and One Data Model. The main goal is to avoid the educational data lake from converting into a data swamp. This methodology was implemented at University as a case study over an open-source data lake environment. The results obtained figures that historical data analysis barriers are overcome thanks to the high capabilities of the data lake. In addition, this approach can be applied to other institutions with great flexibility, with commodity solutions, and regardless of the source data format.","","978-1-6654-8744-3","10.1109/ETCM56276.2022.9935751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9935751","big data;common data model;data lake;education;HDFS;one data model","Data lakes;Analytical models;Data analysis;Standards organizations;Education;Organizations;Big Data applications","","1","","18","IEEE","9 Nov 2022","11-14 Oct. 2022","11-14 Oct. 2022","IEEE","IEEE Conferences"
"A Big Data Architecture for Heterogeneous Data in Precision Agriculture","A. George","Department of Computer Science, Alliance University, Bangalore, India",2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT),"26 Dec 2022","2022","","","1","5","The increase in human population has triggered the need to increase the agriculture production worldwide. At the same time climatic conditions, water scarcity and population growth are decreasing the arable land. Hence there is a need to evolve novel ways to improve agricultural produce while utilizing lesser resources. Precision Agriculture combines temporal, spatial, remote, and individual data along with decisions to enable specific automated actions on fields. Big Data is one of the central technologies used in precision farming to store, retrieve and process abstract information. In the article we propose a system, method to efficiently collate, store and process data from multiple sources on a Big Data system and validate the approach. The proposed system will build on the Hadoop framework.","","978-1-6654-5262-5","10.1109/ICCCNT54827.2022.9984478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9984478","Big Data;Hadoop;Precision Agriculture;Remote Sensing","Sociology;Merging;Computer architecture;Production;Big Data;Agriculture;Sensors","","","","10","IEEE","26 Dec 2022","3-5 Oct. 2022","3-5 Oct. 2022","IEEE","IEEE Conferences"
"Research and Design of Traffic Information Processing Based on Hadoop Big Data Architecture","R. Niu","Tianjin University of Technology, Tianjin, China",2023 2nd International Conference on Artificial Intelligence and Autonomous Robot Systems (AIARS),"20 Oct 2023","2023","","","162","166","As the information resources in the field of transportation become more and more huge, the traditional processing methods can hardly support the needs of real-time computing, low-latency query and statistical analysis of massive data. In the paper, a design method of intelligent traffic information processing based on Hadoop big data architecture is proposed. By analyzing the application requirements and the current situation in the field of intelligent transportation, the paper investigates the computation mode combined with big data processing technology to collect, process, analyze and utilize multi-user requirements and large-scale and massive traffic data, and realize the sharing and common use of big data, as well as efficient and convenient storage methods and accurate computation methods. In order to provide personalized services to people in a dynamic, timely and accurate manner. The final construction of traffic management, travel reference, monitoring and criminal investigation and other comprehensive, multi-faceted intelligent traffic information processing system.","","979-8-3503-2435-8","10.1109/AIARS59518.2023.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10285238","Big Data;Intelligent Transportation;Hadoop;HBase;Streaming Computing","Information resources;Statistical analysis;Transportation;Information processing;Computer architecture;Big Data;Real-time systems","","","","7","IEEE","20 Oct 2023","29-31 July 2023","29-31 July 2023","IEEE","IEEE Conferences"
"Open Data Lake to Support Machine Learning on Arctic Big Data","A. M. Olawoyin; C. K. Leung; A. Cuzzocrea","Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; iDEA Lab University of Calabria, Rende, Italy",2021 IEEE International Conference on Big Data (Big Data),"13 Jan 2022","2021","","","5215","5224","The era of big data is evolving with the introduction of the data lake concept. While a data warehouse provides a well-structured model to manage big data, a data lake accepts data of any types and formats with or without schema and provides access to the data for diverse communities of users. A data lake provides flexible, agile, and scalable solution to manage the ever-increasing volume of big data we are witnessing in the world today, including many siloed data collected over the years by researchers through Arctic expeditions. In this paper, we present our conceptual model of a data lake for integrating the diverse huge amount of data collected by researchers during Arctic expedition. We also design a baseline metadata using a data-driven approach to manage the disparately huge structured, semi-structured, and unstructured data collected from the Arctic region. The resulting open data lake not only effectively manages big Arctic data but also supports machine learning on these big data.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671453","big data;data management;data lake;open data;reusability;FAIR principle;CARE principle;Arctic data;Arctic expedition;machine learning;data mining","Renewable energy sources;Visual analytics;Machine learning;Production;Metadata;Lakes;Data warehouses","","23","","78","IEEE","13 Jan 2022","15-18 Dec. 2021","15-18 Dec. 2021","IEEE","IEEE Conferences"
"Finding Your Way Through the Jungle of Big Data Architectures","T. Priebe; S. Neumaier; S. Markus","Data Intelligence Research Group, St. Pölten University of Applied Sciences, Austria; Data Intelligence Research Group, St. Pölten University of Applied Sciences, Austria; Simplity AT GmbH, Vienna, Austria",2021 IEEE International Conference on Big Data (Big Data),"13 Jan 2022","2021","","","5994","5996","This paper presents a systematic review of common analytical data architectures based on DAMA-DMBOK and ArchiMate. The paper is work in progress and provides a first view on Gartner’s Logical Data Warehouse paradigm, Data Fabric and Dehghani’s Data Mesh proposal as well as their interdependencies. It furthermore sketches the way forward how this work can be extended by covering more architecture paradigms (incl. classic Data Warehouse, Data Vault, Data Lake, Lambda and Kappa architectures) and introducing a template with among others ""context"", ""problem"" and ""solution"" descriptions, leading ultimately to a pattern system providing guidance for choosing the right architecture paradigm for the right situation","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671862","Data Architecture;Data Lake;Logical Data Warehouse;Data Fabric;Data Mesh","Systematics;Software design;Conferences;Computer architecture;Data warehouses;Big Data applications;Fabrics","","12","","14","IEEE","13 Jan 2022","15-18 Dec. 2021","15-18 Dec. 2021","IEEE","IEEE Conferences"
"DataLakeIO: A Connector Between Apache Beam and Data Lake","T. Zhang; H. Liu; Y. Liu; W. Chen","Nanhu Laboratory, Research Center of Big Data Technology, JiaXing, China; Nanhu Laboratory, Research Center of Big Data Technology, JiaXing, China; Nanhu Laboratory, Research Center of Big Data Technology, JiaXing, China; Nanhu Laboratory, Research Center of Big Data Technology, JiaXing, China",2024 9th International Conference on Electronic Technology and Information Science (ICETIS),"24 Jul 2024","2024","","","790","793","In the era of big data, Apache Beam is widely used because it provides a unified programming model and supports multiple data processing engines. At the same time, data lake is becoming more and more widely used. However, Apache Beam is not currently interconnected with the data lake. In this paper, we proposed DataLakeIO, a connector between Apache Beam and data lake. First, a Apache Beam pipeline is initialized. Then, Apache Beam ingests the data from the data source, converts it to Row type, and put it into pipeline. Then, Apache Beam passes the data and parameters to the write method of DataLakeIO. In this method, a Spark session is created based on these parameters, the data is converted into a Dataset, and finally stored in data lake. The process for Apache Beam to ingest data from data lake into its pipeline is similar. This connector supports the interconnection of Apache Beam with Delta Lake, Apache Hudi, and Apache Iceberg, which shows the extensibility for data lakes. The experimental result shows the efficiency of DataLakeIO.","","979-8-3503-8834-3","10.1109/ICETIS61828.2024.10593666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10593666","big data;Apache Beam;data lake;interconnection;pipeline","Connectors;Information science;Soft sensors;Pipelines;Memory;Lakes;Programming","","","","13","IEEE","24 Jul 2024","17-19 May 2024","17-19 May 2024","IEEE","IEEE Conferences"
"The research of big data architecture on telecom industry","F. Su; Y. Peng; X. Mao; X. Cheng; W. Chen","China Unicom Network Technology Research Institute; National Satellite Meteorological Center; China National Institute of Standardization, Beijing, China; China Unicom Network Technology Research Institute; China Unicom Network Technology Research Institute",2016 16th International Symposium on Communications and Information Technologies (ISCIT),"24 Nov 2016","2016","","","280","284","In Big Data era, telecom operators have massive data resources, such as user call data, user online data, user location data, network performance data, and so on. These data reaches PB level and is distributed in the NEs and interfaces. How to effectively carry out the collection, parsing, analysis for the amount of data to support the network construction, maintenance and optimization is a major opportunities and challenges that the telecom operators face. This paper proposes a big data platform (BDP) to solve the above problem for telecom industries. Through the collection of telecom network data, the BDP can realize data parsing, storage and analysis for MR(Measure Report), CDR(Call Detail Record), OMC(Operation and Maintenance Centre) data and etc. It can achieve a unified storage and management of all types of data. Based on BDP, operators can carry out big data analysis and data mining to realize the value of data. Finally, this paper builds a testing platform for BDP to test the performance of big data loading and big data analysis. The results of experiment show that the performance of data loading and analysis of BDP is better than traditional data warehouse. It can be applied by the telecom operators to be the foundational infrastructure to carry on the future application of big data.","","978-1-5090-4099-5","10.1109/ISCIT.2016.7751636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7751636","Big Data;Hadoop;ETL;MPP Database","Big data;Telecommunications;Data visualization;Data analysis;Industries;Maintenance engineering;Data mining","","10","","30","IEEE","24 Nov 2016","26-28 Sept. 2016","26-28 Sept. 2016","IEEE","IEEE Conferences"
"Data Lake Approaches: A Survey","E. Zagan; M. Danubianu","Faculty of Electrical Engineering and Computer Science, Stefan cel Mare University, Suceava, Romania; Faculty of Electrical Engineering and Computer Science, Stefan cel Mare University, Suceava, Romania",2020 International Conference on Development and Application Systems (DAS),"5 Jun 2020","2020","","","189","193","The explosion of new data: social media, commercial, industrial, health, school, etc. appeared in recent years, has led to the emergence and development of new technologies and techniques of data management. The old technologies of data storage and data processing are beginning to be overwhelmed by the large volume of data and their variety. Data Lake is one of the latest technologies that seem to be in the spotlight in the last period. In this article, we analyze some of the recent approaches and architectures using Data Lake, approaches that have tried to cover several shortcomings encountered with the advent of these new technologies.","","978-1-7281-6870-8","10.1109/DAS49615.2020.9108912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108912","Data Lake;Data Warehouses;Databases;Data Analysis;Data Mining","Social networking (online);Memory;Big Data applications;Data processing;Explosions;Data mining","","17","","12","IEEE","5 Jun 2020","21-23 May 2020","21-23 May 2020","IEEE","IEEE Conferences"
"Data Lakehouse - a Novel Step in Analytics Architecture","D. Oreščanin; T. Hlupić","Poslovna inteligencija d. o. o., Zagreb, Croatia; Poslovna inteligencija d. o. o., Zagreb, Croatia","2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)","15 Nov 2021","2021","","","1242","1246","Data Lakes, as a modern concept of raw analytical data storage, were presented as a next step that will take over Data Warehouses. In the course of time after the Data Lakes emergence, it is clear that those two architectures complement each other with their actual usage. A new architecture concept, Data Lakehouse, has recently been introduced as a next step in the analytical data storage. The Data Lakehouse architecture should be able to deal with currently insurmountable challenges that both Data Warehouses and Data Lakes cannot overcome. In this article, a current state of the Data Lakehouse architecture and vendor implementation will be given. Furthermore, a comparison of the Data Lakehouse will be done between both Data Warehouses and Data Lakes with a focus on tackling their known challenges. Finally, an approach to combine existing Data Warehouses and Data Lakes into a unified Data Lakehouse will be presented, with a special focus on the high-level architecture.","2623-8764","978-953-233-101-1","10.23919/MIPRO52101.2021.9597091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597091","Data Lakehouse;Data Lake;Data Warehouse;Big Data;novel analytics architecture","Architecture;Buildings;Memory;Machine learning;Data warehouses;Big Data applications;Complexity theory","","32","","19","","15 Nov 2021","27 Sept.-1 Oct. 2021","27 Sept.-1 Oct. 2021","IEEE","IEEE Conferences"
"Transforming RTLS Data Architecture to Big Data Architecture for Location Data","C. B. Yılmaz; O. Gövem; M. O. Ünalır","R&D Center, Litum Information Technologies, Izmir, Turkey; R&D Center, Litum Information Technologies, Izmir, Turkey; Department of Computer Engineering, Ege University, Izmir, Turkey",2023 Innovations in Intelligent Systems and Applications Conference (ASYU),"31 Oct 2023","2023","","","1","6","Real-time Location System (RTLS) locates and monitors any person or asset within a defined zone covered by a radio frequency (RF) network. This system produces location data for each entity to track from several times per second to every few minutes, depending on how often it is desired to refresh the location data. The increase in the volume of data that is required to be collected, stored, processed, analyzed, and reported, is one of the reasons for the development of big data technologies. This paper aims to explain the transformation of data architecture according to the target short-term and long-term analytical needs of RTLS and to compare traditional architecture and big data architecture on read times and storage costs. In order to achieve that, the data in the relational database system is extracted to.csv files in its raw form with a microservice triggered daily within the relational database management system. Data is processed in Python language to meet the three different reporting requirements of RTLS. Analyzed data is stored in a column-family NoSQL database Apache Cassandra by modeling differently in line with the query parameters for faster query purposes. By not archiving the location data on the relational database, without affecting the performance health of RTLS, meaningful results are produced from this data and are reported on the application. As the size of the input and output data used for reporting increases, the need to use a NoSQL database is essential in terms of query response times. NoSQL database systems may require the same data to reside in multiple tables, so the storage cost per row is about 67% lower than SQL database, but as the number of queries to the data increases, storage costs can exceed SQL databases.","2770-7946","979-8-3503-0659-0","10.1109/ASYU58738.2023.10296768","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10296768","real-time location systems;big data architecture;location data;NoSQL database","Structured Query Language;Technological innovation;Costs;NoSQL databases;Relational databases;Big Data;Real-time systems","","","","11","IEEE","31 Oct 2023","11-13 Oct. 2023","11-13 Oct. 2023","IEEE","IEEE Conferences"
"Data Lake Architecture for Distribution System Operator","B. B. Cardoso; S. B. Righetto; E. L. Martins; M. A. Izumida Martins; A. L. Pereira; S. de Francisci","CERTI Foundation, Sustainable Energy Center, Florianópolis, Brazil; CERTI Foundation, Sustainable Energy Center, Florianópolis, Brazil; CERTI Foundation, Sustainable Energy Center, Florianópolis, Brazil; CERTI Foundation, Sustainable Energy Center, Florianópolis, Brazil; New Technology, Enel Distribuição São Paulo, Barueri, Brazil; New Technology, Enel Distribuição SãoPaulo, Barueri, Brazil",2021 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT),"16 Mar 2021","2021","","","1","5","Ignited by the advent of digital technologies, power distribution utilities are generating more and more data about their own assets and their environment. To handle this amount of data, some solutions emerge to help distribution system operators in understanding their own data and turning this Big Data into actionable insights. One of the solutions is a Data Lake. This article illustrates the architecture of a cloud-based Data Lake developed by Enel Distribuicao Sao Paulo to manage big data from systems such as GIS, SCADA O&M systems and other data generated in a Network Digital Twin® model in the city of Sao Paulo This Data Lake has a combination of data sources. It stores data in raw, processed, and refined format using structured, unstructured and semi-structured data. It uses tools to execute queries, searches, processing streams and to visualize data. This paper presents the design and implementation details, as well as usage scenarios of the data lake in a smart grid project.","2472-8152","978-1-7281-8897-3","10.1109/ISGT49243.2021.9372181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372181","Data Lake;Network Digital Twin®;Grid Digitalization","Urban areas;Companies;Lakes;Big Data;Turning;Smart grids;Virtualization","","5","","13","IEEE","16 Mar 2021","16-18 Feb. 2021","16-18 Feb. 2021","IEEE","IEEE Conferences"
"BASIS: A big data architecture for smart cities","C. Costa; M. Y. Santos","ALGORITMI Research Centre, University of Minho, Guimarães, Portugal; ALGORITMI Research Centre, University of Minho, Guimarães, Portugal",2016 SAI Computing Conference (SAI),"1 Sep 2016","2016","","","1247","1256","Nowadays, cities are the common choice for living, representing a complex system where governments need to perform adequately, despite current restrictions, in order to satisfy the needs of the citizens and overcome economic, social and environmental sustainability challenges. The Smart City term emerges to conceptualize the need to understand citizens, namely their services demand and their relevance in a participatory government. Smart Cities are known for their human dynamics, which makes recurrent use of permanently connected devices, frequently known as Internet of Things (IoT). Consequently, since these new cities generate a vast volume of data with significant variety and velocity, they have the potential to be one of the richest and challenging systems to generate Big Data and to benefit from its adequate storage, processing, analysis and public availability. This paper presents a Big Data architecture for Smart Cities, entitled BASIS, whose specification pays particular attention to the creation of multiple abstraction layers, from the most conceptual to the most technological, fulfilling the lack of technological detail often observed in the literature. BASIS also pays particular attention to the public availability of data. Tested in a demonstration case, the obtained results reveal adequate capability to store, process, analyse and make available Big Data in the context of Smart Cities.","","978-1-4673-8460-5","10.1109/SAI.2016.7556139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556139","Big Data;Smart Cities;Big Data Architecture;Big Data Analytics","Big data;Smart cities;Computer architecture;Data mining;Context;Distributed databases","","29","","22","IEEE","1 Sep 2016","13-15 July 2016","13-15 July 2016","IEEE","IEEE Conferences"
"Towards a Big Data Architecture for Facilitating Cyber Threat Intelligence","C. Wheelus; E. Bou-Harb; X. Zhu","Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, USA; Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, USA; Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, USA","2016 8th IFIP International Conference on New Technologies, Mobility and Security (NTMS)","22 Dec 2016","2016","","","1","5","Internet and organizational network security is still threatened by devastating malicious activities. Given the continuous escalation of such attacks in terms of their frequency, sophistication and stealthiness, it is of paramount importance to generate effective cyber threat intelligence that aim at inferring, attributing, characterizing and mitigating such misdemeanors. Nevertheless, such imperative tasks are partially impeded by the lack of approaches that can produce prompt and accurate actionable intelligence by investigating various network traffic sources. In this paper, we propose and evaluate a big data architecture that is rooted in real-time network traffic processing, distributed messaging and scalable data storage. The key innovation behind the proposed architecture is that it automates the analysis of heterogeneous network data, allowing the focus to remain on devising effective cyber threat intelligence analytics, rather than being hindered by data management, aggregation, reconciliation and formatting. Empirical evaluations investigating the application of machine learning analytics by exploiting the artifacts of the proposed architecture and by using 100 GB of real network traffic, indeed demonstrate the practicality, effectiveness, and addedvalue of the proposed architecture.","2157-4960","978-1-5090-2914-3","10.1109/NTMS.2016.7792484","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7792484","","Malware;Big data;Computer architecture;Context;Computer security;Training","","10","","18","IEEE","22 Dec 2016","21-23 Nov. 2016","21-23 Nov. 2016","IEEE","IEEE Conferences"
"Design and Implementation of Manufacturing Data Lake in Hadoop","S. Munirathinam; S. Sun; J. Rosin; H. Sirigibathina; A. Chinthakindi","Data Science, Micron Technology Inc., Manassas, VA, USA; Quality Assurance, Micron Technology Inc., Manassas, VA, USA; Information Technology, Micron Technology Inc., Manassas, VA, USA; Information Technology, Micron Technology Inc., Manassas, VA, USA; Quality Assurance, Micron Technology Inc., Manassas, VA, USA","2019 IEEE International Conference on Smart Manufacturing, Industrial & Logistics Engineering (SMILE)","23 Jan 2020","2019","","","19","23","The manufacturing industry generates vast amounts of data today and modern semiconductor manufacturing is one of the key contributors to this tsunami of data. Efficient storage and analysis of data have a significant impact on productivity and profit. In this paper, we will explore design and implementation of a manufacturing Data Lake in Hadoop ecosystem and how the data is used to generate business intelligence.","","978-1-5386-7998-2","10.1109/SMILE45626.2019.8965302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965302","Big Data;Hadoop;Hive;Data Lake;Semiconductor Manufacturing","Productivity;Electronics industry;Ecosystems;Semiconductor device manufacture;Big Data applications;Tsunami;Explosives;Manufacturing;Engines;Logistics","","5","","11","IEEE","23 Jan 2020","20-21 April 2019","20-21 April 2019","IEEE","IEEE Conferences"
"A big data architecture for managing oceans of data and maritime applications","I. Lytra; M. -E. Vidal; F. Orlandi; J. Attard","Enterprise Information Systems, University of Bonn & Fraunhofer IAIS, Germany; Universidad Simón Bolívar, Venezuela; Enterprise Information Systems, University of Bonn & Fraunhofer IAIS, Germany; Enterprise Information Systems, University of Bonn & Fraunhofer IAIS, Germany","2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)","5 Feb 2018","2017","","","1216","1226","Data in the maritime domain is growing at an unprecedented rate, e.g., terabytes of oceanographic data are collected every month, and petabytes of data are already publicly available. Big data from heterogeneous sources such as sensors, buoys, vessels, and satellites could potentially fuel a large number of interesting applications for environmental protection, security, fault prediction, shipping routes optimization, and energy production. However, because of several challenges related to big data and the high heterogeneity of the data sources, such applications are still underdeveloped and fragmented. In this paper, we analyze challenges and requirements related to big maritime data applications and propose a scalable data management solution. A big data architecture meeting these requirements is described, and examples of its implementation in concrete scenarios are provided. The related data value chain and use cases in the context of a European project, BigDataOcean, are also described.","","978-1-5386-0774-9","10.1109/ICE.2017.8280019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8280019","Big Data;Big Data Applications;Oceanographic Data;Maritime Applications","Marine vehicles;Temperature sensors;Big Data applications;Sea measurements;Engines","","19","","8","IEEE","5 Feb 2018","27-29 June 2017","27-29 June 2017","IEEE","IEEE Conferences"
"Corddl: An Efficient and Extensible Connector between Relational Databases and Data Lakes","T. Zhang; H. Liu; C. Yu; P. Wang","Research Center of Big Data Technology Nanhu Laboratory, JiaXing, China; Research Center of Big Data Technology Nanhu Laboratory, JiaXing, China; Research Center of Big Data Technology Nanhu Laboratory, JiaXing, China; Research Center of Big Data Technology Nanhu Laboratory, JiaXing, China","2023 5th International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)","2 Apr 2024","2023","","","173","177","In the era of big data, data lakes have been widely used. However, enterprise applications generally do not interact directly with data lakes, but with relational databases. Relational databases may become data silos because they can only store structured data. In this paper, we proposed Corddl, a connector between relational databases and data lakes. For ingesting data from a relational database into a data lake, first, Corddl uses configuration files and parameters to match the data source class and data source instance for the analysis engine. Then, Corddl uses the JDBC driver to realize the connection to the relational database, and do data conversion according to the data type configuration file. Finally, the ingested data is written into the data lake. There is a similar process for ingesting data from a data lake into a relational database. Experimental results show that Corddl has high efficiency and strong extensibility.","2994-2977","979-8-3503-5993-0","10.1109/MLBDBI60823.2023.10481929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10481929","big data;data lake;relational database;data ingestion;data conversion","Connectors;Data conversion;Soft sensors;Relational databases;Machine learning;Lakes;Big Data applications","","","","15","IEEE","2 Apr 2024","15-17 Dec. 2023","15-17 Dec. 2023","IEEE","IEEE Conferences"
"6G Enabled Smart Environments and Sustainable Cities: an Intelligent Big Data Architecture","E. M. Ouafiq; R. Saadane; A. Chehri; M. Wahbi","SIRC/LaGeS-EHTP, EHTP Km 7 Route, El Jadida, Morocco; SIRC/LaGeS-EHTP, EHTP Km 7 Route, El Jadida, Morocco; University of Quebec in Chicoutimi, Chicoutimi, QC, Canada; SIRC/LaGeS-EHTP, EHTP Km 7 Route, El Jadida, Morocco",2022 IEEE 95th Vehicular Technology Conference: (VTC2022-Spring),"25 Aug 2022","2022","","","1","5","Nowadays, there is an important need for fault-tolerant and energy-efficient self-organization systems, especially within smart cities. Internet of Things (IoT) proved capable of observing and examining the environment, generating & processing data. IoT is now applicable to almost every industry, including transportation and logistics, utilities, agriculture, smart cities, and more. In these industries, various types of meters, sensors, and trackers are used to constantly monitor activities, automate processes and optimize tasks. With the help of big data analytics, they can drive decision-making systems based on observations. As a result, the cities-management challenges are growing. The smart cities requirements are increasing to remedy the challenges, which requires a self-organized network composed of a sizeable number of nodes distributed across an area of interest. The traditional communication systems show limitations, especially when dealing with massive data rates, latency, the explosive growth of vehicular communication, and dynamic mobility. In this study, we explore a way to leverage the capabilities of wireless communication and big data analytics in favor of Smart Cities.","2577-2465","978-1-6654-8243-1","10.1109/VTC2022-Spring54318.2022.9860772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9860772","Big Data;Data Science;Smart City;Smart Farming;Wireless Network;5G;6G","Temperature sensors;Temperature measurement;Wireless sensor networks;Smart cities;Big Data;Agriculture;Internet of Things","","9","","18","IEEE","25 Aug 2022","19-22 June 2022","19-22 June 2022","IEEE","IEEE Conferences"
"Big Data Architecture for Mobile Network Operators","M. N. Simaković; Z. G. Cica; I. B. Masnikosa","School of Electrical Engineering, University of Belgrade, Belgrade, Serbia; School of Electrical Engineering, University of Belgrade, Belgrade, Serbia; School of Electrical Engineering, University of Belgrade, Belgrade, Serbia","2021 15th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS)","22 Nov 2021","2021","","","283","286","Mobile network operators are faced with tremendous data growth in their networks. Complex and multilayered networks, high-quality signal demands, and strong competition are only some of the aspects that push operators to further optimize their networks. Also, introduction of 5G in their networks enabled mobile operators to offer broad spectrum of 5G services, especially IoT (Internet of Things) and M2M (Machine to Machine) services which further increase traffic volume and the amount of collected data. Traditional data management solutions currently used are not able to successfully respond to such huge amounts of data. Big data technologies represent a modern approach for coping with the enormous data quantities. In this paper, we propose a big data solution that can collect and process huge amounts of data to extract valuable information and help mobile operators to bring their networks to enhanced quality level and offer full IoT solutions to their customers.","","978-1-6654-4442-2","10.1109/TELSIKS52058.2021.9606290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606290","Big data;Mobile networks;IoT;Lambda architecture","Performance evaluation;Machine-to-machine communications;5G mobile communication;Big Data;Nonhomogeneous media;Telecommunications;Internet of Things","","5","","21","IEEE","22 Nov 2021","20-22 Oct. 2021","20-22 Oct. 2021","IEEE","IEEE Conferences"
"An Effective and Scalable Data Modeling for Enterprise Big Data Platform","J. Patel","Data Engineer for Rockstar Games, Carlsbad, CA, USA",2019 IEEE International Conference on Big Data (Big Data),"24 Feb 2020","2019","","","2691","2697","The enormous growth of the internet, enterprise applications, social media, and IoT devices in the current time caused a huge spike in enterprise data growth. Big data platform provided scalable storage to manage enterprise data growth and served easier data access to decision-makers, stakeholders and business users. It is a well-known challenge to classify, organize and store all this data and process it to provide business insights. Due to nature, variety, velocity, volume and value of data make it difficult to effectively process big data. Enterprises face challenges to apply complex business rules, to generate insights and to support data-driven decisions in a timely fashion. As big data lake integrates streams of data from a bunch of business units, stakeholders usually analyze enterprise-wide data from various data models. Data models are a vital component of Big data platform. Users may do complex processing, run queries and perform big table joins to generate required metrics depending on the available data models. It is usually a time consuming and resource-intensive process to find the value from data. It is a no-brainer that big data platform in the enterprise needs high-quality data modeling methods to reach an optimal mix of cost, performance, and quality. This paper addresses these challenges by proposing an effective and scalable way to organize and store data in Big Data Lake. It presents some of the basic principles and methodology to build scalable data models in a distributed environment. It also describes how it overcomes common challenges and presents findings.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9005614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005614","Big Data;Big Data Lake;Scalable Data Modeling;Hadoop;Spark;Business Intelligence;Big Data Analytics","Data models;Big Data;Business;Analytical models;Computational modeling;Lakes;Solid modeling","","25","","23","IEEE","24 Feb 2020","9-12 Dec. 2019","9-12 Dec. 2019","IEEE","IEEE Conferences"
"Analysis Technology of Data Mining Technology and Cloud Computing","L. Chong; W. Lei","(Department of Information Engineering, Cangzhou Technical College, Cangzhou, Hebei, China; (Department of Information Engineering, Cangzhou Technical College, Cangzhou, Hebei, China","2015 International Conference on Intelligent Transportation, Big Data and Smart City","21 Jan 2016","2015","","","121","124","At present, the technology of data mining and analysis of practical stronger and stronger, the connotation of analyzing large data mining technology, characteristics, and according to the characteristics of classification is a series of challenging projects. Hardtop cloud computing can be used in large data mining platform system architecture is analyzed, the paper will be of HDFS and graphs processing technology is introduced in detail.","","978-1-5090-0464-5","10.1109/ICITBS.2015.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7383982","Big data;Mining technology;Cloud computing","Transportation;Big data;Smart cities","","2","","6","IEEE","21 Jan 2016","19-20 Dec. 2015","19-20 Dec. 2015","IEEE","IEEE Conferences"
"Efficient Data Exchange Between Typical Data Lake and DWH Corporate Systems","A. Suleykin; A. Bobkova; P. Panfilov; I. Chumakov","Russian Academy of Sciences, Doctoral School V.A. Trapeznikov Institute of Control Sciences, Moscow, Russia; Department of Business Informatics, Graduate School of Business, HSE University, Moscow, Russia; Department of Business Informatics, Graduate School of Business, HSE University, Moscow, Russia; Digital Marketing&e-Commerce Liebherr Appliances Liebherr-International Deutschland GmbH, Mooscow, Russia","2021 International Conference on Electrical, Computer and Energy Technologies (ICECET)","11 Feb 2022","2021","","","1","6","In the last five years, many companies around the world have been successfully implemented Apache Hadoop as a main Data Lake storage for all data presented in the organization. At the same time, the adoption of other Open-Source technologies has been also increasing for years, such as classical MPP-based systems for Analytical workloads. Thus, the question of efficient and fast data integration between Apache Hadoop and other organizational data storage systems is highly important for enterprises, where business and decision makers need the minimum delay of big heterogeneous data exchange between Hadoop and other storages. In this paper, we compare different options for loading data from Apache Hadoop, representing the Data Lake of organization, into Open-Source MPP Greenplum database with the role of classical data warehouse for analytical workloads, and choose the best one. Also, we identify potential risks of using different data loading methods.","","978-1-6654-4231-2","10.1109/ICECET52533.2021.9698468","RFBR(grant numbers:20-07-00958); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9698468","Big Data;Data Lake;Hadoop Distributed File System;Greenplum;Massively Parallel Processing;Data Warehouse","Loading;Distributed databases;Data integration;Cluster computing;Computer architecture;Production;Data warehouses","","","","11","IEEE","11 Feb 2022","9-10 Dec. 2021","9-10 Dec. 2021","IEEE","IEEE Conferences"
"Research on Guangxi Multi-dimensional Visualization Platform Construction of Distribution Network Based on Big Data Architecture","L. Shuo; Q. Liwen; Y. Xiaoyong; Z. Yangjun; L. Shan","Electric Power Research Institute of Guangxi Power Grid Co., Ltd., Nanning, Guangxi; Electric Power Research Institute of Guangxi Power Grid Co., Ltd., Nanning, Guangxi; Electric Power Research Institute of Guangxi Power Grid Co., Ltd., Nanning, Guangxi; Electric Power Research Institute of Guangxi Power Grid Co., Ltd., Nanning, Guangxi; Electric Power Research Institute of Guangxi Power Grid Co., Ltd., Nanning, Guangxi",2019 2nd International Conference on Safety Produce Informatization (IICSPI),"19 May 2020","2019","","","56","60","It is urgent to build an effective big data management platform for power distribution network in view of the problems of massive power data being hard to be fully explored and managed integrally. Based on the big data architecture of power, this paper constructs the multidimensional visualization platform of distribution network, and realizes the multi-function architecture of the platform by integrating the production decision-making system and data analysis technology of multi-source distribution network. Based on the geographic information system, a large-screen visualization display platform of distribution network production business is established. Rich charts and geographic information are used to realize the comprehensive display of distribution network production business, providing users with smooth data visualization interaction and assisting in the decision-making of distribution network production business. The construction of multi-dimensional visualization platform of distribution network based on big data architecture has important research significance and application value to comprehensively improve the intelligent construction of distribution network.","","978-1-7281-4566-2","10.1109/IICSPI48186.2019.9095937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095937","Distribution network;Visualization platform;Data mining;Geographic information system","Big Data;Data visualization;Cloud computing;Distributed databases;Computer architecture;Power systems;Production","","","","15","IEEE","19 May 2020","28-30 Nov. 2019","28-30 Nov. 2019","IEEE","IEEE Conferences"
"Research on Federated Learning Data Management Method Based on Data Lake Technology","L. Kai; Z. Liang; Y. Yaojing; Y. Dazhu; Z. Min","Yunnan Tobacco Company, Kunming, China; Yunnan Huaye Investment Co., Ltd, Kunming, China; Yunnan Tobacco Company, Kunming, China; Yunnan Tobacco Company, Kunming, China; Yunnan Tobacco Company Information Center, Kunming, China","2023 International Conference on Computers, Information Processing and Advanced Education (CIPAE)","14 Dec 2023","2023","","","385","390","With the diversified development of data information in the era of big data, the scale of data is also increasing. Due to the multi-source and heterogeneous data characteristics in the information age, the data sources are also more diverse. It is difficult to identify valid data, and data consistency cannot be guaranteed. Based on the above background, we gained a complete understanding of enterprise requirements and challenges after in-depth research on the federated learning data for data lake technology. This paper designs and implem12 -*+ents a data lake federated learning and data management system. Firstly, the application of enterprise big data is analyzed in detail, and the many deficiencies in its sources and query methods are clarified. On this basis, through in-depth customization of the unified query system, based on data lake technology and federated learning technology, the enterprise's multi-heterogeneous data system is re-planned to run stably and reliably and manage enterprise data more efficiently.","","979-8-3503-4271-0","10.1109/CIPAE60493.2023.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350237","Data lake;Metadata management;Federated learning;Multi-source heterogeneity;Unified query system","Federated learning;Pain;Soft sensors;Memory;Information processing;Metadata;Media","","1","","5","IEEE","14 Dec 2023","26-28 Aug. 2023","26-28 Aug. 2023","IEEE","IEEE Conferences"
"Analyzing Data Format Interoperability in API Ecosystems Using Big Data Architecture","W. Alzyadat; S. Al-Showarah","Department of Software Engineering, Faculty of Science and IT Alzaytoonah, University of Jordan, Amman, Jordan; dept of Software Engineering, Faculity of Information Technology, Mutah University",2023 International Conference on Information Technology (ICIT),"29 Aug 2023","2023","","","609","612","The API is a key player in cut edge technology for interact and exchange information across platforms whatever internally or external where the transfer information needs to be adjusted by several issues during request/response functions.by traditional concept of API was handle it by data mapping functions for this point uncapitalizable with big data architecture especially of variety of data which data able to presents in different kinds of structured data that aimed to fnd out approach to solve it, for this point the XML play an important role for variety data by dynamic behavior with effective","2831-3399","979-8-3503-2006-0","10.1109/ICIT58056.2023.10225959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10225959","API;Big Data","Ecosystems;XML;Big Data;Behavioral sciences;Information technology;Interoperability","","","","14","IEEE","29 Aug 2023","9-10 Aug. 2023","9-10 Aug. 2023","IEEE","IEEE Conferences"
"Banking Comprehensive Risk Management System Based on Big Data Architecture of Hybrid Processing Engines and Databases","S. Ma; H. Wang; B. Xu; H. Xiao; F. Xie; H. -N. Dai; R. Tao; R. Yi; T. Wang","Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Department of ICT and Natural Sciences, Norwegian University of Sci. & Tech., Aalesund, Norway; School of Economics and Commerce, South China University of Technology, Guangdong, China; College of Computer, Guangdong University of Technology, Guangdong, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Faculty of Information Tech., Macau University of Sci. and Tech., Macau, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China","2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","6 Dec 2018","2018","","","1844","1851","Banks are shifting from a simple credit risk management model to the comprehensive risk management model. Banking risks come from many channels and systems. Big data technology provides an innovative and effective solution for data management, and thus is suitable to be applied in the risk management scenarios that require high-quality data and complex data analysis. This paper firstly proposes big data architecture of hybrid processing engines and databases. This architecture uses Hadoop ecosystem with ETL and Spark processing engines, and using massive parallel processing databases (MPP), transactional databases, and HDFS. Then a banking comprehensive risk management system prototype based on the proposed big data architecture is implemented. Comparisons and evaluations clearly demonstrate that the proposed system has better performance.","","978-1-5386-9380-3","10.1109/SmartWorld.2018.00310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8560288","comprehensive risk management;big data;hybrid architecture","Technological innovation;Databases;Smart cities;Computer architecture;Banking;Big Data;Systems support;Risk management;Sparks;Engines","","2","","31","IEEE","6 Dec 2018","8-12 Oct. 2018","8-12 Oct. 2018","IEEE","IEEE Conferences"
"Soft and Declarative Fishing of Information in Big Data Lake","B. Małysiak-Mrozek; M. Stabla; D. Mrozek","Institute of Informatics, Silesian University of Technology, Gliwice, Poland; Institute of Informatics, Silesian University of Technology, Gliwice, Poland; Institute of Informatics, Silesian University of Technology, Gliwice, Poland",IEEE Transactions on Fuzzy Systems,"2 Oct 2018","2018","26","5","2732","2747","In recent years, many fields that experience a sudden proliferation of data, which increases the volume of data that must be processed and the variety of formats the data is stored in have been identified. This causes pressure on existing compute infrastructures and data analysis methods, as more and more data are considered as a useful source of information for making critical decisions in particular fields. Among these fields exist several areas related to human life, e.g., various branches of medicine, where the uncertainty of data complicates the data analysis, and where the inclusion of fuzzy expert knowledge in data processing brings many advantages. In this paper, we show how fuzzy techniques can be incorporated in big data analytics carried out with the declarative U-SQL language over a big data lake located on the cloud. We define the concept of big data lake together with the Extract, Process, and Store process performed while schematizing and processing data from the Data Lake, and while storing results of the processing. Our solution, developed as a Fuzzy Search Library for Data Lake, introduces the possibility of massively parallel, declarative querying of big data lake with simple and complex fuzzy search criteria, using fuzzy linguistic terms in various data transformations, and fuzzy grouping. Presented ideas are exemplified by a distributed analysis of large volumes of biomedical data on Microsoft Azure cloud. Results of performed tests confirm that the presented solution is highly scalable on the Cloud and is a successful step toward soft and declarative processing of data on a large scale. The solution presented in this paper directly addresses three characteristics of big data, i.e., volume, variety, and velocity, and indirectly addresses, veracity and value.","1941-0034","","10.1109/TFUZZ.2018.2812157","Microsoft Research within Microsoft Azure for Research Award; Statutory Research Funds of Institute of Informatics, Silesian University of Technology, Gliwice, Poland(grant numbers:BK/213/RAU2/2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314734","Big data;biomedical data analysis;cloud computing;declarative languages;fuzzy logic;querying","Big Data;Lakes;Bioinformatics;Data analysis;Relational databases;Pragmatics","","42","","76","IEEE","12 Mar 2018","Oct. 2018","","IEEE","IEEE Journals"
"Evaluating the Quality of Social Media Data in Big Data Architecture","A. Immonen; P. Pääkkönen; E. Ovaska","VTT Technical Research Centre of Finland, Oulu, Finland; VTT Technical Research Centre of Finland, Oulu, Finland; VTT Technical Research Centre of Finland, Oulu, Finland",IEEE Access,"20 May 2017","2015","3","","2028","2043","The use of freely available online data is rapidly increasing, as companies have detected the possibilities and the value of these data in their businesses. In particular, data from social media are seen as interesting as they can, when properly treated, assist in achieving customer insight into business decision making. However, the unstructured and uncertain nature of this kind of big data presents a new kind of challenge: how to evaluate the quality of data and manage the value of data within a big data architecture? This paper contributes to addressing this challenge by introducing a new architectural solution to evaluate and manage the quality of social media data in each processing phase of the big data pipeline. The proposed solution improves business decision making by providing real-time, validated data for the user. The solution is validated with an industrial case example, in which the customer insight is extracted from social media data in order to determine the customer satisfaction regarding the quality of a product.","2169-3536","","10.1109/ACCESS.2015.2490723","Tekes and VTT through the DIGILE’s Need for Speed Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299603","architecture;big data;metadata;quality attribute;quality of data;Architecture;big data;metadata;quality attribute;quality of data","Big data;Social network services;Computer architecture;Meta data;Online services","","94","","52","OAPA","16 Oct 2015","2015","","IEEE","IEEE Journals"
"The Automation of the Data Lake Ingestion Process from Various Sources","A. Tunjić","Multicom d.o.o., Zagreb, Croatia","2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","11 Jul 2019","2019","","","1276","1281","In a big data environment, it is often necessary to ingest data from different sources into a unique storage. Because of low memory price, system distribution and failure tolerance, that storage is typically HDFS. It enables users to manipulate data with different tools from the Hadoop ecosystem. The process of data ingestion seems simple. However, because sources can be different database systems, structured, semi-structured and unstructured data complicate the ingestion procedure. It is usually not enough to just store everything. Data needs to be stored in such a way that enables users to quickly access and manipulate it. There are many ingestion-specific solutions in the big data ecosystem. This paper will describe an implemented system for data ingestion from MSSQL, MySQL and Postgres into a Hive database. The process starts with creating tables with corresponding metadata, continues with the ingestion process and ends with a description of how the process is automated. The implementation of Sqoop as an open-source tool and Hue, a web user interface from Cloudera, will be described.","2623-8764","978-953-233-098-4","10.23919/MIPRO.2019.8756864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756864","hadoop;sqoop;hive;data ingestion automation;big data","Tools;Big Data;Metadata;Relational databases;Servers;Password","","1","","8","","11 Jul 2019","20-24 May 2019","20-24 May 2019","IEEE","IEEE Conferences"
"A Semantics-Enabled Approach for Data Lake Exploration Services","M. Garda","Dept. of Information Engineering, University of Brescia, Brescia, Italy",2019 IEEE World Congress on Services (SERVICES),"29 Aug 2019","2019","2642-939X","","327","330","Ignited by the advent of Data Science, organisations are spending more and more resources in understanding their Big Data, attracted by the opportunity of turning them into actionable insights. Data Lakes have been proposed as repositories in charge of storing vast amount of heterogeneous data, regardless its structure, enabling the possibility of postponing transformation and analytical processes. In this context, Semantic Web technologies may be used to enable interoperability and improve data access, by providing Data Exploration Services. Starting from these premises, the goal of this paper is to describe a semantic approach apt to the compelling challenge of Data Exploration Services, aimed at personalising the exploration experience. The approach has been preliminary validated within a Smart City context, where aggregation of urban data, according to multiple perspectives through the definition of proper indicators, enables urban data exploration at different granularity levels for distinct categories of users.","2642-939X","978-1-7281-3851-0","10.1109/SERVICES.2019.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8817206","data exploration services;data lake;semantic web;Big Data","Lakes;Ontologies;Semantics;Smart cities;Metadata","","1","","14","IEEE","29 Aug 2019","8-13 July 2019","8-13 July 2019","IEEE","IEEE Conferences"
"A Big Data Lake for Multilevel Streaming Analytics","R. Liu; H. Isah; F. Zulkernine","School of Computing, Queen’s University, Kingston, Canada; School of Computing, Queen’s University, Kingston, Canada; School of Computing, Queen’s University, Kingston, Canada",2020 1st International Conference on Big Data Analytics and Practices (IBDAP),"5 Nov 2020","2020","","","1","6","Large organizations are seeking to create new architectures and scalable platforms to effectively handle data management challenges due to the explosive nature of data rarely seen in the past. These data management challenges are largely posed by the availability of streaming data at high velocity from various sources in multiple formats. The changes in data paradigm have led to the emergence of new data analytics and management architecture. This paper focuses on storing high volume, velocity and variety data in the raw formats in a data storage architecture called a data lake. First, we present our study on the limitations of traditional data warehouses in handling recent changes in data paradigms. We discuss and compare different open source and commercial platforms that can be used to develop a data lake. We then describe our end-to-end data lake design and implementation approach using the Hadoop Distributed File System (HDFS) on the Hadoop Data Platform (HDP). Finally, we present a real-world data lake development use case for data stream ingestion, staging, and multilevel streaming analytics which combines structured and unstructured data. This study can serve as a guide for individuals or organizations planning to implement a data lake solution for their use cases.","","978-1-7281-8106-6","10.1109/IBDAP50342.2020.9245460","IBM Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9245460","Hadoop Data Platform;Hadoop Distributed File System;NiFi;streaming data;unstructured data","Data analysis;Distributed databases;Organizations;Lakes;Big Data;Data warehouses;Planning","","11","","17","IEEE","5 Nov 2020","25-26 Sept. 2020","25-26 Sept. 2020","IEEE","IEEE Conferences"
"Research on data lakehouse architecture for grid business data","Y. Meng; Q. Li; Z. Wang","State Grid Information and Telecommunication Group Co., Ltd., Beijing, China; State Grid Information and Telecommunication Group Co., Ltd., Beijing, China; State Grid Information and Telecommunication Group Co., Ltd., Beijing, China","2024 3rd International Conference on Energy, Power and Electrical Technology (ICEPET)","13 Aug 2024","2024","","","523","527","With the development of national informatization construction and big data technology, the traditional database design can no longer support the efficient storage and real-time analysis of massive data, and it is difficult to adapt to increasingly complex business scenarios with high reliability and timeliness. Therefore, to build a high-performance and low-cost big data processing system, combined with the characteristics of the grid business data, this paper proposes an optimized big data architecture based on data lakehouse, using the pre-computing and ETL capabilities of the Doris database instead of the original complex technology stacks, and designing a Doris table structure that meets the statistical analysis requirements of the five-level organizational structure of State Grid to support data analysis result query. The lightweight architecture supports high concurrency, sub-second latency, and multi-dimensional analysis. Finally, a big data analysis system for power grid business operation is realized with less development cost and lower deployment difficulty, which can quickly dig deep information of application and user data and improve platform operation capability.","","979-8-3503-5265-8","10.1109/ICEPET61938.2024.10626461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10626461","Data lakehouse;data processing;database","Data analysis;Costs;Databases;Statistical analysis;Organizations;Big Data;Reliability engineering","","","","7","IEEE","13 Aug 2024","17-19 May 2024","17-19 May 2024","IEEE","IEEE Conferences"
"Cloud-Based Data Lake","V. Choudhary; Kartik; N. Bala","Computer Science & Engineering, Chandigarh University, Mohali, India; Computer Science & Engineering, Chandigarh University, Mohali, India; Computer Science & Engineering, Chandigarh University, Mohali, India",2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA),"21 Feb 2025","2024","","","1","5","A Cloud-Based Data Lake is a robust data storage and administration architecture that uses cloud computing's scalability, flexibility, and cost-effectiveness to manage massive amounts of organized and unstructured data. This article investigates the design, deployment options, and advantages of employing a cloud-hosted information lake, focusing on its role as part of contemporary data-driven processes for making decisions. If a data centre or data mart appears to be a container of water cleansed and ready for consumption, then “Data Lake” is a full lake of data that has been cleaned and is ready to use. A major emphasis is on how cloud-based solutions, such as expandable storage, analytics in real time, and machine learning connections, enable businesses to store, process, and review data with unparalleled efficiency and agility. The report also looks at the obstacles that come with cloud-based information lakes, such as data security, administration, and compliance and suggests solutions. This research offers a detailed review of data stored in cloud lakes, providing significant insights for enterprises. This research offers an in-depth analysis of cloud-based information lakes, providing useful knowledge to enterprises contemplating using cloud infrastructure for more efficient data management and data analysis, which will promote innovation and edge in a rapidly changing digital landscape.","","979-8-3315-1795-3","10.1109/ICAIQSA64000.2024.10882348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10882348","Cloud Computing;Big Data;Real Time Analytics;Cost-Efficiency","Cloud computing;Technological innovation;Quantum computing;Reviews;Scalability;Memory;Machine learning;Lakes;Big Data applications;Real-time systems","","","","18","IEEE","21 Feb 2025","20-21 Dec. 2024","20-21 Dec. 2024","IEEE","IEEE Conferences"
"Towards a heterogeneous, polystore-like data architecture for the US Department of Veteran Affairs (VA) enterprise analytics","E. Begoli; D. Kistler; J. Bates","Computational Sciences and Engineering, Division Oak Ridge National Laboratory, Tennessee, USA; Computational Sciences and Engineering, Division Oak Ridge National Laboratory, Tennessee, USA; Business Intelligence Service Line US Department of Veterans Affairs (VA), Washington, DC, USA",2016 IEEE International Conference on Big Data (Big Data),"6 Feb 2017","2016","","","2550","2554","The Polystore architecture revisits the federated approach to access and querying the standalone, independent databases in the uniform and optimized fashion, but this time in the context of heterogeneous data and specialized analyses. In light of this architectural philosophy, and in the light of the major data architecture development efforts at the US Department of Veterans Administration (VA), we discuss the need for the heterogeneous data store consisting of large relational data warehouse, an image and text datastore, and a peta-scale genomic repository. The VA's heterogeneous datastore would, to a larger or smaller degree, follow the architectural blueprint proposed by the polystore architecture. To this end, we discuss the current state of the data architecture at VA, architectural alternatives for development of the heterogeneous datastore, some relevant use cases, the anticipated challenges, and the drawbacks and benefits of adopting the polystore architecture.","","978-1-4673-9005-7","10.1109/BigData.2016.7840896","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840896","","Genomics;Bioinformatics;Medical services;Computer architecture;Databases;Biomedical imaging;Big data","","11","","21","IEEE","6 Feb 2017","5-8 Dec. 2016","5-8 Dec. 2016","IEEE","IEEE Conferences"
"Data Ingestions as a Service (DIaaS): A Unified Interface for Heterogeneous Data Ingestion, Transformation, and Metadata Management for Data Lake","H. V. Sreepathy; B. Dinesh Rao; M. Kumar Jaysubramanian; B. Deepak Rao","Manipal School of Information Sciences, Manipal Academy of Higher Education, Manipal, India; Manipal School of Information Sciences, Manipal Academy of Higher Education, Manipal, India; Frameworks and Tools, MulticoreWare, Coimbatore, India; Manipal School of Information Sciences, Manipal Academy of Higher Education, Manipal, India",IEEE Access,"29 Oct 2024","2024","12","","156131","156145","Data ingestion tools are critical component of Data Lake. Existing data ingestion tools face challenges of handling large variety, formats, sources of data. There exists void for unified data ingestion interface to handle the above research problems. This study proposes an innovative and integrated framework for data ingestion in a data lake, addressing the challenges posed by heterogeneous data sources, formats, and metadata management. The framework comprises three novel modules: First Unified Data Integration Connectors (UDIC), which provide seamless connectivity and data retrieval capabilities from diverse sources including databases, data warehouses, file systems, cloud storage, and APIs; Second, Adaptive Data Variety Transformation (ADVT), a module that intelligently handles the transformation and processing of structured, semi-structured, and unstructured data types, ensuring efficient ingestion into the data lake; and third, Intelligent Metadata Management (IMM), a module that captures, stores, and manages metadata associated with the ingested data, offering advanced search, discovery, and enrichment functionalities. Comparative study corroborates features offered by the service with existing data ingestion tools to evaluate the novelty and significance of the study. Performance validation shows varying ingestion latencies across different data types: approximately 148.1 microseconds per record for structured data, 234.2 microseconds per record for semi-structured data, 65.6 microseconds per kilobyte (KB) for video data, and 42.7 microseconds per KB for image data. These results underscore the importance of considering data structure and size in optimizing ingestion processes. Overall, this research aims to revolutionize data ingestion in data lake environments by providing a unified solution for handling diverse data sources, formats, and metadata management.","2169-3536","","10.1109/ACCESS.2024.3479736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10716380","Data ingestion;data lake;data sources;data formats;unified interface;data ingestion service;big data","Big Data applications;Metadata;Soft sensors;Real-time systems;Organizations;Java;Internet of Things;Relational databases;File systems;Data lakes","","5","","24","CCBYNCND","14 Oct 2024","2024","","IEEE","IEEE Journals"
"Big data lakes can support better population health for rural India — Swastha Bharat","S. Gupta; P. Tripathi","Research Scholar, Mewar University, Ghaziabad, India; Mewar University, Ghaziabad, India",2016 International Conference on Innovation and Challenges in Cyber Security (ICICCS-INBUSH),"15 Aug 2016","2016","","","145","150","As India seeks to become a world power, there's maybe nothing additional vital than the health and well-being of its citizens. Better population health is one among the vital considerations in India. While, those living in cities and massive cities have access to high finish health services, the ample folks living in rural India, notably within the remote elements of the country face issues of inadequate facilities and poor access to attention. The inefficiencies and inequities within the public health care access in India have pushed forward the necessity for power and innovative solutions to strengthen a similar. Paper identifies the large shortage of correct health care facilities and addresses a way to give bigger access to primary health care services in rural India. any this paper, it conjointly addresses the important computing and analytical ability of Big Data in process huge volumes of transactional information in real time things to show the dream of Swastha Bharat (Healthy India) into reality. Furthur the target of this paper is to suggest the reforms within the health care sector and boosts the discussions on how government will harness innovations within the big data analytics to boost the health care system.","","978-1-5090-2084-3","10.1109/ICICCS.2016.7542361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542361","Big Data Analytics;Health care in India;Big Data Lake;Big Data;Rural Health Care;e-Health Care;Swastha Bharat","Big data;Sociology;Statistics;Government;Hospitals;Diseases","","2","","10","IEEE","15 Aug 2016","3-5 Feb. 2016","3-5 Feb. 2016","IEEE","IEEE Conferences"
"Big Data architecture proposal for vehicular traffic detection","N. I. Herrera Herrera","Informática y Ciencias de la Computación, Universidad UTE Pichincha, Quito",2020 International Conference of Digital Transformation and Innovation Technology (Incodtrin),"23 Aug 2021","2020","","","118","122","Currently, IT solutions that detect situations of vehicle congestion use isolated technologies, which are not part of an ecosystem that manages them together, made it difficult to gear the tools used by affecting the operation of the solutions.This study aims to present a Big Data architecture proposal for the implementation of vehicle traffic detection software. The research is presented based on the base architecture established for Big Data systems, as well as established studies identifying the particular phases identified for the processing of vehicle traffic records collected in the city of Quito-Ecuador.","","978-1-6654-2319-9","10.1109/Incodtrin51881.2020.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516660","Twitter;Big Data;Architecture;Application","Technological innovation;Gears;Digital transformation;Urban areas;Ecosystems;Computer architecture;Big Data","","","","0","IEEE","23 Aug 2021","28-30 Oct. 2020","28-30 Oct. 2020","IEEE","IEEE Conferences"
"A big data architecture for learning analytics in higher education","F. Matsebula; E. Mnkandla","School of Natural and Applied Sciences, Sol Plaatje University, Kimberley, South Africa; School of Computing, University of South Africa, Pretoria, South Africa",2017 IEEE AFRICON,"7 Nov 2017","2017","","","951","956","Data with high volume, velocity, variety and veracity brings the new experience curve of analytics. Big data in higher education comes from different sources that include blogs, social networks, student information systems, learning management systems, research, and other machine-generated data. Once the data is analysed it promises better student placement processes; more accurate enrolment forecasts, and early warning systems that identify and assist students at-risk of failing or dropping out. Big data is becoming a key to creating competitive advantages in higher education. Like with any organization, traditional data processing and analysis of structured and unstructured data using RDBMS and data warehousing no longer satisfy big data challenges. The lack of adequate conceptual architectures for big data tailored for institutions of higher education has led to many failures to produce meaningful, accessible, and timely information for decision making. Therefore, this calls for the development of conceptual architectures for big data in higher education. This paper presents an architecture for big data analytics in higher education.","2153-0033","978-1-5386-2775-4","10.1109/AFRCON.2017.8095610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8095610","learning analytics;big data;educational data mining","Education;Data mining;Big Data;Computer architecture;Decision making;Data visualization;Data analysis","","27","","20","IEEE","7 Nov 2017","18-20 Sept. 2017","18-20 Sept. 2017","IEEE","IEEE Conferences"
"A Real-Time Big Data Architecture for Glasses Detection Using Computer Vision Techniques","A. Fernández; R. Casado; R. Usamentiaga","Fundación CTIC (Technological Center) Technological Scientific Park of Gijón, Gijón, Asturias, Spain; University of Oviedo, Gijón, Asturias, Spain; University of Oviedo, Gijón, Asturias, Spain",2015 3rd International Conference on Future Internet of Things and Cloud,"26 Oct 2015","2015","","","591","596","Automatic glasses detection is a hot topic withing the large-scale face images classification domain, which has impact on face recognition or soft biometrics for person identification. In many practical video surveillance applications, the faces acquired by cameras are low resolution. Therefore, this type of applications requires processing of a large number of relatively small-sized images. However, continuous stream of image and video data processing is a big data challenge. This need fits with the goals of Big Data streaming processing systems. In this paper, we propose a real-time Big Data architecture in order to collect, maintain and analyze massive volumes of images related with the problem of automatic glasses detection. This architecture can be used as an automatic image tagging related with glasses detection on face images.","","978-1-4673-8103-1","10.1109/FiCloud.2015.78","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300872","big data;real-time processing;glasses detection","Big data;Streaming media;Face;Glass;Fasteners;Computer architecture;Support vector machines","","7","1","32","IEEE","26 Oct 2015","24-26 Aug. 2015","24-26 Aug. 2015","IEEE","IEEE Conferences"
"Still Open Problems in Data Warehouse and Data Lake Research: extended abstract","R. Wrembel","Faculty of Computing and Telecommunications, Poznan University of Technology, Poznan, Poland","2021 Eighth International Conference on Social Network Analysis, Management and Security (SNAMS)","16 Mar 2022","2021","","","01","03","During recent years, we observe a widespread of new data sources, especially all types of social media and IoT devices, which produce huge data volumes, whose content ranges from fully structured to totally unstructured. All these types of data are commonly referred to as big data. They are typically described by the three most important characteristics, called 3V [1], namely: an extremely large volume, a variety of data models and structures (data representations), as well as a high velocity at which data are generated. We argue that out of these three Vs, the most challenging is variety [2]. Such data need to be integrated and transformed into a common representation, which is suitable for analysis, in a similar manner as traditional (mainly table-like) data.","","978-1-6654-9495-3","10.1109/SNAMS53716.2021.9732098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9732098","data integration;data warehouse;data lake;big data;extract transform load;data processing workflow;data processing pipeline;data quality;ETL optimization;data source evolution;metadata","Social networking (online);Soft sensors;Transforms;Data warehouses;Big Data applications;Data models;Security","","4","","34","IEEE","16 Mar 2022","6-9 Dec. 2021","6-9 Dec. 2021","IEEE","IEEE Conferences"
"The Practical Model DAM for Analyzing Data Lake Architectures in a Financial Institution in Peru","C. Z. Ramirez; S. B. Mauricio; L. Wong","Information Systems Engineering Program Universidad Peruana de Ciencias Aplicadas, Lima, Perú; Information Systems Engineering Program Universidad Peruana de Ciencias Aplicadas, Lima, Perú; Information Systems Engineering Program Universidad Peruana de Ciencias Aplicadas, Lima, Perú","2023 International Conference on Electrical, Computer and Energy Technologies (ICECET)","22 Jan 2024","2023","","","1","6","As the volume of data generated in the financial sector continues to grow organizations are challenged to effectively manage this vast amount of information. However, the implementation of a technological solution, especially in highly regulated financial environments with stringent security and privacy requirements, does not achieve the expected result. This study proposes a novel model, called DAM (Data Lake Analysis Model), to analyze the implemented Data Lake architecture of a Peruvian financial institution in order to identify opportunities for improvement and close the gaps that may arise in the management of large volumes of data. This methodology consists of 3 levels: (1) data and internal process analysis, (2) architecture and tools analysis, and (3) data governance analysis. A case study was conducted in a financial institution, and interviews and questionnaires were conducted with analysts and data scientists. The results at the three levels of analysis were very positive, with scores of 4.33, 4.06, and 4.11, respectively. In addition, the results of the questionnaire indicate that the experts rated the analysis as “good”, suggesting that the DAM model is effective in addressing the challenges of financial data management in the Peruvian context.","","979-8-3503-2781-6","10.1109/ICECET58911.2023.10389359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10389359","data lake;big data;data lake architecture;architecture analysis;financial institution","Analytical models;Privacy;Dams;Computational modeling;Computer architecture;Organizations;Lakes","","","","21","IEEE","22 Jan 2024","16-17 Nov. 2023","16-17 Nov. 2023","IEEE","IEEE Conferences"
"Big Data Pipeline with ML-Based and Crowd Sourced Dynamically Created and Maintained Columnar Data Warehouse for Structured and Unstructured Big Data","K. Ghane","Anagira, Inc.",2020 3rd International Conference on Information and Computer Technologies (ICICT),"14 May 2020","2020","","","60","67","The existing big data platforms take data through distributed processing platforms and store them in a data lake. The architectures such as Lambda and Kappa address the real-time and batch processing of data. Such systems provide real time analytics on the raw data and delayed analytics on the curated data. The data denormalization, creation and maintenance of a columnar dimensional data warehouse is usually time consuming with no or limited support for unstructured data. The system introduced in this paper automatically creates and dynamically maintains its data warehouse as a part of its big data pipeline in addition to its data lake. It creates its data warehouse on structured, semi-structured and unstructured data. It uses Machine Learning to identify and create dimensions. It also establishes relations among data from different data sources and creates the corresponding dimensions. It dynamically optimizes the dimensions based on the crowd sourced data provided by end users and also based on query analysis.","","978-1-7281-7283-5","10.1109/ICICT50521.2020.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092124","Big Data;Data Lake;Data Warehouse;Data Pipeline;Machine Learning;Structured Data;Unstructured Data;Columnar Database","Data warehouses;Lakes;Real-time systems;Big Data;Distributed databases;Data mining","","8","","36","IEEE","14 May 2020","9-12 March 2020","9-12 March 2020","IEEE","IEEE Conferences"
"Big Data Architectures Benchmark for Forecasting Electricity Consumption","H. Daki; A. El Hannani; H. Ouahmane","Laboratory of Information Technologies, National School of Applied Sciences, University of Chouaib Doukkali, El Jadida, Morocco; Laboratory of Information Technologies, National School of Applied Sciences, University of Chouaib Doukkali, El Jadida, Morocco; Laboratory of Information Technologies, National School of Applied Sciences, University of Chouaib Doukkali, El Jadida, Morocco",2020 5th International Conference on Cloud Computing and Artificial Intelligence: Technologies and Applications (CloudTech),"2 Mar 2021","2020","","","1","6","Now a day, educational institutions present one of the highest power consuming sector due to their new activities and occupancy pattern. This enormous amount of energy consumption at the university need a huge effort to reduce it. Smart grid is among the efficient solution to save energy and balance supply and demand. For the same purpose, the National School of Applied Sciences of El Jadida-Morocco wants take advantage from smart grid to maintain the balance between energy production and consumption. Despite of all added value of this smart grid solution for the school, it has the issue of managing energy production surplus, because it cannot inject it into Moroccan electrical infrastructure neither store it using storage devices. So, to overcome this challenge the system need to predict electrical consumption to be able to produce exactly the same value. Recently, Big Data contributed very well in analysing electrical consumption data using many tools and advanced techniques. It process, interprets and analyzes huge quantity of data to make it more profitable and valuable. For that reason, the school will take refuge in Big data technology to implement a custom system to predict electrical energy consumption by analyze all factors that influence electrical energy use. In this paper, we propose a benchmark of the main Big Data architectures in the field and that will cover all electrical energy data processing from data collection, data storage, data analytic and data visualization. The aim of this benchmark is to choose the optimal architecture in term of fault tolerance, resource management, data storage and data modelling to forecast electricity consumption in educational institutions.","","978-1-7281-6175-4","10.1109/CloudTech49835.2020.9365912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9365912","Big Data architecture;Lambda architecture;SMACK architecture;Electrical forecasting;Smart grid","Data analysis;Memory;Computer architecture;Big Data;Benchmark testing;Smart grids;Resource management","","","","16","IEEE","2 Mar 2021","24-26 Nov. 2020","24-26 Nov. 2020","IEEE","IEEE Conferences"
"The Delta Big Data Architecture for Mobility Analytics","G. Vouros; A. Glenis; C. Doulkeridis","Dept. of Digital Systems, University of Piraeus, Piraeus, Greece; Dept. of Digital Systems, University of Piraeus, Piraeus, Greece; Dept. of Digital Systems, University of Piraeus, Piraeus, Greece",2020 IEEE Sixth International Conference on Big Data Computing Service and Applications (BigDataService),"28 Aug 2020","2020","","","25","32","Motivated by requirements in mobility analytics that require joint exploitation of streamed and voluminous archival data from diverse and heterogeneous data sources, this paper presents the δ architecture. Denoting ""difference"", δ emphasises on the different processing requirements from loosely-coupled components, which serve intertwined processing purposes, forming processing pipelines. The δ architecture, contributes principles for realizing systems, focusing on the requirements from components and pipelines, which are specified as constraints on performance indicators. The article presents a specific instantiation of the δ architecture to satisfy requirements for big data mobility analytics, exploiting real-world mobility data for performing realtime and batch analysis tasks.","","978-1-7281-7022-0","10.1109/BigDataService49289.2020.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9179581","Big Data Architecture, Mobility Analytics, Software System","Computer architecture;Task analysis;Big Data;Pipelines;Surveillance;Batch production systems","","2","","24","IEEE","28 Aug 2020","3-6 Aug. 2020","3-6 Aug. 2020","IEEE","IEEE Conferences"
"Big data architectures for data lakes: A systematic literature review","S. Ramchand; T. Mahmood","School of Mathematics and Computer Science (SMCS), Institute of Business Administration (IBA), Karachi Karachi, Pakistan; School of Mathematics and Computer Science (SMCS), Institute of Business Administration (IBA), Karachi Karachi, Pakistan","2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)","10 Aug 2022","2022","","","1141","1146","The rise in big technologies has been demanding different concepts and practices for data exploitation; among them data lake is a recently emerged concept that is meant to deal with the heterogeneous data. Data lakes have been residing in the big data era since 2010, but there has not been any systematic review yet over data lake implementation. In this research survey, we conduct a review and provide a road map to researcher that elaborates what has happened to data lakes till now. We aim to give understanding for basic concept of data lakes and propose a novel data lake definition that could best describe the concept based on the literature review. One of the main problem while implementing data lake is deciding the technologies to use, this study covers technologies that can potentially be used for data lake implementation. Furthermore, data lake architectures and their variants are discussed in detail. Moreover, we analyze current state, challenges, pros and cons of the data lake. This study is all in one place for researchers who try to understand data lake concept, architectures, technologies, approaches, current state and challenges.","0730-3157","978-1-6654-8810-5","10.1109/COMPSAC54236.2022.00179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842704","Data Lakes;Data Lakes Big Data;Data Lake Management;Data Lake Storage;Data Lake Architecture","Systematics;Computational modeling;Bibliographies;Roads;Computer architecture;Lakes;Metadata","","3","","20","IEEE","10 Aug 2022","27 June-1 July 2022","27 June-1 July 2022","IEEE","IEEE Conferences"
"Evaluation of Banking Standards to ascertain their suitability for building Data Models for Big data based Data Lake for Banking Domain","N. B. Satyendra; N. K. Swami; P. V. Bhailume","Edgeverve, INFOSYS, Bangalore, India; Edgeverve, INFOSYS, Bangalore, India; Edgeverve, INFOSYS, Bangalore, India","2020 IEEE International Conference on Technology, Engineering, Management for Societal impact using Marketing, Entrepreneurship and Talent (TEMSMET)","6 Oct 2021","2020","","","1","7","Data Lakes for banks are built to take care of the reporting and Analytics needs of the banks. Hence Data Lake is designed to provide the decision-making queries and results that are analyzed for Banking needs. Data Lakes of banks are OLAP in nature. A mere duplication of source system schema doesn’t translate into an effective Data Lake. It requires a restructuring of data and creating appropriate data models to suit the required Banking needs. The three notable standards in Banking are BIAN, ISO 20022 and FIBO. In this paper, we explore the suitability of these standards for building the data models that can be used by Banks for its Big data based Data Lake.","","978-1-6654-0482-2","10.1109/TEMSMET51618.2020.9557578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557578","Data Lake;Data Warehouse;Big Data;Data Model;Analytics;Banking Standards","ISO Standards;Engineering management;Buildings;Decision making;Entrepreneurship;Banking;Lakes","","","","10","IEEE","6 Oct 2021","10-10 Dec. 2020","10-10 Dec. 2020","IEEE","IEEE Conferences"
"AB-DOM: An Algorithmic Framework for Supporting Privacy-Preserving Big Data Publishing in Big Data Lakes","A. Cuzzocrea; S. Soufargi","Big Data Engineering and Analytics Laboratory (iDEA Lab), University of Calabria, Rende, Italy; Big Data Engineering and Analytics Laboratory (iDEA Lab), University of Calabria, Rende, Italy",IEEE Transactions on Big Data,"12 Nov 2025","2025","11","6","3029","3046","With the emergence of new technologies that extend the capabilities of actual data collection methods, healthcare data are more and more amassed in the purpose of being later analyzed to serve the ultimate, well-known, goal of 4P medicine (Predictive, Preventive, Personalized, Participative). Given the sensitive nature of healthcare data, and in a matter of compliance with data protection and privacy regulations, there is a need to make data publishing more secure. This is one of the main goals of the EU H2020 QUALITOP research project, with particular regards to the issue of defining a big health data smart digital platform and the shared data lake. In this context, we design, implement and experimentally assess an innovative algorithmic framework called Advanced Privacy-Preserving Big Data Publishing in Hierarchical DOMains (AB-DOM). AB-DOM is based on state-of-the-art anonymization techniques mixed with a graph coloring algorithm and an integrated data sampling method to guarantee that sensitive data are highly secured.","2332-7790","","10.1109/TBDATA.2025.3570081","EU H2020 QUALITOP - Call Reference: H2020 - SC1-DTH- 01-2019(grant numbers:875171); research project SERICS(grant numbers:PE00000014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11003804","Privacy-preserving Big Data;Big Data lakes","Data privacy;Big Data;Information integrity;Information filtering;Medical services;Publishing;Data analysis;Precision medicine;Cancer;Immunotherapy","","","","56","IEEE","14 May 2025","Dec. 2025","","IEEE","IEEE Journals"
"Enrichment Patterns for Big Data","K. Holley; G. Sivakumar; K. Kannan","IBM Fellow and Master Inventor, IBM, USA; Senior Certified Architect, Master Inventor IBM, Australia; Researcher IBM, India",2014 IEEE International Congress on Big Data,"25 Sep 2014","2014","","","796","799","Importance of ""Big Data"" in terms of business value is very well understood across different sectors such as telecom, banking, insurance etc for targeted campaigns or real time performance actions. ""Big Data"" emphasizes the following characteristics, Velocity, Volume, Variety, and Veracity. Business adopts one or more of the above properties to cater to the requirements of the clients. Data being crucial in this case has different facets. The sources of data being different and consumption across different businesses makes the data modeling a tougher problem. Data schema evolves with new sources of data, changes due to change in data sources, etc Thus enrichment of data constantly triggers the needs to device methods to adopt the models to the new patterns. When the enrichment patterns are understood, modeling the Big Data and Management becomes easy. We highlight the list of such identified patterns based upon our real world implementations. In this work, we propose a method to evolve the data models from its initially defined schema such that data models can easily adapt to changes. We show through cases studies from real world example that our model can adopt to evolve data from different sources.","2379-7703","978-1-4799-5057-7","10.1109/BigData.Congress.2014.127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906871","Data Architecture patterns for Big Data","Big data;Data models;Organizations;Abstracts;Context;Real-time systems","","7","","4","IEEE","25 Sep 2014","27 June-2 July 2014","27 June-2 July 2014","IEEE","IEEE Conferences"
"Defining architecture components of the Big Data Ecosystem","Y. Demchenko; C. de Laat; P. Membrey","System and Network Engineering Group, University of Amsterdam, Amsterdam, The Netherlands; System and Network Engineering Group, University of Amsterdam, Amsterdam, The Netherlands; Hong Kong Polytechnic University, Hong Kong SAR, China",2014 International Conference on Collaboration Technologies and Systems (CTS),"31 Jul 2014","2014","","","104","112","Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a socalled Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties (also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Data phenomena and related challenges to modern technologies, and initiate wide discussion.","","978-1-4799-5158-1","10.1109/CTS.2014.6867550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6867550","Big Data Technology;Big Data Ecosystem;Big Data Architecture Framework (BDAF);Big Data Infrastructure (BDI);Big Data Lifecycle Management (BDLM);Cloud based Big Data Infrastructure Services","Big data;Data models;Computer architecture;Security;Biological system modeling;Ecosystems;Industries","","259","1","45","IEEE","31 Jul 2014","19-23 May 2014","19-23 May 2014","IEEE","IEEE Conferences"
"From Data Warehouse to Lakehouse: A Comparative Review","A. A. Harby; F. Zulkernine","School of Computing, Queen’s University, Kingston, Canada; School of Computing, Queen’s University, Kingston, Canada",2022 IEEE International Conference on Big Data (Big Data),"26 Jan 2023","2022","","","389","395","Digital information systems currently generate a vast amount of data every minute which emphasizes the continuing need to advance big data management systems with efficient data ingestion and knowledge extraction capabilities. To address the ‘big data’ problems due to high volume, velocity, variety, and veracity, data management systems evolved from structured databases to big data storage systems, graph databases, data warehouses, and data lakes but each solution has its strengths and shortcomings. The need to produce actionable knowledge fast from unstructured data ingested from distributed sources requires a marriage of data warehouses and data lakes to create a data Lakehouse (LH). The objective is to use the strengths of the data warehouse in producing insights fast from processed merged data, and of the data lake in ingesting and storing high-speed unstructured data with post-storage transformation and analytics capabilities. In this paper, we present a comparative review of the existing data warehouse and data lake technology to highlight their strengths and weaknesses and propose the desired and necessary features of the LH architecture, which has recently gained a lot of attention in the big data management research community.","","978-1-6654-8045-1","10.1109/BigData55660.2022.10020719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020719","Big data;Data Warehouse;Data Lake;Data Lakehouse","Distributed databases;Data warehouses;Big Data applications;Data mining;Information systems","","58","","31","IEEE","26 Jan 2023","17-20 Dec. 2022","17-20 Dec. 2022","IEEE","IEEE Conferences"
"Big Data Augmentation with Data Warehouse: A Survey","U. Aftab; G. F. Siddiqui","Department of Computer Science, Quaid-i-Azam University, Islamabad, Pakistan; Department of Computer Science, Quaid-i-Azam University, Islamabad, Pakistan",2018 IEEE International Conference on Big Data (Big Data),"24 Jan 2019","2018","","","2775","2784","With dynamic changes in world's technology, an increasing growth and adoption observed in the usage of social media, computer networks, internet of things, and cloud computing. Research experiments are also generating huge amount of data which are to be collected, managed and analyzed. This huge data is known as ""Big Data"". Research analysts have perceived an increase in data that contains both useful and useless entities. In extraction of useful information, data warehouse finds difficulties in enduring with increasing amount of data generated. With shifts in paradigm, big data analytics emerged as promising area of research which supports business intelligence in terms of decision making. This paper provides a comprehensive survey on BigData, BigData problems, BigData Analytics and Big Data Warehouse. In addition, it also explains how the need for augmentation of big data and data warehouse emerged in perspective of decision making, comparing methods and research problems. It also elaborates applications which support Big Data, Data Warehouse, and its challenges.","","978-1-5386-5035-6","10.1109/BigData.2018.8622182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622182","Data Warehouse;Big Data;Map Reduce;Augmentation;Data Lake;OLAP;CMM;D&M","Data warehouses;Big Data;Current measurement;Data mining;Decision making;Organizations","","13","","30","IEEE","24 Jan 2019","10-13 Dec. 2018","10-13 Dec. 2018","IEEE","IEEE Conferences"
"Big Data Augmentation with Data Warehouse: A Survey","U. Aftab; G. F. Siddiqui","Department of Computer Science, Quaid-i-Azam University, Islamabad, Pakistan; Department of Computer Science, Quaid-i-Azam University, Islamabad, Pakistan",2018 IEEE International Conference on Big Data (Big Data),"24 Jan 2019","2018","","","2785","2794","With dynamic changes in world's technology, an increasing growth and adoption observed in the usage of social media, computer networks, internet of things, and cloud computing. Research experiments are also generating huge amount of data which are to be collected, managed and analyzed. This huge data is known as ""Big Data"". Research analysts have perceived an increase in data that contains both useful and useless entities. In extraction of useful information, data warehouse finds difficulties in enduring with increasing amount of data generated. With shifts in paradigm, big data analytics emerged as promising area of research which supports business intelligence in terms of decision making. This paper provides a comprehensive survey on BigData, BigData problems, BigData Analytics and Big Data Warehouse. In addition, it also explains how the need for augmentation of big data and data warehouse emerged in perspective of decision making, comparing methods and research problems. It also elaborates applications which support Big Data, Data Warehouse, and its challenges.","","978-1-5386-5035-6","10.1109/BigData.2018.8622206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622206","Data Warehouse;Big Data;Map Reduce;Augmentation;Data Lake;OLAP;CMM;D&M","Data warehouses;Big Data;Current measurement;Data mining;Decision making;Organizations","","9","","30","IEEE","24 Jan 2019","10-13 Dec. 2018","10-13 Dec. 2018","IEEE","IEEE Conferences"
"Research on the Application of Medical Big Data","M. Li; C. Wang; L. Yan; S. Wei","School of Computer Science, Hubei University of Technology; School of Computer Science, Hubei University of Technology; School of Computer Science, Hubei University of Technology; CCCC Second Highway Consultants Co. Ltd., Wuhan, China",2019 14th International Conference on Computer Science & Education (ICCSE),"23 Sep 2019","2019","","","478","482","Big data technology is increasingly used in the field of medical. Through medical big data technology, the growing medical data can be effectively processed, and the utilization of medical data can be improved. In this study, an architecture of medical big data application is proposed based on the analysis of the main sources and basic characteristics of medical big data. This architecture elaborates and discusses the collection, storage, analysis, exchange and sharing of medical big data, proposes data standards, data governance, data operational maintenance management, and information security systems. The specific application of medical big data is discussed as well. Finally, the challenges of current medical big data application are analyzed from the aspects of open sharing platform, application requirements, data utilization, data security and privacy, and the construction of compound professional talents.","2473-9464","978-1-7281-1846-8","10.1109/ICCSE.2019.8845376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845376","Medical big data;Architecture analysis;Data application","Medical diagnostic imaging;Standards;Drugs;Big Data applications;Information security","","4","","23","IEEE","23 Sep 2019","19-21 Aug. 2019","19-21 Aug. 2019","IEEE","IEEE Conferences"
"DLMetaChain: An IoT Data Lake Architecture Based on the Blockchain","M. Pingos; P. Christodoulou; A. Andreou","Department of Electrical Engineering, Computer Engineering and Informatics, Cyprus University of Technology, Limassol; Department of Computer Science, Neapolis University, Pafos; Department of Electrical Engineering, Computer Engineering and Informatics, Cyprus University of Technology, Limassol","2022 13th International Conference on Information, Intelligence, Systems & Applications (IISA)","30 Sep 2022","2022","","","1","8","Nowadays, the IoT ecosystem is evolving rapidly, with multiple heterogeneous sources producing high volumes of data and processes transforming this data into meaningful or “smart” information. These volumes of data, including IoT data, need to be stored in repositories that can host raw, unprocessed, relational and non-relational types of data, such as Data Lakes. Due to the weakness of metadata management, security & access control is one of the main challenges of Big Data storage architectures as Data Lakes can be replaced without oversight of the contents. Recently, the Blockchain technology has been introduced as an effective solution to build trust between different entities, where trust is either nonexistent or unproven, and to address security and privacy concerns. In this paper we introduce DLMetaChain, an extended Data Lake metadata mechanism that consists of data from heterogeneous data sources which interact with IoT data. The extended mechanism mainly focuses on developing an architecture to ensure that the data in the Data Lake is not modified or altered by taking into advantage the capabilities of the Blockchain.","","978-1-6654-6390-4","10.1109/IISA56318.2022.9904404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904404","Internet of Things;Smart Data Processing;Data Lakes;Heterogeneous Data Sources;Metadata Mechanism;Data Blueprint;Blockchain;Smart Contracts","Data privacy;Privacy;Soft sensors;Smart contracts;Semantics;Production;Metadata","","3","","22","IEEE","30 Sep 2022","18-20 July 2022","18-20 July 2022","IEEE","IEEE Conferences"
"A Big Data Architecture for the Extraction and Analysis of EHR Data","S. Silvestri; A. Esposito; F. Gargiulo; M. Sicuranza; M. Ciampi; G. De Pietro","Department of Engineering of the University of Naples ""Parthenope"", Centro Direzionale di Napoli, Naples, Italy; Institute for High Performance Computing and Networking of the National Research Council of Italy, Naples, Italy; Institute for High Performance Computing and Networking of the National Research Council of Italy, Naples, Italy; Institute for High Performance Computing and Networking of the National Research Council of Italy, Naples, Italy; Institute for High Performance Computing and Networking of the National Research Council of Italy, Naples, Italy; Institute for High Performance Computing and Networking of the National Research Council of Italy, Naples, Italy",2019 IEEE World Congress on Services (SERVICES),"29 Aug 2019","2019","2642-939X","","283","288","In the current Italian eHealth scenario, a national IT platform has been designed and developed with the purpose of ensuring the interoperability between the various Electronic Health Record (EHR) systems that have been adopted in the different regions of the country, according to the requirements provided by Italian Laws. In this way, the healthcare providers and the policy makers can acquire and process the data of a patient despite its initial format and source, allowing an improved quality of patient care and optimizing the management of the financial resources. To further exploit this huge resource of health and social data, it is very important to allow the extraction of the complex information buried under the Big Data source enabled by the EHRs, providing the physicians, the researchers and public health policy makers with innovative instruments. Meeting this need is not a trivial task, due to the difficulties of processing different document formats and processing Natural Language text, alongside to the problems related to the data size. In this paper we propose a Big Data architecture that is able to extract information from the documents acquired by the EHRs, integrate and process them, providing a set of valuable data for both physicians and patients, as well as decision makers.","2642-939X","978-1-7281-3851-0","10.1109/SERVICES.2019.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8817262","Big Data Analytics;Electronic Health Record Interoperability;Natural Language Processing","Data mining;Interoperability;Standards;Medical services;Task analysis;Big Data;Data integration","","17","","22","IEEE","29 Aug 2019","8-13 July 2019","8-13 July 2019","IEEE","IEEE Conferences"
"A big data repository and architecture for managing hearing loss related data","B. Ye; I. Basdekis; M. Smyrlis; G. Spanoudakis; K. Koloutsou","City University of London, UK; City University of London, UK; City University of London, UK; City University of London, UK; Guys and St. Thomas NHS Hospital, London, UK",2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),"9 Apr 2018","2018","","","174","177","The vast amount of data, which arise in healthcare applications makes traditional data processing technology inadequate and requires the use of fast emerging big data technologies to cope with key challenges, including data heterogeneity, pace of acquisition, size, privacy and security. Addressing these challenges requires a shift from traditional data analysis systems and techniques to big data management and processing platforms as well as big data analytics centric architectures. In this paper, we introduce such an architecture. The architecture has been developed to support the acquisition and analysis of big data sets regarding hearing loss and the provision of related healthcare services for the purpose of informing public health policy making. The paper provides an overview of the system and presents the outcomes of an initial evaluation of its performance.","","978-1-5386-2405-0","10.1109/BHI.2018.8333397","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8333397","big data;architectures;security;hearing loss and audiological data;e-health","Hospitals;Computer architecture;Big Data;Servers;Auditory system;Hearing aids;Testing","","10","","13","IEEE","9 Apr 2018","4-7 March 2018","4-7 March 2018","IEEE","IEEE Conferences"
"Big data architecture with mobile cloud in CDroid operating system for storing huge data","S. Koley; S. Nandy; P. Dutta; S. Dhar; T. Sur","Dept. of Computer Science & Engg., Budge Budge Institute of Technology, Kolkata, India; Dept. of Computer Science & Engg., Budge Budge Institute of Technology, Kolkata, India; Dept. of Computer Science & Engg., Budge Budge Institute of Technology, Kolkata, India; Dept. of Computer Science & Engg., Budge Budge Institute of Technology, Kolkata, India; Dept. of Computer Science & Engg., Budge Budge Institute of Technology, Kolkata, India","2016 International Conference on Computing, Analytics and Security Trends (CAST)","1 May 2017","2016","","","12","17","We are stepping frontward for an epoch of zeta bytes from Giga/Tera/Peta/Exa bytes in this era of computer science. The data storage in clouds is not the only preference as big data technology is obtainable for processing of both structured and unstructured data. Today a colossal sum of data is engendered by mobile phones (Smartphone) of both the composition types. For the sake of faster processing and elegant data utilization for gigantic quantity of data CDroid operating systems can be implemented with big data. Big data architecture is realized with mobile cloud for paramount deployment of wherewithal. The faster execution can be ended feasible for the make use of a new data centric architecture of MapReduce technology where as HDFS (Hadoop Distributed File System) also plays a big accountability in using data with dissimilar structures. As time advances the degree of data and information generated from smartphone augments and faster execution is call for the same. As per our research and development the only resolution for this mammoth amount of data is to put into practice Big data with CDroid scheme for best use of it. We believe this effort will budge a step ahead on the road to healthier civilization in close proximity to expectations.","","978-1-5090-1338-8","10.1109/CAST.2016.7914932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7914932","Big data;CDroid;Hadoop;MapReduce;Mobile Cloud","Cloud computing;Big Data;Computer architecture;Mobile communication;Servers;File systems;Mobile handsets","","","","26","IEEE","1 May 2017","19-21 Dec. 2016","19-21 Dec. 2016","IEEE","IEEE Conferences"
"Research on Highway Enterprise-Level Big Data Platform Architecture and Predictive Analytics Algorithm","X. Sun; R. Sun; X. Chen","Yunnan Communications Investment and Construction Group Co., Ltd, Yunnan, China; Yunnan Communications Investment and Construction Group Co., Ltd, Yunnan, China; Yunnan Communications Investment and Construction Group Co., Ltd, Yunnan, China",2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD),"10 Aug 2023","2023","","","214","219","With the continuous expansion of highway network and digital construction, the system scale and data volume show exponential growth, and the construction and application of highway enterprise-level big data platform can effectively improve the digitization of business systems and significantly enhance the level of highway operation and management services. In this paper, based on the study of the data architecture and data governance of the highway enterprise-level big data platform, we focus on the application algorithm model of the highway enterprise-level big data platform, build the interval short-time prediction algorithm and the interval cycle trend prediction algorithm, and actually apply and verify them in the big data center platform of Yunnan Communications Investment and Construction Group Co., Ltd. After the study, the interval short-time prediction algorithm and interval cycle trend prediction algorithm are above 90%, with high accuracy and reliability, and have high application value.","2769-3554","978-1-6654-9125-9","10.1109/ICAIBD57115.2023.10206383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10206383","highway;enterprise-level big data platform;data architecture;interval short-time prediction algorithm;interval periodic trend prediction algorithm","Road transportation;Transportation;Big Data;Predictive models;Prediction algorithms;Market research;Data models","","","","10","IEEE","10 Aug 2023","26-29 May 2023","26-29 May 2023","IEEE","IEEE Conferences"
"Building a Data Lake for Smart Building Data: Architecture for Data Quality and Interoperability","J. L. Hernández; S. Martín; P. Kapsalis; K. Katsigarakis; E. Sarmas; V. Marinakis","Energy Division, CARTIF Technology Centre, Boecillo, Valladolid, Spain; Energy Division, CARTIF Technology Centre, Boecillo, Valladolid, Spain; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece; Faculty of the Built Environment, University College of London, London, United Kindom; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece","2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)","15 Dec 2023","2023","","","1","8","Building data is growing, where sources are heterogeneous and still treated as silos from different building domains (energy, architecture elements or automation networks, among others). This leads to a lock-in when providing capabilities of data exploitation, such as added-value services, artificial intelligence services or machine-learning activities. Assuring data integration via interoperability mechanisms becomes then pivotal in building data management schemas. Under this perspective, this paper presents an architecture of a data lake that integrates heterogeneous data sources from diverse building domains with the aim of homogenising data-sets and creating data-quality procedures to ensure high-quality services to make better decisions. Based on enriched data between static and dynamic data-sets, the data lake ultimate develops business intelligence mechanism to extract knowledge and information.","","979-8-3503-1806-7","10.1109/IISA59645.2023.10345892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10345892","data lake;data quality;interoperability;digitalisation;smart buildings","Smart buildings;Architecture;Data integrity;Soft sensors;Buildings;Pipelines;Metadata","","5","","16","IEEE","15 Dec 2023","10-12 July 2023","10-12 July 2023","IEEE","IEEE Conferences"
"Research On Fault Information Detection Method Of Power System Based On Big Data Architecture","W. Jingjing; F. Hao; W. Yixi; L. Fen; Y. Zheng",Information & Communication Branch of Hubei epc.; Information & Communication Branch of Hubei epc.; Information & Communication Branch of Hubei epc.; Information & Communication Branch of Hubei epc.; Information & Communication Branch of Hubei epc.,2019 International Conference on Robots & Intelligent System (ICRIS),"22 Aug 2019","2019","","","311","317","In order to solve the problem of poor robustness of power system faults, the fault information detection method of power system is studied based on the big data framework, and the fault information characteristics of power system are collected and analyzed by combining the neural network principle, the characteristic parameters of system operation data are calculated, the standard monitoring parameters are calculated, and the fault detection and diagnosis are carried out according to the standard reference data, thus effectively completing the main group monitoring of power system fault information. Finally, the experiment proves that the power system fault information monitoring method based on big data architecture has higher robustness than the traditional method and fully meets the research requirements.","","978-1-7281-2632-6","10.1109/ICRIS.2019.00086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806608","big data;Power system;Fault detection","Conferences;Robots;Intelligent systems","","","","10","IEEE","22 Aug 2019","15-16 June 2019","15-16 June 2019","IEEE","IEEE Conferences"
"Bank Big Data Architecture Based on Massive Parallel Processing Database","S. Ma; H. Xiao; B. Xu; R. Tao; F. Xie; D. Zeng; T. Wang","Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; College of Computer, Guangdong University of Technology, Guangdong, China; South China University of Technology; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China","2018 15th International Symposium on Pervasive Systems, Algorithms and Networks (I-SPAN)","7 Feb 2019","2018","","","93","99","Banking systems generates lots of data (TB) daily and records PB historical transaction data, which requires a cost-effective and high performance data processing system for data management. This paper introduces the existing data processing architecture, and proposes a hybrid database solution based upon Massive Parallel Processing (MPP), transactional databases, Hadoop and Storm platforms, which has been applied in Fujian Rural Credit Union. Based on the high-performance features of MPP, a data loading method of Extraction-Load-Transform (ETL) is established. The performance of the hybrid prototype against the traditional Oracle one is validated through five common data processing models (insert only, truncate and insert, etc.) with practical data. The experiment results clearly show that the hybrid database prototype is more cost-effective and provides better performance.","2375-527X","978-1-5386-8534-1","10.1109/I-SPAN.2018.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8636287","bank data architecture;massive paralleling processing;extraction-load-transform;hybrid structure","Databases;Computer architecture;Business;Servers;Big Data applications","","3","","25","IEEE","7 Feb 2019","16-18 Oct. 2018","16-18 Oct. 2018","IEEE","IEEE Conferences"
"Early warning of abnormal operation data of power generation equipment based on data lake collaborative multi-core correlation vector","H. Meng; X. Li","CHN Energy Group Ningxia Power Co., Ltd, Yinchuan, China; CHN Energy Group Ningxia Power Co., Ltd, Yinchuan, China","2025 IEEE 3rd International Conference on Sensors, Electronics and Computer Engineering (ICSECE)","2 Dec 2025","2025","","","168","173","The early warning of abnormal operation data of power generation equipment can further realize the overall goal of power system reform. This paper puts forward an early warning model of abnormal operation data of power generation equipment based on the data lake collaborative multi-core correlation vector, constructs the data lake collaborative multi-core correlation vector for the joint analysis of the production and consumption of power commodities, and realizes the reconstruction and feature combination control of the operation data of power generation equipment by using the joint analysis of market operation rules, market management methods and market operation models. Then, this study established a fair and open distribution model for the electricity trading market, and combined it with the geographical location factors of power generation equipment operation for transaction control. Based on the market coverage area, the market power of market participants will be monitored and controlled, so as to realize the data lake collaborative multi-core correlation analysis of abnormal early warning of power generation equipment operation data and realize intelligent early warning. The simulation results show that the model can effectively realize the early warning and control of abnormal operation data of power generation equipment, and realize the intelligent planning, stable operation control and dynamic management of power grid and power generation equipment.","","979-8-3315-0356-7","10.1109/ICSECE65727.2025.11256819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11256819","data lake;Collaborative multi-core correlation vector;Power generation equipment;Operational data;Abnormal early warning","Analytical models;Correlation;Evaluation models;Collaboration;Production;Big Data applications;Power markets;Data models;Vectors;Power generation","","","","10","IEEE","2 Dec 2025","29-31 Aug. 2025","29-31 Aug. 2025","IEEE","IEEE Conferences"
"Internet of Things Big Data Analytics: The Case of Noise Level Measurements at the Roskilde Music Festival","T. -M. Groenli; B. Flesch; R. Mukkamala; R. Vatrapu; S. Klavestad; H. Bergner","Mobile Technology Lab, Kristiania University College, Oslo, Norway; Dep. Digitalization, Copenhagen Business School, Copenhagen, Denmark; Dep. Digitalization, Copenhagen Business School, Copenhagen, Denmark; Dep. Technology, Kristiania University College, Oslo, Norway; Dep. Technology, Kristiania University College, Oslo, Norway; Dep. Technology, Kristiania University College, Oslo, Norway",2018 IEEE International Conference on Big Data (Big Data),"24 Jan 2019","2018","","","5153","5158","In this paper we demonstrate the feasibility of IoT deployment for noise level measurement to time-limited and high-intense, high-volume data, events. Through an iterative process, a prototype solution were designed and implemented in a real-time, privacy-compliant IoT sensor system under tight constraints concerning budget and development time. Our sensor system enables festival management to easily track, document and further, by applying real time big data analytics to the harvested information, have fact-full insights generated for decision making in terms of resolving noise disturbances. The whole approach was demonstrated by the use of lightweight Internet of Things architecture demonstrating how web technologies can be used throughout the technology stack in and IoT big data analytics case.","","978-1-5386-5035-6","10.1109/BigData.2018.8622406","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622406","Internet of things;Big Data;Architecture;Big data analytics;IoT analytics;sound measurement;web stack","Big Data;Internet of Things;Real-time systems;Noise level;Noise measurement;Urban areas;Logic gates","","5","","21","IEEE","24 Jan 2019","10-13 Dec. 2018","10-13 Dec. 2018","IEEE","IEEE Conferences"
"Application of Big Data in Intelligent Government Affairs Management: An Example in Natural Resources Management","F. Meng; M. Yao; D. Kong; X. Wang; Y. Fan; F. Meng","Information Center of Ministry of Natural Resources, Beijing, P. R. China; Information Center of Ministry of Natural Resources, Beijing, P. R. China; Information Center of Ministry of Natural Resources, Beijing, P. R. China; Information Center of Ministry of Natural Resources, Beijing, P. R. China; Information Center of Ministry of Natural Resources, Beijing, P. R. China; Academy of The National Territorial Planning, Heilongjiang, P. R. China",2022 7th International Conference on Big Data Analytics (ICBDA),"21 Apr 2022","2022","","","50","53","China's government affairs service has been rapidly evolving from the stage of data-guided to data-driven in recent years. The effective utilization of big data is a critical step toward developing a smart government affairs management system. Using natural resources big data as an example, this paper discusses the data architecture, spatial data analysis techniques and their applicability to intelligent land management system on a broad scale, as well as several technical challenges that must be addressed, such as integrated computing of multi-source distributed data, the lack of intelligence in the present government affairs management system, and the need for real-time collaboration between multi-level databases. This paper intends to broaden researchers' understanding of big data technology and application in the field of natural resources, and it serves as a reference point for big data in the pursuit of intelligent government affairs management.","","978-1-6654-7938-7","10.1109/ICBDA55095.2022.9760366","Ministry of Natural Resources; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760366","natural resources big data;spatial data analysis techniques;intelligent government affairs management;Ministry of Natural Resources;application","Data analysis;Government;Decision making;Distributed databases;Collaboration;Big Data;Spatial databases","","","","9","IEEE","21 Apr 2022","4-6 March 2022","4-6 March 2022","IEEE","IEEE Conferences"
"Multilayer Big Data Architecture for Remote Sensing in Eolic Parks","E. Moguel; J. C. Preciado; F. Sánchez-Figueroa; M. A. Preciado; J. Hernández","Department of Telematic and Informatic Systems Engineering, Universidad de Extremadura, Cáceres, Spain; Department of Telematic and Informatic Systems Engineering, Universidad de Extremadura, Cáceres, Spain; Department of Telematic and Informatic Systems Engineering, Universidad de Extremadura, Cáceres, Spain; Homeria Open Solutions, S.L., Edificio Tajo de Gestión del Conocimiento, Universidad de Extremadura, Cáceres, Spain; Department of Telematic and Informatic Systems Engineering, Universidad de Extremadura, Cáceres, Spain",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"19 May 2017","2015","8","10","4714","4719","Due to their nature, Eolic parks are situated in zones with difficult access. As a result, management of Eolic parks using remote sensing techniques is of great importance. In addition, the huge amount of data managed by Eolic parks, together with their nature (distributed, heterogeneous, produced, consumed at different times, etc.) makes them ideal to apply big data techniques. In this paper, we present a multilayer hardware/software architecture that applies cloud computing techniques for managing big data from Eolic parks. This architecture allows tackling the processing of large, distributed, and heterogeneous data sets in a remote sensing context. An innovative contribution of this work is the combination of different techniques at three different layers of the proposed hardware/software architecture for Eolic park big data management and processing.","2151-1535","","10.1109/JSTARS.2015.2415583","Ministerio de Ciencia e Innovacion (Spanish Contract MIGRARIA)(grant numbers:TIN2011-27340); European Regional Development Fund (ERDF); Gobierno de Extremadura(grant numbers:GR10129); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7080843","Big data;cloud computing;Eolic parks;remote sensing;wind turbine;Big data;cloud computing;Eolic parks;remote sensing;wind turbine","Wind turbines;Substations;Big data;Remote sensing;Cloud computing","","8","","22","IEEE","6 Apr 2015","Oct. 2015","","IEEE","IEEE Journals"
"A novel big data architecture in support of ADS-B data analytic","E. Boci; S. Thistlethwaite","Exelis, Herndon, VA; Exelis, Herndon, VA","2015 Integrated Communication, Navigation and Surveillance Conference (ICNS)","11 Jun 2015","2015","","","C1-1","C1-8","The first building block of the Federal Aviation Administration's (FAA) Next Generation Air Transportation System (NextGen) initiative to modernize the US national airspace system (NAS) was the implementation of the Automatic Dependent Surveillance-Broadcast (ADS-B) ground infrastructure. A primary aspect of the ADS-B program design is the terrestrial radio station infrastructure. It determined the terrestrial radio stations layout throughout the US and was optimized to meet system performance, safety and security in the NAS. In March 2014, the FAA completed the nationwide infrastructure upgrade, enabling air traffic controllers to track aircraft with greater accuracy and reliability, while giving pilots more information in the cockpit. More than 650 ADS-B radios communicate with equipped aircraft, supporting the new satellite-based surveillance system. Currently, the ADS-B system ingests processes and stores large data sets, while operating at ten percent capacity. As aircraft avionics equipage increases, the volume of data and storage needs will increase beyond our existing system's capacity and processing capability. A new, Hadoop-based architecture was tested to ingest and analyze billions of CAT033 reports in minutes. This paper presents the “Big Data” approach that was adopted to support fast analytics of large ADS-B data volume.","2155-4951","978-1-4799-8952-2","10.1109/ICNSURV.2015.7121218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7121218","","Computer architecture;Big data;Hardware;Lakes;Aircraft;Software;Aerospace electronics","","14","1","12","IEEE","11 Jun 2015","21-23 April 2015","21-23 April 2015","IEEE","IEEE Conferences"
"Enhancing Speed and Quality of Somatic Variant Calling via Big Data Architecture and Deep Learning Models","E. Abidi; Z. T. Ayoub; S. Ouni","RAMSIS, CRISTAL Laboratory ENSI, University of Manouba, Tunisia; RAMSIS, CRISTAL Laboratory ENSI, University of Manouba, Tunisia; RAMSIS, CRISTAL Laboratory ENSI, University of Manouba, Tunisia",2024 IEEE/ACS 21st International Conference on Computer Systems and Applications (AICCSA),"11 Mar 2025","2024","","","1","2","Cancer, a centuries-old challenge in medicine, is now understood as a collection of diseases driven by unique genetic mutations [1] [2]. Identifying these variants is pivotal. Somatic variant calling is a process used in genomics to detect DNA mutations by comparing the genetic data of normal (healthy) cells with that of potentially mutated cells, typically from a tumor, and it is essential for understanding cancer development, diagnosis, and tailoring therapies. Accurate identification is a critical step [3], especially after Next-generation sequencing technologies emerged, enabling the production of genome sequences at an unprecedented rate [4]. Variant calling pipelines streamline the process; nevertheless, it is not without challenges. One of the primary issues is handling the vast genomic data efficiently. Traditional large-scale computation is typically processor-bound, which is suitable for conventional applications. However, in the big data world, where vast amounts of data are generated, genomics in our case, disk latency becomes a significant bottleneck. To address this, a new framework based on distributed computing is necessary. This framework is designed to scale from single servers to multiple machines, collectively known as a cluster. The core idea is to distribute the data across a large cluster of machines and bring the program to the data. This approach ensures that the entire cluster is utilized for both reading and processing the data [5]. This ensures faster somatic mutation identification, which is vital as these variants can provide valuable insights into the exact type of cancer, its aggressiveness, and in turn, potential treatment options. Therefore, speeding up the detection process can lead to early diagnosis and earlier interventions that could substantially improve survival rates. Additionally, compared with germline variations, the detection of somatic variants in the cancer genome is complex due to tumor purity (proportion of tumor cells relative to normal cells in the tumor) and tumor heterogeneity (different tumor cells can have different mutations) [6]. So enhancing the accuracy of these calls minimizes the chances of false positives (incorrectly identifying a mutation) and false negatives (missing a mutation), ensuring that patients receive the correct treatment","2161-5330","979-8-3315-1824-0","10.1109/AICCSA63423.2024.10912614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912614","","Sequential analysis;Accuracy;Pipelines;Genomics;Production;Big Data;Servers;Bioinformatics;Tumors;Cancer","","","","10","IEEE","11 Mar 2025","22-26 Oct. 2024","22-26 Oct. 2024","IEEE","IEEE Conferences"
"A profile-based Big data architecture for agricultural context","S. Lamrhari; H. Elghazi; T. Sadiki; A. El Faker","ENSIAS, Mohammed V University in Rabat; International University of Rabat; International University of Rabat; ENSIAS, Mohammed V University in Rabat",2016 International Conference on Electrical and Information Technologies (ICEIT),"25 Jul 2016","2016","","","22","27","Bringing Big data technologies into agriculture presents a significant challenge; at the same time, this technology contributes effectively in many countries' economic and social development. In this work, we will study environmental data provided by precision agriculture information technologies, which represents a crucial source of data in need of being wisely managed and analyzed with appropriate methods and tools in order to extract the meaningful information. Our main purpose through this paper is to propose an effective Big data architecture based on profiling system which can assist (among others) producers, consulting companies, public bodies and research laboratories to make better decisions by providing them real time data processing, and a dynamic big data service composition method, to enhance and monitor the agricultural productivity. Thus, improve their traditional decision-making process, and allow better management of the natural resources.","","978-1-4673-8469-8","10.1109/EITech.2016.7519585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519585","Big data;precision agriculture;profiling system;decision making","Big data;Agriculture;Real-time systems;Computer architecture;Cloud computing;Meteorology;Distributed databases","","9","","14","IEEE","25 Jul 2016","4-7 May 2016","4-7 May 2016","IEEE","IEEE Conferences"
"AI-optimized data Lakes for Real-Time Big Data Management and Autonomous Query Optimization","G. Ramesh; N. V. Sivareddy; L. H. Jasim; P. Murugeswari; B. Kumaraswamy; M. L","Department of CSE, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, Telangana, India; Department of Computer Science and Engineering, CMR Institute of Technology, Hyderabad; Department of Computers Techniques Engineering, College of Technical Engineering, The Islamic University, Najaf, Iraq, Al Diwaniyah, Iraq; Department of Electrical Communication Engineering, Sethu Institute of Technology, Pulloor, Kariapatti, Tamil Nadu, India; Department of CS & IT, Kalinga University, Raipur, India; Department of Mathematics, Saveetha Institute of Medical and Technical Sciences, Chennai, Tamilnadu, India",2025 International Conference on Metaverse and Current Trends in Computing (ICMCTC),"17 Oct 2025","2025","","","1","5","Due to the massive explosion of big data, efficient data lakes with ‘real-time’ data management and ‘autonomous’ query optimization have become inevitable. One of the problems attached to traditional data lakes is the difficulty of retrieving data, which is slow to query, inefficiently, and with high complexities of schema evolution the ability of the data lake to optimize workloads dynamically. To overcome these problems, the work presented in this paper brings forward the concept of an AI-optimized data lake framework that exploits machine learning and deep learning for intelligent data ingestion, adaptive indexing as well as self-optimizing query execution. The system is proposed to incorporate hierarchical storage management with AI-driven, self-studying indexing mechanisms, and reinforcement learning-aided query optimization to improve data retrieval efficiency. Furthermore, through an integrated AI-powered anomaly detection system, data processing is made robust and reliable in real time. On top of that the framework also involves autonomous governance and security that can use explainable AI for compliance auditing and a dynamic role-based access control (RBAC). Experimental evaluations show that, with up to a 90% time saving, and with real-time decision-making capabilities, it improves over both aspects in a variety of data workloads. This research brings forth the integration of AI-based optimizations for the development of a broad and flexible framework for intelligently and scaleably building large data lake architectures, thus becoming the future-ready solution for any big data ecosystem within healthcare, financial, or IoT-based smart systems.","","979-8-3315-3821-7","10.1109/ICMCTC62214.2025.11196397","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11196397","Role-based access control;AI-driven;Healthcare;Hadoop Distributed File System","Access control;Data ingestion;Accuracy;Query processing;Storage management;Medical services;Big Data applications;Real-time systems;Anomaly detection;Indexing","","","","14","IEEE","17 Oct 2025","10-11 April 2025","10-11 April 2025","IEEE","IEEE Conferences"
"Personal Data Lake with Data Gravity Pull","C. Walker; H. Alrehamy","School of Computer Science and Informatics, Cardiff University, Cardiff, United Kingdom; School of Computer Science and Informatics, Cardiff University, Cardiff, United Kingdom",2015 IEEE Fifth International Conference on Big Data and Cloud Computing,"29 Oct 2015","2015","","","160","167","This paper presents Personal Data Lake, a unified storage facility for storing, analyzing and querying personal data. A data lake stores data regardless of format and thus provides an intuitive way to store personal data fragments of any type. Metadata management is a central part of the lake architecture. For structured/semi-structured data fragments, metadata may contain information about the schema of the data so that the data can be transformed into queryable data objects when required. For unstructured data, enabling gravity pull means allowing third-party plugins so that the unstructured data can be analyzed and queried.","","978-1-4673-7183-4","10.1109/BDCloud.2015.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310733","personal data;data lake;metadata;big data","Lakes;Metadata;Memory;Semantics;Big data;Gravity","","52","1","15","IEEE","29 Oct 2015","26-28 Aug. 2015","26-28 Aug. 2015","IEEE","IEEE Conferences"
"An Artificial Joint Material Database Based on Dynamic Heterogeneous Data Architecture","H. Gong; Y. Tang; H. Xiu; X. Zhang; Y. Li","Beijing Advanced Innovation Center for Materials Genome Engineering University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; Beijing Advanced Innovation Center for Materials Genome Engineering University of Science and Technology Beijing, Beijing, China; School of Materials Science and Engineering, University of Science and Technology Beijing, Beijing, China","2025 IEEE 7th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","20 Jan 2026","2025","7","","1","5","To address the challenges of dynamically heterogeneous data in artificial joint materials, this study introduces a dynamic data storage architecture capable of integrating four key data categories: (1) basic material information, (2) in vitro experimental data, (3) large animal experimental data, and (4) clinical data. To support structured data acquisition, we developed large language model-based APIs for automated extraction of relevant information from scientific literature. These interfaces were utilized to retrieve in vitro test results and post-retrieval joint analysis data at scale. The proposed system enables efficient, standardized, yet flexible data management while supporting high-quality dataset for joint replacement research.","2693-2776","979-8-3315-1355-9","10.1109/IMCEC66174.2025.11331861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11331861","database;Artificial joint material;data extraction;dynamic heterogeneous data","Databases;Animals;Memory;Standardization;Predictive models;Ontologies;Metadata;Real-time systems;Data mining;In vitro","","","","23","IEEE","20 Jan 2026","5-7 Dec. 2025","5-7 Dec. 2025","IEEE","IEEE Conferences"
"MongoDB in the Era of Big Data Architecture, Opportunities, Challenges, and Future Directions","L. Upadhyay; D. Domadiya","Computer Science M.V.M. College of Com., Mgt., & I.T., Rajkot, India; Computer Science National Computer College, Jamnagar, India",2025 International Conference on Sustainable Energy Technologies and Computational Intelligence (SETCOM),"25 Mar 2025","2025","","","1","5","The emerging field of Big Data analytics has sparked the development and application of several procedures, technologies, structures, and fields by researchers worldwide beneficial to assess the gigantic amount of data which is produced on the daily basis. The enormous volumes of data that comprise “Big Data” are difficult for traditional database management systems to process. The Big Data architecture that can be used to address the issues the Big Data industry is currently facing is described in this paper. We also briefly discussed about the Opportunities as well as Big Data’s Challenges from an Analytical and Storage Perception. An overview and quick comparison of four different kinds of databases have been provided in this document. This study also aims to demonstrate the significance of MongoDB database which provides an efficient means of addressing Big Data issues and potential future developments.","","979-8-3315-2054-0","10.1109/SETCOM64758.2025.10932493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10932493","Big Data;MongoDB;NoSQL;Hadoop;Apache Spark;Cassandra;Traditional RDBMS;Architecture;Sources of Data;Storage of Data;Processing in Batch;Ingestion of Messages in Real Time;Processing in Streams;Data Store based on Analytics;Reporting;Analysis;AI/ML;Orchestration;Opportunities;Challenges;Future Directions","Industries;Memory;Computer architecture;Big Data;Data processing;Real-time systems;Database systems;Complexity theory;Streams;Computational intelligence","","","","18","IEEE","25 Mar 2025","21-23 Feb. 2025","21-23 Feb. 2025","IEEE","IEEE Conferences"
"An Efficient Healthcare Medication System with Clustering Algorithm Using Euclidean Distance Adjoining Data Lake","D. Babu M.; K. Ramesh; P. N. Renjith; B. Prabha","Department of Computer Science and Engineering, Hindustan Institute of Technology and Science, Chennai, India; Department of Computer Science and Engineering, Hindustan Institute of Technology and Science, Chennai, India; Department of Computer Science and Engineering, Hindustan Institute of Technology and Science, Chennai, India; Department of Computer Science and Engineering, Hindustan Institute of Technology and Science, Chennai, India","2022 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)","15 Apr 2022","2022","","","1","5","The health care services make use of the patient information along with big data analytics towards the doctor's prescription advice to patients. Still, the majority medical data is not in the standard structured standard format. So it requires enormous effort in converting the unstructured data to structured format. This paper highlights a data lake architecture which helps in decreasing the data ingestion time thereby increasing and improving the accuracy in healthcare data analytics. This facilitates the analytical process to be done completed with the removal of data silos. The new intended data lake architecture improves working analysis of data in the way of making connections with third party data providers. The Hadoop Distributed File System (HDFS) is used for storing the structures as well as unstructured data. This paper utilizes the Euclidean distance for clustering process where the patients with similar related health conditions are clustered. Then each cluster is subjected to Support Vector Machine (SVM) for the accurate doctor's prescription. The experimental results showed a decrease in ingesting data by the proposed data lake architecture. One more advantage is the precise and accurate cluster formation than the existing methods. It also improves the healthcare medication by eliminating the data silos.","","978-1-6654-9529-5","10.1109/ACCAI53970.2022.9752473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9752473","cluster;data lake architecture;data silos;Euclidean Distance;Hadoop Distributed File System;Health Care Services","Support vector machines;Memory;Medical services;Computer architecture;Euclidean distance;Data warehouses;Lakes","","3","","23","IEEE","15 Apr 2022","28-29 Jan. 2022","28-29 Jan. 2022","IEEE","IEEE Conferences"
"Hadoop based real-time Big Data Architecture for remote sensing Earth Observatory System","M. M. Rathore; A. Ahmad; A. Paul; A. Daniel","School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea","2015 6th International Conference on Computing, Communication and Networking Technologies (ICCCNT)","1 Feb 2016","2015","","","1","7","Recently, Big Data analytics emerged as a hot topic because of the incredible growth of the information and communication technology. One of the exceedingly anticipated key contributors of the Big Data is real-time Earth Observatory System (EOS). Although the data generated by the individual satellite in EOS may not be significant, the overall data generated across numerous satellites may yield to the significant amount of the Big Data. Thus, extracting the useful information in an efficient manner leads a system towards major computational challenges in EOS, such as, to analyze, to aggregate, and to store, where data is remotely collected. Therefore, the paper proposes a set of requirements for achieving pervasive, integrated information system of EOS and associated services (real-time and offline data processing). The Big Data Architecture is also proposed to address all the aspect of the Big Data ecosystem and includes the following components: Data Acquisition Unit, Data Processing Unit, Data Storage Unit, and Data Analysis and Decision Unit. The proposed architecture is termed as Holistic as it considers the flow of data from satellites to services, which is designed for efficiently process and analyze the Big Data. Finally, a detailed analysis of remotely sensed earth observatory Big Data for Land and Sea area are provided using UBUNTU 14.04 LTS core™i5 machine with 3.2 GHz processor and 4 GB memory. The results show that the proposed network architecture efficiently process EOS data at a real-time as well as offline.","","978-1-4799-7984-4","10.1109/ICCCNT.2015.7395242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7395242","Remote sensing;Big Data;Land and Sea Area","Big data;Measurement units;Servers;IP networks;Algorithm design and analysis;Sensors","","16","","23","IEEE","1 Feb 2016","13-15 July 2015","13-15 July 2015","IEEE","IEEE Conferences"
"Security situation awareness method of power mobile application based on big data architecture","L. Yong; C. Mu; D. ZaoJian; C. Lu","State Grid Key Laboratory of Information & Network Security State Grid Smart Grid Research Enstitute Co., Ltd, Nanjing, China; State Grid Key Laboratory of Information & Network Security State Grid Smart Grid Research Enstitute Co., Ltd, Nanjing, China; State Grid Key Laboratory of Information & Network Security State Grid Smart Grid Research Enstitute Co., Ltd, Nanjing, China; State Grid Key Laboratory of Information & Network Security State Grid Smart Grid Research Enstitute Co., Ltd, Nanjing, China",2022 5th International Conference on Data Science and Information Technology (DSIT),"17 Nov 2022","2022","","","1","6","According to the characteristics of security threats and massive users in power mobile applications, a mobile application security situational awareness method based on big data architecture is proposed. The method uses open-source big data technology frameworks such as Kafka, Flink, Elasticsearch, etc. to complete the collection, analysis, storage and visual display of massive power mobile application data, and improve the throughput of data processing. The security situation awareness method of power mobile application takes the mobile terminal threat index as the core, divides the risk level for the mobile terminal, and predicts the terminal threat index through support vector machine regression algorithm (SVR), so as to construct the security profile of the mobile application operation terminal. Finally, through visualization services, various data such as power mobile applications and terminal assets, security operation statistics, security strategies, and alarm analysis are displayed to guide security operation and maintenance personnel to carry out power mobile application security monitoring and early warning, banning disposal and traceability analysis and other decision-making work. The experimental analysis results show that the method can meet the requirements of security situation awareness for threat assessment accuracy and response speed, and the related results have been well applied in a power company.","","978-1-6654-9868-5","10.1109/DSIT55514.2022.9943899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943899","component;situational awareness;power mobile application;big data architecture;SVR;terminal threat index","Support vector machines;Visualization;Law;Big Data;Throughput;Threat assessment;Mobile applications","","","","16","IEEE","17 Nov 2022","22-24 July 2022","22-24 July 2022","IEEE","IEEE Conferences"
"Chapter 2: Azure Data Lake Server and ADF Integration","M. Beckner",NA,"Quick Start Guide to Azure Data Factory, Azure Data Lake Server, and Azure Data Warehouse","","2019","","","33","64","","","9781547401291","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10785668.pdf&bkn=10783667&pdfType=chapter","","Big Data applications;Pipelines;Servers;Navigation;Encryption;Databases;Costs;Security;Runtime;Pricing","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"Architecture Design Based on Big Data Storage Technology for Launch Vehicle Test Data","S. Yuan; L. Zhao; J. Qi; Y. Zhang","China Academy of Launch Vehicle Technology, Beijing Institute of Astronautical Systems Engineering, Beijing, China; China Academy of Launch Vehicle Technology, Beijing Institute of Astronautical Systems Engineering, Beijing, China; China Academy of Launch Vehicle Technology, Beijing Institute of Astronautical Systems Engineering, Beijing, China; China Academy of Launch Vehicle Technology, Beijing Institute of Astronautical Systems Engineering, Beijing, China",2025 4th International Symposium on Computer Applications and Information Technology (ISCAIT),"3 Jun 2025","2025","","","2146","2150","In recent years, the test data of launch vehicle shows the characteristics such as large data volumes, numerous files, complex data types and rapid growth rates. Traditional relational databases are inadequate to meet the requirements for the storage and application of massive data produced by launch vehicle test due to the relatively low query efficiency for large volume data, lack of data backup and poor scalability. A storage and application architecture based on big data technology including HDFS, HBase, SeaweedFS, Elasticsearch and Hive is designed for massive launch vehicle test data. Practical engineering application has demonstrated that this architecture shows good reliability and scalability, and can meet the storage and query demands of launch vehicle test data effectively.","","979-8-3315-4285-6","10.1109/ISCAIT64916.2025.11010775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11010775","test data;launch vehicle;big data;architecture design","Scalability;Memory;Computer architecture;Relational databases;Computer applications;Big Data;Reliability engineering;Information technology;Periodic structures","","2","","8","IEEE","3 Jun 2025","21-23 March 2025","21-23 March 2025","IEEE","IEEE Conferences"
"A Big Data architecture for knowledge discovery in PubMed articles","F. Gargiulo; S. Silvestri; M. Ciampi","Institute for High Performance Computing and Networking, Via Pietro Castellino 111, Naples, Italy; Institute for High Performance Computing and Networking, Via Pietro Castellino 111, Naples, Italy; Institute for High Performance Computing and Networking, Via Pietro Castellino 111, Naples, Italy",2017 IEEE Symposium on Computers and Communications (ISCC),"4 Sep 2017","2017","","","82","87","The need of smart information retrieval systems is in contrast with the difficulties to deal with huge amount of data. In this paper we present a Big Data Analytics architecture used to implement a semantic similarity search tool for natural language texts in biomedical domain. The implemented methodology is based on Word Embeddings (WEs) models obtained using the word2vec algorithm. The system has been assessed with documents extracted from the whole PubMed library. It will be also presented a user friendly web front-end able to assess the methodology on a real context.","","978-1-5386-1629-1","10.1109/ISCC.2017.8024509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8024509","Big Data Analytics;Word Embeddings;Semantic Similarity Search;Natural Language Processing;Bio-Medical Literature;SPARK;PubMed","Big Data;Semantics;Data models;Data mining;Natural languages;Biological system modeling;Computer architecture","","11","","25","IEEE","4 Sep 2017","3-6 July 2017","3-6 July 2017","IEEE","IEEE Conferences"
"Data Lake Architecture for Storing and Transforming Web Server Access Log Files","E. Zagan; M. Danubianu","Faculty of Electrical Engineering and Computer Science, Ştefan cel Mare University of Suceava, Suceava, Romania; Faculty of Electrical Engineering and Computer Science, Ştefan cel Mare University of Suceava, Suceava, Romania",IEEE Access,"1 May 2023","2023","11","","40916","40929","Web server access log files are text files containing important data about server activities, client requests addressed to a server, server responses, etc. Large-scale analysis of these data can contribute to various improvements in different areas of interest. The main problem lies in storing these files in their raw form, over long time, to allow analysis processes to be run at any time enabling information to be extracted as foundation for high quality decisions. Our research focuses on offering an economical, secure, and high-performance solution for the storage of large amount of raw log files. Proposed system implements a Data Lake (DL) architecture in cloud using Azure Data Lake Storage Gen2 (ADLS Gen2) for extract–load–transform (ELT) pipelines. This architecture allows large volumes of data to be stored in their raw form. Afterwards they can be subjected to transformation and advanced analysis processes without the need of a structured writing scheme. The main contribution of this paper is to provide a solution that is affordable and more accessible to perform web server access log data ingestion, storage and transformation over the newest technology, Data Lake. As derivative contribution, we proposed the use of Azure Blob Trigger Function to implement the algorithm of transforming log files into parquet files leading to 90% reduction in storage space compared to their original size. That means much lower storage costs than if they had been stored as log files. A hierarchical data storage model has also been proposed for shared access to data over different layers in the DL architecture, on top of which Data Lifecycle Management (DLM) rules have been proposed for storage cost efficiency. We proposed ingesting log files into a Data Lake deployed in cloud due to ease of deployment and low storage costs. The aim is to maintain this data in the long term, to be used in future advanced analytics processes by cross-referencing with other organizational or external data. That could bring important benefits. While the proposed solution is explicitly based on ADLS Gen2, it represents an important benchmark in approaching a cloud DL solution offered by any other vendor.","2169-3536","","10.1109/ACCESS.2023.3270368","ANTREPRENORDOC, in the framework of Human Resources Development Operational Programme 2014–2020; European Social Fund(grant numbers:36355/23.05.2019 HRD OP /380/6/13–SMIS,123847); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107911","Cloud data lake;ADLS Gen2;data lake architecture;web server access log data;Azure function Blob trigger","Computer architecture;Web servers;Big Data applications;Costs;Data models;Companies;Data mining","","7","","40","CCBYNCND","25 Apr 2023","2023","","IEEE","IEEE Journals"
"Big Data as the Big Game Changer","G. Smorodin; O. Kolesnichenko","EMC Academic Alliance Russia & CIS, St. Petersburg, Russia; Security Analysis Bulletin, Moscow, Russia",2015 9th International Conference on Application of Information and Communication Technologies (AICT),"30 Nov 2015","2015","","","40","43","Big Data is the phenomenon of the Information era. Big Data is a new dimension to explore, collecting Big Data we fix the time. Big Data has some functions, including impact on society, form spatio-temporal structures, change the world and future, and integration society with IT technologies. Most important aspect is risk in Cloud computing. To leverage risks, secure Cloud services and get additional benefits an Integrated Approach should be applied. It is important to separate the various kinds of “Security” needs when considering Cloud computing issues. Also Security Analyst should be included into Data Science Team. Data-driven economy is based on three points: open data, legislation for Big Data, and education. For students is very important practical training that engages students into the culture of Big Data Analytics. This opportunity provides the EMC Academic Alliance Russia & CIS through the establishment of ad-hoc Big Data Analytics Teams among universities. The results of the first stage of launched in 2015 the Big Data Analytics Multicenter Study are presented.","","978-1-4673-6856-8","10.1109/ICAICT.2015.7338512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7338512","Big Data;Data Analytics Multicenter Study;Cloud computing;Security Integrated Approach;Federation Business Data Lake","Terrorism;Big data;Force;Blogs","","6","","8","IEEE","30 Nov 2015","14-16 Oct. 2015","14-16 Oct. 2015","IEEE","IEEE Conferences"
"Using MEAN stack for development of GUI in real-time big data architecture","M. Štajcer; M. Štajcer; D. Oreščanin","Poslovna Inteligencija d.o.o., Zagreb, Croatia; Poslovna Inteligencija d.o.o., Zagreb, Croatia; Poslovna Inteligencija d.o.o., Zagreb, Croatia","2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","28 Jul 2016","2016","","","524","529","There are several key criteria for successful software development branch and one of them is architecture. We describe in detail architecture, design and development of graphic user interface for real-time fraud detection system in the telecom industry. Our focus is on a web application architecture, which includes data model component, technical infrastructure component, and components that interact or are associated in any way with the system (users, third party components).","","978-953-233-086-1","10.1109/MIPRO.2016.7522200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7522200","","Business;Browsers;Real-time systems;Servers;Graphical user interfaces;Computer architecture","","1","","12","","28 Jul 2016","30 May-3 June 2016","30 May-3 June 2016","IEEE","IEEE Conferences"
"A System-dynamic-based Model to Study the Effect of Singular AWS Bucket Management Big Data Architecture into the Automotive Industry","C. M. Martinez-Soto; M. A. Negrete-Rodriguez; A. Elizondo-Noriega; D. Güemes-Castorena","School of Social Sciences and Government, Tecnologico de Monterrey, Monterrey, N.L., Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, N.L., Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, N.L., Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, N.L., Mexico",2024 Portland International Conference on Management of Engineering and Technology (PICMET),"4 Sep 2024","2024","","","1","11","Industry 4.0 is a paradigm that relies on the latest production and service evolution stage, with Big Data technology playing a pivotal role. This data volume enables interpreting significant insights through latent data mining to enhance decision-making capabilities. Although the use of Big Data technology is becoming common and adopted in manufacturing facilities, more research is needed on the impact of implementing this paradigm in organizations. Regardless of Big Data's maturation, its extensive economic influence on industrial performance is yet to be fully understood. This gap highlights the necessity of several analyses to mitigate the risks associated with technological investments. This paper proposes a System-Dynamic-based model to study the economic impact of Big Data architecture in the automotive industry. The proposed model considers sensor data from various vehicles into a singular AWS bucket. This architecture facilitates comprehensive data analysis and reporting via AWS Quicksight service using the structure of a Redshift data warehouse. The proposed model serves as a strategic tool for technological assessment and a method for effective Big Data utilization in the automotive sector.","2159-5100","978-1-890843-45-8","10.23919/PICMET64035.2024.10653414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10653414","","Industries;Economics;Decision making;Organizations;Big Data;Data models;Production facilities","","","","27","","4 Sep 2024","4-8 Aug. 2024","4-8 Aug. 2024","IEEE","IEEE Conferences"
"SDN-based Architecture for Big Data Network","Y. Xu; Z. Sun; Z. Sun","Nanjing University of Posts and Telecommunications, Nan Jing, China; Zhongtian Technology Corporation, Nan Tong, China; Nanjing University of Posts and Telecommunications, Nan Jing, China",2017 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC),"11 Jan 2018","2017","","","513","516","Big data needs underlying network for data transmission in the practice, big data network is an essential content of big data research. In this paper, a big data network framework for the demands in the life cycle of big data is proposed, and the main challenges of big data network using traditional technologies are analyzed. Software defined networking (SDN) separates the control layer from the data layer, and has the advantages of logical concentration, scalability and programmability. According to the characteristics of each subnet in big data network framework, we design the SDN-based architectures of data access network, content transmission network, data center network and backbone network respectively, and elaborate their implementation methods, main functions and collaborative operation.","","978-1-5386-2209-4","10.1109/CyberC.2017.102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8250413","big data;software-defined networking;network architecture","Big Data;Content distribution networks;Computer architecture;Network architecture;Servers;Ground penetrating radar","","3","","10","IEEE","11 Jan 2018","12-14 Oct. 2017","12-14 Oct. 2017","IEEE","IEEE Conferences"
"Research on Spatial Big Data Management and High Performance Computing Based on Information Cloud Platform","Z. He","Urban Vocational College of Sichuan, Sichuan, China",2021 5th Annual International Conference on Data Science and Business Analytics (ICDSBA),"3 Feb 2022","2021","","","23","28","In the new era, with the development of urban construction and the improvement of social and economic level, in the face of increasing information requirements, the computer technology used in the past has been unable to meet the current market demand. Therefore, on the basis of understanding the technical research background, this paper analyzes the characteristics and key technologies of spatial big data management on the information cloud platform, and deeply discusses the contents of high-performance computing on the information cloud platform.","","978-1-6654-4590-0","10.1109/ICDSBA53075.2021.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693798","Information;Cloud platform;Space;Big data management;High performance;To calculate","Training;Economics;Technological innovation;High performance computing;Big Data;Spatial databases;Real-time systems","","1","","11","IEEE","3 Feb 2022","24-26 Sept. 2021","24-26 Sept. 2021","IEEE","IEEE Conferences"
"The Impact of Big Data on the Choice of Storage","A. Bogdanov; I. Ulitina; T. K. Lwin; N. Shchegoleva","Plekhanov Russian University of Economics, Moscow, Russia; St.-Petersburg State University, St.-Petersburg, Russia; St.-Petersburg StateUniversity, St.-Petersburg, Russia; Plekhanov Russian University of Economics, Moscow, Russia",2019 Computer Science and Information Technologies (CSIT),"11 Nov 2019","2019","","","33","36","Data Lake is a technology that became very popular because Big Data is a part of modern reality. However, modern databases often do not fit the data that organizations want to store because of various reasons. When should people think about using Data Lakes? In what cases can Data Lakes be used, and when will their use bring some benefits to companies? We introduce the Data Lake view to Big Data processing. We present a new approach to distributed Database System and we propose to use some effective Data tools for databases management. In this article, we analyze how to use this technology, discuss the prospects and possible problems in the implementation of Data Lakes in practice.","","978-1-7281-2858-0","10.1109/CSITechnol.2019.8895173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8895173","big data;Data Lakes;data warehouse","Computer science;Distributed databases;Companies;Data warehouses;Big Data applications;Database systems;Information technology","","1","","12","IEEE","11 Nov 2019","23-27 Sept. 2019","23-27 Sept. 2019","IEEE","IEEE Conferences"
"From silos to open, federated and enriched Data Lakes for smart building data management","J. L. Hernández; S. Martín; V. Marinakis; I. de Miguel","Energy division, CARTIF Technology Centre, Boecillo, Spain; Energy division, CARTIF Technology Centre, Boecillo, Spain; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece; Universidad de Valladolid, Valladolid, Spain",2023 IEEE International Workshop on Metrology for Living Environment (MetroLivEnv),"4 Jul 2023","2023","","","29","33","Current building data is treated as silos from the different building domains. However, this provokes the lack of cross-domain data mixture to provide added-value services, mainly due to lack of interoperability. Data quality is also an issue when collecting data from buildings. The proposed data lake aims to solve these challenges by considering the whole data life-cycle to ensure minimum data quality requirements, providing high-quality services to make better-informed decisions. Heterogeneous building-related data is thus combined to enrich the information, being able to address multiple stakeholders in the smart building context. The data lake is being deployed in the DigiBUILD project, where data from 10 pilots with different purposes are collected to demonstrate the capability and benefits of its application.","","978-1-6654-5693-7","10.1109/MetroLivEnv56897.2023.10164046","European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10164046","data lake;data quality;standards;ontologies;smart buildings","Smart buildings;Data integrity;Conferences;Ontologies;Metrology;Big Data applications;Stakeholders","","7","","18","IEEE","4 Jul 2023","29-31 May 2023","29-31 May 2023","IEEE","IEEE Conferences"
"QoE-Driven Big Data Architecture for Smart City","X. He; K. Wang; H. Huang; B. Liu",Nanjing University of Posts and Telecommunications; Hong Kong Polytechnic University; Hong Kong Polytechnic University; La Trobe University,IEEE Communications Magazine,"13 Feb 2018","2018","56","2","88","93","In the era of big data, the applications/services of the smart city are expected to offer end users better QoE than in a conventional smart city. Nevertheless, various types of sensors will produce an increasing volume of big data along with the implementation of a smart city, where we face redundant and diverse data. Therefore, providing satisfactory QoE will become the major challenge in the big-data-based smart city. In this article, to enhance the QoE, we propose a novel big data architecture consisting of three planes: the data storage plane, the data processing plane, and the data application plane. The data storage plane stores a wide variety of data collected by sensors and originating from different data sources. Then the data processing plane filters, analyzes, and processes the ocean of data to make decisions autonomously for extracting high-quality information. Finally, the application plane initiates the execution of the events corresponding to the decisions delivered from the data processing plane. Under this architecture, we particularly use machine learning techniques, trying to acquire accurate data and deliver precise information to end users. Simulation results indicate that our proposals could achieve high QoE performance for the smart city.","1558-1896","","10.1109/MCOM.2018.1700231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291120","","Big Data;Smart cities;Quality of experience;Memory;Data mining;Sensors","","93","","15","IEEE","13 Feb 2018","Feb. 2018","","IEEE","IEEE Magazines"
"Big Data Architectures for the Climate Change Analysis: A Systematic Mapping Study","A. Cravero; S. Sepúlveda; L. Muñoz",Universidad de La Frontera; Universidad de La Frontera; Universidad Tecnologica de Panama,IEEE Latin America Transactions,"26 Mar 2021","2020","18","10","1793","1806","Despite the volume of data generated, scientists cannot accurately predict how climate change will manifest itself locally and what measures should be applied to mitigate it effectively. On the other hand, Big Data is a new technology that faces the challenge of collecting, characterizing and analyzing a large amount of data, taking into account data from multiple sources, multiple variables and multiple scales with different spatial and temporal attributes. To do this, we review and synthesize the current state of research of Big Data architectures that help solve the problems caused by climate change in health (16%), agriculture(8%), biodiversity(16%), energy(8%), water resources(4%) and clima(48%). To achieve the objective, we have carried out a systematic mapping study, which includes four research questions, including 25 studies, published from 2013 to 2019. The architectures found have been classified according to their use, which can be for statistical analysis, monitoring and simulations; helping researchers to integrate knowledge into the practical use of Big Data in the context of climate change.","1548-0992","","10.1109/TLA.2020.9387671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387671","Big Data;Climate Change;Architectures;Systematic mapping","Big Data;Climate change;Meteorology;Data models;Systematics;Monitoring;Libraries","","3","","","IEEE","26 Mar 2021","October 2020","","IEEE","IEEE Journals"
"Research on Multi-layer Power Enterprise Data Management Architecture Based on Big Data","W. Jijun; C. Yongqiu; C. Li","Jiangsu Electric Power Information Technology Co.,LTD., Jiangsu, Nanjing, China; Jiangsu Electric Power Information Technology Co.,LTD., Jiangsu, Nanjing, China; Jiangsu Electric Power Information Technology Co.,LTD., Jiangsu, Nanjing, China",2022 IEEE 8th International Conference on Computer and Communications (ICCC),"20 Mar 2023","2022","","","1194","1198","In view of the characteristics of current electric power data, such as massive, high dimensional and multi-source heterogeneous, to meet the development needs of electric power enterprises, a multi-layer power enterprise data management architecture based on big data is proposed in the paper on the basis of summarizing the concept, development status, major difficulties and challenges in the field of electric power data control. Firstly, a general mathematical model of data management and control architecture is established with reference to the characteristics of electric power data, and the key technologies of its data processing are described algorithmically. Then, after analyzing and referring to the idea of big data platform architecture construction, a multi-layer system architecture for data management and control of electric power enterprises is further proposed. The architecture is divided into three layers: infrastructure virtualization layer, cloud computing support platform layer and power data application layer, which truly realizes the integration of physical facilities, data resources and business applications in one while taking into account security. Finally, the possible future research directions in this field are summarized and prospected.","","978-1-6654-5051-5","10.1109/ICCC56324.2022.10065634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10065634","data architecture;cloud computing;big data;virtualization;smart grid","Cloud computing;Systems architecture;Computer architecture;Data processing;Big Data applications;Mathematical models;Power systems","","1","","31","IEEE","20 Mar 2023","9-12 Dec. 2022","9-12 Dec. 2022","IEEE","IEEE Conferences"
"A prototype of healthcare big data processing system based on Spark","W. Liu; Q. Li; Y. Cai; Y. Li; X. Li","Research Center for Biomedical Information Technology, Shenzhen Institutes of Advanced Technology, CAS, Shenzhen, China; Research Center for Biomedical Information Technology, Shenzhen Institutes of Advanced Technology, CAS, Shenzhen, China; Research Center for Biomedical Information Technology, Shenzhen Institutes of Advanced Technology, CAS, Shenzhen, China; Research Center for Biomedical Information Technology, Shenzhen Institutes of Advanced Technology, CAS, Shenzhen, China; School of Software, Nanchang University, Nanchang, China",2015 8th International Conference on Biomedical Engineering and Informatics (BMEI),"11 Feb 2016","2015","","","516","520","With many theoretical and technological obstacles in health big data processing, it is hard to transfer data into successful and valuable applications. Meeting the Challenge of handling big data in healthcare information construction procedure, this paper proposes a referential architecture on the platform solution to overcome the problems in tremendous of healthcare big data process. Based on the proposed architecture a prototype has been built for healthcare big data analysis. Taking statistical analysis in administrator decide supporting service as an example, this paper tests the running performance and demonstrating effect of the prototype system for healthcare big data processing based on Spark.","","978-1-5090-0022-7","10.1109/BMEI.2015.7401559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401559","healthcare big data;architecture;data visualization;Spark","Decision support systems;Biomedical engineering;Informatics;US Department of Defense","","8","","18","IEEE","11 Feb 2016","14-16 Oct. 2015","14-16 Oct. 2015","IEEE","IEEE Conferences"
"An Overview of Current Data Lake Architecture Models","T. Hlupić; D. Oreščanin; D. Ružak; M. Baranović","Poslovna Inteligencija d. o. o., Zagreb, Croatia; Poslovna Inteligencija d. o. o., Zagreb, Croatia; Algebra University College, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia","2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)","27 Jun 2022","2022","","","1082","1087","As the Data Lakes have gained a significant presence in the data world in the previous decade, several main approaches to building Data Lake architectures have been proposed. From the initial architecture towards the novel ones, omnipresent layers have been established, while at the same time new architecture layers are evolving. The evolution of the Data Lake is mirrored in the architectures, giving each layer a distinctive role in data processing and consumption. Moreover, evolving architectures tend to incorporate established approaches, such as Data Vaults, into their layers for more refined usages. In this article, several well-known architecture models will be presented and compared with the goal of identifying their advantages. Next to the architecture models, the topic of Data Governance in the terms of the Data Lake will be covered in order to expound its impact on the Data Lake modeling.","2623-8764","978-953-233-103-5","10.23919/MIPRO55190.2022.9803717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9803717","Data Lake;Data Lake model;Data Lake Architecture;Data Vault","Analytical models;Architecture;Pipelines;Lakes;Big Data applications;Data processing;Data models","","23","","12","","27 Jun 2022","23-27 May 2022","23-27 May 2022","IEEE","IEEE Conferences"
"Synchrophasor Big Data Architectures, Platforms and Applications: A Review","D. Villegas; K. Dharmapala; A. Rajapakse","Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, MB, Canada; Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, MB, Canada; Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, MB, Canada","2022 International Conference and Utility Exhibition on Energy, Environment and Climate Change (ICUE)","4 May 2023","2022","","","1","10","The world is moving towards an era of data driven analytics and decision making. Concurrently, the electrical power industry is moving towards a data driven analytical environment from a model driven analytical environment. Electrical power industry utilizes different types of data. Synchrophasor data is one of the main data types associated with many of the power system applications. However, with the expansion of Phasor Measurement Units (PMU) networks, the synchrophasor data is becoming a Big Data (BD) issue. Therefore, many researchers have drawn their attention on synchrophasor big data handling and utilization. This paper briefly discusses power system BD architectures and standard architectures available in real-world applications. The goals of this paper are to make a review of existing BD architectures and commercially available platforms for synchrophasor applications; to do a comparative analysis of existing BD architectures; and to do a review of the existing applications and the compatibility these applications with the existing BD platforms.","","979-8-3503-3326-8","10.1109/ICUE55325.2022.10113522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10113522","Big data architecture;synchrophasor data;big data platforms;Hadoop;big data applications","Climate change;Analytical models;Decision making;Big Data applications;Phasor measurement units;Power industry;Real-time systems","","2","","65","IEEE","4 May 2023","26-28 Oct. 2022","26-28 Oct. 2022","IEEE","IEEE Conferences"
"A Big Data Architecture Design for Smart Grids Based on Random Matrix Theory","X. He; Q. Ai; R. C. Qiu; W. Huang; L. Piao; H. Liu","Department of Electrical Engineering, Shanghai Jiaotong University, Shanghai, China; Department of Electrical Engineering, Shanghai Jiaotong University, Shanghai, China; Department of Electrical and Computer Engineering, Tennessee Technological University, Cookeville, TN, USA; Department of Electrical Engineering, Shanghai Jiaotong University, Shanghai, China; Department of Electrical Engineering, Shanghai Jiaotong University, Shanghai, China; Department of Electrical Engineering, Shanghai Jiaotong University, Shanghai, China",IEEE Transactions on Smart Grid,"20 May 2017","2017","8","2","674","686","Model-based analysis tools, built on assumptions and simplifications, are difficult to handle smart grids with data characterized by volume, velocity, variety, and veracity (i.e., 4Vs data). This paper, using random matrix theory (RMT), motivates data-driven tools to perceive the complex grids in high-dimension; meanwhile, an architecture with detailed procedures is proposed. In algorithm perspective, the architecture performs a high-dimensional analysis and compares the findings with RMT predictions to conduct anomaly detections. Mean spectral radius (MSR), as a statistical indicator, is defined to reflect the correlations of system data in different dimensions. In management mode perspective, a group-work mode is discussed for smart grids operation. This mode breaks through regional limitations for energy flows and data flows, and makes advanced big data analyses possible. For a specific large-scale zone-dividing system with multiple connected utilities, each site, operating under the group-work mode, is able to work out the regional MSR only with its own measured/simulated data. The large-scale interconnected system, in this way, is naturally decoupled from statistical parameters perspective, rather than from engineering models perspective. Furthermore, a comparative analysis of these distributed MSRs, even with imperceptible different raw data, will produce a contour line to detect the event and locate the source. It demonstrates that the architecture is compatible with the block calculation only using the regional small database; beyond that, this architecture, as a data-driven solution, is sensitive to system situation awareness, and practical for real large-scale interconnected systems. Five case studies and their visualizations validate the designed architecture in various fields of power systems. To our best knowledge, this paper is the first attempt to apply big data technology into smart grids.","1949-3061","","10.1109/TSG.2015.2445828","National Key Technology Research and Development Program of Science and Technology(grant numbers:2013BAA01B04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154500","Architecture;big data;group-work mode;high-dimension;large-scale distributed system;mean spectral radius (MSR);random matrix;smart grid","Big data;Smart grids;Data models;Mathematical model;Correlation;Computer architecture","","194","","48","IEEE","10 Jul 2015","March 2017","","IEEE","IEEE Journals"
"Design and Interface Testing of Connected Data Architecture of DataLake","B. Cha; S. Park; J. Kim","School of Electrical Engineering and Computer Science, GIST, GwangJu, Korea; School of Electrical Engineering and Computer Science, GIST, GwangJu, Korea; School of Electrical Engineering and Computer Science, GIST, GwangJu, Korea",2018 International Conference on Information and Communication Technology Convergence (ICTC),"18 Nov 2018","2018","","","780","782","The data plays a pivotal role in many aspects of enterprise operations, and is becoming more and more important to many companies in aspect of Industry Revolution 4.0 and Big Data. Gradually, the value of the enterprise is changing to data-centric. In this paper, we analyze the requirements of the CDA for integrating and managing the data lifecycle of various application areas based on the advantages of the DataLake framework, design the interfaces for CDA, and performs validation of interface # 3 between micro-Storage and DataLake.","2162-1233","978-1-5386-5041-7","10.1109/ICTC.2018.8539708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539708","connected data architecture;Data Lake;Big Data;Interfaces;Storage;micro-Storage;KOREN network","Lakes;Computer architecture;Industries;Media;Cloud computing;Testing;Sun","","1","","4","IEEE","18 Nov 2018","17-19 Oct. 2018","17-19 Oct. 2018","IEEE","IEEE Conferences"
"Data Lake Architecture for Air Traffic Management","R. Raju; R. Mital; D. Finkelsztein","SGT, A KBRwyle Business Unit, Cambridge, MA, U.S.A; SGT, A KBRwyle Business Unit, Cambridge, MA, U.S.A; SGT, A KBRwyle Business Unit, Cambridge, MA, U.S.A",2018 IEEE/AIAA 37th Digital Avionics Systems Conference (DASC),"9 Dec 2018","2018","","","1","6","The air traffic transformation underway in the US with the FAA NextGen and in Europe with SESAR relies on information sharing and system interoperability to increase efficiencies, safety and capacity. The proliferation and dissemination of flight, weather, aeronautical, and environmental data by all air traffic participants represents a treasure trove of air traffic optimization opportunities awaiting to be exploited. Traditional data exploitation methods and tools tend to rely on structured data stores and analytical capability architected to answer defined and current questions. SGT, in collaboration with the US DOT Volpe National Transportation Systems Center, developed a prototype air transportation cloud based Data Lake to harness big data from a variety of sources and build the current and next generation of analytics capability. The Data Lake prototype ingests data from multiple sources including FAA sources like SFDPS, TFMData, TBFM, STDDS, ITWS, and AEDT data sources, and stores it in raw, processed, and refined format. The prototype offers an illustration for how users can realize powerful air traffic related data analysis using structured, unstructured and semi-structured data using open source tools to execute queries, searches, processing streams and to visualize data. Using a combination of traditional SQL and NOSQL, Open-Source and COTS products - PostgreSQL, Elastic-Logstash-Kibana, Apache Kafka, Apache Spark and visualization tools like Tableau, D3 and others, the project shows how analysts can quickly and easily build powerful data pipelines and statistical models.","2155-7209","978-1-5386-4112-5","10.1109/DASC.2018.8569361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8569361","Data Lake;Data Analytics;Volpe","Lakes;Tools;Fuels;Data analysis;XML;Data visualization;Prototypes","","9","","1","IEEE","9 Dec 2018","23-27 Sept. 2018","23-27 Sept. 2018","IEEE","IEEE Conferences"
"Core Model and Simulation Operation of Economic Management Big Data Platform Based on Cloud Computing","H. Wang; B. He; X. Li; F. Zhou","Tianfu Information Vocational College, Chengdu, Sichuan, China; Tianfu Information Vocational College, Chengdu, Sichuan, China; Tianfu Information Vocational College, Chengdu, Sichuan, China; Tianfu Information Vocational College, Chengdu, Sichuan, China","2024 International Conference on Electrical Drives, Power Electronics & Engineering (EDPEE)","31 May 2024","2024","","","872","876","In recent years, big data and cloud computing have emerged as prominent buzzwords in the realm of information technology. The evolution and advancement of data technology are intricately linked to database development, with each novel data technology posing fresh demands on database construction. The establishment of a cloud computing big data platform encompasses various components such as the overall big data architecture, analysis platform software architecture, platform network architecture, and a unified approach to big data platform construction. This study delves into the online interactive data model that leverages cloud computing and big data, highlighting the benefits of their integration into online interactive platforms. It aims to offer valuable insights for professionals in this domain. Drawing from the principles and technologies of cloud computing, as well as the challenges posed by big data in government statistics, this paper outlines the fundamental structure of a statistical cloud. It further elaborates on the architecture, functional modules, and operational workflow of a government statistics platform rooted in cloud computing. To fulfill these functionalities, a comprehensive framework for the platform is designed, encompassing the acquisition, processing, storage, analysis, and secure dissemination of accounting big data. The incorporation of big data theory in the data acquisition phase aims to gather all pertinent accounting big data, both internal and external to the enterprise that can inform business decisions. This ensures enhanced relevance in the quality of accounting information. Leveraging cutting-edge front-end information technology, namely cloud computing, this paper advocates for the development of a more efficient accounting big data analysis platform.","","979-8-3503-9563-1","10.1109/EDPEE61724.2024.00168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10539757","Cloud computing;economic management;big data platform;core model;simulation operation","Economics;Cloud computing;Databases;Computational modeling;Government;Computer architecture;Big Data","","","","10","IEEE","31 May 2024","27-29 Feb. 2024","27-29 Feb. 2024","IEEE","IEEE Conferences"
"A Big Data Architecture for Automotive Applications: PSA Group Deployment Experience","A. Haroun; A. Mostefaoui; F. Dessables","RDD, PSA Group, Bessoncourt, France; FEMTO-ST Institute/CNRS, Bourgognes-Franche-Comte University, Montbéliard, France; DDCE, PSA Group, Bessoncourt, France","2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)","13 Jul 2017","2017","","","921","928","Vehicles have become moving sensor platforms collecting huge volumes of data from their various embedded sensors. This data has a great value for automotive manufacturers and vehicles owners. Indeed, connected vehicles data can be used in a large broad of automotive services ranging from safety services to well-being services (e.g. fatigue detection). However, vehicle fleets send big volumes of data that traditional computing and storage approaches are not able to manage efficiently. In this paper, we present the experience of the PSA Group on leveraging big data in automotive context. We describe in depth the big data architecture deployed within the PSA Group and the underlaying technologies/products used in each component.","","978-1-5090-6611-7","10.1109/CCGRID.2017.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7973799","Big Data;Reference Architecture;Connected Vehicles","Big Data;File systems;Sparks;Parallel processing;Automotive applications;Batch production systems","","7","","27","IEEE","13 Jul 2017","14-17 May 2017","14-17 May 2017","IEEE","IEEE Conferences"
"Data Model and Analysis for Big Data Mapping and Management in the Energy Data Platform","M. Riasetiawan; F. Anggara; A. Ashari; S. Winardi; B. N. Prastowo","Dept. of Computer Science and Electronics, Faculty of Mathematic and Natural Scienves, Universitas Gadjah Mada, Yogyakarta, Indonesia; Dept. of Geology Faculty of Engineering, Universitas Gadjah Mada, Yogyakarta, Indonesia; Dept. of Computer Science and Electronics, Faculty of Mathematic and Natural Scienves, Universitas Gadjah Mada, Yogyakarta, Indonesia; Dept. of Geology Faculty of Engineering, Universitas Gadjah Mada, Yogyakarta, Indonesia; Dept. of Computer Science and Electronics, Faculty of Mathematic and Natural Scienves, Universitas Gadjah Mada, Yogyakarta, Indonesia","2021 International Conference on Data Science, Artificial Intelligence, and Business Analytics (DATABIA)","24 Dec 2021","2021","","","1","6","The energy data scope is very broad including oil and gas, coal, minerals, new energy, renewable and conversion energy, electricity, and others. The different volume, variety, veracity, and velocity of data have challenge to address with the energy data model. The works focus on the development of data model for big data storage implementation schemes in the energy data. The data model has produces by analyzed the national energy big data architecture, develop the data mapping and correlation, big data master data management with energy industry standardization, big data management portal for upstream energy and downstream energy. The research has goal to establishing a foundation for building technology and big data management in the energy sector which includes petroleum, coal, geothermal and renewable energy, and in the future can be the basis for predictive analysis and national energy production.","","978-1-6654-2680-0","10.1109/DATABIA53375.2021.9650117","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650117","big data;energy;data model;big data schemes","Renewable energy sources;Oils;Standardization;Production;Big Data;Data science;Data models","","4","","18","IEEE","24 Dec 2021","11-12 Nov. 2021","11-12 Nov. 2021","IEEE","IEEE Conferences"
"Reference architecture for data ingestion in Data Lake","J. Lagos; A. Cravero","Depto. Cs. De la Computación e Informática, Universidad de La Frontera, Temuco, Chile; Depto. Cs. De la Computación e Informática, Universidad de La Frontera, Temuco, Chile",2023 18th Iberian Conference on Information Systems and Technologies (CISTI),"15 Aug 2023","2023","","","1","9","The article presents a Reference Architecture Proposal for Data Ingestion in a Data Lake. The project is developed in the context of a consulting firm that provides services to banking and retail companies, where a general flexible architecture capable of representing and relating the components required for the ingestion process in a Data Lake and its concrete application with technologies mapped in the literature or added by the users of the representation is proposed and implemented. At the graphic level, Feature Model is used to diagram the architecture, which is subjected to an evaluation of usability and quality by the members of the consulting firm.","2166-0727","978-989-33-4792-8","10.23919/CISTI58278.2023.10211281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10211281","Data Lake;Ingestion;Architecture;Feature Model","Graphics;Companies;Banking;Big Data applications;Data models;Proposals;Usability","","3","","0","","15 Aug 2023","20-23 June 2023","20-23 June 2023","IEEE","IEEE Conferences"
"Big Data Architecture for Building Energy Management Systems","M. D. Ruiz; J. Gómez-Romero; C. Fernandez-Basso; M. J. Martin-Bautista","Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain; Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain; Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain; Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain",IEEE Transactions on Industrial Informatics,"14 Jun 2022","2022","18","9","5738","5747","The enormous quantity of data handled by building management systems are key to develop more efficient energy operational systems. However, the inability of current systems to take benefit from the generated data may waste good opportunities of improving building performance. Big Data appears as a suitable framework to sustain the management system and conduct future prospective analysis. In this article, we present a Big Data-based architecture for the efficient management of buildings. The different Big Data components are involved not only in the data acquisition phase, but also in the implementation of algorithms capable of analyzing massive data collected from very heterogeneous sources. They also enable fast computations that can help the generation of optimal operational plan generations to improve the building functioning. The proposed architecture has been effectively introduced in four different-purpose buildings, demonstrating that Big Data can help during the energy cycle of the building.","1941-0050","","10.1109/TII.2021.3130052","Spanish Ministry of Science, Innovation, and Universities(grant numbers:TIN2017-91223-EXP); FEDER Programme; Andalusian Regional Government(grant numbers:A-TIC-244-UGR20); European Commission(grant numbers:EeB.NMP.2013-4,608981); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9625776","Building energy management system (BEMS);Big Data;distributed computing;energy building","Big Data;Buildings;Computer architecture;Architecture;Proposals;Energy management systems;Smart grids","","17","","46","IEEE","23 Nov 2021","Sept. 2022","","IEEE","IEEE Journals"
"Interactive System Using LDA for Exploratory Visualization to Extract Data Association in a Data Lake","T. Yamada; Y. Maekawa; Y. Kato; T. Tomiyama","Center for Technology Innovation ‐‐ Systems Eng., Hitachi, Ltd., Yokohama, Japan; Center for Technology Innovation ‐‐ Systems Eng., Hitachi, Ltd., Yokohama, Japan; Center for Technology Innovation ‐‐ Systems Eng., Hitachi, Ltd., Yokohama, Japan; Center for Technology Innovation ‐‐ Systems Eng., Hitachi, Ltd., Yokohama, Japan","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","17 Jan 2019","2018","","","172","177","An interactive system previously developed for exploratory visualization of data associations in a data lake using a self-organizing structure of schemas has been improved by incorporating a machine learning function for latent Dirichlet allocation (LDA) and a categorization function. A topic (i.e., a list of data values and corresponding appearance probabilities) estimated by LDA can be used as a recommendation that indicates latent data association of co-occurrences in a complex network structure. Results of experiments using random data demonstrated that a latent data association with a signal strength of 0.20 (Jaccard coefficient) can be detected over noise with a strength of up to 0.24. The detected recommendation potentially can help the user to create a hypothesis of a useful pattern in big data.","2577-1655","978-1-5386-6650-0","10.1109/SMC.2018.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616035","exploratory visualization;extraction;latent Dirichlet allocation;topic model data association","Data visualization;Machine learning;Signal detection;Histograms;Lakes;Big Data;Interactive systems","","","","13","IEEE","17 Jan 2019","7-10 Oct. 2018","7-10 Oct. 2018","IEEE","IEEE Conferences"
"Using Big Data Analytics to Create a Predictive Model for Joint Strike Fighter","R. Norman; J. Bolin; E. T. Powell; S. Amin; J. Nacker","Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Joint Strike Fighter Program Office (JPO), Naval Air Systems Command (NAVAIR), Arlington, VA; Joint Strike Fighter Program Office (JPO), Naval Air Systems Command (NAVAIR), Arlington, VA",2018 IEEE International Conference on Big Data (Big Data),"24 Jan 2019","2018","","","3590","3596","The amount of information needed to acquire knowledge on today's acquisition systems is growing exponentially due to more complex, higher resolution, software-intensive acquisition systems that need to operate in System-of-Systems (SoS), Family-of-Systems (FoS), Joint, and Coalition environments. Unfortunately, the tools and methods necessary to rapidly collect, aggregate, and analyze this information have not evolved as a whole in conjunction with this increased system complexity and, therefore, has made analysis and evaluation increasingly deficient and ineffective. The Test Resource Management Center's (TRMC's) vision is to build a DoD test and evaluation (T&E) knowledge management (KM) and analysis capability that leverages commercial big data analysis and cloud computing technologies to improve evaluation quality and reduce decision-making time. An evaluation revolution, starting with the Joint Strike Fighter (JSF) program, is underway to ensure the T&E community can support the demands of next-generation weapon systems.The true product of T&E is knowledge ascertained through the collection of information about a system or item under test. However, the T&E community's ability to provide this knowledge is hampered by more complex systems, more complex environments, and the need to be more agile in support of strategic initiatives, such as agile acquisition and the 3rd Offset Strategy. This increased complexity and need for speed cause delayed analysis and problems that go undetected during T&E. The primary reason for these shortfalls is antiquated tools and processes that make data hard to locate, aggregate, and convert into knowledge. In short, DoD has not evolved its evaluation infrastructure as its weapon systems have evolved.Conversely, commercial entities, such as medical observation and diagnosis, electric power distribution, retail, and industrial manufacturing, have embraced agility in their methodologies while modernizing analytics capabilities to keep up with the massive influx of data. Raw physical sensors could provide data, higher-quality image or video cameras, radio frequency identification (RFID) devices, faster data collectors, more detailed point-of-sale information or digitized records, and ultimately is providing more data to analysts in size and complexity than ever before. As more data has become available, an interrelated phenomenon is the desire of analysts to ask more detailed questions about their consumers and their business infrastructure. To drive the process of implementing big data analytics, businesses have begun establishing analytics centers which either take pre-defined business cases and apply methods to address them or implement existing knowledge within the data architecture to create a higher level of awareness to business groups or the company at-large. To meet these demands, data storage and computation architectures have become more sophisticated, dozens of technologies were developed for large-scale processing (such as Apache Hadoop or GreenPlum), and streaming architectures which allow data to be processed and actioned on in real-time as it is collected have become commonplace. The net result of these commercial best practices is a solid foundation for the DoD to transform how it uses data to achieve faster, better, and smarter decisions throughout the acquisition lifecycle.","","978-1-5386-5035-6","10.1109/BigData.2018.8622388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622388","Big Data;Data Analytics;Knowledge Management;Data Management;Virtualization;Cloud Computing;Predictive Maintainance;Department of Defense;Test and Evaluation","Big Data;Knowledge management;Tools;US Department of Defense;Cloud computing;Computer architecture;Data analysis","","5","","0","IEEE","24 Jan 2019","10-13 Dec. 2018","10-13 Dec. 2018","IEEE","IEEE Conferences"
"Credit Investigation and Comprehensive Risk Management System based Big Data Analytics in Commercial Banking","M. VenkateswaraRao; S. Vellela; V. R. B; N. Vullam; K. B. Sk; R. D","Dept. of CSE, Chalapathi Institute of Technology, Guntur, AP, India; Dept. of CSE, Chalapathi Institute of Technology, Guntur, AP, India; Dept. of CSE, Chalapathi Institute of Technology, Guntur, AP, India; Dept. of CSE, Chalapathi Institute of Technology, Guntur, AP, India; Dept. of CSE, Chalapathi Institute of Technology, Guntur, AP, India; Dept. of CSE, Chalapathi Institute of Technology, Guntur, AP, India",2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS),"5 May 2023","2023","1","","2387","2391","The banking industry has experienced significant transformations in terms of how effectively they function and provide services over the past few decades. The banking services infrastructure will be challenged by an expanding worldwide population. While serving a sizable segment of clients, it improves the number of consumers, online transactions, and produces enormous amounts of data. Today, banks in the US and other nations use Big Data Analytics (BDA) to handle this scenario daily. It looks for different trends in their databases in order to help their organizations make more money. Banks are changing from a straightforward approach to managing credit risk to a comprehensive risk management methodology. Banking dangers originate from numerous systems and channels. Big data technology offers an insightful and effective method for managing data, making it appropriate for use in risk management applications that call for complicated data analysis and increased data. The big data architecture of a banking credit investigation and integrated risk management system is described in this analysis. Comparisons and analyses unambiguously show that the described system performs better. Hence, this model shows that efficiency and security has improved.","2575-7288","979-8-3503-9737-6","10.1109/ICACCS57279.2023.10113084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10113084","Big Data Analytics (BDA);credit risk management;banking;transactions","Industries;Databases;Sociology;Banking;Organizations;Big Data;Market research","","51","","20","IEEE","5 May 2023","17-18 March 2023","17-18 March 2023","IEEE","IEEE Conferences"
"The Danish National Energy Data Lake: Requirements, Technical Architecture, and Tool Selection","H. B. Hamadou; T. Bach Pedersen; C. Thomsen","Department of Computer Science, Aalborg University, Aalborg, Denmark; Department of Computer Science, Aalborg University, Aalborg, Denmark; Department of Computer Science, Aalborg University, Aalborg, Denmark",2020 IEEE International Conference on Big Data (Big Data),"19 Mar 2021","2020","","","1523","1532","Renewable Energy Sources such as wind and solar do not emit CO2 but their production vary considerably depending on time and weather. Thus, it is important to use the flexibility in device loads to shift energy consumption to follow the production. For example, an Electrical Vehicle (EV) can be charged very flexibly between arriving home at 5PM and leaving again at 7AM. Utilizing all available energy flexibility requires applying machine learning and AI on massive amounts of Big Data from many different actors and devices, ranging from private consumers, over companies, to energy network operators, and using this to create digital solutions to enable and exploit flexibility. The project Flexible Energy Denmark (FED) is building the foundation for this for the entire Danish society. Specifically, FED collects data from a number of Living Labs (LLs) in representative real-life physical environments. The data is stored in the Danish National Energy Data Lake, called FED Data Lake (FEDDL) to enable efficient and advanced analysis. FEDDL is built using only open source tools which can run both on-premise and in cloud settings. In this paper, we describe the requirements for FEDDL based on a representative LL case study, present its technical architecture, and provide a comparison of relevant tools along with the arguments for which ones we selected.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378368","Data Lake;Energy Data;Living Labs;Data Ingestion;Data Governance;Data Security;Open Source;GDPR","Wind;Renewable energy sources;Production;Machine learning;Tools;Big Data;Lakes","","7","","44","IEEE","19 Mar 2021","10-13 Dec. 2020","10-13 Dec. 2020","IEEE","IEEE Conferences"
"A Study on Recognising the Application of Multiple Big Data Technologies and its Related Issues, Difficulties and Opportunities","M. Sharma; A. A. Hagar; G. R. Krishna Murthy; K. Beyane; B. W. Gawali; B. Pant","Chandigarh University, Mohali, Punjab, India; Department of Computer Science & Information Technology, Dr. Babasaheb Ambedkar Marathwada University, Aurangabad, India; Department of Management, COBE, Wollega University, Nekemte, Ethiopia; Department of Management, COBE, Wollega University, Nekemte, Ethiopia; Department of Computer Science & Information Technology, Dr. Babasaheb Ambedkar Marathwada University, Aurangabad, India; Computer Science & Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India",2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),"18 Jul 2022","2022","","","341","344","The current revolution in data is focused in reshaping the overall knowledge and data which are produced, the manner in which the business is performed and handled in an effective manner. The application of big data offers major insights and opportunities in many industries, moreover it also raises many issues and difficulties which needs to be addressed so as to achieve the overall sustainable development. It has been stated that the critical development of big data can offer real time information which will enable in taking effective action, identify the nature of issues and needs, provide feedback on the critical effectiveness related to the policy. In the present digital environment, the information is collated and saved at a rate which rapidly exceeds the overall range. Currently, nearly 4.5 billion individuals are connected through internet and advanced technologies and this is expected to grow many folds in the next 10 years. However, it can be stated that the big data is still in earlier stage and the domains needs to be reviewed and analysed in an effective manner. The big data presents the overall challenges for the digital earth to process and share the data. The usage of cloud computing offers fundamental support to enhance the challenges through computing resources, storage of data and other aspects. This paper intends to recognised the application of multiple big data technologies and its related issues, difficulties and opportunities, the researchers apply secondary data in collating the data from various sources, the different sources include Google Scholar, ProQuest, published articles in Scopus journals etc.","","978-1-6654-3789-9","10.1109/ICACITE53722.2022.9823623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9823623","Big Data;Data Architecture;Security;Data Management","Industries;Printing;Terminology;Filtering;Face recognition;Organizations;Big Data","","10","","10","IEEE","18 Jul 2022","28-29 April 2022","28-29 April 2022","IEEE","IEEE Conferences"
"Data Lake Validation Strategies: Ensuring Quality in Data Warehousing Pipelines","S. Sachi; R. Kiran Pagidi; S. Karunakaran; S. K. Gupta; S. Dharmapuram; O. Goel","Department of Computer Application, L N Mishra Institute of Economic Development and Social Change, Patna, Bihar, India; N.Y. University Waterford Dr, Edison, NJ, USA; Carl H. Lindner College of Business, University of Cincinnati, Cincinnati, OH, United States; Western Governors University, United States; Carnegie Mellon University, Pittsburgh, PA, United States; ABES Engineering College, Ghaziabad, U.P., India",2025 International Conference on Intelligent and Secure Engineering Solutions (CISES),"5 Dec 2025","2025","","","918","922","The most recent trend is storing vast quantities of raw and unstructured data. Nonetheless, this still places enormous challenges on the quality and reliability of the data in these lakes to support data warehousing pipelines. Any inaccurate, incomplete, or outdated data used in business analytics can produce incorrect insights and decisions, resulting in potential losses for organizations. So, it is essential to enforce data quality and make sure data warehousing pipelines are operating to their best by introducing data lake validation best practices. A critical approach that is often used is data profiling, where we analyze the data to detect patterns, relationships, and anomalies. This is the main reason why it is always a good practice to review the data first since this enables data engineers to gather information about the nature of the data and see its quality. Moreover, data can be cleaned by using techniques to find and correct errors in data, such as missing data or inconsistencies. The reason is that this step allows for the cleansing of data and ultimately ensures that downstream data processing can be done accurately.","","979-8-3315-7349-2","10.1109/CISES66934.2025.11265447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11265447","Storing;Vast;Quantities;Enormous;Challenges","Shape;Reviews;Data integrity;Warehousing;Pipelines;Standards organizations;Organizations;Big Data applications;Market research;Reliability","","","","25","IEEE","5 Dec 2025","11-13 Aug. 2025","11-13 Aug. 2025","IEEE","IEEE Conferences"
"A Risk Model Based Heart Disease Prediction Using Data Lake Architecture","D. B. M; K. Ramesh; P. N. Renjith; B. Prabha","Department of Computer Science and Engineering, Hindustan Institute of Technology and Science, Chennai, Tamil Nadu, India; Department of Computer Science and Engineering, Hindustan Institute of Technology and Science, Chennai, Tamil Nadu, India; Department of Computer Science and Engineering, Hindustan Institute of Technology and Science, Chennai, Tamil Nadu, India; Department of Information Technology, Loyola ICAM College of Engineering and Technology, Chennai, Tamil Nadu, India","2022 First International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT)","10 May 2022","2022","","","1","6","Recently there is a gradual increase of heart diseases at a very fast rate. It is extremely essential to provide strategies for earlier detection of heart disease in patients. With the advent of data lake approach, the health record data available from various providers can be enriched for predicting the risk factor of the heart disease among different patients. The Personal health record (PHR) available in the data lake along with the Electronic health record (EHR) is used to outline the cardiovascular patient risk model. The risk model is based on feature extracted from the physical health records. The preprocessing involves the PHR which is stored in XML format to be merged along with the patient master database. Here in this paper, 3 different classification algorithms are used. The machine learning algorithms KNN, Naïve Bayes' Classifier, Random Forest Classifier are employed on the data. These machine learning algorithms are employed for predicting and classifying the patients with heart disease. It is then followed by the risk score calculation. The calculated risk score clearly identifies the patients with most likely occurrence of heart disease. The proposed model predicts the accuracy of patients to have most likely heart diseases. The proposed model improved the prediction of heart disease in patients.","","978-1-6654-3647-2","10.1109/ICEEICT53079.2022.9768452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768452","EHR;PHR;KNN;Naïve Bayes classifier;Data Lake;Random forest Classifier","Heart;Machine learning algorithms;XML;Predictive models;Big Data applications;Feature extraction;Data models","","4","","11","IEEE","10 May 2022","16-18 Feb. 2022","16-18 Feb. 2022","IEEE","IEEE Conferences"
"Instructional Model for Building Effective Big Data Curricula for Online and Campus Education","Y. Demchenko; E. Gruengard; S. Klous","System and Network Engineering Group, University of Amsterdam, Amsterdam, The Netherlands; Laureate Online Education; KPMG Amsterdam, Amsterdam, Netherlands",2014 IEEE 6th International Conference on Cloud Computing Technology and Science,"12 Feb 2015","2014","","","935","941","This paper presents current results and ongoing work to develop effective educational courses on the Big Data (BD) and Data Intensive Science and Technologies (DIST) that is been done at the University of Amsterdam in cooperation with KPMG and by the Laureate Online Education (online partner of the University of Liverpool). The paper introduces the main Big Data concepts: multicomponent Big Data definition and Big Data Architecture Framework that provide the basis for defining the course structure and Common Body of Knowledge for Data Science and Big Data technology domains. The paper presents details on approach, learning model, and course content for two courses at the Laureate Online Education/University of Liverpool and at the University of Amsterdam. The paper also provides background information about existing initiatives and activities related to information exchange and coordination on developing educational materials and programs on Big Data, Data Science, and Research Data Management.","","978-1-4799-4093-6","10.1109/CloudCom.2014.162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7037787","Education and Training on Big Data Technologies;Online Education;Instructional methodology;Common Body of Knowledge;Bloom's Taxonomy;Andragogy;Big Data Architecture Framework","Big data;Data models;Taxonomy;Industries;Seminars;Educational institutions","","21","","22","IEEE","12 Feb 2015","15-18 Dec. 2014","15-18 Dec. 2014","IEEE","IEEE Conferences"
"Enhancing the data privacy for public data lakes","Y. -H. Chen; H. -H. Chen; P. -C. Huang","National Taipei University of Technology, Yuan Ze University, Taipei City, Taiwan R.O.C.; National Taipei University of Technology, Yuan Ze University, Taipei City, Taiwan R.O.C.; National Taipei University of Technology, Yuan Ze University, Taipei City, Taiwan R.O.C.",2018 IEEE International Conference on Applied System Invention (ICASI),"25 Jun 2018","2018","","","1065","1068","With the rapid development of big data technologies, the value of data are discovered in a wide spectrum of application scenarios. How to effectively share valuable data therefore becomes a design focus of data lakes, which is a popular means of data sharing. Unfortunately, the privacy issues due to data sharing remains a missing piece in the data lake designs, which become a barrier of data sharing between foreign peers that might not completely trust each other. In this paper, we propose a novel framework for public data lakes to control and protect the data privacy of data sharing. The major objective of this work is to boost the circulation of valuable data for big data analytics, and promote the development of big data technologies.","","978-1-5386-4342-6","10.1109/ICASI.2018.8394461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8394461","data privacy;data lake;data analytics","Lakes;Data privacy;Cloud computing;Data analysis;Protocols;Big Data;Virtual machining","","4","","13","IEEE","25 Jun 2018","13-17 April 2018","13-17 April 2018","IEEE","IEEE Conferences"
"Data Lake Lambda Architecture for Smart Grids Big Data Analytics","A. A. Munshi; Y. A. -R. I. Mohamed","Electrical and Computer Engineering Department, University of Alberta, Edmonton, AB, Canada; Electrical and Computer Engineering Department, University of Alberta, Edmonton, AB, Canada",IEEE Access,"13 Aug 2018","2018","6","","40463","40471","The advances in smart grids are enabling huge amount of data to be aggregated and analyzed for various smart grid applications. However, the traditional smart grid data management systems cannot scale and provide sufficient storage and processing capabilities. To address these challenges, this paper presents a smart grid big data eco-system based on the state-of-the-art Lambda architecture that is capable of performing parallel batch and real-time operations on distributed data. Furthermore, the presented eco-system utilizes a Hadoop Big Data Lake to store various types of smart grid data including smart meter, images, and video data. An implementation of the smart grid big data eco-system on a cloud computing platform is presented. To test the capability of the presented eco-system, real-time visualization and data mining applications were performed on the real smart grid data. The results of those applications on top of the eco-system suggest that it is capable of performing numerous smart grid big data analytics.","2169-3536","","10.1109/ACCESS.2018.2858256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417407","Smart grids;smart meter;big data;cloud;data mining;clustering;visualization","Smart grids;Big Data;Computer architecture;Real-time systems;Data mining;Distributed databases;Task analysis","","99","","36","OAPA","23 Jul 2018","2018","","IEEE","IEEE Journals"
"NeoMycelia: A software reference architecturefor big data systems","P. Ataei; A. Litchfield","School of Engineering, Computer and Mathematical Sciences, Auckland University of Technology, Auckland, New Zealnd; Service and Cloud Computing Research Lab, Auckland University of Technology, Auckland, New Zealand",2021 28th Asia-Pacific Software Engineering Conference (APSEC),"17 Feb 2022","2021","","","452","462","The big data revolution began when the volume, velocity, and variety of data completely overwhelmed the systems used to store, manipulate and analyze that data. As a result, a new class of software systems emerged called big data systems. While many attempted to harness the power of these new systems, it is estimated that approximately 75% of the big data projects have failed within the last decade. One of the root causes of this is software engineering and architecture aspect of these systems. This paper aims to facilitate big data system development by introducing a software reference architecture. The work provides an event driven microservices architecture that addresses specific limitations in current big data reference architectures (RA). The artefact development has followed the principles of empirically grounded RAs. The RA has been evaluated by developing a prototype that solves a real-world problem in practice. At the end, succesful implementation of the reference architecture have been presented. The results displayed a good degree of applicability with respect to Quality factors.","2640-0715","978-1-6654-3784-4","10.1109/APSEC53868.2021.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712121","Reference architecture;Architecture;Big data reference architecture;Big data architecture;Big data systems;Big data software engineering;Event driven;Microservices","Q-factor;Distributed databases;Prototypes;Computer architecture;Big Data;Software systems;Complexity theory","","7","","59","IEEE","17 Feb 2022","6-9 Dec. 2021","6-9 Dec. 2021","IEEE","IEEE Conferences"
"A big spatiotemporal streaming data architecture for smart city crisis monitoring using VGI","M. A. Ben Rhaiem; M. Selmi; I. R. Farah; A. Bouzeghoub","RIADI Laboratory, University Manouba, Manouba, Tunisia; RIADI Laboratory, University Manouba, Manouba, Tunisia; RIADI Laboratory, University Manouba, Manouba, Tunisia; Samovar Telecom SudParis, Institut Polytechnique de Paris, Paris",2022 2nd International Conference of Smart Systems and Emerging Technologies (SMARTTECH),"4 Aug 2022","2022","","","107","111","The exponential growth of human activities and the climate change put cities around the world in face of multiple risks and threats that led eventually to the emergence of a new urban model, which is the smart city resilience. Although being equipped with a myriad of connected smart devices and sensors, the smart city is still physically made up of buildings, roads, parks, industrial sites, shopping centers, etc. Therefore, location-based crisis management endorses a geospatial modeling strategy approach for major hazard data management in a smart city. Hence, spatial data remains always at the center of risk management processes. However, smart and resilient cities still strive to solve the imparity between the huge amounts of geospatial data generated mostly in real time in particular geographic user content contributions also known as Volunteered Geographic Information (VGI) and the delayed decision-making. In this paper, we reviewed major studies using VGI in big spatiotemporal data analytics in supporting smart city resilience. Then, we propose a vision of big spatiotemporal data architecture perquisites leveraging big data technologies, VGI and deep learning techniques for smart hazard management.","","978-1-6654-0973-5","10.1109/SMARTTECH54121.2022.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842436","Smart city resilience;Big spatiotemporal data;VGI;IoT;streaming processing","Smart cities;Roads;Urban planning;Hazards;Spatial databases;Spatiotemporal phenomena;Geospatial analysis;Climate change","","1","","24","IEEE","4 Aug 2022","9-11 May 2022","9-11 May 2022","IEEE","IEEE Conferences"
"Proposing Big Data Architecture for Addressing Dropout Problem in MOOC Platforms","A. -K. Nguyen; D. -K. Nguyen; K. T. VO; T. Nguyen; T. -A. Nguyen-Hoang; N. -T. Dinh; H. -T. Nguyen","Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; The Industrial University of Ho Chi Minh City, Vietnam; Aalto University, Finland",2024 International Conference on Advanced Technologies for Communications (ATC),"7 Mar 2025","2024","","","522","527","Accessing academic knowledge on Massive Open Online Courses (MOOCs) has made learning more convenient with flexible schedules and a vast array of course options. The common weakness of these platforms, however, lies in the difficulty of controlling learners' behaviour. Noone can know for certain whether the level of engagement during learning is sufficient for learners to fully grasp the knowledge, or whether learners may fail to complete the courses they have enrolled in, leading to dropout behaviour. In this study, we also ap-plied an artificial intelligence model to predict whether current students can complete the course, enabling quick detection of dropout behaviour and timely preventive measures. Based on the proposed architecture, a real-time monitoring, analysis, and management application system for learner behavior can be developed. This empowers course managers to detect which learners might drop out of which courses, enabling timely alerts to learners for adjusting their study plans or, on a broader scale, restructuring the organization of courses with excessively high dropout rates. To maximize scalability with the increasing volume of MOOC data and applicability across different MOOC platforms, our architecture will be built on the Microsoft Azure Cloud computing service, utilizing modern and renowned big data technologies to perform tasks ranging from streaming data collection, batch data processing, distributed processing of large-scale data, to storing data in any format with the latest data lakehouse storage architecture, and real-time data visualization and anomaly detection through integrated models.","2162-1039","979-8-3503-5398-3","10.1109/ATC63255.2024.10908166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10908166","big data architecture;clickstream data;MOOC;dropout prediction","Computer aided instruction;Distributed processing;Electronic learning;Scalability;Distributed databases;Computer architecture;Predictive models;Real-time systems;Data models;Monitoring","","2","","19","IEEE","7 Mar 2025","17-19 Oct. 2024","17-19 Oct. 2024","IEEE","IEEE Conferences"
"Data Discovery as a Service for Data Lake","H. V. Sreepathy; B. Dinesh Rao; J. Mohan Kumar; B. Deepak Rao","Manipal School of Information Sciences, Manipal Academy of Higher Education, Manipal, India; Manipal School of Information Sciences, Manipal Academy of Higher Education, Manipal, India; Manipal School of Information Sciences, Manipal Academy of Higher Education, Manipal, India; Manipal School of Information Sciences, Manipal Academy of Higher Education, Manipal, India","2024 Second International Conference on Networks, Multimedia and Information Technology (NMITCON)","4 Oct 2024","2024","","","1","9","Data Lake (DL) is a low-cost big-data architecture designed to centralize an organization’s data, enabling the extraction of valuable insights and economic benefits. To effectively manage, describe, and discover these data assets, data catalog tools are essential. These tools utilize metadata to inventory data assets, allowing end-users to search, query, and locate datasets within the Data Lake. Existing data catalogs do not provide the necessary context or descriptive statistics of datasets, hindering the efficient and insightful utilization of data. Furthermore, it struggles to categorize data based on context or domain during ingestion and lack the necessary automation and scalability to support modern data stacks. This work proposes integrating Data Discovery as a Service(DDaaS) into Data Lake. The Data Discovery service, developed using Plotly-Dash, is an interactive web dashboard integrated into a data lake. DDaaS assists end-users in discovering structured datasets based on domain. Service provides descriptive statistics of data using interactive visualization and pre-computed statistical views to describe data. DDaaS reduces latency in locating related datasets and describes trends, patterns, and insights. To validate the proposed Data Discovery as a Service (DDaaS) features, a comparative study is conducted, corraborating its attributes with those of existing data catalog systems. This study aims to demonstrate DDaaS’s superiority in context-based categorization and the provision of descriptive statistics. Performance validation is executed by measuring the resource consumption of each service component, including metrics such as CPU usage, memory consumption, to ensure operational efficiency. Additionally, the efficacy of DDaaS is assessed by evaluating the latency of its descriptive statistics methods across datasets from diverse domains and varying record sizes. This evaluation ensures that DDaaS can deliver timely and accurate statistical descriptions, confirming its robustness and effectiveness in handling datasets of different natures and scales.","","979-8-3503-7289-2","10.1109/NMITCON62075.2024.10699255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10699255","Data Lake;Data Discovery Service;Data Catalog;Data Categorization;Domain based data serach;Descriptive statistics visualization of datasets","Measurement;Economics;Scalability;Memory management;Data visualization;Metadata;Big Data applications;Market research;Robustness;Information technology","","","","48","IEEE","4 Oct 2024","9-10 Aug. 2024","9-10 Aug. 2024","IEEE","IEEE Conferences"
"Smart Grid Big Data Architecture Design based on Improved K-means Algorithm","J. Guo; J. Jia; S. Jiang; T. Ma; N. Lv","State Grid Xinjiang Electric Power Co.,LTD. Information and Telecommunication Company, Urumqi, China; State Grid Xinjiang Electric Power Co.,LTD. Information and Telecommunication Company, Urumqi, China; State Grid Xinjiang Electric Power Co.,LTD. Information and Telecommunication Company, Urumqi, China; State Grid Xinjiang Electric Power Co.,LTD. Information and Telecommunication Company, Urumqi, China; State Grid Xinjiang Electric Power Co.,LTD. Information and Telecommunication Company, Urumqi, China",2023 IEEE 15th International Conference on Computational Intelligence and Communication Networks (CICN),"30 Jan 2024","2023","","","495","502","This study focuses on the analysis and improvement of clustering algorithms for smart grid big data analysis. The goal is to address the unique challenges posed by smart grid data, such as high dimensionality, sparsity, and the presence of categorical features. The proposed architecture incorporates enhancements to the traditional K-means algorithm, including seed selection initialization, specific distance metrics, and convergence criteria. The experimental evaluation involves a real-world smart grid dataset and employs evaluation metrics such as the Silhouette Coefficient, Rand Index, and Davies-Bouldin Index. The results demonstrate the effectiveness and efficiency of the improved algorithms, showcasing well-separated clusters, high similarity to reference clusterings, and compact cluster structures. The findings highlight the importance of appropriate distance metrics, such as cosine similarity, and the utilization of domain knowledge in the initialization process. Comparisons with traditional K-means clustering reveal the superior performance of the improved algorithms in terms of cluster quality. The implications of these findings for smart grid data analysis include improved energy management, anomaly detection, load forecasting, and grid optimization. Further research is warranted to validate the algorithms on diverse datasets and under different scenarios. The proposed architecture and improved K-means algorithms offer valuable insights for researchers and practitioners seeking to analyze and optimize smart grid big data.","2472-7555","979-8-3503-2443-3","10.1109/CICN59264.2023.10402273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10402273","smart grid;big data analysis;clustering algorithms;K-means","Measurement;Clustering algorithms;Computer architecture;Big Data;Smart grids;Indexes;Optimization","","","","18","IEEE","30 Jan 2024","22-23 Dec. 2023","22-23 Dec. 2023","IEEE","IEEE Conferences"
"Towards a Quality-centric Big Data Architecture for Federated Sensor Services","L. Ramaswamy; V. Lawson; S. V. Gogineni","Department of Computer Science, University of Georgia, Athens, GA, USA; School of Science and Technology, Georgia Gwinnett College, Lawrenceville, GA, USA; Department of Computer Science, University of Georgia, Athens, GA, USA",2013 IEEE International Congress on Big Data,"16 Sep 2013","2013","","","86","93","As the Internet of Things (IoT) paradigm gains popularity, the next few years will likely witness 'servitization' of domain sensing functionalities. We envision a cloud-based eco-system in which high quality data from large numbers of independently-managed sensors is shared or even traded in real-time. Such an eco-system will necessarily have multiple stakeholders such as sensor data providers, domain applications that utilize sensor data (data consumers), and cloud infrastructure providers who may collaborate as well as compete. While there has been considerable research on wireless sensor networks, the challenges involved in building cloud-based platforms for hosting sensor services are largely unexplored. In this paper, we present our vision for data quality (DQ)-centric big data infrastructure for federated sensor service clouds. We first motivate our work by providing real-world examples. We outline the key features that federated sensor service clouds need to possess. This paper proposes a big data architecture in which DQ is pervasive throughout the platform. Our architecture includes a markup language called SDQ-ML for describing sensor services as well as for domain applications to express their sensor feed requirements. The paper explores the advantages and limitations of current big data technologies in building various components of the platform. We also outline our initial ideas towards addressing the limitations.","2379-7703","978-0-7695-5006-0","10.1109/BigData.Congress.2013.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6597123","Internet of Things;Federated Sensor Clouds;Data Quality;Sensor Virtualization","Feeds;Clouds;Wireless sensor networks;Computer architecture;Fluid flow measurement;Markup languages;Data models","","51","","27","IEEE","16 Sep 2013","27 June-2 July 2013","27 June-2 July 2013","IEEE","IEEE Conferences"
"Open-Source Big Data Analytics Architecture for Businesses","M. O. Gökalp; K. Kayabay; M. Zaki; A. Koçyiğit; P. E. Eren; A. Neely","Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Institute for Manufacturing, University of Cambridge, Cambridgeshire, UK",2019 1st International Informatics and Software Engineering Conference (UBMYK),"23 Jan 2020","2019","","","1","6","Unaware of existing big data technologies, organizations fail to develop a big data capability despite its disruptive impact on today’s competitive business environment. To determine the shortcomings and strengths of developing a big data architecture with open-source tools from technical and managerial perspectives, this study (1) systematically reviews the available open-source big data technologies to present a comprehensive picture, and (2) proposes an open-source architecture for businesses to take as a reference while developing big data analytics capabilities. Lastly, we discuss technical, domain-specific, and firm-specific soft challenges related to establishing a big data architecture in an organization, and how these challenges are reshaping the big data research domain.","","978-1-7281-3992-0","10.1109/UBMYK48245.2019.8965572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965572","Big Data;Big Data Technologies;Big Data Analytics;Reference Architecture;Systematic Review","Computer architecture;Organizations;Big Data;Informatics;Systematic literature review;Software engineering","","12","","39","IEEE","23 Jan 2020","6-7 Nov. 2019","6-7 Nov. 2019","IEEE","IEEE Conferences"
"Data Lake Conceptualized Web Platform for Food Research Data Collection","G. -t. An; S. Oh; E. Kim; J. -m. Park","Korea Food Research Institute, Wanju-gun, Republic of Korea; Korea Food Research Institute, Wanju-gun, Republic of Korea; Korea Food Research Institute, Wanju-gun, Republic of Korea; Korea Food Research Institute, Wanju-gun, Republic of Korea",Journal of Web Engineering,"4 Jun 2024","2024","23","3","377","392","Food research is uniquely intertwined with everyday life and necessitates the utilization of big data. Within this domain, the research data consist of various forms and formats, encompassing biological experiment results, chemical analysis data, nutritional information, microbiological data, sensor data, images, and videos. This diversity stems from the integration of data from various subdomains within the larger field. With recent advancements in deep learning technology, the importance of data has grown significantly, resulting in increased reliance on data-driven research. Although specialized platforms for sharing and utilizing data have been established at the national level, particularly in the bioscience field, food research lacks a dedicated infrastructure and specialized data-sharing platforms. In this study, we develop a platform that leverages Hadoop-based distributed file systems to create a data lake. This platform enables data storage and sharing through a web-based interface. The distributed file system supports scalability by adding data nodes, making it an effective solution for capacity expansion. In addition, the web-based platform ensures high accessibility, allowing users access from anywhere, at any time, using any device. Finally, we introduce the establishment of a 1.8 PB Hadoop-based physical storage system and present an approach for building a highly accessible web platform with substantial utility.","1544-5976","","10.13052/jwe1540-9589.2333","Korea Food Research Institute (KFRI)(grant numbers:E0220700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10547279","Food research data;big data;data platform;data collection;web-based platform","Technological innovation;File systems;Scalability;Distributed databases;Memory;User interfaces;Metadata","","","","30","","4 Jun 2024","May 2024","","River Publishers","River Publishers Journals"
"Fast-data architecture proposal to alert people in emergency","W. Velásquez; A. Munoz-Arcentales; J. Salvachúa","Escuela Técnica Superior de Ingenieros de Telecomunicación, Universidad Politécnica de Madrid, Spain; Escuela Superior Politécnica del Litoral, ESPOL, Guayaquil, Ecuador; Escuela Técnica Superior de Ingenieros de Telecomunicación, Universidad Politécnica de Madrid, Spain",2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC),"26 Feb 2018","2018","","","165","168","This paper states a brief overview of technologies related to Smart Cities and Big Data ecosystems in order to develop and present an architecture proposal for deploying services using the paradigm of Fast Data. The main goal of this architecture, is to present a set of tools and how it could be integrated for providing fast data services focus on Resilient Smart Cities. Finally, proposals for analysis the response times, delays, incidents, and future works are presented.","","978-1-5386-4649-6","10.1109/CCWC.2018.8301721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301721","Fast Data;Architecture;Emergency;Smart City;IoT;Big Data","Big Data;Proposals;Real-time systems;Smart cities;Emergency services;Tools;Sparks","","3","","29","IEEE","26 Feb 2018","8-10 Jan. 2018","8-10 Jan. 2018","IEEE","IEEE Conferences"
"Sigma: a Scalable High Performance Big Data Architecture","N. Cassavia; E. Masciari","ICAR-CNR, Rende, Italy; DIETI, University Federico II and ICAR CNR, Napoli, Italy","2021 29th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)","21 Apr 2021","2021","","","236","239","In this paper, a new architecture, named Sigma (as Sigma uppercase usually denote a sum and this architecture is a summarization of Lambda and Kappa), is proposed to provide a solution for build a complete Big Data System, interactive and scalable, using a variety of tools and techniques. The architecture have been tested in a real life scenario and the early results obtained are quite encouraging both on scalability and high performance.","2377-5750","978-1-6654-1455-5","10.1109/PDP52278.2021.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407117","Big Data;Architectures","Scalability;Big Data;Tools","","2","","10","IEEE","21 Apr 2021","10-12 March 2021","10-12 March 2021","IEEE","IEEE Conferences"
"The Significance of using Data Extraction Methods for an Effective Big Data Mining Process","M. Sharma; R. Gupta","dept. Computer Science Engoneering, Graphic Era deemed to be University, Dehradun, India; dept. Computer Science Engoneering, Graphic Era hill University, Dehradun, India",2023 2nd International Conference for Innovation in Technology (INOCON),"19 Apr 2023","2023","","","1","4","Data is identified as the fuel of modern society for its versatility of use and effectiveness of use. In addition, modern businesses are making a decline based on analysis of historical data and patterns of the data. Such dependency on data analysis makes the process of data analysis important for data mining. Therefore the overall study has shed light on the significance of the data mining process and extraction process of data in order to make a data-driven decision. Additionally, the problems related to the process of data extraction and data mining are mentioned in the study which helps to achieve an overall concept for the data extraction and data mining process. Additionally, the significance of the process is mentioned in the study. Additionally, there are tables constructed that represent problems of the data extraction process and mining and the significance of the stems of mining. The study concludes in a way that helps in the implication of data extraction methods for business.","","979-8-3503-2092-3","10.1109/INOCON57975.2023.10101236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10101236","Big data mining;Data extraction methods;Data Mining process;Data warehouse;Data lake;Data analysis;Decision making;Artificial intelligence;Business intelligence;data-driven decision-making","Technological innovation;Data analysis;Decision making;Big Data;Data mining;Fuels;Business","","4","","20","IEEE","19 Apr 2023","3-5 March 2023","3-5 March 2023","IEEE","IEEE Conferences"
"Unstructured Big Data Quality Measurements and Failed Data Re-Processing Approach","P. Pande; N. Rao","Deutsche India Private Limited, Magarpatta, Hadapsar, Pune, India; Deutsche India Private Limited, Magarpatta, Hadapsar, Pune, India",2023 World Conference on Communication & Computing (WCONF),"4 Sep 2023","2023","","","1","7","This paper discusses role of data quality checks, in identifying message loss during large volume semi structured and unstructured data processing. We discuss data quality dimensions, applicable to semi structured and unstructured data in the form of email data. Email data confirms to RFC822 format and can have unstructured data like images, documents as attachments. Along with discussion of applicable data quality dimensions, we also discuss the formulae to evaluate data quality for each of these dimensions. The paper, focuses on big-data reprocessing, starting with need for data re-processing and identifying generic re-processing scenarios. This scenario identification step is important to ensure that the solution caters to all the re-processing requirements. It further discusses about types of data re-processing, core concepts on which re-processing solution is based and approach for handling different type of re-processing. The paper subsequently discusses principles of backlog processing for streaming data. The streaming data like email data, keeps flowing continuously at a very high rate. Any downtime in processing system, results in accumulation of data backlog. This accumulated data must be processed fully without creating a domino of backlogs. This document discusses statistical approach for forecasting time required to clear piled-up backlog of streaming data.","","979-8-3503-1120-4","10.1109/WCONF58270.2023.10235088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10235088","Data Architecture Framework;Data Governance;Batch processing systems;Distributed systems","Data integrity;Computer architecture;Big Data;Data processing;Electronic mail;Forecasting","","","","14","IEEE","4 Sep 2023","14-16 July 2023","14-16 July 2023","IEEE","IEEE Conferences"
"Application of Big Data, Fast Data, and Data Lake Concepts to Information Security Issues","N. Miloslavskaya; A. Tolstoy","National Research Nuclear University MEPhI (Moscow Engineering Physics Institute), Moscow, Russia; National Research Nuclear University MEPhI (Moscow Engineering Physics Institute), Moscow, Russia",2016 IEEE 4th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW),"18 Oct 2016","2016","","","148","153","Today we witness the appearance of some additional to Big Data concepts: data lakes and fast data. Are they simply the new marketing labels for the old Big Data IT or really new ones? Thus the key goal of the paper is to identify the relationship between these three concepts, giving special attention to their application to information security (IS) issues. The reason lies in the fact that volumes of IS-related information is one thing, but the real problem for securing enterprises' IT infrastructure assets is the speed with which things related to IS happen.","","978-1-5090-3946-3","10.1109/W-FiCloud.2016.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592715","","Data mining;Big data;Distributed databases;Lakes;Information security;Real-time systems","","28","","17","IEEE","18 Oct 2016","22-24 Aug. 2016","22-24 Aug. 2016","IEEE","IEEE Conferences"
"A Big Data Architecture for Fault Prognostics of Electronic Devices: Application to Power MOSFETs","C. J. Alonso-González; B. Pulido; M. Cartón; A. Bregon","Departamento de Informática, Universidad de Valladolid, Valladolid, Spain; Departamento de Informática, Universidad de Valladolid, Valladolid, Spain; Madison MK, Valladolid, Spain; Departamento de Informática, Universidad de Valladolid, Valladolid, Spain",IEEE Access,"7 Aug 2019","2019","7","","102160","102173","This paper deals with the problem faced performing prognostics of electronic devices using a data-driven approach to generate degradation models for predicting their remaining useful life. To be able to generate good models, a lot of experimental data are required. Moreover, the high frequency sampling required for electronic devices implies that huge amounts of experimental data must be efficiently stored, transformed, and analyzed in the prediction models. The first contribution of this paper is the proposal of a Big Data architecture that can be used for a generic prognostics approach of electronic devices. To illustrate the proposal, the dataset for power MOSFET prognostics developed at the NASA Prognostics Center of Excellence is used. This paper carefully illustrates the analysis, extraction, and transformation stages required to obtain the data for the estimation of the degradation models. An additional contribution of this paper is to study scalable methods to perform such estimation. Instead of using typical approaches such as extended Kalman filters, particle filters, or relevance vector machines to perform the estimation, we propose to use much simpler techniques (such as least squares or horizontal average) to allow a scalable implementation in a Big Data (distributed and parallelized) platform. After applying our approach to the MOSFETs dataset, we have shown that the obtained results are competitive when compared with more complex techniques.","2169-3536","","10.1109/ACCESS.2019.2929111","Universidad de Valladolid; Departamento de Informática, Universidad de Valladolid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764332","Accelerated aging;Big Data applications;degradation;power MOSFET;prognostics and health management;remaining life assessment;regression analysis;reliability engineering","Big Data;Degradation;MOSFET;Data models;Estimation;Proposals;Accelerated aging","","16","","16","CCBY","16 Jul 2019","2019","","IEEE","IEEE Journals"
"Big Data Architecture for Efficient Energy Management in Multi Microgrid Scenarios","A. F. D. S. Veloso; M. M. D. N. Costa; V. R. José; P. F. F. Abreu; G. S. Netol; T. A. Silva; L. H. D. O. Mendes","Federal University of Piauí, Piauí, Brazil; iCEV Faculty (iCEV), Piauí, Brazil; Federal University of Piauí, Piauí, Brazil; Federal University of Piauí, Piauí, Brazil; Federal University of Piauí, Piauí, Brazil; Federal University of Piauí, Piauí, Brazil; Federal University of Piauí, Piauí, Brazil",2024 XIV Brazilian Symposium on Computing Systems Engineering (SBESC),"3 Dec 2024","2024","","","1","6","The traditional electric power distribution network is evolving to support scalable and connected services in Smart Cities (SC). The emergence of Smart Grid (SG) architecture connects Smart Meters (SM) to the Electric Power Company (EPC) using various communication technologies like Power Line Communication (PLC) and wireless networks such as 5G, LoRa, and others. However, the vast amount of data generated by this infrastructure can lead to network overload and storage and processing challenges. To address this, this paper proposes implementing a Big Data Analytics framework under the Hybrid Demand Side Management as a Service (HyDSMaaS) architecture in the Multi Microgrid scenario. This approach divides the SG into Microgrids, creating smaller groups of nodes and transforming the centralized infrastructure into a scalable and decentralized one. Additionally, a monitoring system using Grafana was implemented to manage server usage flow and monitor access and services. The framework achieved high speed compared to traditional models and demonstrated accuracy of nearly 99.9% in consumption prediction and power quality classification algorithms when operating with up to 1000 microgrids in under 1000 seconds.","2324-7894","979-8-3315-0900-2","10.1109/SBESC65055.2024.10771911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10771911","Iorawan;loramesh;smart grid;multi microgrid;big data analytics;hydsmaas;demand side management;spark","Accuracy;Wireless networks;Power quality;Microgrids;Computer architecture;Big Data;Smart meters;Classification algorithms;Monitoring;Testing","","1","","19","IEEE","3 Dec 2024","26-29 Nov. 2024","26-29 Nov. 2024","IEEE","IEEE Conferences"
"Spatio-temporal trajectory big data analysis based on HNCORS","Y. Zhang; X. Zeng; M. Ao; W. Jin","Hunan Institute of Geomatics, Science and Technology, Changsha, China; Hunan Institute of Geomatics, Science and Technology, Changsha, China; Hunan Institute of Geomatics, Science and Technology, Changsha, China; Hunan Institute of Geomatics, Science and Technology, Changsha, China",2022 5th International Conference on Data Science and Information Technology (DSIT),"17 Nov 2022","2022","","","1","7","The analysis based on spatio-temporal trajectory big data is of great significance for mining user operation rules, predicting behavior trends, and exploring application expansion. Hunan continuously operating reference station network, which provides the official real-time kinematic service to the public, is one of the most important regional geospatial datum infrastructures in Hunan province, China. Using the location based big data of users, the multi-scale and multi-time characteristics of trajectory operation data and fixed solution ratio are analyzed by preprocessing, interpolation, kernel density analysis and other methods. The results show that the distribution characteristics of trajectory data in Hunan province are related to the working habit in field surveying and mapping, and the overall performance is reduced from the Middle East to the West, from economically developed areas to economically poor areas, and from plain hilly areas to mountain / lake areas. Among them, the suburbs of towns are relatively dense areas of trajectory data. The amount of trajectory operations is also significantly correlated with the local economy. By analyzing the spatio-temporal sequence diagram of the trajectory data, the evolution process is divided into six stages, which is manifested in the continuous growth and decline around Changsha-Zhuzhou-Xiangtan region and the eleven urban areas in a natural day.","","978-1-6654-9868-5","10.1109/DSIT55514.2022.9943937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943937","Trajectory big data;real-time kinematic;HNCORS;kernel density analysis;spatial-temporal analysis","Urban areas;Big Data;Lakes;Predictive models;Real-time systems;Trajectory;Planning","","","","21","IEEE","17 Nov 2022","22-24 July 2022","22-24 July 2022","IEEE","IEEE Conferences"
"AI-Powered Data Governance Models for Automated Compliance in Big Data Architectures","E. Sumalatha; B. K. Gudepu; S. Yadav","AuditSubbaraoVamanan &Co, Hyderabad, Telangana; Department of Information Technology, Developer 4, Systems Software at Kemper, USA; Shri Krishan Institute of Engineering and Technology, Kurukshetra University, Kurukshetra, India",2025 International Conference on Recent Innovation in Science Engineering and Technology (ICRISET),"28 Nov 2025","2025","","","1","6","The following paper presents a discussion of developing AI-Powered Data Governance Models of Automated Compliance in Big Data Architectures through Hybrid AI Models with Reinforcement Learning (RL) to be able to adapt in real-time. Taking advantage of the IBM Watson OpenScale, the study suggests a dynamic approach to best deal with the increased risks encountered in large-scale and complex data environments related to data governance and automation of data compliance. This hybrid AI model is also an integration of unsupervised and supervised learning that will allow the system to evolve along with the change of the regulations and streamline these processes of compliance with no manual work. The reinforcement learning constantly updates the model and therefore the compliance measures are always up to date with the regulations that keep changing. IBM Watson OpenScale improves the level of transparency in a system with the help of explainable AI, which enables trust and responsibility in the decision-making process. Compared to the existing solutions, the proposed idea shows considerable scalability gains, processing performance, and near-real-time adaptation, which makes it a fit possible solution to industries, where data compliance is essential, including finance, healthcare, and IoT.","","979-8-3315-5833-8","10.1109/ICRISET64803.2025.11252324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11252324","AI-powered data governance;automated compliance;hybrid AI models;reinforcement learning;real-time adaptation;IBM Watson OpenScale;big data architectures","Industries;Adaptation models;Biological system modeling;Reinforcement learning;Computer architecture;Big Data;Data models;Real-time systems;Regulation;Data governance","","","","16","IEEE","28 Nov 2025","1-2 Aug. 2025","1-2 Aug. 2025","IEEE","IEEE Conferences"
"DEWA R&D Data Lake: Big Data Platform for Advanced Energy Data Analytics","H. Y. Youssef; M. Ashfaque; J. V. Karunamurthy","Dubai Electricity and Water Authority, Research and Development Center, Dubai, United Arab Emirates; Dubai Electricity and Water Authority, Research and Development Center, Dubai, United Arab Emirates; Dubai Electricity and Water Authority, Research and Development Center, Dubai, United Arab Emirates",2023 International Conference on IT Innovation and Knowledge Discovery (ITIKD),"19 Apr 2023","2023","","","1","6","The digital transformation of the utility sector has resulted in a flood of data incoming from diverse and dispersed data sources, which requires huge integration, storage, processing, and management efforts. In this work, we present a Big Data advanced analytics platform for utility data, that allows for easier data retrieval, processing, and visualization, with enhanced data security. The successful implementation of Data Lake at DEWA (Dubai Electricity and Water Authority) R&D Center increases valuable insight extraction from raw and processed data, that can be employed in informed decision-making and cross-utilization of data between different sectors in the utility company.","","978-1-6654-6372-0","10.1109/ITIKD56332.2023.10099717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10099717","utility data;big data platform;internet of things;digital transformation;advanced data analytics","Technological innovation;Data analysis;Soft sensors;Digital transformation;Decision making;Data visualization;Big Data applications","","2","","34","IEEE","19 Apr 2023","8-9 March 2023","8-9 March 2023","IEEE","IEEE Conferences"
"Large scale optimization to minimize network traffic using MapReduce in big data applications","S. Neelakandan; S. Divyabharathi; S. Rahini; G. Vijayalakshmi","Department of CSE, Jeppiaar Institute of Technology, Chennai, India; Dept. of CSE, Jeppiaar Institute of Technology; Dept. of CSE, Jeppiaar Institute of Technology; Dept. of CSE, Jeppiaar Institute of Technology","2016 International Conference on Computation of Power, Energy Information and Commuincation (ICCPEIC)","1 Sep 2016","2016","","","193","199","The Map-Reduce model simplifies the large scale data handling on commodities group by abusing parallel map & reduces assignments.. The use of this model is beneficial only when the enhanced distributed shuffle procedure (which reduces network communication cost) and fault tolerance features of the MapReduce framework come into existence. Improving the communication cost is essential to a good MapReduce algorithm. They disregard the network activity produced in the mix stage, which assumes a basic part in execution upgrade. Generally, a hash capacity is utilized to segment middle of the road information among decrease assignments, which, nonetheless, is not movement effective in light of the fact that network topology which is the arrangement of the various elements like links, nodes, etc of a computer network. Reexamine to lessen system movement cost for a Map-Reduce work by planning a novel moderate information segment plan. A decomposition based dynamic & healthcare monitoring algorithm is proposed to manage the huge scale optimization issue for enormous information application in a dynamic way. Finally, broad reproduction results show that the proposed recommendations can altogether decrease network movement cost under offline cases.","","978-1-5090-0901-5","10.1109/ICCPEIC.2016.7557196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557196","Big data;Dynamic decomposition based k-means algorithm;Traffic minimization‥","Data models;Silicon;Roads;Java;Computational modeling;Lead;Logic gates","","33","","13","IEEE","1 Sep 2016","20-21 April 2016","20-21 April 2016","IEEE","IEEE Conferences"
"Cloud based big data infrastructure: Architectural components and automated provisioning","Y. Demchenko; F. Turkmen; C. de Laat; C. Blanchet; C. Loomis","Universiteit van Amsterdam, Amsterdam, Noord-Holland, NL; System and Network Engineering Group, University of Amsterdam, Amsterdam, Netherlands; System and Network Engineering Group, University of Amsterdam, Amsterdam, Netherlands; CNRS IFB, Orsay, France; SixSq Sàrl, Geneva, Switzerland",2016 International Conference on High Performance Computing & Simulation (HPCS),"15 Sep 2016","2016","","","628","636","This paper describes the general architecture and functional components of the cloud based Big Data Infrastructure (BDI). The proposed BDI architecture is based on the analysis of the emerging Big Data and data intensive technologies and supported by the definition of the Big Data Architecture Framework (BDAF) that defines the following components of the Big Data technologies: Big Data definition, Data Management including data lifecycle and data structures, Big Data Infrastructure (generically cloud based), Data Analytics technologies and platforms, and Big Data security, compliance and privacy. The paper provides example of requirements analysis and implementation of two bioinformatics use cases on cloud and using SlipStream based cloud applications deployment and management automation platform being developed in the CYCLONE project. The paper also refers to importance of standardisation of all components of BDAF and BDI and provides short overview of the NIST Big Data Interoperability Framework (BDIF). The paper discusses importance of automation of all stages of the Big Data applications developments, deployment and management and refers to existing cloud automation tools and new developments in the SlipStream cloud automation platform that allows multi-cloud applications deployment and management.","","978-1-5090-2088-1","10.1109/HPCSim.2016.7568394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568394","Big Data Architecture Framework;Big Data Infrastructure;Multi-cloud Services Provisioning Automation;SlipStream Cloud Automation platform;Intercloud Architecture Framework (ICAF)","Decision support systems","","10","1","30","IEEE","15 Sep 2016","18-22 July 2016","18-22 July 2016","IEEE","IEEE Conferences"
"The Technique of Operational Processing of Heterogeneous Surveillance Data in Assessing Situation in Geographic Information Systems","M. Rakushev; O. Matsko; O. Permiakov; O. Lavrinchuk; O. Koshlan; I. Varlamov","National Defence University of Ukraine, Named After Ivan Cherniakhovskyi, Kyiv, Ukraine; National Defence University of Ukraine, Named After Ivan Cherniakhovskyi, Kyiv, Ukraine; National Defence University of Ukraine, Named After Ivan Cherniakhovskyi, Kyiv, Ukraine; National Defence University of Ukraine, Named After Ivan Cherniakhovskyi, Kyiv, Ukraine; National Defence University of Ukraine, Named After Ivan Cherniakhovskyi, Kyiv, Ukraine; National Defence University of Ukraine, Named After Ivan Cherniakhovskyi, Kyiv, Ukraine",2021 IEEE 3rd International Conference on Advanced Trends in Information Theory (ATIT),"20 Jan 2022","2021","","","149","153","The paper deals with the analysis of observational data in the assessment of the situation developed technique of heterogeneous data operational processing in assessing situation with the help of Geographic Information Systems, which allow to store raw data about surveillance objects, structured heterogeneous surveillance data due to the principle ""Data Lake"".The basis of the technique is the Model of Storage of Heterogeneous Data, which differs from the known ones by the presence of templates of objects of observation and templates of parameters of objects of observation, which allow distributed storage of both unstructured heterogeneous data and structured data according to a certain scheme, to access data.","","978-1-6654-3847-6","10.1109/ATIT54053.2021.9678766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678766","information;heterogeneous data;processing;model;method;technique;surveillance objects","Decision support systems;Surveillance;Distributed databases;Memory;Big Data applications;Market research;Data models","","2","","17","IEEE","20 Jan 2022","15-17 Dec. 2021","15-17 Dec. 2021","IEEE","IEEE Conferences"
"Omnichannel Retail Analytics: A Scalable Big Data Architecture Using Data Vault 2.0 and Apache Spark for Retail Intelligence","U. Kumar; D. Krishnamoorthy; R. Ghadiyaram",NA; NA; NA,2025 IEEE Conference on Cloud and Big Data Computing (CBDCom),"23 Jan 2026","2025","","","207","212","Retailers often struggle to integrate data from disparate sources such as their eCommerce platforms, physical stores, and inventory systems. This fragmentation hampers timely decision-making, creates inconsistent customer experiences, and complicates regulatory compliance. To address these challenges, this paper proposes a scalable, intelligent data warehousing architecture for retail applications utilizing Data Vault 2.0 in conjunction with Apache Spark. This innovative framework facilitates the aggregation, management, and analysis of omnichannel data, ensuring flexibility, traceability, and scalability. A synthetic simulation, based on representative retail data, validates the architecture's performance and adaptability. The integration of Data Vault 2.0 and Apache Spark provides a powerful solution for managing and analyzing retail data, empowering retailers to derive rapid insights and respond swiftly to market dynamics.","","979-8-3315-9094-9","10.1109/CBDCom68404.2025.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11344184","Data Vault 2.0;Apache Spark;Data Warehousing;eCommerce;Retail;POS;ETL;Omnichannel;Big Data;Intelligent Systems;Retail Analytics","Scalability;Warehousing;Decision making;Cluster computing;Computer architecture;Big Data;Electronic commerce;Intelligent systems","","","","16","IEEE","23 Jan 2026","21-24 Oct. 2025","21-24 Oct. 2025","IEEE","IEEE Conferences"
"The Bidirectional Data Flow Based On The Data-Lake","L. Xu; L. Qian; Z. Chang; Z. Wu","National Science Library, Chinese Academy of Sciences, Beijing, China; National Science Library, Chinese Academy of Sciences, Beijing, China; National Science Library, Chinese Academy of Sciences, Beijing, China; National Science Library, Chinese Academy of Sciences, Beijing, China","2020 13th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","25 Nov 2020","2020","","","971","976","In order to comply with the rapid development of our data resources, this paper focuses on the collection, analysis and integration of our multi-source heterogeneous data resources based on the data-lake structure (short for the forward data flow), and publishes the standard data from our data-lake to many characteristic field centers through the micro service (short for the reverse data flow). So as to keep the data fresh by bidirectional data flow, and to achieve the optimal utilization rate. It effectively supports the data display and knowledge service of many characteristic field centers, and supports scientific researchers with convenience of utilizing knowledge resources in their professional field. At present, the bidirectional data flow mechanism has established friendly cooperation with more than 10 characteristic field centers, and has provided regular and continuous data flow services, the amount of data reached to 18 million.","","978-0-7381-0545-1","10.1109/CISP-BMEI51763.2020.9263496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9263496","data lake;bidirectional data flow;forward data flow;reverse data flow;micro service","Big Data;Distributed databases;Real-time systems;Standards organizations;Protocols;Patents;Organizations","","","","22","IEEE","25 Nov 2020","17-19 Oct. 2020","17-19 Oct. 2020","IEEE","IEEE Conferences"
"The Atlassian Data Lake: consolidating enriched software development data in a single, queryable system","A. Friedman; R. Dhupelia; B. Jackson","Atlassian, Sydney, Australia; Atlassian, Sydney, Australia; Atlassian, Sydney, Australia",2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR),"12 Jul 2023","2023","","","265","266","Software teams are under continuous pressure to work effectively and achieve a high bar of performance. The data contained within software development lifecycle tools presents the opportunity to obtain visibility into DevOps metrics [12] , Flow metrics [17] , and other signals that provide insights into team effectiveness [14] . Such tool-based data can complement other information sources, such as employee surveys, towards a comprehensive picture of organization and team health [13] . Moreover, managing work across multiple teams requires a high level of visibility into the work of those teams, to inform decisions on team velocity, resource allocation, and return on investment. Since much of the work is conducted in software development tools, they are an essential source for consolidating and presenting a clear picture of that work. As organizations strive to rip the benefits that location flexibility offers for employee outcomes [3] and shift to hybrid or remote work, the reliance on software development tools to obtain that level of visibility is likely to increase.","2574-3864","979-8-3503-1184-6","10.1109/MSR59073.2023.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174105","Data lake;CDC;Software Analytics","Measurement;Surveys;Organizations;Big Data applications;Software;Remote working;Resource management","","1","","22","IEEE","12 Jul 2023","15-16 May 2023","15-16 May 2023","IEEE","IEEE Conferences"
"AI Technologies Enhancement Using Data Catalog on Data Lake","S. Watanabe","Hitachi Ltd. Research & Development Division, Kokubunji-shi, Tokyo, Japan",2024 International Conference on AI x Data and Knowledge Engineering (AIxDKE),"16 May 2025","2024","","","104","107","Digital transformation (DX) is one of the major challenges for enterprises, which aims to improve their competitiveness by utilizing information technologies. Furthermore, several opportunities of DX have been provided by the remarkable advancement in artificial intelligence (AI) technologies. However, there remains essential difficulties in applying AI to field business, which are caused by the lack of domain knowledge (DK) specific to the enterprise. Data catalog (DC) is data management software employed on data lakes, which is designed to facilitate the utilization of data assets. DC provides data analysts with the enterprise-specific DK to find appropriate data for their analysis. Thus, the DK retained in DC can be beneficial for enhancing AI technologies. Under these considerations, we utilized DC for enhancing AI technologies. By employing the enterprise-specific DK in DC, the performance of AI can be improved with respect to the affinity to the enterprise. We developed two use cases of utilizing DC for enhancing AI technologies. These use cases demonstrate the advantages integrating AI and DC into a system for applying AI to field business, which has not been sufficiently investigated due to the subdivision of research areas.","2831-7203","979-8-3315-1704-5","10.1109/AIxDKE63520.2024.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990111","data lake;data catalog;domain knowledge;AI;artificial intelligence","Knowledge engineering;Digital transformation;Big Data applications;Software;Artificial intelligence;Information technology;Business","","","","25","IEEE","16 May 2025","11-13 Dec. 2024","11-13 Dec. 2024","IEEE","IEEE Conferences"
"Towards a Model-Driven Design Tool for Big Data Architectures","M. Guerriero; S. Tajfar; D. A. Tamburri; E. Di Nitto","Dipartimento di Elettronica, Politec. di Milano, Milano, Italy; Dipartimento di Elettronica, Politec. di Milano, Milano, Italy; Dipartimento di Elettronica, Politec. di Milano, Milano, Italy; Dipartimento di Elettronica, Politec. di Milano, Milano, Italy",2016 IEEE/ACM 2nd International Workshop on Big Data Software Engineering (BIGDSE),"16 Jan 2017","2016","","","37","43","Big Data technologies are rapidly becoming a key enabler for modern industries. However, the entry costs inherent to ``going Big"" are considerable, ranging from learning curve, renting/buying infrastructure, etc. A key component of these costs is the time spent on learning about and designing with the many big data frameworks (e.g., Spark, Storm, HadoopMR, etc.) on the market. To reduce said costs while decreasing time-to-market we advocate the usage of Model-Driven Engineering (MDE), i.e., software engineering by means of models and their automated manipulation. This paper outlines a tool architecture to support MDE for big data applications, illustrating with a case-study.","","978-1-4503-4152-3","10.1145/2896825.2896835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811385","Software Engineering;Big Data;Model-Driven Development","Computational modeling;Data models;Computer architecture;Big data applications;Sparks;Storms","","11","","17","","16 Jan 2017","16-16 May 2016","16-16 May 2016","IEEE","IEEE Conferences"
"A novel SDN-based IoT architecture for big data","M. T. Kakiz; E. Öztürk; T. Çavdar","Computer Engineering Karadeniz Technical University, Trabzon, Turkey; Computer Engineering Karadeniz Technical University, Trabzon, Turkey; Computer Engineering Karadeniz Technical University, Trabzon, Turkey",2017 International Artificial Intelligence and Data Processing Symposium (IDAP),"2 Nov 2017","2017","","","1","5","Although Internet of Things (IoT) is an evolving paradigm which allows everyday physical objects, devices and appliances to connect to the internet, and to communicate with each other, there are several essential challenges that should be addressed. One of them is big data generated by physical objects. It is quite challenging to manage and control such enormous amount of data. In this paper, we propose an IoT architecture originated from Software Defined Networking (SDN) to overcome big data problem. Instead of evaluating the sensor values in the application layer, we analyze them in lower layers, especially in gateway layer, before being sent to the internet. By the proposed architecture, to the best of our knowledge, big data problem is handled because only useful and helpful packets are sent to the internet.","","978-1-5386-1880-6","10.1109/IDAP.2017.8090186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8090186","IoT;internet of things;SDN;software defined networking;big data;architecture","Computer architecture;Logic gates;Big Data;Software defined networking;Actuators;Software;Hardware","","15","","12","IEEE","2 Nov 2017","16-17 Sept. 2017","16-17 Sept. 2017","IEEE","IEEE Conferences"
"Hybrid Data Lake Entities Localization Optimization Based on Complex Networks","E. M. Mendes; J. Rady De Almeida","Programa de Pós-Graduação em Engenharia Elétrica, Universidade de São Paulo, São Paulo, Brazil; Programa de Pós-Graduação em Engenharia Elétrica, Universidade de São Paulo, São Paulo, Brazil",IEEE Access,"28 Jan 2026","2026","14","","12744","12749","Data Lakes are a relevant analytics architecture, with current implementations in hybrid and multi-cloud environments presenting governance challenges in cost management and data localization. This work proposes the “Entity Migration Recommender System,” an engine that ingests Data Lake metadata to create optimized complex network digraphs with recommended entity localities. The tool demonstrated a 16.2% overall cost reduction by optimizing data entity placement across cloud and on-premise infrastructure. This method leverages complex network metrics to address the critical dimension of data interoperation costs in distributed analytics environments.","2169-3536","","10.1109/ACCESS.2026.3656719","Programa de Pós-graduação em Engenharia Elétrica da Universidade de São Paulo—Brazil (PPGEE), University of São Paulo (USP); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11359678","Cloud computing;complex networks;data analytics;data lakes","Cloud computing;Costs;Big Data applications;Complex networks;Metadata;Recommender systems;Standards organizations;Location awareness;Distributed databases;Sparks","","","","19","CCBY","21 Jan 2026","2026","","IEEE","IEEE Journals"
"An Iterative Methodology for Defining Big Data Analytics Architectures","R. Tardío; A. Maté; J. Trujillo","Stratebi Business Solutions Ltd., Madrid, Spain; University of Alicante, Lucentia Lab Ltd., Alicante, Spain; University of Alicante, Lucentia Lab Ltd., Alicante, Spain",IEEE Access,"2 Dec 2020","2020","8","","210597","210616","Thanks to the advances achieved in the last decade, the lack of adequate technologies to deal with Big Data characteristics such as Data Volume is no longer an issue. Instead, recent studies highlight that one of the main Big Data issues is the lack of expertise to select adequate technologies and build the correct Big Data architecture for the problem at hand. In order to tackle this problem, we present our methodology for the generation of Big Data pipelines based on several requirements derived from Big Data features that are critical for the selection of the most appropriate tools and techniques. Thus, thanks to our approach we reduce the required know-how to select and build Big Data architectures by providing a step-by-step methodology that leads Big Data architects into creating their Big Data Pipelines for the case at hand. Our methodology has been tested in two use cases.","2169-3536","","10.1109/ACCESS.2020.3039455","ECLIPSE project (RTI2018-094283-B-C32) from the Spanish Ministry of Science, Innovation and Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264179","Big data pipelines;business intelligence;data management;Hadoop;NoSQL","Big Data;Pipelines;Data models;Proposals;Computer architecture;Big Data applications;Tools","","14","","37","CCBY","19 Nov 2020","2020","","IEEE","IEEE Journals"
"Big Data Infrastructure for Agricultural Tomographic Images Reconstruction","G. M. Alves; P. E. Cruvinel","Federal University of São Carlos Computer Science Departament, São Carlos, SP, Brazil; Federal University of São Carlos Computer Science Departament, São Carlos, SP, Brazil",2018 IEEE 12th International Conference on Semantic Computing (ICSC),"12 Apr 2018","2018","","","346","351","A single agricultural soil sample obtained by a tomograph is composed of too many projections. In addition, considering that a sample is scanned at different angles a big set of projections is formed. Therefore, when using micro-resolution tomographic instruments, for a single soil sample it is necessary to deal with amounts of data in the order of gigabytes. On the other hand, the quantity of samples contributes to quality of information, for example, in the construction of maps to study agricultural soils. In general, in order to get improvements in the quality of soil analyzes it is required to increase exponentially the amount of the soil samples, i. e., increasing the amount of data to be reconstructed, which exceed the order of terabytes. This massive amount of data suggests new emerging methods and technologies. In this sense, Big Data has shown the great potential in optimizing data, making decisions, spotting business trends in various fields such agriculture. In this work, the infrastructure for the process of tomographic reconstruction of agricultural soil samples based on Big Data is presented. We introduced the Big Data architecture which uses the Hadoop framework. Additionally, we present the Filtered Back-Projection (FBP) algorithm adapted to the MapReduce model. The use of Big Data environment allows reconstructing a greatest number of agricultural soil tomographic images in the same time-frame and, consequently, it allows increasing the number of analysis contributing to improvement of quality of information about agricultural soils. Furthermore, the developed application has required both interpretation and language generation to allow the organization of knowledge, as well as the establishment of an adequate computational semantics for its operation.","","978-1-5386-4408-9","10.1109/ICSC.2018.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334494","big data;infrastructure;semantics in big data;agricultural tomograph;apache hadoop","Image reconstruction;Soil;Big Data;Attenuation;Computed tomography;Mathematical model","","5","","37","IEEE","12 Apr 2018","31 Jan.-2 Feb. 2018","31 Jan.-2 Feb. 2018","IEEE","IEEE Conferences"
"Research on Marketing and Data Analysis System Based on Computer Big Data","X. Wu",Macau University of Science and Technology,"2022 4th International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)","22 May 2023","2022","","","286","289","This paper establishes a set of enterprise marketing decision-making system based on computer big data calculation. According to the characteristics of marketing data collection and sorting, this paper proposes a mashup data architecture and a data application functional architecture. The author describes the overall functional structure of the system and the design and implementation of key processes such as the generation of marketing activities, the production of marketing activities, and the execution of marketing activities among the modules of the system. At the same time, it expounds the main functions and technical realization modes of the CRM shopping guide module, product unified management module, grid management module, marketing management module, production scheduling management module, and work division management module. This paper mines feature from the three dimensions of users, merchants, and the relationship between users and merchants in the marketing system. A total of 121 features are constructed from multiple perspectives under each dimension. In this paper, the improved Relief algorithm is used to select features with stronger discriminative ability for minority class samples and build a single model to predict the repeated purchase behavior of users. The experimental results show that after using the improved Relief algorithm to select features, the predicted effect of the model is better.","","979-8-3503-3394-7","10.1109/MLBDBI58171.2022.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10125444","computer;big data;marketing;user repeat purchase behavior;marketing analysis system","Computational modeling;Mashups;Decision making;Production;Computer architecture;Predictive models;Prediction algorithms","","","","8","IEEE","22 May 2023","28-30 Oct. 2022","28-30 Oct. 2022","IEEE","IEEE Conferences"
"Big Data Architecture for Automatic Transformation and Validation of Heterogeneous Geospatial Data Compliant with INSPIRE Directive","M. Negru; B. -C. Mocanu; C. Negru; I. Petre","Computer Science Dept., National University of Science and Technology POLITEHNICA, Bucharest, Romania; Computer Science Dept., National University of Science and Technology POLITEHNICA, Bucharest, Romania; Computer Science Dept., National University of Science and Technology POLITEHNICA, Bucharest, Romania; National Institute for Research Development in Informatics ICI, Bucharest, Romania",2025 24th RoEduNet Conference: Networking in Education and Research (RoEduNet),"30 Oct 2025","2025","","","1","6","Geospatial data playa fundamental role in decision-making processes within government entities, private sector organizations and in the context of natural resource management. The integration and harmonization of geospatial data from heterogeneous sources represents a significant challenge in the context of the implementation of the INSPIRE (Infrastructure for Spatial Information in Europe) Directive. The need for stan-dardization of geospatial data, both on a global scale and in the context of the INSPIRE Directive, is primarily driven by the need for interoperability, integration and efficient analysis of spatial information from different systems, formats and semantic structures. In this paper we propose a comprehensive and extensible architecture for the automatic transformation and harmonization of heterogeneous spatial data into INSPIRE-compliant formats, that ensures interoperability within the European infrastructure. Our solution is based on open-source technologies and tools and is validated using the official INPIRE Reference Validation tool.","2247-5443","979-8-3315-5713-3","10.1109/RoEduNet68395.2025.11208431","Ministry of Research, Innovation and Digitization(grant numbers:PN-IV-PCB-RO-MD-2024-0364); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11208431","INSPIRE Directive;Geospatial data;Big data;Data management","Standards organizations;Europe;Distributed databases;Big Data;Spatial databases;Stability analysis;Geospatial analysis;Time factors;Interoperability;Thermal stability","","","","22","IEEE","30 Oct 2025","17-20 Sept. 2025","17-20 Sept. 2025","IEEE","IEEE Conferences"
"Research on the Construction of Rural Talent Information Platform Under the Background of Big Data","P. Liu; X. Tan","Harbin University of Commerce, Harbin, Heilongjiang, China; Harbin University of Commerce, Harbin, Heilongjiang, China",2021 2nd International Conference on Big Data Economy and Information Management (BDEIM),"17 Feb 2022","2021","","","260","263","Based on the cloud platform of large data sharing technology to break the existing talent information service platform, to the household registration data, education statistics, social security service data and other related data sharing, structures, data architecture, the focus on talent chain, industry chain, information chain combination data sharing mechanism, to build a one-stop talent data analysis engine, In view of the problems existing in the construction of information platform, such as low informatization efficiency of talent resource allocation and unsuitable talent training platform mode, this paper improves the data center layer and application layer of the platform, aiming to provide reference for the digital development and specific practice of rural talent revitalization in China.","","978-1-6654-8288-2","10.1109/BDEIM55082.2021.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708926","Big data;Information platform construction;Talent revitalizing","Training;Industries;Cloud computing;Force;Information services;Big Data;Information management","","","","5","IEEE","17 Feb 2022","3-5 Dec. 2021","3-5 Dec. 2021","IEEE","IEEE Conferences"
"Guizhou Big Data Management System and Key Technology","S. Lin; B. Luo; J. Luo; Z. Wang; Y. Wei","Beijing Advanced Innovation Center for Future Internet Technology, Beijing, China; College of Software. Beijing University of Technologv. Beiiina, China; Surveying and Mapping Institute of Guizhou Province, China; Beijing Yuhe Spatiotemporal Information Systems, LLC, Beijing, China; Beijing Yuhe Spatiotemporal Information Systems, LLC, Beijing, China",2018 26th International Conference on Geoinformatics,"6 Dec 2018","2018","","","1","7","Big Data has been integrated into people's life in the past few years and providing abundant data and opportunities to improve and/or enable research and decision-support applications with unprecedented value for digital earth applications including business, sciences and engineering. Data is not just an asset. Big data can also serve as foundation for decision making. Taking Guizhou as an example, our study designs a spatio-temporal big data management system based on GIS bussing technique, and visualized the results, which aims to provide technical support for the transformation of Guizhou's tourism by scientific and effective measures.","2161-0258","978-1-5386-7619-6","10.1109/GEOINFORMATICS.2018.8557109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8557109","Big Data;Architecture;Data management","Industries;Earth;Government;Decision making;Big Data;Dynamic scheduling;Real-time systems;Information exchange;Business;Geographic information systems","","2","","13","IEEE","6 Dec 2018","28-30 June 2018","28-30 June 2018","IEEE","IEEE Conferences"
"A Big Data Architecture for Digital Twin Creation of Railway Signals Based on Synthetic Data","G. Salierno; L. Leonardi; G. Cabri","Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy; Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy; Department of Physics, Informatics and Mathematics, University of Modena and Reggio Emilia, Modena, Italy",IEEE Open Journal of Intelligent Transportation Systems,"18 Jul 2024","2024","5","","342","359","Industry 5.0 has introduced new possibilities for defining key features of the factories of the future. This trend has transformed traditional industrial production by exploiting Digital Twin (DT) models as virtual representations of physical manufacturing assets. In the railway industry, Digital Twin models offer significant benefits by enabling anticipation of developments in rail systems and subsystems, providing insight into the future performance of physical assets, and allowing testing and prototyping solutions prior to implementation. This paper presents our approach for creating a Digital Twin model in the railway domain. We particularly emphasize the critical role of Big Data in supporting decision-making for railway companies and the importance of data in creating virtual representations of physical objects in railway systems. Our results show that the Digital Twin model of railway switch points, based on synthetic data, accurately represents the behavior of physical railway switches in terms of data points.","2687-7813","","10.1109/OJITS.2024.3412820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554659","Big data;digital twin;machine learning;synthetic data;railway industry;artificial intelligence","Rail transportation;Switches;Digital twins;Big Data;Data models;Computer architecture;Synthetic data;Machine learning;Artificial intelligence;Computer architecture","","10","","30","CCBY","11 Jun 2024","2024","","IEEE","IEEE Journals"
"Integrating flight-related information into a (Big) data lake","M. A. Martínez-Prieto; A. Bregon; I. García-Miranda; P. C. Álvarez-Esteban; F. Díaz; D. Scarlatti","Departamento de Informática, Universidad de Valladolid, Valladolid, Spain; Departamento de Informática, Universidad de Valladolid, Valladolid, Spain; Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid, Valladolid, Spain; Instituto de Investigación en Matemáticas (IMUVA), Universidad de Valladolid, Valladolid, Spain; Departamento de Informática, Universidad de Valladolid, Valladolid, Spain; Boeing Research & Technology Europe, Madrid, Spain",2017 IEEE/AIAA 36th Digital Avionics Systems Conference (DASC),"9 Nov 2017","2017","","","1","10","Flight cancellations, departure delays, congestion in taxi times and airborne holding delays are increasingly frequent problems that negatively impact the performance, fuel burn, emissions rate and customer satisfaction at major airports in the world. However, this is just a brushstroke of the future to come. The dramatic growth in the air traffic levels has become a problem of paramount importance, leading into an increased interest for enhancing the current Air Traffic Management (ATM) systems. The main objective is to being able to cope with the sustained air traffic growth under safe, economic, efficient and environmental friendly working conditions. The ADS-B (Automatic Dependent Surveillance - Broadcast) technology plays a major role in the new ATM systems, since it provides more accurate real-time positioning information than secondary radars, in spite of using a cheaper infrastructure. However, the main flaw in the use of ADS-B technology is the generation of large volumes of data, that, when merged with other flight-related information, faces important scalability issues. In this work, we start off from a previously developed data lake for the support of the full ADS-B data life-cycle in a scalable and cost-effective way, and propose a data architecture to integrate data from different providers and reconstruct flight trajectories that can ultimately be used to improve the efficiency in flight operations. This data architecture is also evaluated using a 2-week testbed which reports some interesting figures about its effectiveness.","2155-7209","978-1-5386-0365-9","10.1109/DASC.2017.8102023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8102023","","Airports;Lakes;Surveillance;Trajectory;Aircraft;Big Data;Meteorology","","17","","16","IEEE","9 Nov 2017","17-21 Sept. 2017","17-21 Sept. 2017","IEEE","IEEE Conferences"
"Task Scheduling for Big Data Management in Fog Infrastructure","T. Islam; M. M. A. Hashem","Dept. of Computer Science and Engineering, Khulna University of Engineering and Technology, Khulna, Bangladesh; Dept. of Computer Science and Engineering, Khulna University of Engineering and Technology, Khulna, Bangladesh",2018 21st International Conference of Computer and Information Technology (ICCIT),"3 Feb 2019","2018","","","1","6","Fog computing is a modern research trend to carry cloud computing benefits to network edges. Edge data center (EDC) or fog devices are used to minimize the network congestion and latency by processing data flows and user demands in close real time. Edge data center (EDC) or fog devices are positioned between data sources or iot devices and cloud data center (CDC). Fog devices work as a semi-permanent storage and mainly provides location awareness. Moreover, for processing data in the EDC or fog devices, task scheduling is a vital issue because here generate a lots of data from IoT or sensor layer. In our proposed strategy, we have used EDC or fog infrastructure for providing real time services in latency sensitive applications. By using ford-fulkerson algorithm and priority based queue, we have done load balancing and task scheduling in fog devices or EDC based network fast processing these large amount of data or big data.","","978-1-5386-9242-4","10.1109/ICCITECHN.2018.8631959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8631959","Fog Computing;Edge data centers;Cloud Computing;Task Scheduling;Internet of Thing;Big Data;Latency Sensitive application","Task analysis;Edge computing;Real-time systems;Big Data;Computer architecture;Internet of Things;Cloud computing","","15","","24","IEEE","3 Feb 2019","21-23 Dec. 2018","21-23 Dec. 2018","IEEE","IEEE Conferences"
"Optimizing Data Lakes for High-Performance Analytics in Big Data Ecosystems","P. Vaghasiya; D. Patel",Mondrian Collection; Staten Island Performing Provider System,2024 Global Conference on Communications and Information Technologies (GCCIT),"6 Feb 2025","2024","","","1","7","This paper proposes an optimized framework for data lakes meant to enhance parameters like data rate, response time, and capacity in big data environments. Some common issues with traditional data lakes include issues of slow data access, and basic problem of scalability that becomes an issue as data sizes increase. These challenges are however countered by the proposed method through the use of distributed data structures of data, indexing quality, concurrent processing and in memory computing. The results obtained are 40% time saving in retrieving large data set and 50% improvement in query response time for heavy data. This in-memory processed system exhibited up to 60% gain in data throughput and achieved better scalability with shorter query response time as more parallel processing nodes were added. The evidences derived from the experiment clearly explain that the proposed method not only improves the performance but also offers cost efficient solution for the organizations those are dealing with big real time data analytics. Subsequent studies may involve the exploration of higher levels of machine learning to enhance the predictability of the analytical approaches used and optimal resource allocation to improved data lake underway in the cloud.","","979-8-3503-8891-6","10.1109/GCCIT63234.2024.10862088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10862088","Data Lakes;Big Data Ecosystems;High-Performance Analytics;Data Retrieval;Query Optimization;Distributed Indexing;Parallel Processing;Real-Time Analytics;Scalability;Storage Optimization","Costs;Scalability;Organizations;Parallel processing;Big Data applications;Throughput;Real-time systems;Time factors;Resource management;Optimization","","","","25","IEEE","6 Feb 2025","25-26 Oct. 2024","25-26 Oct. 2024","IEEE","IEEE Conferences"
"A Novel Big Data Assisted Analysis Architecture for Telecom Operator","Y. Zhang; X. Cheng; L. Xu; X. He; J. Guan; K. Chao; C. Song","Network Technology Research Institute, China Unicom Network Technology Research Institute, Beijing, China; Network Technology Research Institute, China Unicom Network Technology Research Institute, Beijing, China; Network Technology Research Institute, China Unicom Network Technology Research Institute, Beijing, China; Network Technology Research Institute, China Unicom Network Technology Research Institute, Beijing, China; Network Technology Research Institute, China Unicom Network Technology Research Institute, Beijing, China; Network Technology Research Institute, China Unicom Network Technology Research Institute, Beijing, China; Network Technology Research Institute, China Unicom Network Technology Research Institute, Beijing, China","2019 IEEE International Conferences on Ubiquitous Computing & Communications (IUCC) and Data Science and Computational Intelligence (DSCI) and Smart Computing, Networking and Services (SmartCNS)","6 Feb 2020","2019","","","611","615","Information technology development leads to the data explosion in many industries. In the era of big data, telecom operator stores huge amount of data, namely telecom big data. Telecom operator can employ data mining and analysis to seek the valuable information from telecom big data. In this paper, we design a novel big data assisted analysis architecture for telecom operator. The proposed architecture collects operation support system data and business support system data of telecom operator. Based on these data, the architecture draws the portrait of each user. Then, the user trajectory is analyzed. Furthermore, the proposed architecture takes the service behavior analysis. Finally, we apply the proposed big data assisted analysis architecture to the local telecom operator.","","978-1-7281-5209-7","10.1109/IUCC/DSCI/SmartCNS.2019.00128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982692","big data;architecture;service behavior","Industries;Computer architecture;Big Data;Data science;Explosions;Telecommunications;Trajectory;Data mining;Information technology;Computational intelligence","","54","","60","IEEE","6 Feb 2020","21-23 Oct. 2019","21-23 Oct. 2019","IEEE","IEEE Conferences"
"Information Storage and Retrieval System for a Molecular Dynamics Based Digital Twin of Materials","D. Topolsky; A. Belyakov; V. Pochinskaia; I. Topolskaya; N. Yumagulov; D. Fedorov","Dept. of Electronic Computing Machines, South Ural State University, Chelyabinsk, Russia; Dept. of Electronic Computing Machines, South Ural State University, Chelyabinsk, Russia; Dept. of Electronic Computing Machines, South Ural State University, Chelyabinsk, Russia; Dept. of Energy and Power Engineering, South Ural State University, Chelyabinsk, Russia; Dept. for Education in Physics and Mathematics Name of Organization, Nizhnevartovsk State University, Nizhnevartovsk, Russia; Dept. of Informatics and Computer Engineering, Surgut State University, Surgut, Russia","2022 IEEE International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON)","23 Jan 2023","2022","","","1760","1764","Digital twin technology becomes an appropriate respond to the new challenge of rapid development in science and industry. Chemical data include the information about structure and properties of materials and compounds. Machine learning technology can help to predict properties of innovative compounds and material, but it takes enormous amount of raw data. The implementation of digital twin technology in spectral and molecular dynamics helps to reduce risks introducing the innovations. Large systems technologies are used in multiscale modeling of materials with computer programs. The world experience of chemical data aggregation and storage is based on specialized databases creation. Disunity of data sources demands a single multiscale data model to operate raw data and amend the accuracy of prediction. To collect and analyze unstructured data full-text search and distributed computing were applied. In respond to perpetual raw data expansion a Data Lake technology is used to store, analyze and search for information of atomic and molecular systems.","","978-1-6654-6480-2","10.1109/SIBIRCON56155.2022.10017100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017100","digital twin;multiscale modeling;Data Lake;full-text search;big data;distributed computing","Technological innovation;Systematics;Computational modeling;Biological system modeling;Soft sensors;Big Data applications;Data models","","2","","25","IEEE","23 Jan 2023","11-13 Nov. 2022","11-13 Nov. 2022","IEEE","IEEE Conferences"
"A Maritime Big Data Framework Integration in a Common Information Sharing Environment","Z. Paladin; N. Kapidani; Ž. Lukšić; T. Nicoletti; M. Moutzouris; A. Blum; A. Astyakopoulos","Administration for Maritime Safety and Port Management, Bar, Montenegro; Administration for Maritime Safety and Port Management, Bar, Montenegro; Administration for Maritime Safety and Port Management, Bar, Montenegro; Engineering I.I., S.p.A., ENG, Milano, Italy; SATWAYS Ltd., Athens, Greece; Secrétariat général de la mer - SGMER, Paris, France; Center for Security Studies, Ministry of Citizen Protection, Athens, Greece","2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)","27 Jun 2022","2022","","","1161","1166","Ensuring a high level of vessel traffic surveillance and maritime safety is determined by exploiting innovative ICT technologies and international cooperation among maritime authorities. Therefore, initiatives for maritime surveillance, global and regional integrations are realised through a collaborative, cost-effective and interoperable Common Information Sharing Environment (CISE). Consisting of the institutional network of maritime authorities that cooperate on various domains like safety, border control, environmental and rescue missions at sea, CISE enables the efficient transfer and economic exchange of maritime data and information via different interoperable systems using modern digital technologies. The ever-increasing amount of data received from heterogeneous data sources requires specific processing through the adoption of a Big Data framework which hosts, manages and distributes data to maritime users, contributing with great overall benefits to the CISE network core functionality. Specifically, this paper analyses the advantages of the Data Lake infrastructure, including its processes, techniques, tools and applications used to enhance maritime surveillance and safety across the CISE network. This part contains the deployment and interoperability achieved through the components of the participating command and control (C2) systems. Last, as a case study, an overview of the EU project EFFECTOR is provided which aims to demonstrate an end-to-end interoperability framework of data-driven solutions for maritime situational awareness at strategic and tactical operations.","2623-8764","978-953-233-103-5","10.23919/MIPRO55190.2022.9803777","Research Executive Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9803777","Big Data;CISE;Data Lake;maritime safety","Economics;Command and control systems;Surveillance;Collaboration;Information sharing;Traffic control;Big Data applications","","6","","22","","27 Jun 2022","23-27 May 2022","23-27 May 2022","IEEE","IEEE Conferences"
"Building a Data Lake for Power BI in the Cloud: A Review on Utilizing Cloud Storage Services for Large Datasets","V. V. Gurbade; P. Verma; S. Gundewar; V. S. Bramhe","Department of Artificial Intelligence and Data Science, Faculty of Engineering and Technology, Datta Meghe Institute of Higher Education & Research (DU), Wardha, Maharashtra, India; Department of Artificial Intelligence and Machine Learning, Faculty of Engineering and Technology, Datta Meghe Institute of Higher Education & Research (DU), Wardha, Maharashtra, India; Department of Artificial Intelligence and Machine Learning, Faculty of Engineering and Technology, Datta Meghe Institute of Higher Education & Research (DU), Wardha, Maharashtra, India; School of Computing Science and Engineering, VIT Bhopal University, Sehore, Madhya Pradesh, India","2024 2nd DMIHER International Conference on Artificial Intelligence in Healthcare, Education and Industry (IDICAIEI)","20 Jan 2025","2024","","","1","6","A data lake is a centralized repository where you may store both structured and unstructured data at any scale. Unlike typical data warehouses, which need data structure for storage, data lakes allow you to store raw data in its natural state. This adaptability makes data lakes suitable for storing large volumes of various data kinds, including photographs, videos, log files, sensor data, and others. When integrating a data lake with Power Business Intelligence (BI), organizations can harness the power of both technologies to gain valuable insights from their data. In the realm of data-driven decision-making, organizations face the challenge of managing and extracting insights from vast and diverse datasets, a task conventional on-premises storage solutions often struggle with due to the exponential growth of data. Thus, the adoption of more scalable and flexible alternatives becomes imperative. Cloud-based data lakes emerge as transformative solutions, offering unparalleled scalability, accessibility, cost-effectiveness, and advanced security protocols. This paper discuss the concept of constructing a cloud-based data lake optimized for Power BI, leveraging leading cloud storage services like Azure Data Lake Storage (ADLS) and Amazon S3. By seamlessly integrating Power BI with the cloud data lake, organizations can overcome traditional storage limitations and reap numerous benefits. The practical applications in advanced analytics, customer insights, IoT data management, and data discovery underscore the real-world utility of cloud data lakes. The integration of Power BI with a cloud data lake augments efficient data analysis and self-service analytics potential, offering organizations a comprehensive solution for deriving actionable insights from their data assets.","","979-8-3315-2871-3","10.1109/IDICAIEI61867.2024.10842802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10842802","Data Lake;Cloud storage;Power BI;Cloud data integration;Data flows","Cloud computing;Scalability;Decision making;Buildings;Organizations;Big Data applications;Security;Data mining;Business intelligence;Self-service","","","","15","IEEE","20 Jan 2025","29-30 Nov. 2024","29-30 Nov. 2024","IEEE","IEEE Conferences"
"An OPC UA-based industrial Big Data architecture","E. Hirsch; S. Hoher; S. Huber","JR Centre for Intelligent and Secure Industrial Automation, Salzburg University of Applied Sciences, Puch, Austria; JR Centre for Intelligent and Secure Industrial Automation, Salzburg University of Applied Sciences, Puch, Austria; JR Centre for Intelligent and Secure Industrial Automation, Salzburg University of Applied Sciences, Puch, Austria",2023 IEEE 21st International Conference on Industrial Informatics (INDIN),"22 Aug 2023","2023","","","1","7","Industry 4.0 factories are complex and data-driven. Data is yielded from many sources, including sensors, PLCs, and other devices, but also from IT, like ERP or CRM systems. We ask how to collect and process this data in a way, such that it includes metadata and can be used for industrial analytics or to derive intelligent support systems. This paper describes a new, query model based approach, which uses a big data architecture to capture data from various sources using OPC UA as a foundation. It buffers and preprocesses the information for the purpose of harmonizing and providing a holistic state space of a factory, as well as mappings to the current state of a production site. That information can be made available to multiple processing sinks, decoupled from the data sources, which enables them to work with the information without interfering with devices of the production, disturbing the network devices they are working in, or influencing the production process negatively. Metadata and connected semantic information is kept throughout the process, allowing to feed algorithms with meaningful data, so that it can be accessed in its entirety to perform time series analysis, machine learning or similar evaluations as well as replaying the data from the buffer for repeatable simulations.","2378-363X","978-1-6654-9313-0","10.1109/INDIN51400.2023.10217899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10217899","OPC UA;query model;IT/OT integration;information model;data retrieval;device decoupling;big data","Performance evaluation;Machine learning algorithms;Soft sensors;Time series analysis;Semantics;Machine learning;Metadata","","9","","29","IEEE","22 Aug 2023","18-20 July 2023","18-20 July 2023","IEEE","IEEE Conferences"
"Inferencing Big Data with Artificial Intelligence & Machine Learning Models in Metaverse","G. Siwach; A. Haridas; D. Bunch","Distinguished Data Scientist IBM, Southbury, US; Site Reliability Engineer, IBM, Hyderabad, India; Infrastructure Specialist, IBM, Costa Mesa, US","2022 International Conference on Smart Applications, Communications and Networking (SmartNets)","3 Jan 2023","2022","","","01","06","This quantitaive study provides different methods of visualization for processing Big Data sets in augmented and virtual reality. The goal is to provide the detailed implementation of the statistical methods and modeling techniques i.e. using machine learning algorithms and artificial intelligence. The Statistical analysis is performed on the Big Data sets in Metaverse, that points towards real time inferencing infrastructure and techniques. Also, This paper elaborates the importance of pervasive and Ubiquitous Computing Architecture and Applications that enable High-end computing on Big Data sets. In this paper, we evaluate the need for a combination of cognitive mechanism and high-end infrastructure to address the performance, latency, and security issues when working on Big Data sets in environments like virtual or Augmented reality. Despite the modernization and advancement in technology there are increasing number of breaches in cloud and hybrid infrastructures, this justifies the need to meet the requirements of strengthening security, safeguard mechanisms and privacy. This paper discusses methods beyond basic visualizations through a deep dive exploration on improvising the applications of existing analytical methods, and use of advanced exploratory tools and visualization techniques on the next generation platforms.","","978-1-6654-8758-0","10.1109/SmartNets55823.2022.9994013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9994013","Big Data;Architecture;Security;Augmented Reality (AR);Virtual Reality (VR);Data Science;Machine Learning;Metaverse","Performance evaluation;Solid modeling;Metaverse;Statistical analysis;Data visualization;Machine learning;Big Data","","8","","13","IEEE","3 Jan 2023","29 Nov.-1 Dec. 2022","29 Nov.-1 Dec. 2022","IEEE","IEEE Conferences"
"6. Big data security issues with challenges and solutions","S. Koley",NA,Big Data Security,"","2019","","","95","142","Big data is a collection of huge sets of data with different categories where it could be distinguished as structured and unstructured data. As we are revolutionizing to zeta bytes from Giga/tera/peta/exabytes in this phase of computing, the threats have also increased in parallel. Besides big organizations, cost reduction is the criterion for the use of small- and medium-sized organizations too, thereby increasing the security threat. Checking of the streaming data once is not the solution as security breaches cannot be understood. The data stack up within the clouds is not the only preference as big data technology is available for dispensation of both structured and unstructured data. Nowadays, an enormous quantity of data is provoked by mobile phones (smartphone) or equally the symphony form. Big data architecture is comprehended among the mobile cloud designed for supreme consumption. The best ever implementation is able to be conked out realistically to make use of a novel data-centric architecture of MapReduce technology, while Hadoop distributed file system also acts with immense liability in using data with divergent arrangement. As time approaches, the level of information and data engendered from different sources enhanced and faster execution is the claim for the same. In this chapter our aim is to find out big data security that is vulnerable and also to find out the best possible solutions for them. We consider that this attempt will dislodge a stride forward along the way to an improved evolution in secure propinquity to opportunity","","9783110605969","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10788800.pdf&bkn=10783458&pdfType=chapter","","Cloud computing;Security;Big Data;Internet;Encryption;Servers;Software as a service;Service-oriented architecture;File systems;Data processing","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"Big data management and processing in the context of the system wide information management","A. F. Leite; L. Weigang; J. A. Fregnani; I. R. de Oliveira","Department of Computer Science, University of Brasília, Brazil; Department of Computer Science, University of Brasília, Brazil; Boeing Research & Technology, Brazil; Boeing Research & Technology, Brazil",2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC),"15 Mar 2018","2017","","","1","8","The 4D trajectory management program will require a major shift in infrastructure and operational management processes to deliver accurate and reliable information to trajectory management team. As a result, air traffic management operation will demand Network Enabled Operations (NEO) concepts such as the System Wide Information Management (SWIM) framework to ensure that the decisions are made with the correction information at the right time. SWIM provides standards, infrastructure, and governance practices to allow information exchanging through interoperable services. Consequently, SWIM must provide methods to (a) integrate a large variety of data; (b) filter information in a way that only the relevant ones are retained to explain the results; (c) enable National Airspace System (NAS) operators, pilots, controllers, and traffic flow specialists to extract value of air traffic systems in real-time; and (d) to seek and explore complex and evolving data's relationships. However, SWIM still lacks support to deal with big data analytics and to aggregate computing resources on-demand. As the main contribution of this paper, we describe the challenges and new focuses of SWIM researches. Likewise, we present an architecture to enable big data analytics services in SWIM. The proposed architecture relies on big data processing frameworks to handle data acquisition and data filtering on near-real time taking into account users' objectives; and to guarantee that the data go through all the gives stage of the life cycle of ATM applications, avoiding the silos that may happen in each data analysis stage.","2153-0017","978-1-5386-1526-3","10.1109/ITSC.2017.8317715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8317715","System Wide Information Management;Big Data Analytics;Big Data Architecture Management;Air Traffic Management","Service-oriented architecture;Big Data;Standards;Computer architecture;Encryption","","3","","33","IEEE","15 Mar 2018","16-19 Oct. 2017","16-19 Oct. 2017","IEEE","IEEE Conferences"
"Proposed Metadata Management Model for Data Lakehouse","P. Rain; A. Cravero","Departamento de Ciencias de la Computación e Informática, Universidad de La Frontera, Temuco, Chile; Departamento de Ciencias de la Computación e Informática, Universidad de La Frontera, Temuco, Chile",2024 43rd International Conference of the Chilean Computer Science Society (SCCC),"3 Dec 2024","2024","","","1","8","The exponential growth in the amount and diversity of data organizations generate has presented significant challenges in data storage, processing, and management. Data Lakehouses, a hybrid solution that combines the capabilities of Data Warehouses and Data Lakes, have been developed to address these challenges. However, metadata management in these environments is crucial to prevent data from becoming inaccessible and unwieldy. We propose a metadata management model for a Data Lakehouse based on a functional architecture that integrates functional metadata features for a Data Lake with business and maintenance metadata for a Data Warehouse. We include the results of an initial implementation and discuss its impact on data accessibility and governance.","2691-0632","979-8-3315-2789-1","10.1109/SCCC63879.2024.10767658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10767658","data lakehouse;metadata;management model","Computer science;Computational modeling;Memory;Organizations;Computer architecture;Metadata;Data warehouses;Big Data applications;Maintenance","","","","0","IEEE","3 Dec 2024","28-30 Oct. 2024","28-30 Oct. 2024","IEEE","IEEE Conferences"
"Research on the Design Scheme Construction of Industrial Big Data Platform Based on Enterprise Portrait","X. Yu; C. Wang","School of Management, Guangdong University of Science and Technology, Dongguan, China; Wuhan University of Engineering Science, Wuhan, China","2023 International Conference on Intelligent Computing, Communication & Convergence (ICI3C)","28 Oct 2024","2023","","","30","34","The complexity and numerous influencing factors of the industrial chain make precise monitoring, optimized control, and scientific management extremely difficult. However, utilizing big data technology to achieve full factor correlation analysis of industries is an effective way to support the modernization development of industries in the future. On the basis of analyzing the current situation of industrial big data applications, this article elaborates on the functions and objectives of the industrial big data platform, and constructs the overall architecture of the platform from four aspects: technical architecture, data architecture, application architecture, and physical architecture. At the same time, this article also analyzes the two key technologies involved in the platform, and combines machine learning related algorithms to profile enterprises, multi-dimensional mining of enterprise information for data display services. By building this platform, precise industrial management based on big data can be achieved, more scientific and objective industrial guidance policies can be formulated, supporting industrial management decisions, and providing valuable references for industrial informatization and intelligent transformation and upgrading.","","979-8-3503-4392-2","10.1109/ICI3C60830.2023.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10731644","industry;big data;data services;service platform;corporate holographic portrait","Correlation;Machine learning algorithms;Architecture;Biological system modeling;Machine learning;Big Data;Data processing;Data models;Data mining;Monitoring","","","","17","IEEE","28 Oct 2024","16-17 Dec. 2023","16-17 Dec. 2023","IEEE","IEEE Conferences"
"Survey of Big Data Architectures and Frameworks on Kubernetes: Challenges, Solutions, and Future Directions","P. Josyula; A. Kumar; G. Hiremath","Staff Salesforce, San Francisco, USA; Staff Salesforce, San Francisco, USA; Salesforce, Dallas, USA",2025 10th International Conference on Big Data Analytics (ICBDA),"4 Nov 2025","2025","","","1","8","The convergence of big data processing frameworks and container orchestration platforms, particularly, Kubernetes, represents a new path for modern data infrastructure. This comprehensive survey examines the evolving landscape of Big Data deployments in Kubernetes, analyzing traditional frameworks refactored for containerized environments with new native ones under development. We investigate significant challenges in stateful storage management, scheduling of resources, and performance optimization. Through systematic analysis of current approaches and architectures, we identify patterns, best practices, and areas requiring further research work. According to our observations, though, Kubernetes offers compelling advantages for Big Data workloads, several technical challenges remain in achieving optimal performance and reliability.","2832-3734","979-8-3315-0393-2","10.1109/ICBDA65366.2025.11211300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11211300","Big Data;Kubernetes;Container Orchestration;Distributed Computing;Cloud Native;Data Processing;Resource Management;Containerization","Surveys;Systematics;Storage management;Computer architecture;Big Data;Containers;Security;Resource management;Reliability;Optimization","","","","34","IEEE","4 Nov 2025","13-15 March 2025","13-15 March 2025","IEEE","IEEE Conferences"
"Big Data Architecture for Network Security","B. Bansal; V. N. Jenipher; R. Jain; R. Dilip; M. Kumbhkar; S. Pramanik; S. Roy; A. Gupta","Dept. of Computer Science and Engineering, Vaish College of Engineering, Rohtak, Haryana, India; Dept. of Computer Science and Engineering, St. Joseph's Institute of Technology, Semmancheri, Chennai, Tamil Nadu, India; Dept. of Electrical and Computer Engineering, Wollega University, Nekemte, Ethiopia; Dept. of Electrical and Electronics Engineering, Global Academy of Technology, Bengaluru, India; Dept. of Computer Science, Christian Eminent College, Indore, Madhya Pradesh, India; Dept. of Computer Science and Engineering, Haldia Institute of Technology, Haldia, West Bengal, India; Dept. of Computational Science, Brainware University, Kolkata, India; Dept. of Computer Science and Engineering, Vaish College of Engineering, Rohtak, Haryana, India",Cyber Security and Network Security,"","2022","","","233","267","Research is considering security of big data and retaining the performance during its transmission over network. It has been observed that there have been several researches that have considered the concept of big data. Moreover, a lot of those researches also provided security against data but failed to retain the performance. Use of several encryption mechanisms such as RSA [43] and AES [44] has been used in previous researches. But, if these encryption mechanisms are applied, then the performance of network system gets degraded. In order to resolve those issues, the proposed work is making using of compression mechanism to reduce the size before implementing encryption. Moreover, data is spitted in order to make the transmission more reliable. After splitting the data contents data has been transferred from multiple route. If some hackers opt to capture that data in unauthentic manner, then they would be unable to get complete and meaning full information. Thus, the proposed model has improved the security of big data in network environment by integration of compression and splitting mechanism with big data encryption. Moreover, the use of user‐defined port and use of multiple paths during transmission of big data in split manner increases the reliability and security of big data over network environment.","","9781119812548","10.1002/9781119812555.ch11","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9823023.pdf&bkn=9820921&pdfType=chapter","","Big Data;Network security;Data visualization;Encryption;Computer science;Memory;Computer crime","","26","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Intelligence Analysis of Crime of Helping Cybercrime Delinquency Based on Knowledge Ggraph","Q. Qi; G. Chen; F. Ye; Z. Lin; Q. Liu","Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China","2022 IEEE 5th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","26 Jan 2023","2022","5","","690","695","This paper studies the crime of helping cybercrime delinquency (CHCD) from two aspects: theoretical literature research and case empirical research. First of all, clarify the basic concept, development trend and case characteristics of the crime of facilitation, and make a comprehensive exposition of the crime of facilitation. Secondly, the basic situation analysis, co-word analysis, and keyword clustering of the theoretical research literature on the CHCD in the literature database in recent years are carried out, so as to obtain the research hotspots and evolution process of the CHCD, and analyze the research in the form of knowledge graph. Then, through the analysis and research of the crime cases, the relevant data and information are extracted from the judgment documents, and the regional differences of the crime, the characteristics of the criminal subject, the characteristics of the criminal behavior, and the judicial sentencing are comprehensively sorted out to provide information for the follow-up intelligence research and judgment support.","2693-2776","978-1-6654-7968-4","10.1109/IMCEC55388.2022.10019848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10019848","knowledge graph;crime of helping cybercrime delinquency;network security;literature analysis","Automation;Databases;Market research;Information management;Behavioral sciences;Data mining;Computer crime","","1","","11","IEEE","26 Jan 2023","16-18 Dec. 2022","16-18 Dec. 2022","IEEE","IEEE Conferences"
"LLM-Based Text-to-SQL for SparkSQL Queries in Manufacturing Data Lakes: An Architecture for Industry 4.0","C. E. Caldeira; A. R. Kretzer; F. Siqueira; A. R. De Mello","CERTI Foundation, Florianópolis, Brazil; CERTI Foundation, Florianópolis, Brazil; Federal University of Santa Catarina (UFSC), Florianópolis, Brazil; CERTI Foundation, Florianópolis, Brazil",2025 12th International Conference on Soft Computing & Machine Intelligence (ISCMI),"30 Jan 2026","2025","","","300","304","The transition to Industry 4.0 has significantly increased the volume and complexity of manufacturing data, creating a barrier for domain experts without deep technical knowledge. To address this challenge, this paper proposes a flexible, on-premises-first architecture that integrates Small or Large Language Models (S/LLMs), agents, and SparkSQL to enable semantic querying of manufacturing data lakes. The architecture features a multi-agent pipeline for schema analysis, table selection, prompt enrichment, and execution-based query refinement, supported by on-premises components for storage, processing (Apache Spark), and orchestration. This design ensures data privacy and low-latency operation. A service-based backend exposes schema and execution endpoints to the agents, and a web interface allows users to interact with the system. The architecture’s capabilities were validated using a custom dataset of natural language queries in Portuguese, demonstrating Executability Rate (ER) of 100%, with Precision of 62.44% and Recall scores of 56,34% in the test set benchmark when using LLM. This result confirms the viability of the multi-agent design, setting a clear performance target for future on-premises models and opening pathways for more human-centric data access in smart manufacturing systems.","2640-0146","979-8-3315-8691-1","10.1109/ISCMI67495.2025.11358579","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11358579","Industry 4.0;Text-to-SQL;SparkSQL;Large Language Models;Data Lake;Big Data","Data privacy;Large language models;Semantics;Pipelines;Natural languages;Big Data applications;Fourth Industrial Revolution;Low latency communication;Machine intelligence;Smart manufacturing","","","","16","IEEE","30 Jan 2026","21-23 Nov. 2025","21-23 Nov. 2025","IEEE","IEEE Conferences"
"Big Data, a Big Thing for Higher Education","A. Z. Bhat; M. Dhibi; I. Ahmed; M. S. Khan","Department of Computing, Middle East College, Muscat, Oman; Deans Office, Middle East College, Muscat, Oman; Department of Computing, Middle East College, Muscat, Oman; Department of Computing, Middle East College, Muscat","2022 10th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","8 Dec 2022","2022","","","1","6","This research paper exhibits the architecture of Big Data implementation in higher education sector with several components that are responsible for providing various features and services to the stakeholders of higher education. Big Data implementation can yield enormous benefits to students, teachers and at the same time can also significantly help higher education management to plan, preempt and predict several aspects that can result in a timely availability of resources and infrastructure. This research study exhibits an architecture with appropriate components that would yield several benefits to higher education institutions if implemented in appropriate manner. The research study proposes and explains different components of the architecture and provides details about how this implementation would yield benefits for different stakeholders. The components of the architecture are thoughtfully placed and designed considering variety of requirements of different stakeholders in a higher education establishment. The architecture proposes a separate component for enhancing teaching and learning, a separate component that would be responsible for assisting and supporting academic faculty and an entirely different component providing critical inputs to administration and management of higher education establishments. This research study is a mere effort to enhance the higher education in variety of aspects and provide advanced features to different stakeholders of higher education.","","978-1-6654-7433-7","10.1109/ICRITO56286.2022.9964829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964829","Big Data in higher education;Technology-assisted learning;EduNatics;Big Data architecture for higher education","Costs;Education;Big Data;Market research;Data models;Complexity theory;Stakeholders","","","","31","IEEE","8 Dec 2022","13-14 Oct. 2022","13-14 Oct. 2022","IEEE","IEEE Conferences"
"A Model for the Analytical Performance of Data Lake in Stock Market Analysis with Databricks Delta Lake","S. Kamalakkannan; A. Yasmin; A. R; P. Kavitha","Department of Information Technology, School of Computing Sciences, Vels Institute of Science, Technology & Advanced Studies, Pallavaram, Chennai, India; Department of Computer Science, JBAS College for women, Chennai, India; Faculty of Computing, Engineering and Science, University of South Wales, Treforest/Newport Campus, United Kingdom; Department of Computer Applications, School of Computing Sciences, Vels Institute of Science, Technology & Advanced Studies, Pallavaram, Chennai, India",2023 International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS),"6 Dec 2023","2023","","","1065","1071","Stock market investments are highly rewarding but also high in risk. Modern investors use variety of tools to take informed investment decisions. In the current era of digital world, financial service industry has generated huge volume and immense verities of data with extreme speed. Due to the rapid growth in data collection and the heterogeneous nature and complexity of the data, there is a need for Big Data analytical solution that would be able to deal with the stock market data. Large volumes of unstructured, heterogeneous raw data can be stored in a massively scalable manner using data lakes, which are the ideal solution to the big data storage conundrum. The ability of a data lake to preserve data in its original format while processing it at runtime using a schema on-read technique is its key feature. The challenge faced in the data lake is performing analytics which is a significant tool to calculate and analyze the stock market. The proposed architecture of Azure Databricks DeltaLake (ADDL) with Azure DataLake Storage Generation 2 (ADLSG2) is used for analytical processes like Fibonacci retracement for better stock analysis, which aid in forecasting the market price for better investment. As a result, the research focus is to produce a storage having read as well as write capabilities by taking into consideration the Extract-Load-Transform (ELT) operation on the datasource. In this experimental databricks implementation, runtime is performed using open source of Apache Spark API and a highly improved execution engine, which results in a significant performance improvement when comparing to the standard source of Apache Spark available on the ADLS platform. Additionally, the Fibonacci retracement level calculation is achieved with the analytics and forecasting of test close price with various ML and DL techniques such as KNN, LSTM are compared with original price of the test data for better prediction of forecast close price.","","979-8-3503-0085-7","10.1109/ICSSAS57918.2023.10331900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10331900","Big data analytics;ADLSG2;Databricks Delta Lake;ELT;stock market;Fibonacci retracement;LSTM;Apache spark","Cloud computing;Runtime;Costs;Cluster computing;Lakes;Writing;Big Data applications","","1","","22","IEEE","6 Dec 2023","18-20 Oct. 2023","18-20 Oct. 2023","IEEE","IEEE Conferences"
"Big Data Platform for Educational Analytics","A. A. Munshi; A. Alhindi","Department of Computer Engineering, Umm Al-Qura University, Makkah, Saudi Arabia; Department of Computer Science, Umm Al-Qura University, Makkah, Saudi Arabia",IEEE Access,"8 Apr 2021","2021","9","","52883","52890","Huge amounts of educational data are being produced, and a common challenge that many educational organizations confront, is finding an effective method to harness and analyze this data for continuously delivering enhanced education. Nowadays, the educational data is evolving and has become large in volume, wide in variety and high in velocity. This produced data needs to be handled in an efficient manner to extract value and make informed decisions. For that, this paper confronts such data as a big data challenge and presents a comprehensive platform tailored to perform educational big data analytical applications. Further, present an effective environment for non-data scientists and people in the educational sector to apply their demanding educational big data applications. The implementation stages of the educational big data platform on a cloud computing platform and the organization of educational data in a data lake architecture are highlighted. Furthermore, two analytical applications are performed to test the feasibility of the presented platform in discovering knowledge that potentially promotes the educational institutions.","2169-3536","","10.1109/ACCESS.2021.3070737","Deanship of Scientific Research at Umm Al-Qura University(grant numbers:19-COM-1-01-0017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393907","Artificial intelligence in education;education;educational big data;educational data mining","Big Data;Lakes;Education;Organizations;Data mining;Data analysis;Production","","31","","31","CCBY","2 Apr 2021","2021","","IEEE","IEEE Journals"
"Big Data Architectures in a patient-driven healthcare system: Implications, Scrutiny and Analysis for future prospects","K. A. Memon; I. Memon; F. Kumbhar; A. B. Bala; N. Iqbal; K. K. Qureshi","Center for Communication Systems and Sensing, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Department of Computer Science, Shah Abdul Latif University, Pakistan; Center for Communication Systems and Sensing, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Center for Communication Systems and Sensing, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Electrical Engineering Department and Center for Communication Systems and Sensing, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Electrical Engineering Department and Center for Communication Systems and Sensing, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia",2024 1st International Conference on Innovative Engineering Sciences and Technological Research (ICIESTR),"19 Dec 2024","2024","","","1","6","The term ""big data"" describes a significant amount of valuable information. Additionally, a sizable amount of big data related to public health comes from biological research. It is necessary to manage and analyse this data with care to get accurate information. There are several problems with every step of large data management that can only be fixed with sophisticated big data computing solutions. This is the reason health professionals need to be fully equipped with the tools necessary to efficiently collect and analyse big data to deliver appropriate solutions to promote public health. By creating new opportunities for contemporary health, proper big data management, analysis, and interpretation may completely transform the game. For this reason, several industries, including the health industry, are moving quickly to seize this chance to provide improved services and financial gains. Modern healthcare organizations have the potential to transform medical and personal medicine via the effective integration of big data and healthcare services. This article outlines many analytical paths that the patient-driven healthcare system might take, as seen from the viewpoints of different players. We have also examined several big data architectures in terms of their analytical influence, application fields, and underlying data sources and challenges in collecting the big data for healthcare systems.","","979-8-3503-4863-7","10.1109/ICIESTR60916.2024.10798299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10798299","Big Data Analytics;Healthcare system;bioinformatics tools;ML;AI;IoT","Industries;Soft sensors;Medical services;Transforms;Computer architecture;Big Data;Supercomputers;Stakeholders;Public healthcare;Biomedical imaging","","","","37","IEEE","19 Dec 2024","14-15 May 2024","14-15 May 2024","IEEE","IEEE Conferences"
"Research and Application of key Technologies of big data Management platform in Intelligent Power Plant","W. Shaohua; Z. Jian; C. Yanxi; D. Hao; F. Yuwei; H. Yaorong","POWERCHINA Guizhou Electric Power Engineering Co., Ltd., Guiyang, China; POWERCHINA Guizhou Electric Power Engineering Co., Ltd., Guiyang, China; POWERCHINA Guizhou Electric Power Engineering Co., Ltd., Guiyang, China; POWERCHINA Guizhou Electric Power Engineering Co., Ltd., Guiyang, China; POWERCHINA Guizhou Electric Power Engineering Co., Ltd., Guiyang, China; POWERCHINA Guizhou Electric Power Engineering Co., Ltd., Guiyang, China","2024 IEEE 6th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","2 Jul 2024","2024","6","","406","410","The progress of science and technology has made the conventional structure of power plant digital systems insufficient for intelligent production and management. Therefore, it is essential to establish an intelligent power plant management platform based on big data. This paper proposes an intelligent power plant management platform based on big data architecture that addresses the issue of outdated technology. In our study of the big data algorithm IGASA-FCM, we implemented adaptive jump probability instead of random probability to adjust the population. This adjustment benefits the algorithm's operation by producing optimal results and significantly improving the accuracy of historical working condition data division.","2693-2776","979-8-3503-1653-7","10.1109/IMCEC59810.2024.10575525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10575525","Smart Power Plant;Big Data;Data Analysis;Clustering algorithm","Employee welfare;Technological innovation;Heuristic algorithms;Sociology;Production;Big Data;Partitioning algorithms","","","","8","IEEE","2 Jul 2024","24-26 May 2024","24-26 May 2024","IEEE","IEEE Conferences"
"Research on Automation System of IoT Data Access Architecture for Power Transmission and Transformation Big Data Platform","Z. Liang; C. Yao; Y. Wang; W. Shen; J. Zhang","Guangdong Power Grid Co., Ltd., Guangzhou, Guangdong, China; Guangdong Power Grid Co., Ltd., Guangzhou, Guangdong, China; Guangdong Power Grid Co., Ltd., Guangzhou, Guangdong, China; Guangdong Power Grid Co., Ltd., Guangzhou, Guangdong, China; Guangdong Power Grid Co., Ltd., Guangzhou, Guangdong, China",2024 4th Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS),"13 Aug 2024","2024","","","483","487","This paper presents a secure terminal architecture for power system big data. This paper analyzes the structure of the system in detail from three aspects: user layer, big data analysis layer and terminal collection layer. The architecture of information security terminal is used to complete the overall architecture of the system. In addition, it uses database firewall, database management backup, access control and password management mechanism to complete the design of database security defense mechanism, so that the disaster recovery radius can be improved, so that the fault can be effectively eliminated. Through the bidirectional cooperation of data flow and service flow, the cooperation of bidirectional data flow and service flow from bottom up and top down is realized, and the extensive and deep value mining of client data is finally realized. Experiments show that the system can effectively reduce the fault diagnosis cycle of the system, speed up the diagnosis efficiency of the system, and ensure the information security of the system.","","979-8-3503-5998-5","10.1109/ACCTCS61748.2024.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612921","Transmission and transformation data;Internet of Things;data architecture;automated system","Substations;Power measurement;Databases;Information security;Power transmission;Production;Passwords","","","","9","IEEE","13 Aug 2024","24-26 Feb. 2024","24-26 Feb. 2024","IEEE","IEEE Conferences"
"Innovative Big Data Analytics: A System for Document Management","M. Fugini; J. Finocchi","Dipartimento di Elettronica, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Milano, Italy",2018 IEEE 27th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE),"18 Oct 2018","2018","","","267","274","This paper shows the solutions developed in the Project ""Sistema Innovativo Big Data Analytics"" named SIBDA (The needs of the three involved companies are described, which led to define an overall framework in the field of Big Data through application cases. The functional and technological requirements of an integrated Big Data Architecture are given. In particular, the criteria for selecting the solutions for Document Management for one company (Microdata Service) are described. The resulting Enterprise Content Management (ECM) system architecture and the overall system architecture are given. SIBDA stands for Sistema Innovativo Big Data Analytics, a project funded by Regione Lombardia within ""Accordi di Competitività"", involving three ICT companies (Mail Up s.p.a, Microdata Service and LineaCom), belonging to the CRIT Consortium, Cremona, and Politecnico di Milano.","1524-4547","978-1-5386-6916-7","10.1109/WETICE.2018.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8495948","Big Data architecture, document and content management, metadata extraction, machine learning for document classification","Big Data;Companies;Electronic countermeasures;Data mining;Content management;Complexity theory;Tools","","2","","8","IEEE","18 Oct 2018","27-29 June 2018","27-29 June 2018","IEEE","IEEE Conferences"
"Concept definition for Big Data architecture in the education system","P. Michalik; J. Štofa; I. Zolotová","Dept. of Cybernetics and Artificial Intelligence, Technical University of Košice, Košice, Slovak Republic; Dept. of Cybernetics and Artificial Intelligence, Technical University of Košice, Košice, Slovak Republic; Dept. of Cybernetics and Artificial Intelligence, Technical University of Košice, Košice, Slovak Republic",2014 IEEE 12th International Symposium on Applied Machine Intelligence and Informatics (SAMI),"29 May 2014","2014","","","331","334","Big Data is a huge phenomenon of last days. Number of applications using this concept is still increasing and area of implementation is still wider and wider. There are different examples such as transport, health-care, industry or education. This work covers just the field of education or university's environment. Purpose of this work is to identify Big Data sources from university's environment and also design of procedure how to work with them. Paper also shows possible using concept of Big Data, but does not show what types of analyses should be performed to improve education process. It means that the main benefit of this work is design of architecture for this problem from the technical perspective. In addition, there are some specific software applications that can be deployed to solve this problem.","","978-1-4799-3442-3","10.1109/SAMI.2014.6822433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822433","","Educational institutions;Computer architecture;Databases;Servers;Companies","","38","","18","IEEE","29 May 2014","23-25 Jan. 2014","23-25 Jan. 2014","IEEE","IEEE Conferences"
"Big Data Knowledge Mining Based Operation Parameters Optimization of Thermal Power","H. Wang; L. Jia","Department of Automation, College of Mechatronics Engineering and Automation, Shanghai University, Shanghai, P.R. China; Department of Automation, Shanghai Key Laboratory of Power Station Automation Technology, College of Mechatronics Engineering and Automation, Shanghai University, Shanghai, P. R. China",2019 IEEE 8th Data Driven Control and Learning Systems Conference (DDCLS),"25 Nov 2019","2019","","","338","343","With the development of electric-power industry, a large amount of historical data of thermal power units are accumulated, conventional optimization methods of operation parameters have the limitations in storage and computation for massive data. To solve the problem, this paper proposes a big data analysis architecture for thermal power based on data processing flow. According to this architecture, a big data mining method for operation parameters optimization based on parallel association rules is presented. Firstly, a new distributed adaptive K-means algorithm is proposed to realize the classification of working conditions based on external constraints, which can improve the computing efficiency and avoid the defect of determining the division number artificially. Then, Spark-based FP-growth algorithm is applied to mine the strong association rules under various working conditions, thus the optimization target values of operation parameters can be obtained by the best strong association rules. Lastly, the excavated optimization target values constitute the historical knowledge database to optimize the real-time operating parameters. The experiment results show that the proposed method in this paper is effective, and can improve the accuracy of operation parameters optimization.","","978-1-7281-1454-5","10.1109/DDCLS.2019.8908932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908932","Big data of thermal power;Big data architecture;Parallel association rule;Parameter optimization","Coal;Employee welfare;Optimization","","","","20","IEEE","25 Nov 2019","24-27 May 2019","24-27 May 2019","IEEE","IEEE Conferences"
"Optimizing File Similarity Search Techniques in Data Lakes using Parallel Processing and Big Data Frameworks","S. S. Daoud Saad; A. Alserafi","Department of Business Informatics, German University in Cairo, Cairo, Egypt; Department of Business Informatics, German University in Cairo, Cairo, Egypt",2023 2nd International Conference on Smart Cities 4.0,"16 May 2024","2023","","","401","406","Smart cities generate a massive amount of disparate data from multiple sources, necessitating the use of Data Lakes for efficient storage and management, especially with the advent of Big Data. However, it is critical to use appropriate search techniques and governance to prevent the Data Lake from becoming a data swamp. The Data Lake encompasses a wide range of documents and topics, which makes finding similar datasets, e.g., through schema matching approaches, difficult and computationally intensive. In this paper, we propose an approach that leverages Data Lakes and Big Data frameworks to improve the search for related or near-identical structured textual datasets. We present a framework for re-implementing the early pruning algorithm “DS-Prox” within a Big Data framework using Spark. The framework involves prototyping with two machine learning models: a Multilayer Perceptron neural network and a Random Forest ensemble learner. The effectiveness of our approach is demonstrated with good accuracy levels, highlighting the benefits of managing heterogeneous Big Data in Data Lakes.","","978-1-6654-7430-6","10.1109/SmartCities4.056956.2023.10526156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10526156","Big Data Frameworks;Data Lakes;Early Pruning Algorithms;Parallel Processing;Similarity Search","Data lakes;Machine learning algorithms;Smart cities;Neural networks;Parallel processing;Multilayer perceptrons;Big Data applications","","","","23","IEEE","16 May 2024","22-24 Oct. 2023","22-24 Oct. 2023","IEEE","IEEE Conferences"
"Challenges and Opportunities in Big Data Analytics for Industry 4.0: A Systematic Evaluation of Current Architectures","A. R. Kretzer; F. Barreto Vavassori Benitti; F. Siqueira","Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil; Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil; Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil",IEEE Access,"30 Oct 2025","2025","13","","183419","183447","The current efforts to integrate Big Data Analytics (BDA) into Industry 4.0 manufacturing systems, despite their usefulness for enhancing data-driven decision-making, are constrained by the lack of architectural standards for data management. This systematic mapping study analyzes many BDA architectures proposed in the literature, revealing a fragmented landscape in which the proposed architectures are largely conceptual with limited industrial validation. Our analysis identifies dominant technological patterns, such as Apache Kafka for ingestion, Spark for processing, and Hadoop and Hive for storage, with the majority of implementations favoring open-source solutions. Despite their theoretical importance, real-time analytics capabilities remain underutilized in practice. This study synthesizes a unified conceptual reference architecture with eight fundamental layers to provide a framework for comparative analysis. We document an imbalance in layer development: storage and processing receive comprehensive attention while querying, infrastructure management, and monitoring layers remain underdeveloped. Implementation approaches show distinct patterns in deployment strategies and data handling, with structured and semi-structured data well supported, whereas unstructured data integration presents ongoing challenges. Future research should focus on developing standardized modular frameworks, benchmarking methodologies, and integrating modern data lakehouse architectures to bridge the gap between theoretical proposals and production-ready systems.","2169-3536","","10.1109/ACCESS.2025.3624558","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES) (Research Organization Registry (ROR) identifier: 00x0ma614) for the Article Processing Charge; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11214321","Big data analytics (BDA);Industry 4.0;Industrial Internet of Things (IIoT);smart manufacturing;cyber-physical systems (CPS);data lake","Fourth Industrial Revolution;Manufacturing;Systematics;Computer architecture;Artificial intelligence;Pipelines;Industrial Internet of Things;Big Data applications;Computer science;Focusing","","","","86","CCBY","22 Oct 2025","2025","","IEEE","IEEE Journals"
"Still Open Problems in Data Warehouse and Data Lake Research","",,"2020 Seventh International Conference on Social Networks Analysis, Management and Security (SNAMS)","3 Feb 2021","2020","","","1","1","Summary form only given. The complete presentation was not made available for publication as part of the conference proceedings. The traditional DW architecture and technologies for some years have been evolving towards handling big data. It has been agreed that the industry to-be standard that allow to integrate big data is a data lake (DL) architecture. A data lake is a repository that stores a vast amount of heterogeneous data in their original formats. Typically, it includes unstructured data from external data sources. It may also stage together internal company DSs (i.e., well-structured, of very high quality) and external DSs (i.e., unstructured, of very low quality). Such staged DSs are then integrated (by ETL processes, a.k.a. data processing workflows - DPW or data processing pipelines - DPP) in another repository in structured way - this repository is a counterpart of a DW. DL architectures are more and more frequently being developed in cloud eco-systems, e.g., Azure, GCP, or AWS. Despite the fact that the DW technologies have been developed for at most 30 years by multiple research communities and IT industry (resulting in mature and advanced technologies and methods), there still exist research problems to be solved. Big data make the (already difficult) problems even more difficult and add new challenges. The following ones will be highlighted in this talk; · handling the impact of the evolution of data source structures on an integration layer, · optimizing executions of data processing workflows, · cataloging available data sets and metadata management, · assuring high quality of data (especially duplicate elimination) in a DW and DL. This talk will present the latest research in this field and cover the current challenges.","","978-0-7381-1180-3","10.1109/SNAMS52053.2020.9336567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9336567","","Data processing;Big Data applications;Software;Medical services;Industries;Data warehouses","","","","","IEEE","3 Feb 2021","14-16 Dec. 2020","14-16 Dec. 2020","IEEE","IEEE Conferences"
"Optimizing Big Data Implementation to Create Business Value and Architecture Proposed in the Banking Industry: A Systematic Review","I. Kristiana; M. Meyliana; A. N. Hidayanto; H. Prabowo","Computer Science Department, Binus Graduate Program – Computer Science, Bina Nusantara University, Jakarta, Indonesia; Information Systems Department, School of Information Systems, Bina Nusantara University, Jakarta, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Management Departement, BINUS Business School Undergraduate Program, Bina Nusantara University, Jakarta, Indonesia","2023 International Conference on Computer Science, Information Technology and Engineering (ICCoSITE)","23 May 2023","2023","","","667","672","The exponential growth of data is compelling organizations to employ data in decision-making. As one of the businesses with an ecosystem that contributes to data growth, banks have challenges in generating insight. A high level of data security is frequently linked to a high level of data access difficulties. This poses a challenge to the implementation of data-driven business, where taking control of our data is one of the best ways to ensure that we not only own data but also have the ability to process and use data to extract business value. Through literature review, a number of challenges to optimizing the implementation of big data analytics in the banking industry were discovered. Data governance refers to the methods and procedures that assist banks in managing and securing data. A big data architecture is presented to address the highlighted issues, particularly with a multi-tiered approach to big data structures. With the adoption of this architecture, it will be simpler to generate business-value-generating insights for the banking industry using big data with accessibility and protection of data.","","979-8-3503-2095-4","10.1109/ICCoSITE57641.2023.10127701","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127701","data-driven;big data;data governance;big data architecture;business value;bank","Industries;Systematics;Data security;Bibliographies;Process control;Computer architecture;Banking","","1","","38","IEEE","23 May 2023","16-16 Feb. 2023","16-16 Feb. 2023","IEEE","IEEE Conferences"
"Business Information Architecture for Big Data and Internet of Things","M. S. HADJ SASSI; L. CHAARI FOURATI; F. GHOZZI JEDIDI","Digital Research Center of Sfax, LT2S Laboratory, TUNISIA; Digital Research Center of Sfax, LT2S Laboratory, TUNISIA; MIRACL Laboratory, Sfax University, TUNISIA",2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC),"22 Jul 2019","2019","","","1749","1756","Even though several architectures have been in existence for over a decade, a new research model has to be created in order to solve the requirements (volume, velocity, and variety) and constraints that affect the intelligence of smart environments. Thus, the merge of computing technologies has made the collection of Big Data (BD) possible from the Internet of Things (IoT) devices. Data do not include only the information about the environments, but also the daily changes of information and so forth. In this context, We propose new business information architecture for BD and IoT (BDIoT). The proposed architecture uses context-aware computing and combines the Data WareHhouse (DWH) and Data Lake (DL) in order to benefit computing mechanisms. The BDIoT architecture is validated through use case related to E-health service (Alzheimer’s disease).","2376-6506","978-1-5386-7747-6","10.1109/IWCMC.2019.8766747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766747","Internet of Things;Big-Data;Architecture;Business Intelligence;Data-flow","Computer architecture;Business;Memory;Tools;Data collection;Internet of Things;Data mining","","7","","35","IEEE","22 Jul 2019","24-28 June 2019","24-28 June 2019","IEEE","IEEE Conferences"
"A “Fast Data” architecture: Dashboard for anomalous traffic analysis in data networks","M. A. L. Peña; C. A. Rua; S. S. Lozoya","Research and Development Department, Sistemas Avanzados de Tecnología, Madrid, S.A., Spain; Research and Development Department, Sistemas Avanzados de Tecnología, Madrid, S.A., Spain; Research and Development Department, Sistemas Avanzados de Tecnología, Madrid, S.A., Spain",2016 Eleventh International Conference on Digital Information Management (ICDIM),"26 Jan 2017","2016","","","37","42","Fast Data is a new Big Data computing paradigm that ensures requirements such as Real-Time processing of continuous data stream, storage at high rates and low latency with no data losses. In this work we propose a “Fast Data” architecture for a specific kind of software application in which input data arrive very fast and the results for each processed data have to match such input rates. We applied this architecture to build a Dashboard for Anomalous Traffic Analysis in Data Networks. In order to fulfill the requirements of Real-Time processing and no data losses, we carry out a design that consists of a pattern of dynamic tree of process pipelines, where the number of branches increases proportionally to the input data rate. Two different approaches have been followed to implement this design pattern: one based in a well-known set of products from the Big Data ecosystem; and the other built with Kafka, Zookeeper and a set of components designed and implemented by us. These two implementations have been compared in terms of velocity and scalability performance. As a result, the implementation built with our own components is significantly faster and scalable than the traditional one. The good results obtained by using both the design pattern of dynamic tree of process pipelines and our implementation make them very suitable for its use in other scenarios and applications such as smart cities, environment monitoring, industry 4.0, distributed control systems, etc.","","978-1-5090-2641-8","10.1109/ICDIM.2016.7829756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829756","Fast Data;Big Data;Data-Driven;Continuous Data Processing;Stream Processing;Scalability","Computer architecture;Real-time systems;Pipelines;Databases;Architecture;Big data;Scalability","","1","","18","IEEE","26 Jan 2017","19-21 Sept. 2016","19-21 Sept. 2016","IEEE","IEEE Conferences"
"Applying data models to big data architectures","P. O'Sullivan; G. Thompson; A. Clifford",NA; NA; NA,IBM Journal of Research and Development,"21 Nov 2014","2014","58","5/6","18:1","18:11","A key message from the early adopters of big data is that technologies such as Hadoop®, NoSQL (Not Only Structured Query Language) databases, and stream computing should not be seen as completely separate technologies but are more valuable when deployed in conjunction with more traditional data management components. There is an urgent need for an overall blueprint for treating both the new and traditional data management components in a holistic and integrated manner. A models-driven approach ensures consistency across this data management landscape in terms of management, governance, and efficiency. This paper focuses on the data modeling considerations relating the big data deployment using the examples of transaction data and mixed unstructured data to ensure that data components are evolved to maximize business value and development efficiencies.","0018-8646","","10.1147/JRD.2014.2352474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6964875","","Big data;Database management;Data models;Transaction processsing;Business","","3","","23","IBM","21 Nov 2014","Sept.-Nov. 2014","","IBM","IBM Journals"
"Efficient social network analysis in big data architectures","I. Sorić; D. Dinjar; M. Štajcer; D. Oreščanin","Poslovna Inteligencija d.o.o., Zagreb, Croatia; Poslovna Inteligencija d.o.o., Zagreb, Croatia; Poslovna Inteligencija d.o.o., Zagreb, Croatia; Poslovna Inteligencija d.o.o., Zagreb, Croatia","2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","13 Jul 2017","2017","","","1397","1400","Social network analysis (SNA) is the application of graph theory to understand, categorize and quantify relationships in a social network. It can be a great tool to improve analytic capabilities in any field, for example marketing analytics, churn prediction, health care, etc. In terms of SNA, network structure is defined by nodes, edges and metrics which quantify the importance or influence of certain nodes in the network or relationship strength between nodes. Algorithms for network metrics calculation are complex and that makes SNA difficult to implement in big data environments on large datasets with many nodes and edges. In this paper we will elaborate how to efficiently and performance wise perform SNA and visualize results of the analysis on large datasets using increasingly popular GraphX and JavaScript libraries.","","978-953-233-090-8","10.23919/MIPRO.2017.7973640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7973640","","Sparks;Tools;Libraries;Social network services;Big Data;Algorithm design and analysis;Data visualization","","4","","10","","13 Jul 2017","22-26 May 2017","22-26 May 2017","IEEE","IEEE Conferences"
"Exploiting Software Product Lines and Formal Concept Analysis for the Design of Data Lake Architectures","M. Huchard; A. Laurent; T. Libourel; C. Madera; A. Miralles",NA; NA; NA; NA; NA,Data Lakes,"","2020","","","41","56","This chapter aims to investigate an approach to assisting the user in the design of a data lake architecture. Software product line engineering is an approach that allows for the formalization of a series of similar software products or systems, which only differ in some of their optional components. The chapter introduces a formalization approach based on the model of product lines. Before doing so, it provides an overview of basic notions and terminology related to Software Product Line and Formal Concept Analysis. The chapter shows an approach to assisting and accelerating the construction of a data lake. This approach consists of high‐level modeling, independent from physical tools, relying on existing software product line concepts. The chapter considers existing semi‐automated processes to generate the feature model that provides us with a preliminary formal model regarding the functionalities of the components of a data lake.","","9781119720423","10.1002/9781119720430.ch3","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822735.pdf&bkn=9820901&pdfType=chapter","","Big Data applications;Task analysis;Software product lines;Computer architecture;Frequency modulation;Software;Real-time systems","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Data Lakehouse in Action: Architecting a modern and scalable data analytics platform","P. Menon",NA,Data Lakehouse in Action: Architecting a modern and scalable data analytics platform,"","2022","","","","","Propose a new scalable data architecture paradigm, Data Lakehouse, that addresses the limitations of current data architecture patternsKey FeaturesUnderstand how data is ingested, stored, served, governed, and secured for enabling data analyticsExplore a practical way to implement Data Lakehouse using cloud computing platforms like AzureCombine multiple architectural patterns based on an organization’s needs and maturity levelBook DescriptionThe Data Lakehouse architecture is a new paradigm that enables large-scale analytics. This book will guide you in developing data architecture in the right way to ensure your organization's success. The first part of the book discusses the different data architectural patterns used in the past and the need for a new architectural paradigm, as well as the drivers that have caused this change. It covers the principles that govern the target architecture, the components that form the Data Lakehouse architecture, and the rationale and need for those components. The second part deep dives into the different layers of Data Lakehouse. It covers various scenarios and components for data ingestion, storage, data processing, data serving, analytics, governance, and data security. The book's third part focuses on the practical implementation of the Data Lakehouse architecture in a cloud computing platform. It focuses on various ways to combine the Data Lakehouse pattern to realize macro-patterns, such as Data Mesh and Data Hub-Spoke, based on the organization's needs and maturity level. The frameworks introduced will be practical and organizations can readily benefit from their application. By the end of this book, you'll clearly understand how to implement the Data Lakehouse architecture pattern in a scalable, agile, and cost-effective manner.What you will learnUnderstand the evolution of the Data Architecture patterns for analyticsBecome well versed in the Data Lakehouse pattern and how it enables data analyticsFocus on methods to ingest, process, store, and govern data in a Data Lakehouse architectureLearn techniques to serve data and perform analytics in a Data Lakehouse architectureCover methods to secure the data in a Data Lakehouse architectureImplement Data Lakehouse in a cloud computing platform such as AzureCombine Data Lakehouse in a macro-architecture pattern such as Data MeshWho this book is forThis book is for data architects, big data engineers, data strategists and practitioners, data stewards, and cloud computing practitioners looking to become well-versed with modern data architecture patterns to enable large-scale analytics. Basic knowledge of data architecture and familiarity with data warehousing concepts are required.","","9781801815109","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163024.pdf&bkn=10163024&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Rethinking Big Data Value Chains: A Comparative Framework Across Hadoop, Modern, and Cloud Stacks","W. Elouataoui; Y. Gahi","Software Project Management Research Team ENSIAS, Mohammed V University, Rabat, Morocco; Laboratory of Engineering Sciences National School of Applied Sciences, Ibn Tofail University, Kenitra, Morocco",2025 11th International Conference on Optimization and Applications (ICOA),"19 Nov 2025","2025","","","1","6","The growing adoption of big data across sectors has triggered a significant transformation in data architecture, shifting from monolithic systems to more dynamic and scalable ecosystems. Initially dominated by Hadoop-based frameworks relying on tools like HDFS and Spark big data processing has since evolved towards more modular architectures. The modern data stack introduces flexibility and tool diversity, while cloud-native platforms redefine scalability and simplify integration. Yet, selecting the appropriate stack remains a complex task, as most prior research focuses on isolated components rather than holistic, practical comparisons. This paper addresses that gap by evaluating three prevalent data architecture paradigms: Hadoop, Modern, and Cloud-Based stacks. We conduct a thorough end-to-end comparison across the full big data value chain, from ingestion to visualization. Moreover, beyond architectural assessment, we implement each stack on a real-world scenario using the Amazon Books Reviews dataset where each implementation is evaluated based on key metrics such as scalability, performance, ease, and deployment costs. Our findings aim to provide data professionals with a practical reference for selecting suitable data architectures in big data environments.","2768-6388","979-8-3315-9957-7","10.1109/ICOA66896.2025.11236898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11236898","Big Data;Data Architecture;Hadoop;Modern Data Stack;Cloud Platforms","Costs;Scalability;Pipelines;Organizations;Big Data;Real-time systems;Regulation;Sparks;Reliability;Optimization","","","","22","IEEE","19 Nov 2025","16-17 Oct. 2025","16-17 Oct. 2025","IEEE","IEEE Conferences"
"Seamless Decision-Making in the Big Data Era: A Modular Approach to Integrating IoT, Cloud Computing, and Data Lakes","M. Zemmouri; F. Z. Laalam; O. Kazar; Y. Himeur; A. Oulefki; C. Toumi; W. Mansoor; S. Attala","Artificial Intelligence and Information Technologies Laboratory, Faculty of New Information and Communication Technologies, Kasdi Merbah Ouargla University, Ouargla, Algeria; Artificial Intelligence and Information Technologies Laboratory, Faculty of New Information and Communication Technologies, Kasdi Merbah Ouargla University, Ouargla, Algeria; Department of Computer Science - LINFI Laboratory, Mohamed Khider University, Biskra, Algeria; College of Engineering and Information Technology, University of Dubai, Dubai, UAE; Department of Computer Science, University of Sharjah, Sharjah, United Arab Emirates; Artificial Intelligence and Information Technologies Laboratory, Faculty of New Information and Communication Technologies, Kasdi Merbah Ouargla University, Ouargla, Algeria; College of Engineering and Information Technology, University of Dubai, Dubai, UAE; College of Engineering and Information Technology, University of Dubai, Dubai, UAE","2023 International Conference on Electrical, Communication and Computer Engineering (ICECCE)","27 Feb 2024","2023","","","1","6","The integration of big data with cutting-edge technologies like IoT and Cloud Computing has profoundly influenced various aspects of modern life, including everyday service processes. To facilitate data-driven decision-making, big data analytics—focused on identifying patterns, trends, and correlations in large data sets—is indispensable. While traditional statistical techniques are useful, new tools and infrastructures such as Hadoop, Spark, and NoSQL are essential to tackle big data challenges. However, modifying the existing environment can be impractical, especially in production settings, due to the need for significant investment and specialized expertise. This article presents a novel computational paradigm that adds a decision-making layer atop existing systems for data analysis, eliminating the need to alter the environment. The approach treats the current information system as a data lake and introduces a new data recovery layer through web services, drawing inspiration from big data technologies like MapReduce. This system offers the advantage of being modular, reusable, and universally compatible, making it an independent decisional framework that can work with any information system or data source.","","979-8-3503-6969-4","10.1109/ICECCE61019.2023.10442390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10442390","Big Data;Data Analysis;Data Science;Paradigm;Design Pattern","Cloud computing;Web services;Decision making;Big Data applications;Time factors;Task analysis;Information systems","","","","31","IEEE","27 Feb 2024","30-31 Dec. 2023","30-31 Dec. 2023","IEEE","IEEE Conferences"
"Indexing And Searching Visual Content in a Data Lake Context","S. Sore; F. T. Ouedraogo; Y. Traore; M. Bikienga","Université Norbert ZONGO, Koudougou, Burkina Faso; Université Norbert ZONGO, Koudougou, Burkina Faso; Université Joseph Ki-Zerbo, Ouagadougou, Burkina Faso; Université Norbert ZONGO, Koudougou, Burkina Faso",2023 8th International Conference on Frontiers of Signal Processing (ICFSP),"1 Jan 2024","2023","","","103","109","Nowadays, we are witnessing a steady increase in the number of available images, whether for experts or the general public, particularly in the age of Big Data, where data are distinguished by their volume, variety, authenticity and speed. Often, these vast databases contain numerous images, accompanied by texts and annotations more or less detailed The aim of this article is to respond to the growing need for high-performance tools for storing, research and exploring these vast image databases. In our context, the analysis of this massive data mainly aims at finding images based on their visual content. This approach enables the search of images based on some visual characteristics such as color patterns (RGB and HSV), shape and texture. The main aim of this research is to group images of crop diseases according to their similarities in a suitable storage system.","","979-8-3503-0879-2","10.1109/ICFSP59764.2023.10372941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10372941","Big data;data lake;image;visual search;visual descriptor;similarity","Visualization;Shape;Image databases;Image color analysis;Annotations;Crops;Signal processing","","","","26","IEEE","1 Jan 2024","23-25 Oct. 2023","23-25 Oct. 2023","IEEE","IEEE Conferences"
"Consideration and Research on Data Architecture for the Future Cyber Society","F. Miao; W. Yang; Y. Xie; W. Fan","Big Data Research Institute, Chengdu University, Chengdu, China; Cyber Security College, Chengdu University of Technology, Chengdu, China; Geophysics College, Chengdu University of Technology, Chengdu, China; Big Data Research Institute, Chengdu University, Chengdu, China","2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","9 Apr 2020","2019","","","1671","1676","The future cyber society is a virtual world made of data, contrasted with the real world made of material. Human beings are already living in these two interacted and fusional worlds. Various of data are not only the kind of valuable resources, but also the new cognitions of methodology from the viewpoint of data. There are too many characteristics and attributions of data we even didn't really know, such as data philosophy, data thinking, data theory, data rules, data assets, data ownership, data protection, data sharing, data application, data method, data architecture, etc. We need to build an open, safety, sharable, ecological data platform to manage all kinds of data and support various applications for the future cyber society. A simple architecture of data-oriented and data ownership-based, constructed of one-body with two-wings for building complex information systems was proposed and it may be suitable for the future ordered cyber data society.","","978-1-7281-4034-6","10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9060237","Data-ism, data architecture, data ownership, data encryption, data registration, public key infrastructure, data security application","Big Data;Computers;Computer architecture;Internet;Collaboration","","5","","15","IEEE","9 Apr 2020","19-23 Aug. 2019","19-23 Aug. 2019","IEEE","IEEE Conferences"
"Examining Amazon Customer Reviews using PySpark and AWS: A Data Lake Approach","R. S; A. S. Karthik; M. H. S. M. K. Karthik; M. Jayasurya; S. Yashwanth","Dept. of Computer Science and Engineering, Amrita Vishwa Vidyapeetham; Dept. of Computer Science and Engineering, Amrita Vishwa Vidyapeetham; Dept. of Computer Science and Engineering, Amrita Vishwa Vidyapeetham; Dept. of Computer Science and Engineering, Amrita Vishwa Vidyapeetham; Dept. of Computer Science and Engineering, Amrita Vishwa Vidyapeetham",2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT),"23 Nov 2023","2023","","","1","6","In the contemporary world, big data analysis with PySpark and AWS has become quite handy. Large multinational companies, including Walmart, trivago, and countless others are using big data. And with the assistance of AWS, which offers a variety of services like glue, Athena, S3, etc., becoming extremely beneficial for cloud storage purposes and also for creating data migration pipelines. Any RDBMS database server might send tens of gigabytes of data to an Amazon S3 bucket using the ETL architecture. Our primary goal in this project is to use PySpark to construct an ETL pipeline for data migration. Amazon wireless devices review analysis, Amazon watches review analysis, Amazon books review analysis, Amazon shoes review analysis, and Amazon musical instruments review analysis are the five separate datasets on which we conducted our analysis. The datasets considered for the analysis are Amazon watch reviews, book reviews, shoe reviews, wireless device reviews and musical instrument reviews . The goal of the project is to obtain the ratio of the number of trustworthy, real reviews to untrusted reviews and a comparison in done in the form of graphs.","2473-7674","979-8-3503-3509-5","10.1109/ICCCNT56998.2023.10307845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10307845","Athena;AWS;ETL Glue;Pipeline;PySpark;RDBMS","Wireless communication;Cloud computing;Instruments;Pipelines;Music;Companies;Footwear","","","","17","IEEE","23 Nov 2023","6-8 July 2023","6-8 July 2023","IEEE","IEEE Conferences"
"Design and Implementation of Hydrogen Fuel Cell Test System Based on Hadoop Architecture","D. Hu; Y. Liu; Y. Zhou; Y. Ge; H. Zhang; C. Sun","Institute of Automation, Qilu University of Technology (Shandong Academy of Sciences), Shandong Provincial Key Laboratory of Automotive Electronic Technology, Jinan, China; Institute of Automation, Qilu University of Technology (Shandong Academy of Sciences), Shandong Provincial Key Laboratory of Automotive Electronic Technology, Jinan, China; Shandong Institute of Inspection on Product Quality, Jinan, China; Institute of Automation, Qilu University of Technology (Shandong Academy of Sciences), Shandong Provincial Key Laboratory of Automotive Electronic Technology, Jinan, China; Institute of Automation, Qilu University of Technology (Shandong Academy of Sciences), Shandong Provincial Key Laboratory of Automotive Electronic Technology, Jinan, China; Institute of Automation, Qilu University of Technology (Shandong Academy of Sciences), Shandong Provincial Key Laboratory of Automotive Electronic Technology, Jinan, China",2023 China Automation Congress (CAC),"19 Mar 2024","2023","","","3591","3595","Traditional file storage and analysis tools can no longer adapt to the growing mass data storage and complex and multi-structured data analysis. Aiming at the problem that the test data analysis of key components of hydrogen fuel cell needs to deal with high concurrency and massive data, this paper adopts Hadoop big data architecture to establish a big data platform for test data management of key components of fuel cell. The test system based on big data analysis can monitor the test environment parameters in real time, complete the analysis and calculation of the test environment parameters, design the big data platform architecture, and verify the feasibility and advantages of the platform design by building the Hadoop cluster environment.","2688-0938","979-8-3503-0375-9","10.1109/CAC59555.2023.10451558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10451558","Hadoop;big data;test system;data analysis","Data analysis;Architecture;Hydrogen;Fuel cells;Computer architecture;Big Data;Real-time systems","","","","10","IEEE","19 Mar 2024","17-19 Nov. 2023","17-19 Nov. 2023","IEEE","IEEE Conferences"
"Computer-Aided Software Engineering (CASE) Tool for Big Data and IoT Architecture","M. S. HADJ SASSI; F. GHOZZI JEDIDI; L. CHAARI FOURATI","Digital Research Center of Sfax, LT2S Laboratory, TUNISIA; MIRACL Laboratory, Sfax University, TUNISIA; Digital Research Center of Sfax, LT2S Laboratory, TUNISIA",2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC),"22 Jul 2019","2019","","","1403","1410","Building a new Business Intelligence (BI) architectures for big data and Internet of Things (IoT) is a complex task. It aims to satisfy the needs of decision makers by taking into consideration several constraints and requirements (volume, velocity, and variety). This can influence the decision of choosing the most appropriate tools, techniques, and technologies in the data flow management for IoT solutions. With the aim of helping the decision makers to control their analytical needs and to achieve the business goals, we propose a Computer-Aided Software Engineering (CASE) tool that supports the design of BI for IoT architecture (BIIoT) based on knowledge. It recommends existing technologies which fit well with the scalability of the business requirements and verifies the data flow in the proposed architecture. Thus, the BIIoT tool is validated through a use case related to agriculture service provisioning.","2376-6506","978-1-5386-7747-6","10.1109/IWCMC.2019.8766522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766522","Internet of Things;Big Data;Architecture;Business Intelligence;Data-flow","Computer architecture;Tools;Big Data;Computer aided software engineering;Task analysis;Business intelligence","","8","","17","IEEE","22 Jul 2019","24-28 June 2019","24-28 June 2019","IEEE","IEEE Conferences"
"Knowledge cubes — A proposal for scalable and semantically-guided management of Big Data","A. Madkour; W. G. Aref; S. Basalamah","Purdue University, West Lafayette, USA; Purdue University, West Lafayette, USA; Umm Al-Qura University, Makkah, KSA",2013 IEEE International Conference on Big Data,"23 Dec 2013","2013","","","1","7","A Knowledge Cube, or cube for short, is an intelligent and adaptive database instance capable of storing, analyzing, and searching data. Each cube is established based on semantic aspects, e.g., (1) Topical, (2) Contextual, (3) Spatial, or (4) Temporal. A cube specializes in handling data that is only relevant to the cube's semantics. Knowledge cubes are inspired by two prime architectures: (1) Dataspaces that provides an abstraction for data management where heterogeneous data sources can co-exist and it requires no prespecified unifying schema, and (2) Linked Data that provides best practices for publishing and interlinking structured data on the web. A knowledge cube uses Linked Data as its main building block for its data layer and encompasses some of the data integration abstractions defined by Dataspaces. In this paper, knowledge cubes are proposed as a semantically-guided data management architecture, where data management is influenced by the data semantics rather than by a predefined scheme. Knowledge cubes support the five pillars of Big Data also known as the five V's, namely Volume, Velocity, Veracity, Variety, and Value. Interesting opportunities can be leveraged when learning the semantics of the data. This paper highlights these opportunities and proposes a strawman design for knowledge cubes along with the research challenges that arise when realizing them.","","978-1-4799-1293-3","10.1109/BigData.2013.6691800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691800","big data architecture;semantics;data management","Semantics;Information management;Data handling;Data storage systems;Resource description framework;Indexes;Catalogs","","9","","26","IEEE","23 Dec 2013","6-9 Oct. 2013","6-9 Oct. 2013","IEEE","IEEE Conferences"
"Educational data mining and big data framework for e-learning environment","P. K. Udupi; N. Sharma; S. K. Jha","Department of Computing, Middle East College, Muscat, Oman; NIMT, Kurukshetra, Haryana, India; AIIT, Amity University, Noida, India","2016 5th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","19 Dec 2016","2016","","","258","261","E-learning data consists of large volume of educational data and available with complex and hybrid data architecture. Capturing of student performances, student evaluation and student's interaction information are one of the challenges faced by the e-learning software users at the time of analysis. Integrating student data along with educational data for analysis needs complex system design framework. New innovations in e-learning also facilitates augmented learning, adaptive learning, web based learning, activity based learning, and project based learning. Education technology interventions using learning management system, content management system, advanced distributed learning; sharable content object reference models and application program interfaces enhanced and extended the e-learning frameworks to a greater horizon. Present technology also ensures transformations of e-learning information without any geographical barriers. These educational and student or user data combined together forms big data architecture under e-learning environment and mining these big data for various requirements or knowledge discoveries needs innovative approaches. This paper identifies and evaluates various e-learning models and associated education technology paradigm. The research further explores and proposes a new framework for big data integrations. The paper also discusses the scope of future research on data mining and role of big data in e-learning environment.","","978-1-5090-1489-7","10.1109/ICRITO.2016.7784961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7784961","E-learning;Big Data Framework;Augmented learning;Adaptive learning","Electronic learning;Data mining;Big Data;Education;Learning management systems;Feature extraction;Data visualization","","9","","","IEEE","19 Dec 2016","7-9 Sept. 2016","7-9 Sept. 2016","IEEE","IEEE Conferences"
"Case study on data architecture for managing scientific data","W. Qi; J. Song; Y. -b. Bao","Eastern Liaoning University, Dandong, China; Northeastern University, Shenyang, China; Northeastern University, Shenyang, China",2010 2nd IEEE International Conference on Information Management and Engineering,"3 Jun 2010","2010","","","84","89","There are many new challenges in building Scientific Data Management System (SDMS), and the most initial and important one of them is designing a reasonably and effectively data architecture. The data architecture should focus on massive metadata, complex data flow, multi-classification data, various data productions and uniform query. Based on the applied projects, we present the classificatory criterions, data architecture, data flow, and query applications of SDMS in this paper as a case study. We propose the common solutions, conclude and share some experiences in the data architecture issues. These industrial experiences will be helpful to design data architecture and system of scientific data.","","978-1-4244-5263-7","10.1109/ICIME.2010.5477535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5477535","data architecture;data classification;database;data warehouse;scientific data","Instruments;Production;Buildings;Databases;Data warehouses;Sea measurements;Hydrologic measurements;Satellites;Hydrology;Computer simulation","","","","6","IEEE","3 Jun 2010","16-18 April 2010","16-18 April 2010","IEEE","IEEE Conferences"
"Analysis of big data security practices","P. Revathy; R. Mukesh","OCBC Bank Limited, Singapore; Hindustan University, Chennai, India",2017 3rd International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT),"21 Jun 2018","2017","","","264","267","In modern world, huge amount of data is common across all businesses which aim to unlock new economy from these sources. Hadoop was developed to analyze large scale data repository in a parallel computing architecture. The main task in this process is to handle this “Big Data” by applying proper strategies. So, present industry is focusing on the methods in which this “Big Data” can be used for their business growth. There's no suspicion that the setup of Data Lake on hadoop can provide a new way of analytics and intuition analysis. Beyond experimentations and POCs, today Hadoop is considered more into production. As we are moving towards the stage where Hadoop is considered for real-time production scenarios and major chunk of the production data is normally sensitive, or subject to many control measures, it becomes high priority to consider the security aspects in hadoop before deciding on Hadoop installation for any enterprise. This paper evaluates various issues in Hadoop ecosystem and its popular distributions by top big data players in the market. It further intends to investigate and compare the current security features being provided in those big data distributions along with other open source big data security solutions to help in building secure big data environment.","","978-1-5386-1144-9","10.1109/ICATCCT.2017.8389145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8389145","Big Data;Hadoop;Security Measures;Hadoop Security Tools;Hadoop Tools-Security Comparision","Encryption;Authentication;Big Data;Authorization;Tools","","5","","17","IEEE","21 Jun 2018","21-23 Dec. 2017","21-23 Dec. 2017","IEEE","IEEE Conferences"
"Architecture and Building the Medical Image Anonymization Service: Cloud, Big Data and Automation","W. -Y. Chen; M. Yu; C. Sun","National Center for High-Performance Computing, Taiwan; National Center for High-Performance Computing, Taiwan; National Center for High-Performance Computing, Taiwan","2021 International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)","31 Jan 2022","2021","","","149","153","Medical images provide significant information to assist patients to obtain correct treatments. In order to create more innovative medical applications, NCHC with the three major medical institutions builds Taiwan's first medical image annotation database. However, under the restriction of personal information law in Taiwan, data privacy is a critical issue. Besides, the data from institutions are a huge amount to process. Thus, we propose “Anonymization Cloud Service” (ACS), based on cloud computing and big data architecture to serve privacy data to be anonymized with DICOM or CSV format. The research has three main components: (1) data conversion between DICOM and CSV, and transmission between transform node and big data cluster, (2) parallelized anonymous process with automation API, and (3) privacy control mechanism for risk evaluation. The results are implemented in more than tens of thousands of cases, over 10 TB of data, and 10 million DICOM files. Those actual cases show the proposed method effectively and efficiently achieves the goals of high performance and low risk.","","978-1-6654-3755-4","10.1109/ICEIB53692.2021.9686426","Ministry of Science and Technology(grant numbers:MOST 108-2634-F-492-001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686426","Data Anonymization;Personal Data Protection;Big Data;Cloud Computing","Data privacy;Cloud computing;Automation;Process control;Computer architecture;Transforms;Medical services","","2","","16","IEEE","31 Jan 2022","10-12 Dec. 2021","10-12 Dec. 2021","IEEE","IEEE Conferences"
"Design and Application of Big Data Platform Architecture for Typical Scenarios of Power System","D. Cao; J. Li; D. Cai; Q. Huang; Y. Teng; W. Hu","School of Energy Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Energy Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Energy Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Energy Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Energy Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Energy Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China",2018 IEEE Power & Energy Society General Meeting (PESGM),"23 Dec 2018","2018","","","1","5","Power systems generate huge data from its operation center, information system and other related equipment, such as EMS, SCADA, GIS, PMU, AMI, external systems, etc. These data possess various characteristics of large volume, high velocity and strong mutual action. New tools and technologies which seek to manage, dig value and visualize of these data are widely used in the power system. By combining the advantages of mainstream big data ecosystem, this paper proposes a new big data platform for the power system. The proposed big data platform includes the data integration layer, the data storage layer, the data processing layer and the data visualization layer. To demonstrate the effectiveness of the proposed big data architecture, a case study which is a salt and non-soluble deposit densities big data application platform of the power system is designed. The results verify the effectiveness of the designed big data platform.","1944-9933","978-1-5386-7703-2","10.1109/PESGM.2018.8586266","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8586266","power system;big data;extract-transform-load architecture;hybrid storage;data processing","Big Data;Sparks;Power systems;Security;Computer architecture;Distributed databases;Data visualization","","6","","7","IEEE","23 Dec 2018","5-10 Aug. 2018","5-10 Aug. 2018","IEEE","IEEE Conferences"
"Redefining cyber security with big data analytics","A. Apurva; P. Ranakoti; S. Yadav; S. Tomer; N. R. Roy","School of Engineering, G D Goenka University, Gurgaon, India; School of Engineering, G D Goenka University, Gurgaon, India; School of Engineering, G D Goenka University, Gurgaon, India; School of Engineering, G D Goenka University, Gurgaon, India; School of Engineering, G D Goenka University, Gurgaon, India",2017 International Conference on Computing and Communication Technologies for Smart Nation (IC3TSN),"8 Feb 2018","2017","","","199","203","The cyber world is expanding rapidly day by day and more and more people are getting connected to this world, resulting in generation of a large amount of data called Big Data. Along with the cyber world, the number of cyber criminals is also expanding rapidly. To fight against the cyber criminals and safeguard the interest of innocent civilians, we take the help of Big Data Analytics. Big data is large in both quantity and quality and can be efficiently used to analyze certain patterns and behavior anomaly which can help us prevent or be prepared for the thread or any upcoming attack. This proactive and analytical approach will help us greatly reduce the rate of Cyber Crimes and also get the knowledge out of that data which was not previously observable. This paper discusses some of the key characteristics of Big data, architecture, categories of cybercrimes and big data analytic techniques that can be used.","","978-1-5386-0627-8","10.1109/IC3TSN.2017.8284476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8284476","Big Data;Cyber Security;Data Flow;Data Visualization;Social Media","Big Data;Computer crime;Electronic mail;Social network services;Cloud computing","","6","","9","IEEE","8 Feb 2018","12-14 Oct. 2017","12-14 Oct. 2017","IEEE","IEEE Conferences"
"AI-Driven Metadata Extraction and Classification using LLMs in Big Data Lakehouses","B. Madupati; K. Alang; S. Kamatala; V. R. Pasam; A. Kumar Jonnalagadda","Independent Researcher, Frisco, Texas, USA; Independent Researcher, Cuptertino, CA, USA; Independent Researcher, Prosper, Texas, USA; Independent Researcher, Irving, Texas, USA; Independent Researcher, Frisco, Texas, USA",2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI),"2 Sep 2025","2025","","","114","120","Modern data lake houses encounter substantial challenges due to their rapid increase in heterogeneous and unstructured data when it comes to metadata administration and classification and semantic discovery. Such massive and diverse datasets exceed the limits of traditional schema-based methods as well as rigid rule-based systems. This research develops an AI-based method for intelligent classification and automated metadata extraction through Large Language Models. The system uses pre-trained LLMs' contextual understanding and transfer learning abilities to accurately extract metadata from documents logs and multimedia items which have semi-structured and unstructured formats. The framework incorporates a zero-shot learning method from LLMs which teams up with supervised fine-tuning for domainspecific tagging. The validated architecture shows better performance and adaptivity through achieving superior accuracy than traditional NLP-based metadata engines when applied to real-world lakehouse dataset storage. Experimental findings demonstrate that LLMs create substantial enhancements in metadata development as well as search functions and data protection metrics in modern big data systems. This proves LLMs can bring substantial changes to future big data platforms.","","979-8-3315-0313-0","10.1109/ICDICI66477.2025.11135266","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135266","Metadata Extraction;Large Language Models (LLMs);Big Data Lake houses;AI-Driven Classification;Semantic Tagging;Zero-Shot Learning;Unstructured Data;Data Governance;Intelligent Data Management;Metadata Enrichment","Measurement;Large language models;Multimedia systems;Zero shot learning;Semantics;Transfer learning;Metadata;Tagging;Data mining;Engines","","","","15","IEEE","2 Sep 2025","9-11 July 2025","9-11 July 2025","IEEE","IEEE Conferences"
"Data Lakehouse for Time Series Data: A Systematic Literature Review","M. Pohl; N. D. Wijemanne; D. Staegemann; C. Haertel; C. Daase; D. Dreschel; D. S. Walia; A. Osterthun; J. Reibert; K. Turowski","German Aerospace Center (DLR), Institute of Data Science, Jena, Germany; German Aerospace Center (DLR), Institute of Data Science, Jena, Germany; Faculty of Computer Science, Otto von Guericke University, Magdeburg, Germany; Faculty of Computer Science, Otto von Guericke University, Magdeburg, Germany; Faculty of Computer Science, Otto von Guericke University, Magdeburg, Germany; Faculty of Computer Science, Otto von Guericke University, Magdeburg, Germany; Faculty of Computer Science, Otto von Guericke University, Magdeburg, Germany; German Aerospace Center (DLR), Institute of Data Science, Jena, Germany; German Aerospace Center (DLR), Institute of Data Science, Jena, Germany; Faculty of Computer Science, Otto von Guericke University, Magdeburg, Germany",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","5833","5842","As data continues to grow exponentially, the fields of data management and analytics must evolve to ensure efficient data ingestion, knowledge extraction, and scalability. The Data Lakehouse architecture, which combines the best features of Data Warehouses and Data Lakes, has emerged as a potential solution. However, to fully leverage the capabilities of Data Lakehouses for time series data, it is crucial to understand the unique challenges and opportunities they present. This literature review examines proposed Data Lakehouse architectures specifically for time series data, exploring their implementation, the software technologies used, and potential real-world applications. The focus is on comparing these architectures to identify the most suitable technologies for similar implementations. Through an in-depth analysis, this study emphasizes the importance of optimizing configurations to enhance system performance and scalability, particularly for data analysis and artificial intelligence (AI) workloads.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825961","Data Lakehouse;Time Series Data;Temporal Data;Virtual Data Warehouse;Literature Review","Data analysis;Costs;Scalability;Time series analysis;Computer architecture;Data warehouses;Big Data applications;Data mining;Artificial intelligence;Systematic literature review","","","","29","IEEE","16 Jan 2025","15-18 Dec. 2024","15-18 Dec. 2024","IEEE","IEEE Conferences"
"The State of Big Data Reference Architectures: A Systematic Literature Review","P. Ataei; A. Litchfield","School of Engineering, Computer and Mathematical Sciences, Auckland University of Technology, Auckland, New Zealand; Service and Cloud Computing Research Laboratory, Auckland University of Technology, Auckland, New Zealand",IEEE Access,"7 Nov 2022","2022","10","","113789","113807","Big Data (BD) is a nascent term emerged to describe large amount of data that comes in different forms from various channels. In modern world, users are the ceaseless generators of structured, semi-structured, and unstructured data that if gleaned and crunched precisely, will reveal game-changing patterns. While the opportunities exist with BD, the unprecedented amount of data has brought traditional approaches to a bottleneck, and the growth of data is outpacing technological and scientific advances in data analytics. It is estimated that approximately 75% of the BD projects have failed within the last decade according to multiple sources. Among the challenges, system development and data architecture are prominent. This paper aims to facilitate BD system development and architecture by conducting a systematic literature review on BD reference architectures (RA). The primary goal is to highlight the state of BD RAs and how they can be helpful for BD system development. The secondary goal is to find all BD RAs, describe the challenges of creating these RA, discuss the common architectural components of these RA and the limitations of these RA. As a result of this work, firstly major concepts about RA are discussed and their applicability to BD system development is depicted. Secondly, 22 BD reference architecture is assessed from academia and practice and their commonalities, challenges, and limitations are identified. The findings gained emerges the understanding that RAs can be an effective artefact to tackle complex BD system development.","2169-3536","","10.1109/ACCESS.2022.3217557","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931012","Big data;big data reference architectures;big data architectures;big data for business;data analytics;data engineering;data-intensive applications;reference architectures","Computer architecture;Big Data;Databases;Systematics;Data analysis;Guidelines","","14","","90","CCBY","26 Oct 2022","2022","","IEEE","IEEE Journals"
"A Use Case of Data Lake Metadata Management","I. Megdiche; F. Ravat; Y. Zhao",NA; NA; NA,Data Lakes,"","2020","","","97","122","This chapter presents a use case of data lake metadata management, applied to the health‐care field, which is particularly known by its heterogeneous sources of data. It also presents an overview of related work on this field by largely referring to articles in subject fields like data warehouses and Big Data. The chapter presents a list of metadata attributes dedicated to the entire lifecycle of data in different zones of a data lake, relative to data lake architecture. It then proposes a classification of intra‐ and inter‐metadata. These metadata are modelled through a conceptual model in order to implement it in a metadata management system. The chapter provides an implementation of the conceptual model which concerns two database management systems (DBMSs) (one relational database and one NoSQL database). It compares relational DBMS with graph DBMS in terms of scalability, performance, flexibility, query language and security.","","9781119720423","10.1002/9781119720430.ch5","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822039.pdf&bkn=9820901&pdfType=chapter","","Big Data applications;Metadata;Hospitals;Fans;Business intelligence;Adaptation models;Organizations","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Nautilus: A Precision-Guided Open Data Architecture for Big Omics Data Analysis","W. Xing; J. Smith; M. Gavrielides; S. Hindmarsh; A. Huffman; H. H. Wang","Scientific Computing STP, The Francis Crick Institute, London, UK; Scientific Computing STP, The Francis Crick Institute, London, UK; Scientific Computing STP, The Francis Crick Institute, London, UK; Scientific Computing STP, The Francis Crick Institute, London, UK; Big Data Institute, Li Ka Shing Centre for Health Information and Discovery University of Oxford, Oxford, UK; Engineering and Applied Science Aston University, Birmingham, UK",2019 2nd International Conference on Artificial Intelligence and Big Data (ICAIBD),"16 Sep 2019","2019","","","1","8","To make valuable omics data useful is becoming more urgent in medical research. The need to provide information on what and how data can be useful for a particular research question has presented significant challenges in big data management and analysis. This paper describes a new open data architecture and its architectural components. It also introduces the Nautilus platform following the architecture design. We evaluate the performance of data management with the Nautilus platform and demonstrate that applying smart technologies improves the performance to cost tradeoff achieved in an experimental environment.","","978-1-7281-0831-5","10.1109/ICAIBD.2019.8836977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836977","big omics data;AI;bio-medical research","Distributed databases;Artificial intelligence;Computer architecture;Data analysis;Metadata;Big Data;Biology","","","","25","IEEE","16 Sep 2019","25-28 May 2019","25-28 May 2019","IEEE","IEEE Conferences"
"Optimizing Cloud Data Lake Queries by Minimizing the Query Coverage Set","G. Weintraub; E. Gudes; S. Dolev","Ben-Gurion University of the Negev, Israel; Ben-Gurion University of the Negev, Israel; Ben-Gurion University of the Negev, Israel",2025 IEEE 41st International Conference on Data Engineering (ICDE),"20 Aug 2025","2025","","","4675","4679","Cloud data lakes provide a modern solution for managing large volumes of data. The fundamental principle behind these systems is the separation of compute and storage layers. In this architecture, inexpensive cloud storage is utilized for data storage, while compute engines are employed to perform analytics on this data in an “on-demand” mode. However, to execute any calculations on the data, it must be transferred from the storage layer to the compute layer over the network for each query. This transfer can negatively impact calculation performance and requires significant network bandwidth. In our work, we examine various strategies to enhance query performance within a cloud data lake architecture. We begin by formalizing the problem and proposing a straightforward yet robust theoretical framework that clearly outlines the associated trade-offs. Central to our framework is the concept of a “query coverage set,” which is defined as the collection of files that need to be accessed from storage to fulfill a specific query. Our objective is to identify the minimal coverage set for each query and execute the query exclusively on this subset of files. This approach enables us to significantly improve query performance across three different domains: indexing, caching, and genetic data.","2375-026X","979-8-3315-3603-9","10.1109/ICDE65448.2025.00375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113036","data lakes;cloud storage;query optimization","Cloud computing;Query processing;Memory;Computer architecture;Big Data applications;Genetics;Data engineering;Object recognition;Engines;Indexing","","","","22","IEEE","20 Aug 2025","19-23 May 2025","19-23 May 2025","IEEE","IEEE Conferences"
"Scalable Data Architecture with Java: Build efficient enterprise-grade data architecting solutions using Java","S. Banerjee",NA,Scalable Data Architecture with Java: Build efficient enterprise-grade data architecting solutions using Java,"","2022","","","","","Orchestrate data architecting solutions using Java and related technologies to evaluate, recommend and present the most suitable solution to leadership and clientsKey FeaturesLearn how to adapt to the ever-evolving data architecture technology landscapeUnderstand how to choose the best suited technology, platform, and architecture to realize effective business valueImplement effective data security and governance principlesBook DescriptionJava architectural patterns and tools help architects to build reliable, scalable, and secure data engineering solutions that collect, manipulate, and publish data. This book will help you make the most of the architecting data solutions available with clear and actionable advice from an expert. You’ll start with an overview of data architecture, exploring responsibilities of a Java data architect, and learning about various data formats, data storage, databases, and data application platforms as well as how to choose them. Next, you’ll understand how to architect a batch and real-time data processing pipeline. You’ll also get to grips with the various Java data processing patterns, before progressing to data security and governance. The later chapters will show you how to publish Data as a Service and how you can architect it. Finally, you’ll focus on how to evaluate and recommend an architecture by developing performance benchmarks, estimations, and various decision metrics. By the end of this book, you’ll be able to successfully orchestrate data architecture solutions using Java and related technologies as well as to evaluate and present the most suitable solution to your clients.What you will learnAnalyze and use the best data architecture patterns for problemsUnderstand when and how to choose Java tools for a data architectureBuild batch and real-time data engineering solutions using JavaDiscover how to apply security and governance to a solutionMeasure performance, publish benchmarks, and optimize solutionsEvaluate, choose, and present the best architectural alternativesUnderstand how to publish Data as a Service using GraphQL and a REST APIWho this book is forData architects, aspiring data architects, Java developers and anyone who wants to develop or optimize scalable data architecture solutions using Java will find this book useful. A basic understanding of data architecture and Java programming is required to get the best from this book.","","9781801072083","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163375.pdf&bkn=10163375&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Data Preservation Process in Big Data Environment using Open Archival Information System","K. N. Rahmanto; M. Riasetiawan","Department of Computer Sciences and Electronics, Universitas Gadjah Mada, Yogyakarta, Indonesia; Department of Computer Sciences and Electronics, Universitas Gadjah Mada, Yogyakarta, Indonesia",2018 4th International Conference on Science and Technology (ICST),"11 Nov 2018","2018","","","1","5","Data preservation deals with ensuring that digital data stored today can be read and interpreted tens or hundreds of years from now. As the amount of data that needs to be preserved has been growing significantly, thus a standardized preservation process into big data environment is required. One of the standardized process recognized by ISO 14721:2012 is Open Archival Information System (OAIS). This research proposed a framework for data preservation process in big data architecture by using OAIS main components: Ingest, Archival Storage, Preservation Planning, Access, and Data Management. Based on the analysis, four out of five OAIS main components working in the proposed framework in the big data environment, which are Archival Storage, Preservation Planning, Data Management, and Access.","","978-1-5386-5813-0","10.1109/ICSTC.2018.8528669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528669","data preservation;big data;data archiving;longterm data;Open Archival Information System","Big Data;Planning;Cloud computing;Media;Metadata;Computer architecture","","4","","9","IEEE","11 Nov 2018","7-8 Aug. 2018","7-8 Aug. 2018","IEEE","IEEE Conferences"
"Research on Financial Information Integration of Agricultural Supply-Side Structural Reform in Heilongjiang Province Under the Framework of Big Data","H. Wang",HARBIN FINANCE UNIVERSITY,2019 International Conference on Virtual Reality and Intelligent Systems (ICVRIS),"5 Dec 2019","2019","","","299","302","Aiming at the low efficiency of financial information integration in agricultural supply-side structural reform caused by existing technologies, this paper studies the financial information integration of agricultural supply-side structural reform in Heilongjiang province under the framework of big data. The web extraction model is used to extract financial information of agricultural supply-side structural reform in Heilongjiang province from various web pages, and the extracted XML data files are sorted to remove the repetitive financial information. The sorted financial information is mapped to the database according to the set mapping rules. Clustering algorithm is used to integrate financial information data in database. In order to verify the research effect of financial information data integration under big data architecture, a comparative experiment is conducted with traditional information integration. The experimental results show that the proposed financial information integration efficiency of agricultural supply-side structural reform in Heilongjiang province under the big data framework is nearly 30% higher than the traditional integration efficiency, which is more advantageous.","","978-1-7281-5050-5","10.1109/ICVRIS.2019.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8921390","big data;agricultural supply-side structural reform;financial information integration","Data mining;Databases;Big Data;XML;Data models;Standards;Web pages","","","","10","IEEE","5 Dec 2019","14-15 Sept. 2019","14-15 Sept. 2019","IEEE","IEEE Conferences"
"Edge Computing with Big Data Cloud Architecture: A Case Study in Smart Building","C. Inibhunu; C. McGregor","Ontario Tech University, Oshawa, Ontario, Canada; Ontario Tech University, Oshawa, Ontario, Canada",2020 IEEE International Conference on Big Data (Big Data),"19 Mar 2021","2020","","","3387","3393","The growth of buildings embedded with technologies that can monitor the internal building environment with respect to energy consumption such as heating, ventilation, air conditioning, wind, motion as well occupancy have an immense potential. From energy management, occupancy administration, security maintenance as well as improving the health and quality of life for humans in indoor or outdoor spaces. These potentials can be realized by a clear understanding of the interplay between vast environmental conditions, humans and their health as well as the many smart products they interact with in their lives. This is a complex process that requires thorough testing and evaluation within smart buildings simulation environments where multiple buildings data can be generated and then effectively analyzed. This can be facilitated by a robust data management process that utilizes big data computing technologies to harness large volumes, variety and velocity of data that can be captured within smart buildings while maintain the security and privacy of data sources.In this paper we describe a smart building architecture that has been designed and developed for management of data from a smart building. In particular the architecture enables acquisition, processing and distribution of simulated environmental building data to multiple consumers and workflows for further processing and analysis locally and in a high performance cloud computing platform. The research premise is that such an architecture enables effective management of multiple data sources within climatic based simulated testing in smart buildings to further research.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9377918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377918","Climatic Facilities;Smart Buildings Simulations;Big Data Architecture;IoT Cloud Frameworks;Edge Computing","Cloud computing;Smart buildings;Architecture;Computer architecture;Big Data;Data models;Testing","","7","","13","IEEE","19 Mar 2021","10-13 Dec. 2020","10-13 Dec. 2020","IEEE","IEEE Conferences"
"An Improved Hybrid Data Warehousing Architecture for Cloud Service Providers","R. Gholivand; P. Goudarzi; D. Maleki","Dept. of Information Technology, ICT Research Institute, Tehran, Iran; Dept. of Information Technology, ICT Research Institute, Tehran, Iran; Dept. of Information Technology, ICT Research Institute, Tehran, Iran","2025 29th International Computer Conference, Computer Society of Iran (CSICC)","24 Apr 2025","2025","","","1","5","Traditional Data Warehouses (DWHs) are inefficient for handling the growing volume, variety, and velocity of modern data. This paper introduces a novel hybrid data warehousing architecture designed for cloud service providers (CSPs), which integrates the strengths of Data Warehouses, Data Lakes, and Data Marts into a unified framework. This innovative architecture enables seamless integration and processing of structured, semi-structured, and unstructured data, addressing the challenges posed by diverse data types in cloud environments. Unlike traditional approaches that treat data processing in isolation, the proposed architecture supports both real-time and batch processing within a single system, improving query performance and facilitating dynamic decision-making. The architecture's flexibility allows it to efficiently manage large datasets and adapt to fluctuating workloads. A key feature of this system is its focus on scalability, security, and real-time analytics, making it particularly suitable for CSPs across service models such as IaaS, PaaS, and SaaS. The proposed hybrid repository model significantly enhances data governance and ensures robust data protection. By unifying different data storage models, it optimizes storage management and streamlines data access.","","979-8-3315-2311-4","10.1109/CSICC65765.2025.10967465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967465","DWH;ETL;ELT;OLAP;Data Lake;CSP;Data mart","Warehousing;Memory;Computer architecture;Data warehouses;Big Data applications;Data models;Real-time systems;Service-oriented architecture;Data governance;Computer security","","1","","37","IEEE","24 Apr 2025","5-6 Feb. 2025","5-6 Feb. 2025","IEEE","IEEE Conferences"
"An IoT Cloud and Big Data Architecture for the Maintenance of Home Appliances","P. Chaves; T. Fonseca; L. L. Ferreira; B. Cabral; O. Sousa; A. Oliveira; J. Landeck","School Of Engineering of the Politechnical Institute of Porto, Porto, Portugal; School Of Engineering of the Politechnical Institute of Porto, Porto, Portugal; School Of Engineering of the Politechnical Institute of Porto, Porto, Portugal; School Of Engineering of the Politechnical Institute of Porto, Porto, Portugal; School Of Engineering of the Politechnical Institute of Porto, Porto, Portugal; Cleanwatts, Coimbra, Portugal; University of Coimbra, Coimbra, Portugal",IECON 2022 – 48th Annual Conference of the IEEE Industrial Electronics Society,"9 Dec 2022","2022","","","1","6","Billions of interconnected Internet of Things (IoT) sensors and devices collect tremendous amounts of data from real-world scenarios. Big data is generating increasing interest in a wide range of industries. Once data is analyzed through compute-intensive Machine Learning (ML) methods, it can derive critical business value for organizations. Powerful platforms are essential to handle and process such massive collections of information cost-effectively and conveniently. This work introduces a distributed and scalable platform architecture that can be deployed for efficient real-world big data collection and analytics. The proposed system was tested with a case study for Predictive Maintenance of Home Appliances, where current and vibration sensors with high acquisition frequency were connected to washing machines and refrigerators. The introduced platform was used to collect, store, and analyze the data. The experimental results demonstrated that the presented system could be advantageous for tackling real-world IoT scenarios in a cost-effective and local approach.","2577-1647","978-1-6654-8025-3","10.1109/IECON49645.2022.9968580","European Regional Development Fund; European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9968580","Internet of Things;Big Data;Analytics;Cloud Computing;Machine Learning;Predictive Maintenance","Vibrations;Cloud computing;Scalability;Pipelines;Computer architecture;Big Data;Sensor systems","","3","","16","IEEE","9 Dec 2022","17-20 Oct. 2022","17-20 Oct. 2022","IEEE","IEEE Conferences"
"A Big Data Financial Information Management Architecture for Global Banking","A. Munar; E. Chiner; I. Sales","GFT Group, Valencia, Spain; GFT Group, Valencia, Spain; GFT Group, Valencia, Spain",2014 International Conference on Future Internet of Things and Cloud,"15 Dec 2014","2014","","","385","388","Global investment banks and financial institutions are facing growing data processing demands. These originate not only from increasing regulatory requirements and an expanding variety and disparity of data sources, but also from ongoing pressures in cost reduction without compromising system scalability and flexibility. In this context, the ability to apply promising state-of-the-art big data technologies to extract the maximum value from the vast amounts of the data generated is generating a lot of interest in the financial services industry. In this paper we present a Big Data architecture system design, based in open distributed computing paradigms like Hadoop map-reduce, offering horizontal scalability and no-SQL flexibility while at the same time meeting the stringent quality and resilience requirements of the banking software standards. The proposed architecture is able to consolidate, validate, enrich and process with different Big Data analytics techniques the data gathered from the different source systems as encountered in the banking practice, while at the same time supporting the different data integration, transmission and process orchestration requirements traditionally encountered in a global financial institution.","","978-1-4799-4357-9","10.1109/FiCloud.2014.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984224","financial information;big data analytics;big data architectures;map-reduce;hadoop","Data models;Banking;Reliability;Big data;Distributed databases","","12","","8","IEEE","15 Dec 2014","27-29 Aug. 2014","27-29 Aug. 2014","IEEE","IEEE Conferences"
"A Lakehouse Architecture for the Management and Analysis of Heterogeneous Data for Biomedical Research and Mega-biobanks","E. Begoli; I. Goethert; K. Knight","Oak Ridge National Laboratory (ORNL), Oak Ridge, Tennessee, USA; Oak Ridge National Laboratory (ORNL), Oak Ridge, Tennessee, USA; Oak Ridge National Laboratory (ORNL), Oak Ridge, Tennessee, USA",2021 IEEE International Conference on Big Data (Big Data),"13 Jan 2022","2021","","","4643","4651","Data Lakehouse is a new paradigm in data architectures that embodies and integrates already established concepts for the systematic management of disparate, large-scale data – a data lake for heterogeneous data management, use of open standards for high-performance querying, and systematic maintenance of the data ""freshness"". In addition to being a new concept, the data lakehouse is also still a conceptual construct. Many projects that use the lakehouse require maturing, empirical studies, and specific implementations. In this paper, we present our implementation of the data lakehouse concept in a biomedical research and health data analytics domain, and we discuss the implementation of some unique and novel features such as support for specialized access controls in support of HIPAA regulation and IRB protocols, and support for the FAIR standard.1","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671534","Battelle; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671534","","Access control;Systematics;Protocols;Data analysis;Data integrity;Conferences;Maintenance engineering","","26","","20","IEEE","13 Jan 2022","15-18 Dec. 2021","15-18 Dec. 2021","IEEE","IEEE Conferences"
"Machine learning approaches on map reduce for Big Data analytics","J. V. N. Lakshmi; A. Sheshasaayee","Research Department of Computer Science, SCSVMV University, Kanchipuram, Tamil Nadu, India; Research Department of Computer Science, SCSVMV University, Kanchipuram, Tamil Nadu, India",2015 International Conference on Green Computing and Internet of Things (ICGCIoT),"14 Jan 2016","2015","","","480","484","To analyze enormous datasets, collection of algorithms, associated systems and perform necessary processing on massive data structures there is obligation for a novel trend, which is framed by Big Data. Architecture of Big Data varies across compound machines and clusters with unique purpose sub systems. The data produced from several sources requires analysis and organization with meager amounts of time. To potentially speed up the processing, a unified way of machine learning is applied on MapReduce frame work. A broadly applicable programming model MapReduce is applied on different learning algorithms belonging to machine learning family for all business decisions. By using ML algorithms with Hadoop for better storage distribution will improve the time and processing speed. This paper presents parallel implementation of various machine learning algorithms implemented on top of MapReduce model for time and processing efficiency.","","978-1-4673-7910-6","10.1109/ICGCIoT.2015.7380512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7380512","Big Data;Hadoop;MapReduce;Machine Learning;Machine Learning Algorithms","Machine learning algorithms;Clustering algorithms;Data models;Big data;Computational modeling;Computer architecture;Algorithm design and analysis","","6","","20","IEEE","14 Jan 2016","8-10 Oct. 2015","8-10 Oct. 2015","IEEE","IEEE Conferences"
"A Big Data Architecture for Security Data and Its Application to Phishing Characterization","P. H. B. Las-Casas; V. S. Dias; W. Meira; D. Guedes","Computer Science Department, Universidade Federal de Minas Gerais; Computer Science Department, Universidade Federal de Minas Gerais; Computer Science Department, Universidade Federal de Minas Gerais; Computer Science Department, Universidade Federal de Minas Gerais","2016 IEEE 2nd International Conference on Big Data Security on Cloud (BigDataSecurity), IEEE International Conference on High Performance and Smart Computing (HPSC), and IEEE International Conference on Intelligent Data and Security (IDS)","4 Jul 2016","2016","","","36","41","As the Internet grows, cybersecurity problems also arise. Different types of malicious activities have been explored by attackers. However, the existent defense mechanisms are not able to completely end the malicious threats, perpetuating this continuous arms race. The development of applications to mitigate those threats presents some complicating factors such as the growth in the amount of data, and the variety of data, that can come from different sources. In this paper we present an architecture built on top of Big Data frameworks that aims to mitigate cybersecurity problems such as spam and phishing and we show how it is being used to study spam and phishing collected using a global honeynet.","","978-1-5090-2403-2","10.1109/BigDataSecurity-HPSC-IDS.2016.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502261","architecture;cybersecurity;spam;phishing;hadoop;spark","Sparks;Big data;Computer architecture;Computer security;Electronic mail;Scalability","","12","","13","IEEE","4 Jul 2016","9-10 April 2016","9-10 April 2016","IEEE","IEEE Conferences"
"Towards social network analytics for understanding and managing enterprise data lakes","A. Farrugia; R. Claxton; S. Thompson","Big Data Research, BT, Ipswich, UK; Big Data Research, BT, Ipswich, UK; Big Data Research, BT, Ipswich, UK",2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),"24 Nov 2016","2016","","","1213","1220","We have built a tool for inspecting and managing data lakes. The motivations for creating this tool are 1) schema discovery (determining links pertinent to solving a data analysis problem), 2) discovering high risk links in data schemas that give rise to Information Security problems and 3) discovering high value relationships enabling data asset curation. The tool works by extracting metadata from the Hive database on a shared-tenancy instance of Hadoop, which contained a multi-terabyte real-world data asset. We use this metadata to calculate a graph of the relationships between the entities based on column matching. This allows us to apply Social Network Analysis (SNA) techniques in order to discover meaningful properties of the accumulated data. For example to extract previously unknown relationships between data entities. The challenges and the agenda for future research are also provided.","","978-1-5090-2846-7","10.1109/ASONAM.2016.7752393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7752393","Data Lake;Database;Data Warehouse;Big Data;Privacy;Data Discovery;Social Network Analysis","Lakes;Social network services;Data mining;Big data;Organizations;Databases","","11","","24","IEEE","24 Nov 2016","18-21 Aug. 2016","18-21 Aug. 2016","IEEE","IEEE Conferences"
"Health Data Information Retrieval For Improved Simulation","M. Ciampi; G. D. Pietro; E. Masciari; S. Silvestri","Institute for High Performance Computing and Networking of the National Research Council of Italy Via Pietro Castellino, 111, Naples, Italy; Institute for High Performance Computing and Networking of the National Research Council of Italy Via Pietro Castellino, 111, Naples, Italy; Institute for High Performance Computing and Networking of the National Research Council of Italy Via Pietro Castellino, 111, Naples, Italy; Institute for High Performance Computing and Networking of the National Research Council of Italy Via Pietro Castellino, 111, Naples, Italy","2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)","14 May 2020","2020","","","364","368","In this paper we propose an architecture specifically devoted to the analysis of huge natural language biomedical textual collections, with the purpose of searching for semantic similarity in order to obtain useful hints for effective simulation that could help physicians in diagnosis tasks. We leverage Word Embedding models trained with word2vec algorithm and a Big Data architecture for their processing and management. We performed some preliminary analyses using a dataset extracted from the whole PubMed library and we developed a web front-end to show the usability of this methodology in a real context.","2377-5750","978-1-7281-6582-0","10.1109/PDP50117.2020.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092346","Medical Information Retrieval;Big Data Architecture;Semantic Search","Big Data;Semantics;Medical services;Tools;Data mining;Biological system modeling;Data models","","1","","17","IEEE","14 May 2020","11-13 March 2020","11-13 March 2020","IEEE","IEEE Conferences"
"Universal Data Model as a Way to Build Multi-Paradigm Data Lakes","A. A. Sukhobokov; Y. E. Gapanyuk; A. A. Vetoshkin; A. R. Mironova; D. R. Nikolskiy; M. A. Morozevich; N. A. Klyukin; R. A. Afanasev; D. S. Lakhvich","SAP America, Inc., Newtown Square, USA; Dep. Information Processing and Management Systems, Bauman Moscow State Technical University, Moscow, Russia; Dep. Information Processing and Management Systems, Bauman Moscow State Technical University, Moscow, Russia; Dep. Information Processing and Management Systems, Bauman Moscow State Technical University, Moscow, Russia; Dep. of Automated and Computer Systems, Voronezh State Technical University, Voronej, Russia; Dep. Information Processing and Management Systems, Bauman Moscow State Technical University, Moscow, Russia; Dep. Information Processing and Management Systems, Bauman Moscow State Technical University, Moscow, Russia; OZON Marketplace Kazakhstan LLP, Almaty, Kazakhstan; Uzum Market, Toshkent, Uzbekistan",2024 9th International Conference on Big Data Analytics (ICBDA),"30 Jul 2024","2024","","","203","211","The paper focuses on data lakes building that combine all data from different models stored and processed across the enterprise in both OLAP and OLTP modes. As a test of this idea, an experiment was conducted to evaluate the performance of a multi-paradigm data lake built on a single SparkSQL-HDFS platform against 4 specialized DBMSs that contained the same data. The experiment showed that such a solution is possible, but further experimentation on a larger amount of data and using unstructured data is needed to confirm. As a further development of the idea of creating multi-paradigm data lakes on a single technological platform, the article proposes the concept of a universal data model. It is based on the archigraph structure supporting graph, tabular and multidimensional data representation, text documents, and Search Engine search index. Unlike the first multi-paradigm data lake experiment, the second one develops a metagraph DBMS as a unified technology platform. The architecture of the data lake management system built on the universal model basis is developed with its use, and the variant of representation of the archigraph data describing the lake structure in the metagraph DBMS is given. The article is furthered by, the paper briefly describes an ongoing project to build a data lake management system using a universal data model, and a planned experiment to evaluate the performance and scalability of the implemented data lake construction method.","","979-8-3503-5296-2","10.1109/ICBDA61153.2024.10607189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10607189","data lake;universal data model;multidimensional cube;table;archigraph;search index;metagraph","Measurement;Adaptation models;Scalability;Merging;Lakes;Search engines;Big Data applications","","3","","36","IEEE","30 Jul 2024","16-18 March 2024","16-18 March 2024","IEEE","IEEE Conferences"
"Solution for detecting sensitive data inside a data lake","S. Tovernić; V. Banović; Z. Hrastić; K. Plantić; A. Šandić; M. Baranović","Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia","2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","2 Jul 2018","2018","","","1284","1288","This paper is the result of a project realized by a team of current master's degree students. The team created an algorithm for recognition of sensitive data, primarily name, surname and OIB (Croatian personal identification number). Same algorithm iterates across given unstructured texts and appoints tags for documents considering the existence of specific sensitive data. This process offers a way for companies to narrow down the search for personal information if a client demands removal of his data. Similar algorithm was implemented for working with server logs as well, which are represented as data streams and analysed in real time. To provide insight on the quantity of sensitive information and how it is distributed across different types of documents the team created a dashboard that shows statistical data accumulated by developed algorithms. The solution is stored on Cloudera, Apache Hadoop-based open source platform designed for data management and analytics, which is deployed on Microsoft Azure cloud infrastructure.","","978-953-233-095-3","10.23919/MIPRO.2018.8400232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400232","","Electric potential;Software algorithms;Semantics;Tagging;Software;Real-time systems;Teamwork;Microelectronics;Information and communication technology;Servers","","6","","20","","2 Jul 2018","21-25 May 2018","21-25 May 2018","IEEE","IEEE Conferences"
"A Global Manufacturing Big Data Ecosystem for Fault Detection in Predictive Maintenance","W. Yu; T. Dillon; F. Mostafa; W. Rahayu; Y. Liu","Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia",IEEE Transactions on Industrial Informatics,"8 Jan 2020","2020","16","1","183","192","Artificial intelligence, big data, machine learning, cloud computing, and Internet of Things (IoT) are terms which have driven the fourth industrial revolution. The digital revolution has transformed the manufacturing industry into smart manufacturing through the development of intelligent systems. In this paper, a big data ecosystem is presented for the implementation of fault detection and diagnosis in predictive maintenance with real industrial big data gathered directly from large-scale global manufacturing plants, aiming to provide a complete architecture which could be used in industrial IoT-based smart manufacturing in an industrial 4.0 system. The proposed architecture overcomes multiple challenges including big data ingestion, integration, transformation, storage, analytics, and visualization in a real-time environment using various technologies such as the data lake, NoSQL database, Apache Spark, Apache Drill, Apache Hive, OPC Collector, and other techniques. Transformation protocols, authentication, and data encryption methods are also utilized to address data and network security issues. A MapReduce-based distributed PCA model is designed for fault detection and diagnosis. In a large-scale manufacturing system, not all kinds of failure data are accessible, and the absence of labels precludes all the supervised methods in the predictive phase. Furthermore, the proposed framework takes advantage of some of the characteristics of PCA such as its ease of implementation on Spark, its simple algorithmic structure, and its real-time processing ability. All these elements are essential for smart manufacturing in the evolution to Industry 4.0. The proposed detection system has been implemented into the real-time industrial production system in a cooperated company, running for several years, and the results successfully provide an alarm warning several days before the fault happens. A test case involving several outages in 2014 is reported and analyzed in detail during the experiment section.","1941-0050","","10.1109/TII.2019.2915846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710319","Big data analytics;cloud computing;fault detection;Internet of Things (IoT);Industry 4.0;manufacturing ecosystem;predictive maintenance (PdM)","Big Data;Manufacturing;Predictive maintenance;Ecosystems;Computer architecture;Real-time systems;Cloud computing","","193","","28","IEEE","9 May 2019","Jan. 2020","","IEEE","IEEE Journals"
"Sustainability Is Not Enough: Towards AI Supported Regenerative Design","T. Kadar; M. Kadar","Central Saint Martins, University of the Arts, London, UK; Department of Computer Science and Engineering, “1 Decembrie 1918” University of Alba Iulia, Alba Iulia, Romania","2020 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)","16 Sep 2020","2020","","","1","6","Sustainability, to describe it in simpler words, is a process of making things less bad. It is not a long-term solution even if it limits the destruction of the environment to a manageable level. Nevertheless, by just becoming sustainable, one cannot bring back what has been lost. The restoration approach is immediately required to fixing what has been broken by using renewable energy, reforestation and creating biodiversity gains. Redesigning our industrial system of production and consumption around the circular patterns of resource and energy use that we observe in mature ecosystems is a must and a complex endeavour. To create a truly regenerative economy challenges us to work with huge amounts of data. New techniques of data science and artificial intelligence are required in each step of the ecological design. This paper presents some examples of biomimicry in circular design and proposes techniques that integrate data science and artificial intelligence (AI) as tools to accelerate the transition towards the regenerative approach. AI, as an emergent `Fourth Industrial Revolution' technology, can support and accelerate the pace of human innovation to design the future urban developments, to enable innovation in cities. AI has the capability to create a step change, to support an effective economic system that is regenerative by design.","","978-1-7281-7037-4","10.1109/ICE/ITMC49519.2020.9198554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9198554","circular design;regenerative economy;big data;artificial intelligence;future cities","Artificial intelligence;Buildings;Urban areas;Big Data;Architecture;Sustainable development;Technological innovation","","10","","20","IEEE","16 Sep 2020","15-17 June 2020","15-17 June 2020","IEEE","IEEE Conferences"
"A practical approach with big data analysis for customer-driven network optimization","C. -Y. Yang; G. -D. Tsai; D. -W. Perng","Chunghwa Telecom. Laboratories, Taiwan; Chunghwa Telecom. Laboratories, Taiwan; Chunghwa Telecom. Laboratories, Taiwan",2019 20th Asia-Pacific Network Operations and Management Symposium (APNOMS),"7 Nov 2019","2019","","","1","3","In this paper we present a practical approach to evaluate customer experience index using big data analysis from data lake which collects data from LTE eNodeBs' user-based trace data. We also present a way to identify which network factors react on customer experience with poor service and how we can do on customer-driven networking optimization via network reaction factors data.","2576-8565","978-4-88552-320-5","10.23919/APNOMS.2019.8892992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892992","customer experience index;network optimization;big data analysis","Big Data applications;Indexes;Optimization;Long Term Evolution","","1","","7","","7 Nov 2019","18-20 Sept. 2019","18-20 Sept. 2019","IEEE","IEEE Conferences"
"Process Formalization Proposal for Data Ingestion in a Data Lake","J. Lagos; A. Cravero","Depto. Cs. De la Computación e Informática, Universidad de La Frontera, Temuco, Chile; Depto. Cs. De la Computación e Informática, Universidad de La Frontera, Temuco, Chile",2022 41st International Conference of the Chilean Computer Science Society (SCCC),"4 Jan 2023","2022","","","1","8","The article presents an experience of “Process Formalization” in a consulting and software development company that provides services to the banking industry. The Formalization consists of proposing the components required for the ingestion process in a Data Lake, providing a framework and an evaluation framework. The components are represented graphicallythrough Feature Model, pointing out the mandatory and optional components of an Data Ingestion, as well as a non-restrictive set of available technologies for each feature. The paper describes the development of the proposal and lessons learned.","2691-0632","978-1-6654-5674-6","10.1109/SCCC57464.2022.10000366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10000366","Data Lake;Ingestion;Architecture;Process Formalization","Big Data applications;Software;Silicon;Proposals;Data warehouses;Data visualization;Computer science","","2","","","IEEE","4 Jan 2023","21-25 Nov. 2022","21-25 Nov. 2022","IEEE","IEEE Conferences"
"A Human-in-the-Loop Anomaly Detection Architecture for Big Traffic Data of Cellular Network","S. Liu; Y. Xia; D. Wang","Big Data Center, State Grid Corporation of China, Beijing, China; Big Data Center, State Grid Corporation of China, Beijing, China; Big Data Center, State Grid Corporation of China, Beijing, China",IEEE Access,"25 Mar 2024","2024","12","","41787","41797","In the era of mobile big data, smart mobile devices have become an integral part of our daily life, which brings many benefits to the digital society. However, their popularity and relatively lax security make them vulnerable to various cyber threats. Traditional network traffic analysis techniques utilizing pattern matching and regular expressions matching algorithms are becoming insufficient for mobile big data. Network traffic anomaly detection is an effective method to replace traditional methods. Network traffic anomaly detection can solve many new challenges brought by future network and protect the security of network. In this article, we propose a streaming network framework for mobile big data, referred to as SNMDF, which provides massive data traffic collection, processing, analysis, and updating functions, to cope with the tremendous amount of data traffic. In particular, by analyzing the specific characteristics of anomaly traffic data from flow and user behavior, our proposed SNMDF demonstrates its capability to offer real data-based advice to address new challenges for future wireless networks from the viewpoints of operators. Tested by real mobile big data, SNMDF has proven its efficiency and reliability. Furthermore, SNMDF is accessed for the digital twin of the space Internet, which validates that it can be generalized to other environments with massive data traffic or big data.","2169-3536","","10.1109/ACCESS.2024.3376413","Science and Technology Project of Big Data Center of State Grid Corporation of China(grant numbers:SGSJ0000HGJS2310029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10471346","Cyber threats;network traffic;network security;big data;SNMDF","Human in the loop;Threat assessment;Telecommunication traffic;Network security;Big Data;Monitoring;Anomaly detection;Malware;6G mobile communication;Digital twins","","3","","27","CCBYNCND","18 Mar 2024","2024","","IEEE","IEEE Journals"
"Toward a Big Data Architecture for Security Events Analytic","L. Fetjah; K. Benzidane; H. E. Alloussi; O. E. Warrak; S. Jai-Andaloussi; A. Sekkaki","Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco",2016 IEEE 3rd International Conference on Cyber Security and Cloud Computing (CSCloud),"18 Aug 2016","2016","","","190","197","Cloud Computing did come up with so many attractive advantages such as scalability, flexibility, accessibility, rapid application deployment, and user self service. However in hindsight, Cloud Computing makes ensuring security within these environments so much challenging. Therefore traditional security mechanisms such as firewalls and antivirus softwares have proven insufficient and incapable of dealing with the sheer amount of data and events generated within a Cloud infrastructure. Herein, we present a highly scalable module based system that relies upon Big Data techniques and tools providing a comprehensive solution to process and analyze relevant events (packets flow, logs files) in order to generate an informative decisions that will be handled accordingly and swiftly.","","978-1-5090-0946-6","10.1109/CSCloud.2016.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545918","Cloud Computing;Security Information and Event Management (SIEM);Security Intelligence;Big Data;Hadoop;Spark;ITIL;SKMS","Security;Big data;Cloud computing;Sparks;Organizations;Context;Correlation","","7","","16","IEEE","18 Aug 2016","25-27 June 2016","25-27 June 2016","IEEE","IEEE Conferences"
"Research on Technology and Industry Situation of Lakehouse","Y. Liu; P. Ma; J. Tian","China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China","2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","29 May 2024","2023","","","2198","2203","The concept of ""Lakehouse"" was proposed by Databricks in 2020. Since ""Lakehouse"" was first written into Gartner’s Hype Cycle for Data Management in 2021, as a new technology, ""Lakehouse"" has received unprecedented attention from the enterprises who need digital transformation. More enterprises believe lakehouse is an important infrastructure for digital transformation. Currently, lakehouse is still in its early stage of development. It is not merely a technical research endeavor, but rather a gradual integration of technologies, representing a transitional phase in the evolution of heterogeneous data platform towards integration. This paper focuses on the lakehouse technology, sorts out the development history of the data platform and the practice path of lakehouse technology. It also lists main manufactures and products of lakehouse and provides the judgments for the future development of lakehouse.","2324-9013","979-8-3503-8199-3","10.1109/TrustCom60117.2023.00308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10538987","data platform;data warehouse;data lake;lakehouse","Industries;Data privacy;Digital transformation;Security;History","","5","","38","IEEE","29 May 2024","1-3 Nov. 2023","1-3 Nov. 2023","IEEE","IEEE Conferences"
"Data Lakehouse Architecture in Healthcare: Implementation and Applications","S. Mohamed Shaffi; S. Vengathattil; J. Mehta","Professional Services, Amazon Web Services, Seattle, WA, USA; Academia & Govt, Clarivate Analytics, Philadelphia, PA, USA; Amazon Air - Corporate Amazon, Seattle, WA, USA",2025 8th International Symposium on Big Data and Applied Statistics (ISBDAS),"21 Aug 2025","2025","","","308","319","This paper presents a comprehensive analysis of Data Lakehouse Architecture implementation and applications in healthcare. It addresses the challenges of managing exponential health care data growth while ensuring regulatory compliance, data security, and operational efficiency. The study demonstrates significant improvements, including 42% reduction in data retrieval time, 35% improvement in patient outcomes, and 28% reduction in diagnosis times [34]. The paper outlines an implementation framework with advanced security measures to address cybersecurity threats [2], and explores the integration of AI, machine learning, and real-time processing within the data lakehouse [3], [4]. Examining the impact on key stakeholders, this research provides health care organizations with actionable insights for modernizing their data infrastructure while ensuring HIP AA compliance through automated PHI protection and privacy-preserving techniques [5]. As the healthcare predictive analytics market is projected to reach USD 184.58 billion by 2032 [7], this work positions the data lakehouse as a transformative solution for the future of data-driven healthcare.","","979-8-3315-0719-0","10.1109/ISBDAS64762.2025.11116832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11116832","Health care Data Lakehouse;Medical Data Architecture;Healthcare Analytics;Clinical Data Integration;HIPAA-Compliant Data Management;Real-time Health care Analytics;AI in Healthcare","Technological innovation;Data integration;Medical services;Organizations;Machine learning;Data retrieval;Real-time systems;Stakeholders;Predictive analytics;Protection","","","","34","IEEE","21 Aug 2025","28 Feb.-2 March 2025","28 Feb.-2 March 2025","IEEE","IEEE Conferences"
"Building a network highway for big data: architecture and challenges","X. Yi; F. Liu; J. Liu; H. Jin","Services Computing Technology and System Lab, Huazhong University of Science and Technology; Services Computing Technology and System Lab, Huazhong University of Science and Technology; Simon Fraser University.; Services Computing Technology and System Lab, Huazhong University of Science and Technology",IEEE Network,"24 Jul 2014","2014","28","4","5","13","Big data, with their promise to discover valuable insights for better decision making, have recently attracted significant interest from both academia and industry. Voluminous data are generated from a variety of users and devices, and are to be stored and processed in powerful data centers. As such, there is a strong demand for building an unimpeded network infrastructure to gather geologically distributed and rapidly generated data, and move them to data centers for effective knowledge discovery. The express network should also be seamlessly extended to interconnect multiple data centers as well as interconnect the server nodes within a data center. In this article, we take a close look at the unique challenges in building such a network infrastructure for big data. Our study covers each and every segment in this network highway: the access networks that connect data sources, the Internet backbone that bridges them to remote data centers, as well as the dedicated network among data centers and within a data center. We also present two case studies of real-world big data applications that are empowered by networking, highlighting interesting and promising future research directions.","1558-156X","","10.1109/MNET.2014.6863125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6863125","","Big data;Streaming media;Distributed databases;Internet;Wireless communication;Network architecture;Wireless sensor networks","","144","","18","IEEE","24 Jul 2014","July-August 2014","","IEEE","IEEE Magazines"
"A fully integrated open-source toolkit for mining healthcare big-data: architecture and applications","A. R. Rao; D. Clarke","Fairleigh Dickinson University, NJ, USA; Fairleigh Dickinson University, NJ, USA",2016 IEEE International Conference on Healthcare Informatics (ICHI),"8 Dec 2016","2016","","","255","261","We create an analytics toolkit based on open-source modules that facilitate the exploration of healthcare-related datasets. We illustrate our framework by providing a detailed analysis of physician and hospital ratings data. Our technique should prove valuable to software developers, big-data architects, hospital administrators, policy makers and patients. As an illustration of the capabilities of our toolkit, we examine a controversial issue in the medical field regarding the relationship between seniority of medical professionals and clinical outcomes. We use a publicly available dataset of national hospital ratings in the USA to suggest that there is no significant association between experience of medical professionals and hospital ratings as defined by the US government.","","978-1-5090-6117-4","10.1109/ICHI.2016.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7776351","","Hospitals;Medical diagnostic imaging;Government;Data visualization;Data models;Surgery","","24","","27","IEEE","8 Dec 2016","4-7 Oct. 2016","4-7 Oct. 2016","IEEE","IEEE Conferences"
"Fuzzy Join for Flexible Combining Big Data Lakes in Cyber-Physical Systems","B. Małysiak-Mrozek; A. Lipińska; D. Mrozek","Institute of Informatics, Silesian University of Technology, Gliwice, Poland; Institute of Informatics, Silesian University of Technology, Gliwice, Poland; Institute of Informatics, Silesian University of Technology, Gliwice, Poland",IEEE Access,"4 Dec 2018","2018","6","","69545","69558","Cyber-physical systems produce large amounts of data that are stored in domain-related data lakes in a variety of formats. By using the big data technologies that enable efficient data processing, the value of the data increases, as these technologies can turn the data into actionable information that influences important decision-making processes. However, a broader view of the operational environment, an investigated phenomena, and challenges related to them can frequently be obtained after combining data from many data sets located in various big data lakes. This requires contact points in both data lakes that must be flexibly joined because in many cases, data sets do not correspond to one another directly. In this paper, we show fuzzy join operation for flexible combining big data lakes. The fuzzy join transforms numerical values of common attributes of joined data sets into fuzzy sets and uses such a representation in the join operation. We propose two variants of the join operation that transforms crisp numerical values of joining attributes into: 1) fuzzy numbers and 2) linguistic terms. The fuzzy join operation is implemented and tested in the declarative U-SQL language that is used for scalable and parallel querying in big data lakes. The ideas presented here are exemplified by a distributed analysis of cardiac disease data on Microsoft Azure cloud. The results of the conducted experiments confirm that the fuzzy join can enrich data sets that are used in making critical decisions and, as a highly scalable cloud-based solution, can be successfully used in processing large volumes of data delivered by cyber-physical systems.","2169-3536","","10.1109/ACCESS.2018.2879829","Microsoft Research; Habilitation Grant of the Rector of the Silesian University of Technology, Gliwice, Poland(grant numbers:02/020/RGH18/0148); Statutory Research Funds of Institute of Informatics, Silesian University of Technology(grant numbers:BK/213/RAU2/2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525267","Cyber-physical systems;big data;fuzzy logic;querying;cloud computing;biomedical data analysis;declarative languages","Lakes;Big Data;Cyber-physical systems;Cloud computing;Sensors;Monitoring;Biomedical monitoring","","17","","51","CCBY","6 Nov 2018","2018","","IEEE","IEEE Journals"
"Modeling Data Analytics Architecture for IoT Applications using DAT","M. Abughazala; H. Muccini","DISIM Department, University of L’Aquila, L’Aquila, Italy; DISIM Department, University of L’Aquila, L’Aquila, Italy",2023 IEEE 20th International Conference on Software Architecture Companion (ICSA-C),"24 Apr 2023","2023","","","284","291","Data analysis plays a significant role in extracting meaningful information from big data. Data analysis consists of acquisition, storage, management, analytics, and visualization. Providing an abstract view of data analytics applications is crucial to ensure that the data will transfer into meaningful information. Data Architecture is one of the ways to provide that. This article shows industrial experiences in building data analytics architecture (DAA). We use model-driven engineering to model a data-analytics architecture for applications using DAT. We evaluated this work by modeling Analytics Data Warehouses as a case study from one company, receiving feedback. Index Terms—Data Architecture, Modeling Data Analytics Architecture, Big Data, IoT.","2768-4288","978-1-6654-6459-8","10.1109/ICSA-C57050.2023.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10092710","Data Architecture;Modeling Data Analytics Architecture;Big Data;IoT","Analytical models;Data analysis;Software architecture;Architecture;Storage management;Computer architecture;Big Data","","6","","21","IEEE","24 Apr 2023","13-17 March 2023","13-17 March 2023","IEEE","IEEE Conferences"
"Big Data Storage","Y. Aytas",NA,"Designing Big Data Platforms: How to Use, Deploy, and Maintain Big Data Systems","","2021","","","41","61","This chapter helps the student to identify the differences between different Big Data storage patterns. Storage patterns have changed drastically with regard to data processing. The chapter explains storage patterns: data lakes, data warehouses, and data marts. The data lake can contain structured, semi‐structured, and unstructured data both from internal and external resources. The data warehouses have been widely adopted by the industry for business intelligence and analytics. An on‐premise platform can cost much less than a cloud‐based solution over the long term. Hadoop distributed file system and Hadoop ecosystem would be the choice for on‐premise big data platform. Hadoop uses the network to transfer files from clients to the DataNodes as well as MapReduce jobs. The chapter discusses capacity planning in terms of the overall cluster and resource sharing among the organization. It illustrates a basic setup for a Hadoop deployment, and reviews some of the hybrid solutions.","","9781119690948","10.1002/9781119690962.ch4","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822714.pdf&bkn=9820885&pdfType=chapter","","Data warehouses;Costs;Companies;Yarn;Memory management;Knowledge transfer;File systems","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"An open schema for XML data in Hive","W. Luo; B. Liu; A. K. Watfa","Enterprise Data Architecture, Sears Holdings, Hoffman Estates, IL, USA; Advertising and Data Platforms, Yahoo, Champaign, IL, USA; Advertising and Data Platforms, Yahoo, Champaign, IL, USA",2014 IEEE International Conference on Big Data (Big Data),"8 Jan 2015","2014","","","25","31","Big data in XML format poses a challenge to distributed data systems. This paper proposes an open Hive schema approach to XML data placement in Hadoop. Placing XML data in Hive with this generic schema to build column-oriented and OLAP-focused XML data warehouse of heterogeneous content has benefits for data access, maintenance and scalability.","","978-1-4799-5666-1","10.1109/BigData.2014.7004409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004409","Hive;Hadoop;open schema;schema-less;column-oriented;XML","XML;Distributed databases;Data models;Books;Companies;Availability;Big data","","3","","26","IEEE","8 Jan 2015","27-30 Oct. 2014","27-30 Oct. 2014","IEEE","IEEE Conferences"
"A Hybrid ETL Framework for Optimized Data Ingestion and Real-Time Processing in Data Lakehouse Architectures using AI-Driven Orchestration and Contextual Data Partitioning","K. Abirami; S. Punitha","Department of Computer and Information Science, Annamalai University, Chidambaram; Department of Computer Science, D.G.Govt.Arts College for Women, Mayiladuthurai","2025 7th International Conference on Signal Processing, Computing and Control (ISPCC)","24 Jun 2025","2025","","","1014","1020","The need for effective Extract, Transform, Load (ETL) technologies that can manage the growing volumes of both structured and unstructured data in information lakehouse architectures is increasing due to the rapid expansion of data environments. Existing ETL systems struggle with performance, scalability, and adaptability, making it difficult to handle the rising demands of both batch and real-time data processing. To address these challenges, this study proposes a novel Hybrid ETL Infrastructure that combines contextual data partitioning with AI-driven orchestration to optimize data ingestion and real-time analysis in information lakehouses. The system addresses key issues, such as inefficient data handling, slow processing times, and inadequate transformation methods, by dynamically adjusting the ETL pipeline based on user requests, context-aware partitioning, and data characteristics. The AI-driven orchestration ensures efficient job scheduling by seamlessly switching between batch and real-time processing based on data importance, thereby improving both performance and flexibility. Contextual partitioning reduces processing costs and enhances query performance by automatically organizing data according to domain-specific knowledge and query intent. The primary goal of this framework is to improve data transformation and loading performance in information lakehouses, enabling faster and more accurate decision-making. Preliminary results show a 30% reduction in ETL processing time and significant improvements in query efficiency and accuracy, particularly in complex, cross-domain data retrieval environments. The proposed approach offers a scalable, adaptable, and intelligent solution for modern data lakehouse scenarios, outperforming traditional ETL methods.","2643-8615","979-8-3315-3893-4","10.1109/ISPCC66872.2025.11039601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039601","Hybrid ETL Framework;Data Lakehouse;AI-Driven Orchestration;Contextual Data Partitioning;Real-Time Processing;Data Ingestion;Batch Processing;Data Transformation;Query Optimization;Scalable Data Architecture","Data ingestion;Accuracy;Scalability;Computer architecture;Transforms;Switches;Signal processing;Real-time systems;Scheduling;Service-oriented architecture","","","","21","IEEE","24 Jun 2025","6-8 March 2025","6-8 March 2025","IEEE","IEEE Conferences"
"A Research on Application Server-Oriented Digital Forensics in New Types of Network Crime","B. Liao; G. Chen; J. Wu; Y. Xu; Q. Liu","Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China","2022 IEEE 5th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","26 Jan 2023","2022","5","","259","265","In the process of application server investigation and evidence collection of new types of network crime, this paper summarizes the analysis of common server clusters, virtual private network servers and IP-based voice transmission servers in public security investigation and forensic identification. Based on the case analysis and the actual process of case investigation, a new type of network crime application server inspection method is proposed, which can be used to analyze new types of application servers in the process of law enforcement inspection and digital forensics practice.","2693-2776","978-1-6654-7968-4","10.1109/IMCEC55388.2022.10020140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020140","application servers;digital investigation;network crime","Strips;Digital forensics;Inspection;Search engines;Virtual private networks;Safety;Servers","","1","","15","IEEE","26 Jan 2023","16-18 Dec. 2022","16-18 Dec. 2022","IEEE","IEEE Conferences"
"Data Lake Strategy for Data Science Workflows","G. colaborativo","Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México",2022 11th International Conference On Software Process Improvement (CIMPS),"10 Feb 2023","2022","","","101","105","This paper details the research and technological strategy carried out to implement a Data Lake and Sandboxes of the Data Science Laboratory at the National Institute of Statistics and Geography (INEGI) Mexico, this project seeks to integrate digital information from different repositories, data sources internal and external, which exist by the various entities that generate statistical and geographic information, in various formats to combine them in a unified storage environment (temporary or permanent), which allows advanced processes to be carried out with techniques oriented towards analytics and data science.","","979-8-3503-9896-0","10.1109/CIMPS57786.2022.10035686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035686","data lake;sandbox;data science","Software;Context modeling;Hardware;Data science;Computational modeling;Big Data applications;Visualization","","","","","IEEE","10 Feb 2023","19-21 Oct. 2022","19-21 Oct. 2022","IEEE","IEEE Conferences"
"A flexible architecture for data mining from heterogeneous data sources in automated production systems","E. Trunzer; I. Kirchen; J. Folmer; G. Koltun; B. Vogel-Heuser","Institute of Automation and Information Systems, Technical University of Munich, Munich, Germany; Institute of Automation and Information Systems, Technical University of Munich, Munich, Germany; Institute of Automation and Information Systems, Technical University of Munich, Munich, Germany; Institute of Automation and Information Systems, Technical University of Munich, Munich, Germany; Institute of Automation and Information Systems, Technical University of Munich, Munich, Germany",2017 IEEE International Conference on Industrial Technology (ICIT),"4 May 2017","2017","","","1106","1111","Data heterogeneity and proprietary interfaces present a major challenge for big data analytics. The data generated from a multitude of sources has to be aggregated and integrated first before being evaluated. To overcome this, an automated integration of this data and its provisioning via defined interfaces in a generic data format could greatly reduce the effort for an efficient collection and preparation of data for data analysis in automated production systems. Besides, the sharing of specific data with customers and suppliers, as well as near real-time processing of data can boost the information gain from analysis. Existing approaches for automatic data integration lack the fulfillment of all these requirements. On this basis, a flexible architecture is proposed, which simplifies data integration, handling and sharing of data over organizational borders. Special focus is put on the ability to process near real-time data which is common in the field of automated production systems. An evaluation with technical experts from the field of automation was carried out by adapting the generic concept for specific use cases. The evaluation showed that the proposed architecture could overcome the disadvantages of current systems and reduce the effort spent on data integration. Therefore, the proposed architecture can be an enabler for automated data analysis of distributed data from sources with heterogeneous data formats in automated production systems.","","978-1-5090-5320-9","10.1109/ICIT.2017.7915517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7915517","Automated production systems (aPS);cyber-physical systems (CPS);data handling;data mining;data processing;knowledge management;middleware","Data models;Tools;Data mining;Computer architecture;Real-time systems;Data integration;Production systems","","22","1","21","IEEE","4 May 2017","22-25 March 2017","22-25 March 2017","IEEE","IEEE Conferences"
"Knowledge Enhanced Digital Objects: a Data Lake Approach","Y. Luo; B. Plale","School of Informatics, Computing and Engineering, Indiana University, Bloomington, IN, USA; School of Informatics, Computing and Engineering, Indiana University, Bloomington, IN, USA","2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)","19 Jul 2023","2023","","","299","301","Open science is gaining traction as a means to bring greater value to the products of research beyond the published manuscript - that is, to make data and software more accessible and usable. The FAIR principles [1] are a significant step forward in defining the characteristics needed of data for it to be shared, used, and reused.","","979-8-3503-0208-0","10.1109/CCGridW59191.2023.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10181171","Knowledge Graphs;Globally Persistent Identifiers;Data Lakes;FAIR principles","Cloud computing;Conferences;Big Data applications;Software;Object recognition","","","","7","IEEE","19 Jul 2023","1-4 May 2023","1-4 May 2023","IEEE","IEEE Conferences"
"Data Lakes: A Survey of Functions and Systems","R. Hai; C. Koutras; C. Quix; M. Jarke","Department of Software Technology, Delft University of Technology, Delft, CD, Netherlands; Department of Software Technology, Delft University of Technology, Delft, CD, Netherlands; Hochschule Niederrhein, Krefeld, Germany and Fraunhofer FIT, Hochschule Niederrhein University of Applied Sciences, Krefeld, Germany; RWTH Aachen University, Aachen, Germany",IEEE Transactions on Knowledge and Data Engineering,"7 Nov 2023","2023","35","12","12571","12590","Data lakes are becoming increasingly prevalent for Big Data management and data analytics. In contrast to traditional ‘schema-on-write’ approaches such as data warehouses, data lakes are repositories storing raw data in its original formats and providing a common access interface. Despite the strong interest raised from both academia and industry, there is a large body of ambiguity regarding the definition, functions and available technologies for data lakes. A complete, coherent picture of data lake challenges and solutions is still missing. This survey reviews the development, architectures, and systems of data lakes. We provide a comprehensive overview of research questions for designing and building data lakes. We classify the existing approaches and systems based on their provided functions for data lakes, which makes this survey a useful technical reference for designing, implementing and deploying data lakes. We hope that the thorough comparison of existing solutions and the discussion of open research challenges in this survey will motivate the future development of data lake research and practice.","1558-2191","","10.1109/TKDE.2023.3270101","Deutsche Forschungsgemeinschaft(grant numbers:390621612); European Union Horizon Programme(grant numbers:101093164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107808","Data discovery;data lake;metadata management","Big Data applications;Metadata;Lakes;Proposals;Memory;Semantics;Maintenance engineering","","79","","156","CCBYNCND","25 Apr 2023","1 Dec. 2023","","IEEE","IEEE Journals"
"DFCNI: Researching on Data-centric Framework of Cloud Network Integration for Telecom Operators","X. Li; X. Xia; H. Chu; J. Zhao; H. Yan","Big Data and Artificial Intelligence Research Institute, China Telecom Research Institute, Beijing, China; Big Data and Artificial Intelligence Research Institute, China Telecom Research Institute, Beijing, China; Xi'an University of Post and Telecommunications, Xian, China; Big Data and Artificial Intelligence Research Institute, China Telecom Research Institute, Beijing, China; Big Data and Artificial Intelligence Research Institute, China Telecom Research Institute, Beijing, China",2022 International Conference on Information Processing and Network Provisioning (ICIPNP),"20 Mar 2023","2022","","","47","51","With the rapid development of network technology and cloud computing, the data of the telecommunications industry has shown massive growth. Traditionally, telecom operators have built integrated information services with cloud and network infrastructure as the core. But data remains isolated and underutilized. The overall big data architecture and infrastructure that oriented data value circulation and integrated multiple data, technologies and resources have not really been established. So we proposes a DFCNI: Data-centric Framework of Cloud Network Integration for Telecom Operators, which can provide an innovative infrastructure for telecom operators' big data industry. We first analyzed the technical architecture, deployment scheme and key technologies of DFCNI. This architecture changes the traditional cloud resource concentration mode, and makes full use of the resource capabilities of the cloud and network through distributed computing, resource migration, virtualization and other technologies. And then we introduced a typical application scenario of DFCNI- -Smart City, Solving the problem of multi-party data fusion in this scenario under the premise of ensuring data privacy. Finally, we summarized three advantages of DFCNI and proposed future research directions including data right confirmation technology and data circulation guarantee technology based on Blockchain.","","978-1-6654-6405-5","10.1109/ICIPNP57450.2022.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10062574","Big Data;Cloud Network Integration;Data Management;Telecom Operators;Private Computing","Industries;Cloud computing;Urban areas;Information services;Computer architecture;Information processing;Big Data","","3","","19","IEEE","20 Mar 2023","15-16 Sept. 2022","15-16 Sept. 2022","IEEE","IEEE Conferences"
"Big Data Approaches for an Accurate Evaluation of Cloud-Related Technology","P. Saraswat; K. Kalsi","Department of Computer Science and Engineering, Sanskriti University, Mathura, Uttar Pradesh, India; Department of Computer Science & Engineering, Chandigarh Engineering College, Jhanjeri",2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART),"24 Feb 2023","2022","","","148","152","A modern tech that has been utilized to ramp up complex calculations and marketplace procedures in several areas is increasing computer generated. Therefore, examination of massive data sets and cloud technology are necessary for “Greater computer” (HPC) to become a reality. Considering the advantages, the research tried to identify the benefits and disadvantages both of Having people and VMware. The research utilized SEM approach to assist the procedure for integrating advanced HPC. The regression models in this investigation were examined using Spss program. Any correlation between dependent and selected variables that has a significance level of 0.05, or “meaningful,” is regarded as significant. The response variable is Income Gain, whereas the study variables are HPC there in domain and year. Depending on the outcomes, there was no significant relationship between the independent and selected variables. The variables tested are not statistically meaningful, according to the Ips data, and the modelling data likewise does not meet the criterion.","2767-7362","978-1-6654-8734-4","10.1109/SMART55829.2022.10046694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10046694","spatial data framework;big data architecture;Big Data;Cloud Computing;Statistics;Data system;Database Engine","Cloud computing;Estimation;Organizations;Market research;Spatial databases;Data models;Reliability","","","","27","IEEE","24 Feb 2023","16-17 Dec. 2022","16-17 Dec. 2022","IEEE","IEEE Conferences"
"Emotion-based social computing platform for streaming big-data: Architecture and application","L. Zhang; J. Zhao; K. Xu","State Key Lab of Software Development Environment, Beihang University, Beijing, China; School of Economics and Management, Beihang University, Beijing, China; State Key Lab of Software Development Environment, Beihang University, Beijing, China",2016 13th International Conference on Service Systems and Service Management (ICSSSM),"11 Aug 2016","2016","","","1","6","Exploration of user generated content in the epoch of Web 2.0 brings unprecedented challenge to the social computing, which has to provide real-time solution in the circumstance of massive data volumes and evolving application scenarios. This paper presents an emotion-based social computing platform namely ESC for streaming big-data. The main aim of ESC is to provide sentiment analysis as the foundation of social computing and enable both real-time computation on streaming big-data and batch computation on off-line big-data with high performance and low risk. Different from conventional data processing technologies, ESC is designed as a scalable and QoS-optimized adaptive platform for developers to only focus on business models instead of being distracted by details of the computing infrastructure. In addition, continuous streaming computing is emphasized in ESC to keep tracking on long term dynamic evolution in social media, which can provide a valuable proxy for in-depth social analytics. The architecture of ESC is implemented by distributed storage, sentiment analysis, data parallelism and routing, real-time streaming computation, batch computation and distributed machine learning. And the evaluation results from real-time and batch computations testify the high performance and scalability of ESC. Moreover, a few applications based on it further demonstrates its usability in enacting on different streaming big-data and variety of social computations.","2161-1904","978-1-5090-2842-9","10.1109/ICSSSM.2016.7538620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7538620","","Quality of service;Computer architecture;Logic gates;Reliability","","1","","14","IEEE","11 Aug 2016","24-26 June 2016","24-26 June 2016","IEEE","IEEE Conferences"
"Research on Automatic Government Data Cataloging System Based on Data Architecture and Local Large Language Model: A Case Study of Suining City","X. Zheng; F. Miao; F. Yi; J. Zhuo; B. Wen; R. Huang","School of Architecture and Civil Engineering, Suining Data Element Laboratory Chengdu University, Chengdu; The Big Data Research Institute, Suining Data Element Laboratory Chengdu University, Chengdu; The Big Data Research Institute, Suining Data Element Laboratory Chengdu University, Chengdu; The Big Data Research Institute, Suining Data Element Laboratory Chengdu University, Chengdu; The Big Data Research Institute, Suining Data Element Laboratory Chengdu University, Chengdu; The Big Data Research Institute, Chengdu University, Chengdu",2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD),"21 Jul 2025","2025","","","480","485","With the in-depth advancement of city-wide digital transformation, government departments generate massive data that is challenging to inventory and manage effectively. Traditional cataloging systems rely heavily on manual input—a time-consuming, error-prone approach that cannot adapt to dynamic data environments. Additionally, data privacy and security constraints often preclude the use of cloud-based solutions, and there is a dearth of specialized tools to automate the cataloging process. To address these issues, this paper proposes an automatic data cataloging method based on a ""One Body, Two Wings"" Data Architecture (DA) and a local large language model (L3M). In this concept, the ""One Body"" refers to a unified data foundation, while the ""Two Wings"" denote intelligent governance and secure sharing. The proposed system automatically obtains metadata and integrates knowledge graphs with semantic classification to achieve automatic directory generation, label optimization, and dynamic catalog updates. Experimental results on three government systems in Suining City (urban management, citizen card, and cloud imaging) show that the classification accuracy reaches approximately 85%, significantly reducing the manual workload and labor costs. This work demonstrates the practical potential of deploying local large language models to obtain secure, efficient, and intelligent government data governance.","2769-3554","979-8-3315-1936-0","10.1109/ICAIBD64986.2025.11082084","Chengdu University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11082084","Data Architecture;Automatic Cataloging;Local Large Language Model;Semantic Classification;Data Governance","Large language models;Government;Urban areas;Semantics;Manuals;Knowledge graphs;Metadata;Data governance;Security;Optimization","","","","7","IEEE","21 Jul 2025","23-26 May 2025","23-26 May 2025","IEEE","IEEE Conferences"
"Enterprise data architecture principles for High-Level Multi-Int fusion: A pragmatic guide for implementing a heterogeneous data exploitation framework","M. A. Solano; G. Jernigan","Space and Airborne Systems, Raytheon Advanced Device Center, Dallas, TX, USA; Space and Airborne Systems, Raytheon Advanced Device Center, Dallas, TX, USA",2012 15th International Conference on Information Fusion,"30 Aug 2012","2012","","","867","874","Databases have been an integral component of Data Fusion from the outset when the JDL model was introduced. As advances in High-Level fusion using Multi-Int data have been made, the original concept of databases as a static repository of Level 0/1 content has evolved to support heterogeneous data, and as a necessary enabler of High-Level fusion processes. Relatively recent database technologies now support specialized storage for complex content such as multi-media, geospatial, and semantic data types. Additionally, database functionality has been extended from what was once almost exclusively storage and retrieval, to include integrated forensic and predictive algorithms, as well as decision support frameworks such as the data cube. These data mining capabilities provide a rich tool-set from which to tailor a fusion application. However, due to their inherent trade-off space, they present a significant design and integration challenge when implementing an enterprise architecture, which has to provide a comprehensive and cohesive framework across the entire fusion workflow, and which has to meet the needs of various Communities-of-Interest. This paper expounds on the role of data architecture as a key discipline to help analyze and synthesize an enterprise fusion system-of-systems, and presents selected principles to maximize heterogeneous data exploitation.","","978-0-9824438-5-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6289893","Data Mining;High-Level Fusion;Data Analytics","Databases;XML;Standards;Geospatial analysis;Algorithm design and analysis;Data mining;Access control","","3","","18","","30 Aug 2012","9-12 July 2012","9-12 July 2012","IEEE","IEEE Conferences"
"Near real-time big data analysis on vehicular networks","A. Daniel; A. Paul; A. Ahmad","Kyungpook National University, Daegu, South Korea; Kyungpook National University, Daegu, South Korea; Kyungpook National University, Daegu, South Korea",2015 International Conference on Soft-Computing and Networks Security (ICSNS),"8 Oct 2015","2015","","","1","7","In this cutthroat era of 21st Century Traffic information is considered as one of the prominent valuable resources in vehicular networks for big data analysis. In order to effectively utilize the acquired resources, big data analysis in near real time will be an appropriate way to produce valuable information from raw data. In order to exhibit the importance of big data investigation, an efficient architecture has been proposed for near real time big data analysis in vehicular networks, which indeed will keep pace with the latest trends and development with respect to emerging big-data paradigm. The proposed architecture, comprises centralized data storage mechanism for batch processing and distributed data storage mechanism for streaming processing in real time analysis. Furthermore a work flow model has also been designed for big data architecture to examine streaming data in near real time process. Furthermore, an algorithm is designed for organizing the vehicle flow in a particular location or place. The proposed system model is for optimal utilization of the massive data set, meant for streaming data in near real time process intended for ITS (Intelligent Transportation System) in a vehicular environment.","","978-1-4799-1753-2","10.1109/ICSNS.2015.7292404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7292404","Centralized data storage;distributed data storage;batch processing;stream processing;ITS","Real-time systems;Big data;Vehicles;Distributed databases;Memory;Algorithm design and analysis;Data models","","10","","15","IEEE","8 Oct 2015","25-27 Feb. 2015","25-27 Feb. 2015","IEEE","IEEE Conferences"
"Design of Connected Data Lake System based on Micro Cloud Storage","S. Park; B. Cha; Y. Cha; J. Mo; S. Oh; J. Kim","School of Electrical Engineernig and Computer Science, GIST, Gwangju, South KOREA; School of Electrical Engineernig and Computer Science, GIST, Gwangju, South KOREA; Research Institute GenoTech Corporation, Gwangju, South KOREA; Research Institute GenoTech Corporation, Gwangju, South KOREA; Research Institute GenoTech Corporation, Gwangju, South KOREA; School of Electrical Engineernig and Computer Science, GIST, Gwangju, South KOREA",2018 International Conference on Information and Communication Technology Convergence (ICTC),"18 Nov 2018","2018","","","917","918","The increasing use of ICBM (IoT & Cloud & Big Data & Mobile), which is the basis of ICT diversity, has led to an increase in various large amounts of data. This increase in data is transforming the society into a data-oriented society. Edge Cloud is increasing to manage increasing data efficiently. However, it is difficult to efficiently integrate distributed data between Edge Cloud and Cloud. This paper proposes a Connected DataLake system that can solve these problems.","2162-1233","978-1-5386-5041-7","10.1109/ICTC.2018.8539510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539510","Cloud;micro cloud storage;data lake;message queue;stream processing","Cloud computing;Distributed databases;Industries;Lakes;Computer science;Scalability;Fault tolerance","","1","","6","IEEE","18 Nov 2018","17-19 Oct. 2018","17-19 Oct. 2018","IEEE","IEEE Conferences"
"An Integrated Framework for Health State Monitoring in a Smart Factory Employing IoT and Big Data Techniques","W. Yu; Y. Liu; T. Dillon; W. Rahayu; F. Mostafa","Philips Research, Shanghai, China; Department of Computer Science and Information Technology, La Trobe University, Melbourne, VIC, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, VIC, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, VIC, Australia; Enterprise Data Services, Australian Energy Market Operator, Melbourne, VIC, Australia",IEEE Internet of Things Journal,"24 Jan 2022","2022","9","3","2443","2454","With the rapid growth in the use of various smart digital sensors, the Internet of Things (IoT) is a swiftly growing technology, which has contributed significantly to Industry 4.0 and the promotion of IoT-based smart factories, which gives rise to the new challenges of big data analytics and the implementation of machine learning techniques. This article proposes a practical framework that combines IoT techniques, a data lake, data analysis, and cloud computing for manufacturing equipment health-state monitoring and diagnostics in smart manufacturing. It addresses all the required aspects in the realization of such a system and allows the seamless interchange of data and functionality. Due to the specific characteristics of IoT sensor data (low quality, redundant multisources, partial labeling), we not only provide a promising framework but also give detailed insights and pay considerable attention to data quality issues. In the proposed framework, an ingestion procedure is designed to manage data collection, data security, data transformation and data storage issues. To improve the quality of IoT big data, a high-noise feature filter is proposed for automated preliminary sensor selection to suppress noisy features, followed by a noisy data cleaning module to provide good quality data for unbiased diagnosis modeling. The proposed framework can achieve seamless integration between IoT big data ingestion from the physical factory and machine learning-based data analytics in the virtual systems. It is built on top of the Apache Spark processing engine, being capable of working in both big data and real-time environments. One case study has been conducted based on a four-stage syngas compressor from real industries, which won the Best Industry Application of IoT at the BigInsights Data & AI Innovation Awards. The experimental results demonstrate the effectiveness of both the proposed IoT-architecture and techniques to address the data quality issues.","2327-4662","","10.1109/JIOT.2021.3096637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9481251","Big data;health state monitoring;Internet of Things (IoT);noisy data cleaning;real-time systems;sensor selection","Big Data;Internet of Things;Intelligent sensors;Data analysis;Cloud computing;Smart manufacturing;Sensor phenomena and characterization","","79","","37","IEEE","12 Jul 2021","1 Feb.1, 2022","","IEEE","IEEE Journals"
"A modern data architecture with apache Hadoop","T. Singh; Darshan V S","Amrita school of engineering, Bangalore, India; Amrita school of engineering, Bangalore, India",2015 International Conference on Green Computing and Internet of Things (ICGCIoT),"14 Jan 2016","2015","","","574","579","This paper represents the analysis of the existing architecture framework used across domains. It also emphasizes on the modern architecture in integration with apache Hadoop. The existing data architecture is under pressure from new data and machine generated data for the upcoming years that is due to emergence of new data types there has been tremendous pressure on all the data systems within an enterprise over the years. An Exponential Growth has been estimated from 2.8 Zeta Byte of data in 2012 to grow to 40 Zeta Byte by 2020 and new data type growth is estimated to be eighty five percent with computer created information being expanded to 15 times all the more by 2020","","978-1-4673-7910-6","10.1109/ICGCIoT.2015.7380530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7380530","Data Architecture;Apache Hadoop;Zeta Byte;Map Reduce;Big Data","Computers;Arrays;Programming;Data analysis;Green computing;Internet of things","","3","","11","IEEE","14 Jan 2016","8-10 Oct. 2015","8-10 Oct. 2015","IEEE","IEEE Conferences"
"MinePCDet: A Big Data-Based Object Detection Method for Underground Smart Mining","R. Tian; G. Gui; R. Yang; W. Yu; Q. Guo; Y. Song","School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; National Graduate College For Elite Engineers, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; Department of Technology and Digitalization, Jinchuan Group Co.,Ltd, Jinchang, China; State Key Laboratory, Jinchuan Nickel & Cobalt Research and Engineering Institute, Jinchang, China",2025 Thirteenth International Conference on Advanced Cloud and Big Data (CBD),"4 Feb 2026","2025","","","138","143","Accurate perception of underground personnel is a cornerstone for efficient operation and safety monitoring in smart mining. However, existing detection methods face challenges in underground scenarios due to high noise, feature degradation, and the vast volume of data, resulting in insufficient accuracy and poor real-time performance. To address these issues, this paper proposes MinePCDet, a big data-based framework for underground point cloud object detection. The framework first constructs a comprehensive point cloud dataset encompassing various personnel behavioral postures and typical traffic scenarios in underground mining environments. Subsequently, a real-time adaptive object detection algorithm, SA-DBSCAN, is introduced to enhance detection accuracy and robustness in complex underground settings. Finally, a big data architecture integrating Apache Kafka is designed to enable real-time processing, multi-device scalability, historical data analysis, and anomaly tracing. Experimental results demonstrate that the proposed method achieves high detection accuracy while maintaining real-time performance and scalability, highlighting the potential of big data technologies in addressing intelligent perception applications in underground mining.","2573-301X","979-8-3315-7966-1","10.1109/CBD69312.2025.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11366760","object detection;big data;smart mining","Point cloud compression;Degradation;Accuracy;Scalability;Object detection;Big Data;Real-time systems;Robustness;Data mining;Personnel","","","","14","IEEE","4 Feb 2026","29 Nov.-1 Dec. 2025","29 Nov.-1 Dec. 2025","IEEE","IEEE Conferences"
"Model for Semantic Base Structuring of Digital Data to Support Agricultural Management","R. A. Neves; P. E. Cruvinel","Embrapa Instrumentation S??o Carlos, SP, Brazil; Embrapa Instrumentation S??o Carlos, SP, Brazil",2020 IEEE 14th International Conference on Semantic Computing (ICSC),"12 Mar 2020","2020","","","337","340","This article presents a semantic model for structuring digital databases to function in a cloud environment and connect to data sources originating from Big Data. The work examines the process of receiving structured, semi-structured and unstructured data for use in agricultural risk management. It is conceived as an architecture that combines Data Mart, Data Warehouse (NoSQL), and Data Lake resources to support decision making, through knowledge discovery and applies algorithms for data mining by machine learning resources. The configuration presented addresses scenarios involving agricultural data, obtained from sensors operating in multiple modes.","2325-6516","978-1-7281-6332-1","10.1109/ICSC.2020.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031490","semantic model, agricultural management, cloud, structuring digital databases","Semantics;Databases;Unified modeling language;Data models;Big Data;Data mining;Computer architecture","","4","","16","IEEE","12 Mar 2020","3-5 Feb. 2020","3-5 Feb. 2020","IEEE","IEEE Conferences"
"Contents","M. Beckner",NA,"Quick Start Guide to Azure Data Factory, Azure Data Lake Server, and Azure Data Warehouse","","2019","","","XI","XII","","","9781547401291","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10785617.pdf&bkn=10783667&pdfType=chapter","","Big Data applications;Buildings;Servers;Production facilities;Pipelines;Monitoring;Load modeling;Data warehouses;Data models;Data integration","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"Introduction","M. Beckner",NA,"Quick Start Guide to Azure Data Factory, Azure Data Lake Server, and Azure Data Warehouse","","2019","","","XIII","XIV","","","9781547401291","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10785599.pdf&bkn=10783667&pdfType=chapter","","Data warehouses;Servers;Production facilities;Pipelines;Monitoring;Big Data applications","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"Frontmatter","M. Beckner",NA,"Quick Start Guide to Azure Data Factory, Azure Data Lake Server, and Azure Data Warehouse","","2019","","","I","IV","","","9781547401291","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10785620.pdf&bkn=10783667&pdfType=chapter","","Servers;Production facilities;Big Data applications;Printing;Libraries;Internet","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"Hybrid big data architecture for high-speed log anomaly detection","P. Tangsatjatham; N. Nupairoj","Department of Computer Engineering, Chulalongkorn University, Bangkok, Thailand; Department of Computer Engineering, Chulalongkorn University, Bangkok, Thailand",2016 13th International Joint Conference on Computer Science and Software Engineering (JCSSE),"21 Nov 2016","2016","","","1","6","Log processing can be very challenging, especially for environments with lots of servers. In these environments, log data is large, coming at high-speed, and have various formats, the classic case of big data problem. This makes anomaly detection very difficult due to the fact that to get good accuracy, large amount of data must be processed in real-time. To solve this problem, this paper proposes a hybrid architecture for log anomaly detection using Apache Spark for data processing and Apache Flume for data collecting. To demonstrate the capabilities of our proposed solution, we implement a SARIMA-based anomaly detection as a case study. The experimental results clearly indicated that our proposed architecture can support log processing in large-scale environment effectively.","","978-1-5090-2033-1","10.1109/JCSSE.2016.7748933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748933","Hadoop;Real-Time;Log Processing;Largs-Scale;Hybrid Processing","Computer architecture;Sparks;Real-time systems;Bandwidth;Servers;Data processing;Predictive models","","3","","16","IEEE","21 Nov 2016","13-15 July 2016","13-15 July 2016","IEEE","IEEE Conferences"
"Research on Intelligent Mobile Police Application Based on 5G Technology","C. Cui; G. Zhou; C. Chen","Key Laboratory of Public Security, Zhejiang Police College, Information Application Based on Big-data Architecture, Ministry of Public Security Hangzhou, China; Department of Computer and Information Security, Zhejiang Police College, Hangzhou, China; Department of Computer and Information Security, Zhejiang Police College, Hangzhou, China","2022 IEEE International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)","6 Apr 2022","2022","","","426","429","Mobile and wireless networks have made remarkable development in the last few years, the rapidly increasing number of smart devices, voluminous mobile internet data, and higher data rate are promoting the birth and development of the 5th generation of mobile communication technology, by providing faster service, very low delay and very wide range of connection through mobile devices, the new technology is expected to revolutionize change the problems faced by traditional mobile wireless communication. With the application of 5G technology, the safety of the public will be significantly improved, especially for some scenes with zero delay tolerance requirements and large population density, such as mega events security and high real-time mobile police service. This paper explorers how the integration of 5G technology, big-data analysis, artificial intelligence and intelligent monitoring equipment can penetrate into the daily police management of urban space and the security of mega events protection. It analyzes these police applications from two interrelated perspectives, focusing on how to use 5G technology to help large-scale event security and use 5G to build three-dimensional prevention and control mode of mobile police. It is hoped that the joint progress of 5G technology and police application will enable us to move towards a safer, smarter and more automated society in the future.","","978-1-6654-1606-1","10.1109/EEBDA53927.2022.9744766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9744766","5G;police application;security protection;mobile police","Law enforcement;5G mobile communication;Wireless networks;Sociology;Real-time systems;Delays;Safety","","4","","6","IEEE","6 Apr 2022","25-27 Feb. 2022","25-27 Feb. 2022","IEEE","IEEE Conferences"
"Data Lake Organization","F. Nargesian; K. Pu; B. Ghadiri-Bashardoost; E. Zhu; R. J. Miller","Department of Computer Science, University of Rochester, Rochester, NY, USA; Department of Computer Science, University of Ontario Institute of Technology, Oshawa, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Microsoft Research, Redmond, WA, USA; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA",IEEE Transactions on Knowledge and Data Engineering,"7 Dec 2022","2023","35","1","237","250","We consider the problem of building an organizational directory of data lakes to support effective user navigation. The organization directory is defined as an acyclic graph that contains nodes representing sets of attributes and edges indicating subset relationships between nodes. A probabilistic model is constructed to model user navigational behaviour. The model also predicts the likelihood of users finding relevant tables in a data lake given an organization. We formulate the data lake organization problem as an optimization over the organizational structure in order to maximize the expected likelihood of discovering tables by navigating. An approximation algorithm is proposed with an analysis of its error bound. The effectiveness and efficiency of the algorithm are evaluated on both synthetic and real data lakes. Our experiments show that our algorithm constructs organizations that outperform many existing organizations including an existing hand-curated taxonomy, a linkage graph, and a common baseline organization. We have also conducted a formal user study which shows that navigation can help users discover relevant tables that are not easily accessible by keyword search queries. This suggests that keyword search and navigation using an organization are complementary modalities for data discovery in data lakes.","1558-2191","","10.1109/TKDE.2021.3091101","NSERC Discovery(grant numbers:RGPIN-2017-05265); National Science Foundation(grant numbers:IIS-1956096,IIS-2107050); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693372","Data lake;dataset discovery;taxonomy;structure learning","Organizations;Big Data applications;Navigation;Lakes;Inspection;Taxonomy;Aquaculture","","5","","51","IEEE","25 Jan 2022","1 Jan. 2023","","IEEE","IEEE Journals"
"Towards adopting Big Data technologies by mobile networks operators: A Moroccan case study","H. Daki; A. El Hannani; A. Aqqal; A. Haidine; A. Dahbi; H. Ouahmane","Laboratory of Information Technologies, University of Chouaib Doukkali, El Jadida, Morocco; Laboratory of Information Technologies, University of Chouaib Doukkali, El Jadida, Morocco; Laboratory of Information Technologies, University of Chouaib Doukkali, El Jadida, Morocco; Laboratory of Information Technologies, University of Chouaib Doukkali, El Jadida, Morocco; Laboratory of Information Technologies, University of Chouaib Doukkali, El Jadida, Morocco; Laboratory of Information Technologies, University of Chouaib Doukkali, El Jadida, Morocco",2016 2nd International Conference on Cloud Computing Technologies and Applications (CloudTech),"9 Feb 2017","2016","","","154","161","Big Data is the term for large and complex data sets that are difficult to treat using traditional management tools. Nowadays, Big Data has an important role in different industries. This huge quantity of datasets can be a great opportunity to help many organizations to understand quantified results better, improve their decisions and be able to make predictive actions to generate more revenues. Many networking infrastructures relay on Big Data applications to make daily activities smarter and faster. In this paper we present the case of a Moroccan operator which migrated from a manual reporting process to a fully automated one in order to have high interactivity, optimal management and great vision on their networks performance indicators. Furthermore, we discuss Big Data opportunities for the mobile network operators (MNO) and propose a Big Data architecture that may be adopted by the Moroccan MNO to overcome the limits of the traditional technologies used in the automatic reporting system.","","978-1-4673-8894-8","10.1109/CloudTech.2016.7847693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847693","Big Data;Mobile Networks Operator (MNO);Reporting;Key Performance Indicators (KPIs);Data Analytics","Relational databases;Business","","5","","28","IEEE","9 Feb 2017","24-26 May 2016","24-26 May 2016","IEEE","IEEE Conferences"
"A Big Data Architecture for Large Scale Security Monitoring","S. Marchal; X. Jiang; R. State; T. Engel","SnT - University of Luxembourg, Luxembourg; Faculty of Sciences Technology and Communication, University of Luxembourg, Luxembourg; SnT - University of Luxembourg, Luxembourg; SnT - University of Luxembourg, Luxembourg",2014 IEEE International Congress on Big Data,"25 Sep 2014","2014","","","56","63","Network traffic is a rich source of information for security monitoring. However the increasing volume of data to treat raises issues, rendering holistic analysis of network traffic difficult. In this paper we propose a solution to cope with the tremendous amount of data to analyse for security monitoring perspectives. We introduce an architecture dedicated to security monitoring of local enterprise networks. The application domain of such a system is mainly network intrusion detection and prevention, but can be used as well for forensic analysis. This architecture integrates two systems, one dedicated to scalable distributed data storage and management and the other dedicated to data exploitation. DNS data, NetFlow records, HTTP traffic and honeypot data are mined and correlated in a distributed system that leverages state of the art big data solution. Data correlation schemes are proposed and their performance are evaluated against several well-known big data framework including Hadoop and Spark.","2379-7703","978-1-4799-5057-7","10.1109/BigData.Congress.2014.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906761","","IP networks;Monitoring;Distributed databases;Security;Big data;Correlation","","95","","36","IEEE","25 Sep 2014","27 June-2 July 2014","27 June-2 July 2014","IEEE","IEEE Conferences"
"A Reference Method for Performance Evaluation in Big Data Architectures","W. S. Martins; B. Tardiole Kuehne; R. F. Sobrinho; F. Preti","Federal University of Itajubá - UNIFEI, Institute of Systems Engineering and Information Technology, Itajubá, MG, Brazil; Federal University of Itajubá - UNIFEI, Institute of Systems Engineering and Information Technology, Itajubá, MG, Brazil; Federal University of Itajubá - UNIFEI, Institute of Systems Engineering and Information Technology, Itajubá, MG, Brazil; DDMX, Itajubá, MG, Brazil",2020 IEEE International Conference on Services Computing (SCC),"11 Dec 2020","2020","","","1","8","This paper presents a reference method for performance evaluation in Big Data architectures, called by Improvement Method for Big Data Architectures (IMBDA) aiming to increase the performance, and consequently raising the quality of service provided. The method will contribute to small businesses and startups that have limited financial re-sources (impossible to invest in market solutions). The proposed approach considers the relationship of the processes in a data processing flow to find possible bottlenecks and optimization points. To this end, IMBDA collects system logs to compose functional metrics (e.g., processing time) and non-functional metrics (e.g., CPU and memory utilization, and other cloud computing infrastructure resources). The system stores these metrics in an external data analysis tool that investigates the correlation of performance between processes. The reference method applies to the architecture of a Big Data application, which provides solutions in fleet logistics. With the use of IMBDA, it was possible to identify performance bottlenecks, allowing the reconfiguration of the architecture to increase service quality at the lowest possible cost.","2474-2473","978-1-7281-8789-1","10.1109/SCC49832.2020.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284541","Big Data;cross-layer architecture;performance analysis and aids;pipeline processors;quality of services;Service Level Agreement","Measurement;Performance evaluation;Correlation;Data integrity;Computer architecture;Tools;Business","","","","17","IEEE","11 Dec 2020","7-11 Nov. 2020","7-11 Nov. 2020","IEEE","IEEE Conferences"
"Considerations for big data: Architecture and approach","K. Bakshi","Cisco Systems, Inc., Herndon, VA, USA",2012 IEEE Aerospace Conference,"19 Apr 2012","2012","","","1","7","The amount of data in our industry and the world is exploding. Data is being collected and stored at unprecedented rates. The challenge is not only to store and manage the vast volume of data (“big data”), but also to analyze and extract meaningful value from it. There are several approaches to collecting, storing, processing, and analyzing big data. The main focus of the paper is on unstructured data analysis. Unstructured data refers to information that either does not have a pre-defined data model or does not fit well into relational tables. Unstructured data is the fastest growing type of data, some example could be imagery, sensors, telemetry, video, documents, log files, and email data files. There are several techniques to address this problem space of unstructured analytics. The techniques share a common characteristics of scale-out, elasticity and high availability. MapReduce, in conjunction with the Hadoop Distributed File System (HDFS) and HBase database, as part of the Apache Hadoop project is a modern approach to analyze unstructured data. Hadoop clusters are an effective means of processing massive volumes of data, and can be improved with the right architectural approach.","1095-323X","978-1-4577-0557-1","10.1109/AERO.2012.6187357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187357","","Benchmark testing;Distributed databases;Computer architecture;File systems;Availability;Relational databases","","134","1","9","IEEE","19 Apr 2012","3-10 March 2012","3-10 March 2012","IEEE","IEEE Conferences"
"Real Time Traffic Prediction Based on Social Media Text Data Using Deep Learning","B. Mounica; K. Lavanya","School of Computer Science and Engineering, VIT University, Vellore, India; School of Computer Science and Engineering, VIT University, Vellore, India",Journal of Mobile Multimedia,"18 Apr 2025","2022","18","2","373","391","Due to urbanization Traffic management is one of the major issues in contemporary civic management, considering this circumstance traffic analysis is turning into the need of the present world. Text data generated by Twitter, Facebook and other social media platforms can be used for traffic management. Big data helps in traffic prediction and traffic analysis of advancing metropolitan zones. Constant traffic investigation requires preparing of information streams that are produced persistently to increase fast experiences. To measures stream information at a fast rate advancements on high figuring limit is required. Social media text data can be processed by using batch processing and stream processing with big data architecture through Spark and Hadoop framework. In this paper big data architecture is proposed for real time traffic text data analysis. In architecture Spark and Kafka are used in combination. Kafka helps in pipelines text data used in conjunction with spark stream processing engine. Big data architecture using Spark, Kafka with ability for processing and preparing huge measure of information, have settled the serious issue of handling and putting away constantly streaming data. The traffic information from Twitter API is streamed. In The proposed model pointed toward ensemble neural network model to reduce the variance in results for better prediction foreseeing traffic stream text data by incorporating Spark and Kafka that will be of an extraordinary incentive to the public authority for traffic management and analysis.","1550-4654","","10.13052/jmm1550-4646.18211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10967092","Ensemble neural network model;streaming data;big data architecture;real time traffic analysis;social media data","Analytical models;Social networking (online);Blogs;Big Data;Predictive models;Real-time systems;Data models;Sparks;Streams;Engines","","","","34","","18 Apr 2025","March 2022","","River Publishers","River Publishers Journals"
"Data Lakes: A Survey of Functions and Systems (Extended abstract)","R. Hai; C. Koutras; C. Quix; M. Jarke",Delft University of Technology; Delft University of Technology; Hochschule Niederrhein; RWTH Aachen University,2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","5679","5680","Data lakes are becoming increasingly prevalent for big data management and data analytics. In contrast to traditional ‘schema-on-write’ approaches such as data warehouses, data lakes are repositories storing raw data in its original formats and providing a common access interface. Despite the strong interest raised from both academia and industry, there is a large body of ambiguity regarding the definition, functions and available technologies for data lakes. A complete, coherent picture of data lake challenges and solutions is still missing. This survey reviews the development, architectures, and systems of data lakes. We provide a comprehensive overview of research questions for designing and building data lakes. We classify the existing approaches and systems based on their provided functions for data lakes, which makes this survey a useful technical reference for designing, implementing and deploying data lakes. We hope that the thorough comparison of existing solutions and the discussion of open research challenges in this survey will motivate the future development of data lake research and practice.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598150","n/a","Surveys;Data analysis;Reviews;Architecture;Buildings;Data warehouses;Big Data applications","","1","","5","IEEE","23 Jul 2024","13-16 May 2024","13-16 May 2024","IEEE","IEEE Conferences"
"Demo Abstract: Gesture-Based Cyber-Physical In-Home Therapy System in a Big Data Environment","M. A. Rahman","Computer Science Department, Umm Al-Qura University, Makkah, Saudi Arabia",2016 ACM/IEEE 7th International Conference on Cyber-Physical Systems (ICCPS),"26 May 2016","2016","","","1","1","This demo provides an overview of a gesture-based cyber-physical therapy system, which integrates entities in the physical as well as cyber world for therapy sensing, therapeutic data computation, interaction between cyber and physical world, and holistic in-home therapy support through a cloud-based big data architecture. To provide appropriate therapeutic services and environment, the CPS uses a multi-modal multimedia sensory framework to support therapy recording and playback of a therapy session and visualization of effectiveness of an assigned therapy. The physical world interaction with the cyber world is stored as a rich gesture semantics with the help of multiple media streams, which is then uploaded to a tightly synchronized cyber physical cloud environment for deducing real-time and historical whole-body Range of Motion (ROM) kinematic data.","","978-1-5090-1772-0","10.1109/ICCPS.2016.7479097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7479097","","Medical treatment;Kinematics;Multimedia communication;Big data;Data visualization;Sensors","","1","","3","IEEE","26 May 2016","11-14 April 2016","11-14 April 2016","IEEE","IEEE Conferences"
"OCF-HP: An Offline Compaction Framework Based on Hotspot Prediction for Data Lakehouse","B. Sun; X. Yang; Y. Guo; Z. Zhao; J. Chen; H. Zhang; J. Wang","Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",2024 9th International Conference on Electronic Technology and Information Science (ICETIS),"24 Jul 2024","2024","","","733","741","With the rapid advancement of information technologies, the global data volume is increasing at an unprecedented speed. Data Lakehouse has become an effective solution for real-time aggregation of multimodal heterogeneous data and supporting multiple query modes. It is worth noting that due to the column-based storage commonly employed in Data Lakehouse and the resulting mechanisms such as Copy-on-Write and Merge-On-Read, data query speed, data freshness, and storage costs have become huge challenges. In this paper, an Offline Compaction Framework based on Hotspot Prediction (OCF-HP) was designed to address the above challenges. Specifically, we analyzed the Timeline data in Hudi which is the mainstream Data Lakehouse framework, then predicted the hotspot periods of data writing based on the improved LSTM model using such data, and realized automatic trigger of Hudi offline compaction tasks in reasonable non-hot periods. The experiment results show that OCF-HP provides Hudi with a more optimized offline compaction solution so that data lakehouse managers could achieve better query speed and data freshness with reducing storage costs in Hudi's read optimized mode.","","979-8-3503-8834-3","10.1109/ICETIS61828.2024.10593781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10593781","Data Lakehouse;Data query;Data storage;LSTM","Analytical models;Costs;Data integrity;Predictive models;Writing;Data models;Compaction","","","","14","IEEE","24 Jul 2024","17-19 May 2024","17-19 May 2024","IEEE","IEEE Conferences"
"Business Intelligence with Databricks SQL: Concepts, tools, and techniques for scaling business intelligence on the data lakehouse","V. Gupta",NA,"Business Intelligence with Databricks SQL: Concepts, tools, and techniques for scaling business intelligence on the data lakehouse","","2022","","","","","Master critical skills needed to deploy and use Databricks SQL and elevate your BI from the warehouse to the lakehouse with confidenceKey FeaturesLearn about business intelligence on the lakehouse with features and functions of Databricks SQLMake the most of Databricks SQL by getting to grips with the enablers of its data warehousing capabilitiesA unique approach to teaching concepts and techniques with follow-along scenarios on real datasetsBook DescriptionIn this new era of data platform system design, data lakes and data warehouses are giving way to the lakehouse – a new type of data platform system that aims to unify all data analytics into a single platform. Databricks, with its Databricks SQL product suite, is the hottest lakehouse platform out there, harnessing the power of Apache Spark™, Delta Lake, and other innovations to enable data warehousing capabilities on the lakehouse with data lake economics. This book is a comprehensive hands-on guide that helps you explore all the advanced features, use cases, and technology components of Databricks SQL. You’ll start with the lakehouse architecture fundamentals and understand how Databricks SQL fits into it. The book then shows you how to use the platform, from exploring data, executing queries, building reports, and using dashboards through to learning the administrative aspects of the lakehouse – data security, governance, and management of the computational power of the lakehouse. You’ll also delve into the core technology enablers of Databricks SQL – Delta Lake and Photon. Finally, you’ll get hands-on with advanced SQL commands for ingesting data and maintaining the lakehouse. By the end of this book, you’ll have mastered Databricks SQL and be able to deploy and deliver fast, scalable business intelligence on the lakehouse.What you will learnUnderstand how Databricks SQL fits into the Databricks Lakehouse PlatformPerform everyday analytics with Databricks SQL Workbench and business intelligence toolsOrganize and catalog your data assetsProgram the data security model to protect and govern your dataTune SQL warehouses (computing clusters) for optimal query experienceTune the Delta Lake storage format for maximum query performanceDeliver extreme performance with the Photon query execution engineImplement advanced data ingestion patterns with Databricks SQLWho this book is forThis book is for business intelligence practitioners, data warehouse administrators, and data engineers who are new to Databrick SQL and want to learn how to deliver high-quality insights unhindered by the scale of data or infrastructure. This book is also for anyone looking to study the advanced technologies that power Databricks SQL. Basic knowledge of data warehouses, SQL-based analytics, and ETL processes is recommended to effectively learn the concepts introduced in this book and appreciate the innovation behind the platform.","","9781803237596","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163377.pdf&bkn=10163377&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Big Data architecture for water resources management: A Systematic Mapping Study","A. Cravero; O. Saldaña; R. Espinosa; C. Antileo","Universidad de La Frontera, Temuco, CL; Universidad de La Frontera, Temuco, CL; Universidad de La Frontera, Temuco, CL; Universidad de La Frontera, Temuco, CL",IEEE Latin America Transactions,"14 May 2018","2018","16","3","902","908","The combination of growth in demand for water, climate and hydrological gap, pushed the decision makers and water resource managers to find strategies for effective management of water resources. In this sense, looking for a new technology that allows data processing on a large scale, and with a complex structure, is that it has been using the new generation of Business Intelligence technology, known as Big Data. In recent years, solutions have been proposed for Big Data management issues of water resources in general. In this paper we provide an overview of the characteristics of the proposed architectures, serving as a starting point for further research","1548-0992","","10.1109/TLA.2018.8358672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358672","architecture;Big Data;resources;systematic mapping;water","Big Data;Water resources;Data models;Data visualization;Systematics;Cloud computing;Google","","6","","","IEEE","14 May 2018","March 2018","","IEEE","IEEE Journals"
"Applying the Big Data Technologies for Enhancing Maritime Interoperability Framework","Z. Paladin; N. Kapidani; E. Kočan; T. Nicoletti; G. Vosinakis; A. Astyakopoulos; C. Bolakis; M. Moutzouris","Administration for Maritime Safety and Port Management of Montenegro (AMSPM), Bar, Montenegro; Administration for Maritime Safety and Port Management of Montenegro (AMSPM), Bar, Montenegro; Faculty of Electrical Engineering, University of Montenegro (UoM), Podgorica, Montenegro; Engineering I.I., S.p.A., (ENG), Milano, Italy; Institute of Communication and Computer Systems (ICCS), Athens, Greece; The Center of Security Studies (KEMEA), Ministry of Citizen Protection, Athens, Greece; The Center of Security Studies (KEMEA), Ministry of Citizen Protection, Athens, Greece; SATWAYS LTD, Athens, Greece",2022 30th Telecommunications Forum (TELFOR),"22 Dec 2022","2022","","","1","4","In this paper, we present the core applications of data lakes and other big data infrastructure technologies for the purpose of enhancing the maritime interoperability framework and ensuring resilient collaboration among agencies. The approach is based on the deployment of multi-layered & semantically enabled Data Lakes for storing various maritime data collected from heterogeneous sensors, and on the information exchange process through the Common Information Sharing Environment (CISE) network using advanced Command and Control (C2) platforms. The results of this paper are derived from the EU-funded project EFFECTOR, highlighting the significant contribution of advanced solutions using Artificial Intelligence algorithms and supporting UAV and C2 technologies to various operations at sea. The validation survey results collected from end-users after the execution of the maritime trials are presented as well.","","978-1-6654-7273-9","10.1109/TELFOR56187.2022.9983697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9983697","Big Data;Data Lake;CISE;UAV;Maritime C2","Command and control systems;Surveillance;Process control;Big Data applications;Market research;Safety;Telecommunications","","3","","22","IEEE","22 Dec 2022","15-16 Nov. 2022","15-16 Nov. 2022","IEEE","IEEE Conferences"
"Medical data lake query assistance","F. Abdelhedi; R. Jemmali; G. Zurfluh","CBI2, Trimane, Paris, France; CBI2, Trimane, IRIT CNRS (UMR 5505), Toulouse University, France; IRIT CNRS (UMR 5505), Toulouse University, Toulouse, France",2023 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA),"2 Apr 2024","2023","","","1","8","In today's world, there is a growing need to analyze data stored in a Data Lake, which is a collection of large, heterogeneous databases. Our work is part of a medical application that aims to help healthcare professionals analyze complex data for decision-making. We propose mechanisms that promote data accessibility. The data are stored in a Data Warehouse (DW) that is periodically built from a data lake. Depending on the needs of the decision-maker, data are extracted from the DW and transferred to a Data Mart (DM) for querying. In this paper, we present a schema recommendation system based on the principle of collaborative filtering. This system can predict the DM schemas that were developed in the past that best match the data need expressed by a decision-maker. It does this by comparing the attributes present in the schemas with the attributes deduced from the need to propose a list of predictions for the most suitable schemas. The technique used is simple, while allowing us to solve the problem of periodic updates to the source data. An experiment was conducted for a medical application.","2161-5330","979-8-3503-1943-9","10.1109/AICCSA59173.2023.10479336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479336","Data Lake;Data Warehouse;Data Mart;NoSQL;Big Data;recommendation system;collaborative filtering","Biomedical equipment;Filtering;Databases;Collaborative filtering;Decision making;Medical services;Data warehouses","","1","","14","IEEE","2 Apr 2024","4-7 Dec. 2023","4-7 Dec. 2023","IEEE","IEEE Conferences"
"PyDaQu: Python Data Quality Code Generation Based on Data Architecture","M. Abughazala; H. Muccini; K. Qadri","DISIM Department, L'Aquila University, L’Aquila, Italy; DISIM Department, L'Aquila University, L’Aquila, Italy; Quality Assurance Team Lead, KABi Technologies, Nablus, Palestine",2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C),"22 Dec 2023","2023","","","60","64","Accurate and dependable data is critical when making crucial business decisions. However, verifying the accuracy of complex and extensive datasets can be both error-prone and time-consuming when done manually. We developed a PyDaQu, our automated framework that creates data quality checks code based on a standardized template. PyDaQu offers a variety of quality assurance measures, including validation, completeness, and consistency checks. These measures ensure exceptional data quality while simultaneously streamlining your data management processes. With PyDaQu, creating data quality checks requires significantly less time and effort. We have thoroughly evaluated PyDaQu using data from two different industry domains.","","979-8-3503-2498-3","10.1109/MODELS-C59198.2023.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350413","Data Quality Framework;Data-Driven;Data Architecture","Codes;Quality assurance;Data integrity;Pipelines;Computer architecture;Reliability engineering;Software","","1","","14","IEEE","22 Dec 2023","1-6 Oct. 2023","1-6 Oct. 2023","IEEE","IEEE Conferences"
"14 Small Data vs Big Data: Back to the Basics","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","69","72","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933602.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"Search Procedures Optimization in Digital Twin Data Lakes","D. Topolsky; A. Beliakov; V. Beliakova","Dep. of Electronic computing machines, South Ural State University (national research university), Chelyabinsk, Russia; Dep. of Electronic computing machines, South Ural State University (national research university), Chelyabinsk, Russia; Dep. of Electronic computing machines, South Ural State University (national research university), Chelyabinsk, Russia",2024 International Russian Smart Industry Conference (SmartIndustryCon),"8 May 2024","2024","","","255","260","The development of Data Lake technology is observed in many areas of smart manufacturing. Data lakes are used to create digital twins in the fuel and energy complex, energy, and metallurgy. The processes of obtaining new materials are no exception in this development direction of science and technology. In the context of the rapid growth of new data and the accumulation of chemical information obtained in the form of digital models of chemical compounds and materials, new information solutions and tools are in great demand, allowing for the search, analysis and visualization of available diverse data. The research is devoted to the development of methods for organizing known information about the structure and properties of compounds and materials, as well as software components for automating and increasing the productivity of search procedures. The issues of organizing the storage and processing of chemical data are considered, ways to improve the performance of search queries are shown, as well as displaying modifications of file structures in a relational database and in a distributed database based on Hadoop tools. File analysis and parsing highlights various properties of crystalline and molecular structures, organizing them into tree structures (JSON format), convenient for indexing and searching information in Data Lake of the “column family” type, which is a sparse matrix of search attributes. The results of accelerating search procedures for some search examples are presented, showing a significant acceleration in obtaining search query results.","","979-8-3503-9504-4","10.1109/SmartIndustryCon61328.2024.10515849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10515849","digital twins;data lake;information search;information indexing;search acceleration;Industry 4.0;digital transformation","Chemical engineering;Distributed databases;Big Data applications;Data models;Digital twins;Safety;Compounds","","1","","20","IEEE","8 May 2024","25-29 March 2024","25-29 March 2024","IEEE","IEEE Conferences"
"Self-Service, On-Demand Creation of OLAP Cubes over Big Data: a Metadata-Driven Approach","O. Latreche; D. Boukraa","dept. of computer science, University of Jijel, Algeria; dept. of computer science, University of Jijel, Algeria",2020 IEEE International Conference on Big Data (Big Data),"19 Mar 2021","2020","","","2907","2914","Nowadays, huge amounts of data are continuously created from different sources in different formats, and stored into data lakes for further use. A typical use case is to conduct online analyses in order to gain business insights and make better decisions. However, there are many obstacles to overcome when it comes on analysing Big Data online, such as dealing with schema-free data, conciliating different data formats, managing different locations, and allowing BI professionals and analysts to create their analytical data by themselves. In this paper, we propose some solutions to overcome these obstacles. We propose a data lake metadata model as well as a metadata-driven approach to create OLAP cubes from data lakes on-demand and in a self-service manner. We apply our work to Twitter social network and we present a proof-of-concept dedicated application.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378026","OLAP;Big Data;Cube;Self-service;Analysis","Social networking (online);Conferences;Blogs;Lakes;Big Data;Metadata;Business","","3","","25","IEEE","19 Mar 2021","10-13 Dec. 2020","10-13 Dec. 2020","IEEE","IEEE Conferences"
"Research on Data Governance Methods and Systems for Large Hub Airports","Y. Li; Y. Liu; T. Yuan; Y. Xu; N. Lei; J. Ning","IT Department, Beijing Capital International Airport Co., Ltd, Beijing, China; Department of Big Data and Artificial Intelligence, Civil Aviation Management Institute of China, Beijing, China; Department of Big Data and Artificial Intelligence, Civil Aviation Management Institute of China, Beijing, China; IT Department, Beijing Capital International Airport Co., Ltd, Beijing, China; IT Department, Beijing Capital International Airport Co., Ltd, Beijing, China; IT Department, Beijing Capital International Airport Co., Ltd, Beijing, China",2025 8th International Conference on Advanced Algorithms and Control Engineering (ICAACE),"9 Jun 2025","2025","","","1631","1634","As a new type of production factor in the digital era, data breaks the qualitative state of traditional production factors and has been highly valued by the state and the industry in recent years. With the continuous advancement of intelligent civil aviation construction, data issues have become the key bottleneck restricting the intelligent construction of airports. Data governance is not only the core grip for airports to give full play to the value of data elements, but also can provide important support for the integration and consolidation of the functions of various information systems and the collaborative control of various business modules in airports. This paper focuses on the data governance path of the Capital Airport, and describes the data governance system framework and information platform architecture of typical hub airports from top to bottom, which can provide a reference for other units in the industry to carry out data governance work with reference significance.","","979-8-3315-3508-7","10.1109/ICAACE65325.2025.11018979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11018979","Data governance;Smart Airport;Data architecture;Data quality;Data security;Data services;Data sharing;Airport big data platform","Industries;Productivity;Systematics;Control engineering;Data security;Data integrity;Information sharing;Airports;Data governance;Information systems","","1","","6","IEEE","9 Jun 2025","21-23 March 2025","21-23 March 2025","IEEE","IEEE Conferences"
"Semantic Smart City: Context Aware Application Architecture","S. Sholla; R. Naaz; M. A. Chishti","Computer Science and Engineering Department, National Institute of Technology Srinagar, Srinagar, India; Computer Science and Engineering Department, National Institute of Technology Srinagar, Srinagar, India; Computer Science and Engineering Department, National Institute of Technology Srinagar, Srinagar, India","2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)","30 Sep 2018","2018","","","721","724","The novel networking paradigm of the Internet of Things (IoT) represents a promising solution to address the challenges facing modern societies. All-pervading smart technologies in the IoT paradigm have facilitated collection of gigantic amounts of personal and organisational data. Effective management of smart city data is critical in providing smart applications to end users in a reliable and secure manner. Semantic computing provides a range of technologies that can aptly address big data concerns of smart city. In this paper we propose a smart city architecture that harnesses the power of semantic computing to realise the smart city vision.","","978-1-5386-0965-1","10.1109/ICECA.2018.8474777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474777","smart city;semantic computing;context-aware;big data;architecture","Smart cities;Semantics;Computer architecture;Conferences;Big Data;Internet of Things;Databases","","11","","8","IEEE","30 Sep 2018","29-31 March 2018","29-31 March 2018","IEEE","IEEE Conferences"
"Cardiovascular Disease Prediction Using Machine Learning-Random Forest Technique","M. P; A. M; M. R; R. S","Department of Computer Applications, Kalasalingam Academy of Research and Education, Krishnankoil, Tamilnadu, India; Department of Computer Applications, Kalasalingam Academy of Research and Education, Krishnankoil, Tamilnadu, India; School of Business and Management, Christ University, Bengaluru, Karnataka, India; School of Sciences, Christ University, Bengaluru, Karnataka, India",2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC),"2 Oct 2024","2024","","","1","6","Cardiovascular diseases (CVDs) pose a significant global health challenge. Early and accurate diagnosis is crucial for effective treatment. This research focuses on developing a robust classification system for CVDs using machine learning techniques. This study proposes an enhanced Random Forest (RF) model optimized for big data environments and explore the potential of CNN-based classification. By leveraging medical imaging data and employing these advanced algorithms, we aim to improve the accuracy and efficiency of CVD diagnosis.","2996-5357","979-8-3503-7994-5","10.1109/ICESC60852.2024.10689896","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10689896","Cardiac Disease Analysis;Convolution Neural Network (CNN);Machine Learning-Random Forest (ML-RF);Deep Learning Algorithm;Big Data Architecture;Image Processing","Support vector machines;Analytical models;Machine learning algorithms;Accuracy;Neural networks;Forestry;Big Data;Data models;Wearable devices;Random forests","","","","26","IEEE","2 Oct 2024","7-9 Aug. 2024","7-9 Aug. 2024","IEEE","IEEE Conferences"
"Policy-Based Access Control System for Delta Lake","Z. Chen; H. Shao; Y. Li; H. Lu; J. Jin","School of Software Engineering, Southeast University, Nanjing, Jiangsu, China; School of Computer Science and Engineering, Southeast University, Suzhou, Jiangsu, China; China Information Consulting & Designing Institute CO, LTD, Nanjing, Jiangsu, China; School of Information Engineering, Nanjing Audit University, Nanjing, Jiangsu, China; School of Computer Science and Engineering, Southeast University, Nanjing, Jiangsu, China",2022 Tenth International Conference on Advanced Cloud and Big Data (CBD),"25 Jan 2023","2022","","","60","65","Delta lake is a new generation of data storage solutions. It stores both transaction log and data files in one directory, and provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing on top of existing data lakes, such as S3, ADLS, GCS, and HDFS. Different from data warehouses, delta lakes allow data to be stored in the original format, retain complete data information, and provide efficient and low-cost storage solutions for data computing and analysis businesses. However, Since Delta Lake metadata is scattered in different resource files, the lack of a unified metadata view increases the difficulty of data governance. Also, Delta Lake adopts an open source storage system as the underlying storage, and its basic access control does not isolate different users, which may lead the risk of data leakage. At present, most common storage systems use data tables’ row and column fields for access control, while delta lake treats the file group as an object. In this paper, aiming at the difficulty of data governance, we design a data lake metadata management method to achieve unified and efficient management of metadata information in heterogeneous data. Then, we design a policy-based data lake access control mechanism, combined with the open source permission framework, and complete the access request for different users and roles in Delta Lake.","","979-8-3503-0971-3","10.1109/CBD58033.2022.00020","National Natural Science Foundation of China; Key Laboratory of Computer Network and Information Integration; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024547","Data Lake;Delta Lake;Metadata;Access Control","Access control;Memory;Lakes;Metadata;Lead;Data warehouses;Big Data applications","","3","","16","IEEE","25 Jan 2023","4-5 Nov. 2022","4-5 Nov. 2022","IEEE","IEEE Conferences"
"The Application of the Big Data Algorithm for Pipeline Lifetime Analysis","J. Gu; H. Zhang; L. Chen; S. Lian","China University of Petroleum, Beijing; China University of Petroleum, Beijing; China University of Petroleum, Beijing; China University of Petroleum, Beijing",2019 Chinese Automation Congress (CAC),"13 Feb 2020","2019","","","824","829","Oil and gas pipeline integrity management has always been a field of huge data accumulation. In recent years, the rise of big data technology has provided new ideas for pipeline integrity evaluation technology. Firstly, this paper systematically studies the key technologies related to the lifetime analysis of oil and gas pipelines and big data. Meanwhile, we also studies the next generation oil and gas pipeline big data system architecture, the development direction of big data architecture tends to be batch-stream unified and integrated. We completes the model establishment process from theoretical derivation, algorithm design and gives the key algorithm steps to accurately predict the pipeline inspection period. From the results, in the single models the minimum risk decision based on Naive Bayes is the best, the accuracy rate is 91.86%, and in the ensemble model the accuracy of GBDT is slightly better than that of the random forest, which accuracy rate reached 99.7%. In contrast, the ensemble learning method has a much better dataset fitting performance, which provides an idea for the selection of the algorithm in engineering applications.","2688-0938","978-1-7281-4094-0","10.1109/CAC48633.2019.8996228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8996228","big data;pipeline integrity;remaining life prediction;machine learning;ensemble learning","Pipelines;Oils;Big Data;Support vector machines;Mathematical model;Bayes methods;Predictive models","","4","","14","IEEE","13 Feb 2020","22-24 Nov. 2019","22-24 Nov. 2019","IEEE","IEEE Conferences"
"Geospatial Big Data for a Sustainable and Green Smart City","Y. Gacha; M. A. B. Rhaiem; T. Abdellatif","SERCOM Laboratory, University of Carthage, Carthage, Tunisia; RIADI Laboratory, University Manouba, Manouba, Tunisia; SERCOM Laboratory, University of Carthage, Carthage, Tunisia",2023 International Conference on Cyberworlds (CW),"6 Dec 2023","2023","","","217","224","Green cities are becoming increasingly important in today’s urban landscape. Smart cities, with their interconnected and intelligent infrastructure combined with advanced technologies, provide an ideal environment for promoting green initiatives. This paper presents a comprehensive survey that aims to highlight the role of geospatial big data technologies in the assertion of green smart cities. Indeed, we show how geospatial big data contributes to solving environmental issues related to cities such as air pollution, water pollution, green zones and biodiversity loss, climate change, and the efficient management of energy and renewable energy. Additionally, this paper suggests a basic and general geospatial big data architecture and presents the main open-source frameworks that can aid in the development of such big data systems for sustainable and green city planners.","2642-3596","979-8-3503-1565-3","10.1109/CW58918.2023.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10337569","Geospatial big data;Sustainable and Green Smart City;Environment issues;Energy management;Renewable energy","Climate change;Geospatial analysis;Big Data;Sustainable development;Green design;Smart cities;Environmental factors;Energy management;Renewable energy sources","","","","77","IEEE","6 Dec 2023","3-5 Oct. 2023","3-5 Oct. 2023","IEEE","IEEE Conferences"
"HEALER2: A Framework for Secure Data Lake Towards Healthcare Digital Transformation Efforts in Low and Middle-Income Countries","P. K. Yeng; J. -B. Diekuu; M. Abomhara; B. Elhadj; M. A. Yakubu; I. N. Oppong; A. Odebade; M. A. Fauzi; B. Yang; R. El-Gassar","Department of Information Security and Communication Technology, NTNU, Gjøvik, Norway; Department of Information Security and Communication Technology, RGU, Garthdee Road, UK; Department of Information Security and Communication Technology, NTNU, Gjøvik, Norway; Department of digital transformation and Electronic Communication, Staffordshire university Staffordshire university, UK; University of Cincinnati, Ohio, USA; Oracle, Accra, Ghana; Department of digital transformation and Electronic Communication, Staffordshire university Staffordshire university, UK; Department of Information Security and Communication Technology, NTNU, Gjøvik, Norway; Department of Information Security and Communication Technology, NTNU, Gjøvik, Norway; Department of Business, Marketing and Law Campus Ringerike (A 312), University of Southen Norway, Norway",2023 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC),"24 Oct 2023","2023","","","1","9","Low and middle-income countries are vigorously digitizing their operations in the healthcare sector as steps in the digital transformation journey. However, some of the basic principles in information security are being skipped. This has a tendency to introduce fundamental vulnerabilities in the core foundation of their healthcare IT infrastructure. This paper, therefore, assessed e-health strategies in Africa and proposed a data lake framework for healthcare IT infrastructure which is deemed secure, privacy-preserving and economically efficient.","","979-8-3503-1487-8","10.1109/ETNCC59188.2023.10284959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10284959","Healthcare;Cyber security;data lake;data warehouse;digital transformation","Privacy;Costs;Digital transformation;Medical services;Africa;Maintenance engineering;Big Data applications","","4","","34","IEEE","24 Oct 2023","16-18 Aug. 2023","16-18 Aug. 2023","IEEE","IEEE Conferences"
"ENLD: Efficient Noisy Label Detection for Incremental Datasets in Data Lake","X. You; L. Zhang; J. Wang; Z. Bao; Y. Wu; S. Dong",University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; Tencent Group; Tencent Group; Tencent Group,2023 IEEE 39th International Conference on Data Engineering (ICDE),"26 Jul 2023","2023","","","1940","1952","Due to the difficulty of obtaining high-quality data in real-world scenarios, datasets inevitably contain noisy labeled data, leading to inefficient data usage and poor model performance. Thus, noisy label detection is an important research topic. Previous efforts mainly focus on noisy label detection on specific datasets that have been collected. Some works select clean samples based on relations between representations during the training process; some works utilize confidence outputs of a pre-trained model for noisy label detection. However, how to perform efficient and fine-grained noisy label detection on constantly arriving datasets in a data lake with a large amount of inventory data has not been explored. The rapidly growing volume and changing distribution of data make conventional methods either incur large computation overhead due to repeated training or become increasingly ineffective on newly arriving data. To address these challenges, in this work, we propose a novel approach ENLD to perform efficient and accurate noisy label detection on incremental datasets. Our extensive experiments demonstrate that ENLD outperforms the next best method in both efficiency and accuracy, which achieves 3.65 ×-4.97× detection speedup and higher average f1 scores with various noise rate settings.","2375-026X","979-8-3503-2227-9","10.1109/ICDE55515.2023.00151","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10184822","Noisy Label Detection;Data Lake","Training;Computational modeling;Big Data applications;Feature extraction;Data engineering;Data models;Noise measurement","","2","","38","IEEE","26 Jul 2023","3-7 April 2023","3-7 April 2023","IEEE","IEEE Conferences"
"SemanticPrefetcher: Accelerate Data Lake Access with Semantics-Aware File Prefetching","T. Wang; G. Wang; M. Yang; M. Luo; M. Zou; C. Chen; M. Guo",Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; University of Cambridge; Shanghai Jiao Tong University; Shanghai Jiao Tong University,2025 IEEE International Conference on Cloud Computing Technology and Science (CloudCom),"20 Jan 2026","2025","","","1","8","Storage-compute disaggregation has become a mainstream paradigm in cloud computing, yet data lake workloads introduce distinct prefetching challenges: massive numbers of small files, interleaved multi-tenant streams, and frequent one-time accesses. Under these conditions, traditional sequential, correlation-based, and semantic prefetching methods become ineffective, leading to cache inefficiency and high latency. We propose SemanticPrefetcher, a lightweight, semantic-aware prefetching mechanism that incrementally constructs meaningful access streams at runtime. The system operates in three stages: it tokenizes file paths or object names into a unified semantic representation, clusters related requests into coherent streams despite multi-tenant interleaving, and detects naming regularities to predict future accesses. This design transforms mixed and seemingly disordered requests into predictable access flows without application modifications. Implemented on JuiceFS, SemanticPrefetcher reduces end-to-end execution time by up to 39.6% and read latency by 79.3% compared to state-of-the-art baselines. These results demonstrate that implicit semantics in file paths can be effectively leveraged for robust and efficient prefetching in cloud-scale data lakes.","2380-8004","979-8-3315-6634-0","10.1109/CloudCom67567.2025.11331481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11331481","Cloud computing;Data lake;Storage-compute disaggregation;Semantic analysis;Prefetching","Computers;Cloud computing;Runtime;Prefetching;Semantics;Transforms;Big Data applications","","","","28","IEEE","20 Jan 2026","14-16 Nov. 2025","14-16 Nov. 2025","IEEE","IEEE Conferences"
"Manipulating Data Lakes Intelligently With Java Annotations","L. M. Hoi; W. Ke; S. K. Im","Faculty of Applied Sciences, Macao Polytechnic University, Macau, China; Faculty of Applied Sciences, Macao Polytechnic University, Macau, China; Faculty of Applied Sciences, Macao Polytechnic University, Macau, China",IEEE Access,"8 Mar 2024","2024","12","","34903","34917","Data lakes are typically large data repositories where enterprises store data in a variety of data formats. From the perspective of data storage, data can be categorized into structured, semi-structured, and unstructured data. On the one hand, due to the complexity of data forms and transformation procedures, many enterprises simply pour valuable data into data lakes without organizing and managing them effectively. This can create data silos (or data islands) or even data swamps, with the result that some data will be permanently invisible. Although data are integrated into a data lake, they are simply physically stored in the same environment and cannot be correlated with other data to leverage their precious value. On the other hand, processing data from a data lake into a desired format is always a difficult and tedious task that requires experienced programming skills, such as conversion from structured to semi-structured. In this article, a novel software framework called Java Annotation for Manipulating Data Lakes (JAMDL) that can manage heterogeneous data is proposed. This approach uses Java annotations to express the properties of data in metadata (data about data) so that the data can be converted into different formats and managed efficiently in a data lake. Furthermore, this article suggests using artificial intelligence (AI) translation models to generate Data Manipulation Language (DML) operations for data manipulation and uses AI recommendation models to improve the visibility of data when data precipitation occurs.","2169-3536","","10.1109/ACCESS.2024.3372618","Macao Polytechnic University(grant numbers:RP/ESCA-03/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458132","Data lake;data precipitation;data stewards;enterprise-level applications;impedance mismatch;java annotations;JAMDL;object-oriented;ORMapping;software framework","Big Data applications;Java;Annotations;Databases;Software engineering;Artificial intelligence;Structured Query Language;Data lakes;Enterprise resource planning;Object oriented databases","","1","","42","CCBYNCND","1 Mar 2024","2024","","IEEE","IEEE Journals"
"A Zero Emission Neighbourhoods Data Management Architecture for Smart City Scenarios: Discussions toward 6Vs challenges","A. Sinaeepourfard; J. Krogstie; S. A. Petersen; A. Gustavsen","Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Department of Architecture and Technology, Norwegian University of Science and Technology (NTNU), Trondheim, Norway",2018 International Conference on Information and Communication Technology Convergence (ICTC),"18 Nov 2018","2018","","","658","663","A huge volume of data are being generated from multiple sources, including smart cities, the IoT devices, scientific modeling, or different big data simulations; but also from users' daily activities. These daily new data are added to historical repositories, providing the huge and complex universe of the digital data. Recently, the Fog-to-Cloud (F2C) data management architecture is envisioned to handle all big data complexities, from IoT devices (the closest layer to the users) to cloud technologies (the farthest layer to the IoT devices), as well as different data phases from creation to usage from fog to cloud scenario. Moreover, the F2C data management architecture can have several benefits from the combined advantages of fog (distributed) and cloud (centralized) technologies including reducing network traffic, reducing latencies drastically while improving security. In this paper, we have several novel contributions. First, we described the previous studies of the Zero Emission Buildings (ZEB) in the context of the data flow and movement architecture. Second, we have proposed Zero Emission Neighbourhoods (ZEN) data management architecture for smart city scenarios based on a distributed hierarchical F2C data management. Indeed, we used the 6Vs big data challenges (Volume, Variety, Velocity, Variability, Veracity, and Value) for evaluating the data management architectures (including ZEB and ZEN). The result of the evaluation shows that our proposed ZEN data management architecture can address 6Vs challenges and is able to manage the data lifecycle from its production up to its usage.","2162-1233","978-1-5386-5041-7","10.1109/ICTC.2018.8539669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539669","Smart City;IoT;Big Data;Vs Challenges;Data Management;Fog-to-Cloud Data Management","Computer architecture;Smart cities;Distributed databases;Big Data;Architecture","","10","","32","IEEE","18 Nov 2018","17-19 Oct. 2018","17-19 Oct. 2018","IEEE","IEEE Conferences"
"Blockchain-Enabled Decentralized Data Lakes for Secure and Transparent AI-Ready Data Storage","L. Gundu; V. Ramachandran; K. Butchi Raju; R. R. Hossain; D. Sreekanth; P. Putta","Department of Computer Science and Engineering, CMR Institute of Technology, Hyderabad; Department of Mechanical Engineering, Sethu Institute of Technology, Pulloor, Kariapatti, Tamil Nadu, India; Department of CSE, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, Telangana, India; Department of Computers Techniques Engineering, College of Technical Engineering, The Islamic University, Najaf, Iraq, Al Diwaniyah, Iraq; Department of ECE, CMR Technical Campus, Hyderabad, Telangana, India; Department of Mechanical Engineering, Mohan Babu University, Tirupati, Andhra Pradesh, India",2025 International Conference on Metaverse and Current Trends in Computing (ICMCTC),"17 Oct 2025","2025","","","1","4","Due to the exponential growth of AI driven applications, it is absolutely necessary that the data storage needs to be secure, transparent and scalable. Traditional centralized data lakes are lack transparency, do not provide data breach, high operational cost. The contributions of this paper include proposing a Blockchain Enabled Decentralized Data Lake (DAIDL), which is a new framework for AI capable data storage of secure, private, and easy access to data. While the proposed architecture involves blockchain for metadata management, decentralized storage (IPFS, Filecoin, Arweave) for data distribution as well as the federated learning for AI model training without exposing raw data. Besides, privacy preserving AI analytics with homomorphic encryption and secure multi-party computation (SMPC). It provides data integrity with a smart contract driven access control mechanisms and an incentivization for the contributors in a tokenized data economy. We show the implementation scales to be high, and is more secure and less expensive than traditional cloud based data lakes. Results of the experiments plus show that while storage efficient, retrieval speed of information is improved and the system is also less susceptible to unauthorized access. DAIDL provides freedom of choice to handle AI applications in critical areas like healthcare, financial sector, and smart cities in a way that data sovereignty and compliance with regulations are satisfied. Building on this, this research offers a roadmap for dealing with the limitations of scalability, interoperability and quantum secure scheme for decentralized AI ready storage system.","","979-8-3315-3821-7","10.1109/ICMCTC62214.2025.11196459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11196459","Secure multi-party computation;Blockchain Enabled Decentralized Data Lake;Smart Contract;InterPlanetary File System","Training;Smart contracts;Memory;Metadata;Big Data applications;Multi-party computation;Blockchains;Artificial intelligence;Homomorphic encryption;Interoperability","","","","14","IEEE","17 Oct 2025","10-11 April 2025","10-11 April 2025","IEEE","IEEE Conferences"
"Research and Application of Multimodal Data Fusion Technology for Oil and Gas Pipelines","S. Jia","PipeChina Institute of Science and Technology, Langfang, China","2024 IEEE 2nd International Conference on Control, Electronics and Computer Technology (ICCECT)","7 Jun 2024","2024","","","1093","1097","With the advent of the era of big data and artificial intelligence, pipeline enterprises are accumulating increasingly rich data. However, currently in the oil and gas pipeline industry, traditional pipeline data processing technologies are mostly aimed at single modal data, which can no longer meet the data needs of big data technology and artificial intelligence technology. Further research on multimodal data fusion technology for pipeline business scenarios is needed. Firstly, this paper investigates the current status of pipeline data fusion technology at home and abroad, constructs a pipeline big data technology architecture, analyzes the sources and types of pipeline data, and systematically elaborates on pipeline multimodal data fusion technology, including data conversion and fusion, logical association fusion, spatial analysis and fusion, semantic feature fusion. Secondly, the paper proposes a pipeline data lake technology architecture, providing services for subsequent data storage and analysis. Finally, this paper proposes that in the future, it is necessary to meet the data needs of new generation artificial intelligence technologies such as large models, and further research and application of multimodal data fusion technology should be carried out.","","979-8-3503-8095-8","10.1109/ICCECT60629.2024.10545908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545908","multimodal;big data;data fusion;artificial intelligence;pipeline","Industries;Data conversion;Oils;Pipelines;Semantics;Data integration;Memory","","1","","25","IEEE","7 Jun 2024","26-28 April 2024","26-28 April 2024","IEEE","IEEE Conferences"
"Convergence of Big Data and Cloud Computing Environment","R. Ganguli","All India Institute of Local Self Government, Deoghar, India","Integration of Cloud Computing with Internet of Things: Foundations, Analytics and Applications","","2021","","","233","249","Summary <p>Big Data is created every day from various heterogeneous sources over the internet and is a challenging task in processing, handling and storing for major organization. This chapter discusses how convergence activities played a major role with Big data in finding a solution in cloud computing platform for handling large volume, fast moving and ever increasing data in the internet along with its pros and cons of the system. For better understanding of characteristics, Big data is classified in different categories: sources, structure format, stores, data Building, and data handling. The Big data architecture is a multilayer processing system which consists of various components that includes data sources & storage, batch processing, real‐time messaging sources, data streaming, analytical storage with reporting and orchestration. Cloud models help organizations to evaluate best business strategy and user requirements. Big data is merged with cloud computing and becomes a leading part of the digital world nowadays with its several challenges.</p>","","9781119769316","10.1002/9781119769323.ch14","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10953483.pdf&bkn=10950310&pdfType=chapter","","Big Data;Cloud computing;Organizations;Data centers;Costs;Convergence;Social networking (online);Real-time systems;Data handling;Smart phones","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Separation Is for Better Reunion: Data Lake Storage at Huawei","X. Tang; C. Chai; D. Zhao; H. Ma; Y. Zheng; Z. Fan; X. Wu; J. Zhang; R. Zhang; D. Li; Y. He; K. Huang; G. Meng; Y. Wang; Y. Zhou; T. Tao; L. Jian; J. Shu; Y. Wang; Y. Yuan; G. Wang; G. Li","Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Mobile Communications; Hashdata; Tsinghua University; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Beijing Institute of Technology, Huawei, China; Tsinghua University",2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","5142","5155","Huawei collaborates with some Chinese large busi-ness companies to store and process exabytes of nationwide operational data in data lake storage to provide business insights. Specifically, our customers will ask to store and process massive log message data to support their real-time and decision-making applications. Thus, we need computation and storage components in the analytic platform to process and store these data cost-efficiently. To meet these user requirements, we have designed a storage system in data lake, StreamLake, which introduces a novel design to serve log message streaming and batch data processing in distributed storage, with high scalability, efficiency, reliability and low cost. Specifically, we introduce a stream (storage) object as a storage abstraction for message streaming data to achieve the storage-disaggregated architecture with high scalability and reliability. Moreover, we utilize the erasure coding and tiered storage to save the storage cost, and furthermore, the stream object can be automatically converted to a table object such that cost-effective stream and batch data processing can be achieved. For tabular data, we implement the lakehouse functionality to support ACID via the table object, with a metadata acceleration to improve the efficiency of data access between the compute and storage engines. Also, we design a LakeBrain optimizer at the storage side to optimize the query performance and resource utilization under the storage-disaggregated architecture. Finally, we have also deployed StreamLake in China Mobile, the world's largest mobile network operator to serve over 20PB production data, and the results demonstrate improvements of 30% to 4x in terms of query performance and over 37% in terms of cost saving.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00386","NSFC(grant numbers:62102215,U23B2019,61925205,62232009,U23A20297,61932004,62225203,U21A20516,U2001211); National Key R&D Program of China(grant numbers:2023YFB4503600,2022YFB2702100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598130","n/a","Costs;Scalability;Computer architecture;Production;Data processing;Big Data applications;Reliability engineering","","3","","47","IEEE","23 Jul 2024","13-16 May 2024","13-16 May 2024","IEEE","IEEE Conferences"
"Secure, Scalable and Privacy Aware Data Strategy in Cloud","V. K. Butte; S. Butte","University of Idaho, Idaho Falls, ID, USA; University of Idaho, Idaho Falls, ID, USA",2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS),"16 Jan 2023","2022","","","925","932","The enterprises today are faced with the tough challenge of processing, storing large amounts of data in a secure, scalable manner and enabling decision makers to make quick, informed data driven decisions. This paper addresses this challenge and develops an effective enterprise data strategy in the cloud. Various components of an effective data strategy are discussed and architectures addressing security, scalability and privacy aspects are provided.","","978-1-6654-8962-1","10.1109/ICAISS55157.2022.10011063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10011063","Cloud;data strategy;data lake;data lake Architecture;cloud computing;enterprise data strategy;modern data architecture","Training;Data privacy;Leadership;Scalability;Computer architecture;Lakes;Stakeholders","","1","","15","IEEE","16 Jan 2023","24-26 Nov. 2022","24-26 Nov. 2022","IEEE","IEEE Conferences"
"Big Data Handling, Storage and Solutions","A. Ahlemeyer-Stubbe; S. Coleman","Director Strategical Analytics, HackerAgency GmbH, Munich, Germany; Technical Director, ISRU, School of Maths and Stats, Newcastle University, UK",Monetizing Data: How to Uplift Your Business,"","2018","","","29","48","This chapter looks at the structure of data arising from and driving everyday business processes and then gives an overview of the technical aspects of storing and accessing data. Structured data includes transactional data, financial data, registration data and more; the characteristic is that it has a clear structure and is often organised in a relational database. Relational data storage systems were appropriate for transaction processing and gave the necessary security and reliability guarantees. Analysis‐based information systems are systems that are necessary to store data and make it ready for analysis. The contents of a data warehouse can be characterised as having four main features, which reveal the significant differences to other operational data: topic orientation, logical integration and homogenisation, presence of a reference period and low volatility. The aim of both data warehouses and big data architecture is an enterprise‐wide integration of all relevant data into a consistent set in a continuous system model.","","9781119125143","10.1002/9781119125167.ch3","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821440.pdf&bkn=9820799&pdfType=chapter","","Big Data;Business;Companies;Information systems;Real-time systems;Costs;Social networking (online)","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Big Data architecture for IT incident management","R. Liu; Q. Li; F. Li; L. Mei; J. Lee","IBM T. J. Watson Research Center, New York, USA; IBM Research - China, Beijing, China; IBM Research - China, Beijing, China; IBM Research - China, Beijing, China; IBM T. J. Watson Research Center, New York, USA","Proceedings of 2014 IEEE International Conference on Service Operations and Logistics, and Informatics","20 Nov 2014","2014","","","424","429","IT incident management aims to restore normal service quality and availability of IT systems from interruptions. IT incidents often have complicated causes aggregated from an IT environment composed of thousands of interdependent components. Incident diagnosis then requires collecting and analyzing a large scale of data regarding these components, often, in real time to find suspect causes. It is extremely difficult to fulfill this requirement using traditional techniques. In this paper, we propose a new analysis architecture using Big Data techniques. This architecture leverages stream computing and MapReduce techniques to analyze data from various data sources, uses NoSQL databases to store incident-related documents and their relationships, and further utilizes other analytical techniques to examine the documents for root causes and failure prediction. We demonstrate this approach using a real-world example and present evaluation results from a recent pilot study.","","978-1-4799-6058-3","10.1109/SOLI.2014.6960762","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6960762","Incident management;co-occurrence;reoccurrence;Big Data;NoSQL;stream computing;MapReduce","Databases;Operating systems","","4","","19","IEEE","20 Nov 2014","8-10 Oct. 2014","8-10 Oct. 2014","IEEE","IEEE Conferences"
"Data Architecture for Digital Twin of Commercial Greenhouse Production","D. Anthony Howard; Z. Ma; J. Mazanti Aaslyng; B. Nørregaard Jørgensen","Center for Energy Informatics, The Maersk Mc-Kinney Moller Institute, Odense, Denmark; Health Informatics and Technology, The Maersk Mc-Kinney Moller Institute, Odense, Denmark; AgroTech, Danish Technological Institute, Denmark; Center for Energy Informatics, The Maersk Mc-Kinney Moller Institute, Odense, Denmark",2020 RIVF International Conference on Computing and Communication Technologies (RIVF),"15 Jul 2020","2020","","","1","7","There is an increasing demand for industry-specific solutions for optimizing production processes with the transitions towards Industry 4.0. The commercial greenhouse sector relies heavily on optimal use of energy with multiple new concepts introduced in recent years e.g. vertical farming and urban agriculture. Digital twins allow utilizing the Internet of Things and big data to simulate the alternative operation strategies without compromising current operation. This paper aims to present the development of a digital twin of the commercial greenhouse production process as a part of the recently launched EUDP funded project Greenhouse Industry 4.0 in Denmark. This digital twin allows using big data and the Internet of Things to optimize the greenhouse production process and communicate with other digital twins representing essential areas in the greenhouse (climate and energy). This digital twin can estimate future states of the greenhouse by using past and real-time data inputs from databases, sensors, and spot markets. This paper also introduces a Smart Industry Architecture Model Framework for the discussion of the required data architecture of the digital twin for the greenhouse production flow which ensures a correct data architecture for the data exchange across all entities in the system.","2162-786X","978-1-7281-5377-3","10.1109/RIVF48685.2020.9140726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140726","industry 4.0;commercial greenhouse;digital twin;data architecture;production process","Production;Green products;Meteorology;Industries;Air pollution;Optimization;Artificial intelligence","","27","","25","IEEE","15 Jul 2020","14-15 Oct. 2020","14-15 Oct. 2020","IEEE","IEEE Conferences"
"A Sentiment Analysis Service Platform for Streamed Multilingual Tweets","I. Karageorgou; P. Liakos; A. Delis","University of Athens, Athens, Greece; University of Athens, Athens, Greece; University of Athens, Athens, Greece",2020 IEEE International Conference on Big Data (Big Data),"19 Mar 2021","2020","","","3262","3271","Micro-blogging and social-media platforms are now prominent forums for disseminating information, opinions and commentaries. Among these, Twitter enjoys an in-excess of 330M base of users who continually produce and consume information snippets. Users collectively create a voluminous and multi-lingual corpus in a very broad range of topics on a daily basis. The discourse generated in the blogosphere is often of prime interest and importance to individuals, organizations, and companies. These actors would certainly like to periodically receive an overall assessment of demonstrated ""sentiments"" on specific issues by automatically classifying tweets expressed in different languages in conjunction with big-data analytics. In this paper, we propose a scalable service platform that employs multilingual sentiment analysis to classify streamed-tweets and yields analytics for selected topics in real-time. We discuss the main component of our Spark-enabled platform as we seek to offer an effective big-data service that can: 1) dynamically handle voluminous as well as high-rate tweettraffic through a multi-component application exploiting the latest software developments, 2) accurately identify messages originated by non-genuine user-accounts, and 3) utilize the Spark machine-learning library (MLib) to successfully classify streamed multi-lingual messages in real-time, using multiple potentially distributed executors. To empower our service platform, we have adopted training sets and developed sentiment analysis (SA) models for English, French, and Greek that help classify streamed tweetswith high accuracy. While experimenting with our distributed analytical platform, we establish both accurate and real-time classification for tweetsexpressed in the above European languages.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9377837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377837","Service Platform for Language Analytics;Real-time Big-data Analysis for Streamed tweets;Spark-enabled Big-data Architecture;Classification of Multilingual tweets","Training;Sentiment analysis;Blogs;Big Data;Real-time systems;Software;Sparks","","2","","29","IEEE","19 Mar 2021","10-13 Dec. 2020","10-13 Dec. 2020","IEEE","IEEE Conferences"
"Modern Data Engineering for Cloud Etl, Migration, and Scalable Analytics","S. K. Gupta; V. K. Koganti; P. Patel; S. Akhmedov; N. Matyakubov","Western Governors University, Millcreek, USA; University of Missouri, Kansas City, USA; Oklahoma State University, Stillwater, United States; Department of Economy, Urgench State University, Urgench, Uzbekistan; Social-Humaniratidan Department, Urgench Innovation University, Urgench, Uzbekistan","2025 International Conference on Sustainability, Innovation & Technology (ICSIT)","19 Dec 2025","2025","","","1","5","The ETL migration and scalable analytics of cloud-native design has revolutionized the current data engineering through the faster transition to cloud-native designs. The resource usage in cloud systems is Pay-as-you-use, which is convenient in real time and bulk processing of data demanded by the businesses. The innovations enable the agile pipelines, migration of legacy systems and analytics migration at scale migration. Nonetheless, they still struggle with such problems as the ability to integrate heterogeneous data, schema change, low-latency processing, regulatory compliance and cost control. These are the main issues that will have to be addressed in order to realize the potential of cloud data systems. This review is going to investigate the trends of cloud-native ETLs, tools and strategies such as the data lakehouses and streaming architecture. The interactions of the modern pipelines are shown through experimental modeling whereas the constraints of the system can be stated by the comparative benchmarks. The analysis also determines the most significant gaps and future opportunities like serverless orchestration, fed ETL, and combined use of batch-stream processing to enhance the interoperability, efficiency and scalability of cloud data engineering.","","979-8-3315-3549-0","10.1109/ICSIT65336.2025.11294479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11294479","Cloud ETL;Data Migration;Scalable Analytics;Data Pipelines;Data Lakehouse;Streaming Analytics","Technological innovation;Reviews;Scalability;Pipelines;Process control;Organizations;Data engineering;Reliability engineering;Real-time systems;Remote working","","","","16","IEEE","19 Dec 2025","22-23 Aug. 2025","22-23 Aug. 2025","IEEE","IEEE Conferences"
"Edge QoE: Intelligent Big Data Caching via Deep Reinforcement Learning","X. He; K. Wang; H. Lu; W. Xu; S. Guo","Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China",IEEE Network,"22 Jul 2020","2020","34","4","8","13","In mobile edge networks (MENs), big data caching services are expected to provide mobile users with better quality of experience (QoE) than normal scenarios. However, the increasing types of sensors and devices are producing an explosion of big data. Extracting valuable contents for caching is becoming a vital issue for the satisfaction of QoE. Therefore, it is urgent to propose some rational strategies to improve QoE, which is the major challenge for content-centric caching. This article introduces a novel big data architecture consisting of data management units for content extraction and caching decision, improving quality of service and ensuring QoE. Then a caching strategy is proposed to improve QoE, including three parts: (1) the caching location decision, which means the method of deploying caching nodes to make them closer to users; (2) caching capacity assessment, which aims to seek suitable contents to match the capacity of caching nodes; and (3) caching priority choice, which leads to contents being cached according to their priority to meet user demands. With this architecture and strategy, we particularly use a caching algorithm based on deep reinforcement learning to achieve lower cost for intelligent caching. Experimental results indicate that our schemes achieve higher QoE than existing algorithms.","1558-156X","","10.1109/MNET.011.1900393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146409","","Quality of experience;Big Data;Computer architecture;Quality of service;Streaming media;Reinforcement learning;Data mining","","13","","15","IEEE","22 Jul 2020","July/August 2020","","IEEE","IEEE Magazines"
"CRISIS: Integrating AIS and Ocean Data Streams Using Semantic Web Standards for Event Detection","A. Soares; R. Dividino; F. Abreu; M. Brousseau; A. W. Isenor; S. Webb; S. Matwin","Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Defence Research and Development Canada (DRDC), Halifax, Nova Scotia; Defence Research and Development Canada (DRDC), Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia",2019 International Conference on Military Communications and Information Systems (ICMCIS),"19 Sep 2019","2019","","","1","7","Information deluge is still an issue in the maritime environment, creating situations where data are sometimes underutilized or in more extreme cases, not utilized, in the decision-making process. In part, this is due to the high volume of incoming data that are available to the operational community. However, better exploitation of these data streams can be accomplished through techniques that focus on the semantics of the incoming stream, to discover information-based alerts that generate knowledge that is only obtainable when considering the totality of the streams. In this paper, we present an agile data architecture for real-time data representation, integration, and querying situations over heterogeneous data streams using Semantic Web Technologies, with the goal of improved knowledge interoperability. We apply the framework to the maritime ship traffic domain to discover real-time traffic alerts by querying and reasoning across multiple streams.","","978-1-5386-9383-4","10.1109/ICMCIS.2019.8842749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842749","","Marine vehicles;Semantics;Real-time systems;Ontologies;Standards;Resource description framework","","22","","26","Crown","19 Sep 2019","14-15 May 2019","14-15 May 2019","IEEE","IEEE Conferences"
"Architecture of Data Lakes","H. Chihoub; C. Madera; C. Quix; R. Hai",NA; NA; NA; NA,Data Lakes,"","2020","","","21","39","This chapter introduces the most important features of data lake systems, and from there it outlines an architecture for these systems. The vision for a data lake system is based on a generic and extensible architecture with a unified data model, facilitating the ingestion, storage and metadata management over heterogeneous data sources. The chapter also introduces a real‐life data lake system called Constance that can deal with sophisticated metadata management over raw data extracted from heterogeneous data sources. With embedded query rewriting engines that support structured data and semi‐structured data, Constance provides users with a unified interface for query processing and data exploration. Big Data has undoubtedly become one of the most important challenges in database research. A MetaData Management System for data lakes should provide means to handle metadata in different data models (relational, XML, JSON, RDF), and should be able to represent mappings between the metadata entries.","","9781119720423","10.1002/9781119720430.ch2","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9823283.pdf&bkn=9820901&pdfType=chapter","","Big Data applications;Metadata;Soft sensors;Data mining;IEEE Sections;Semantics;Distributed databases","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Security Intelligence Centers for Big Data Processing","N. Miloslavskaya","National Research Nuclear University, MEPhI (Moscow Engineering Physics Institute), Moscow, Russia",2017 5th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW),"20 Nov 2017","2017","","","7","13","Today numerous information security (IS) incidents in organizations' networks have become not only more sophisticated but also damaging. Hence the systems with proper security services in place to mitigate and promptly respond to IS threats by helping organizations better understand their current network situation, as well as to perform routine work in big IS-related data processing in automatic mode are needed as never before. They are known as Security Operations Centers (SOCs) and Security Intelligence Centers (SICs) as their next evolution step. The key features of SICs are summarized. The SIC business logic and data architecture are proposed. These results lead to the main area of further research.","","978-1-5386-3281-9","10.1109/FiCloudW.2017.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113762","Big Data IT;Big Data Processing;Information Security;Security Ingelligence;Security Intelligence Center","Security;Silicon carbide;Organizations;Distributed databases;Big Data;Monitoring","","8","","22","IEEE","20 Nov 2017","21-23 Aug. 2017","21-23 Aug. 2017","IEEE","IEEE Conferences"
"A big data based product ranking solution","J. Li; B. Shao; J. Xu; H. Li; Q. Wang","Industry & Solutions Research, IBM Research-China, Beijing, P.R. China; Industry & Solutions Research, IBM Research-China, Beijing, P.R. China; Industry & Solutions Research, IBM Research-China, Beijing, P.R. China; Industry & Solutions Research, IBM Research-China, Beijing, P.R. China; Industry & Solutions Research, IBM Research-China, Beijing, P.R. China","2016 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI)","25 Aug 2016","2016","","","190","194","Users' online behavior, generated from endpoints of e-commerce website and app, is regarded as big data which can create large business value by mining them to acquire insights of users' preference, inclination and purpose. A good ranking result of product search and product assortment in online category classification can lift user's click rate, increase purchasing conversion rate and improve customer online experience. In this paper, we will introduce an online product based learning to rank model to intelligently learn product ranking. A big data architecture will also be introduced to implement this learning to rank model which analyzes huge amount of users' online behavior.","","978-1-5090-2927-3","10.1109/SOLI.2016.7551685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551685","","Big data;Feature extraction;Data models;Training data;Numerical models;Training;Support vector machines","","","","10","IEEE","25 Aug 2016","10-12 July 2016","10-12 July 2016","IEEE","IEEE Conferences"
"A Novel Architecture and Algorithm for Prediction of Students Psychological Health based on Big Data","C. Cheng; X. Cheng; Y. Zheng; L. Cao; Y. Han; Y. Jia; Q. Zhang; Y. Zhang; Y. Zhang; L. Xu","Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China; Research Institute, China United Network Communications Corporation, Beijing, China","2021 IEEE 20th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","9 Mar 2022","2021","","","1391","1396","Psychological health of students has become a widespread social problem, while the management and assessment of college students' psychological health is still stay in passive and manual mode based on the traditional method. In this paper, we design a novel architecture for the prediction of college students' psychological health based on Multi-Source big data including Operation Support System big data, educational data and psychological health questionnaire data. Then we propose the Optimized Decision Tree using Multiple-Target Particle Swarm Optimization (DT-MTPSO) algorithm. Experiment shows that the proposed algorithm can solve the Multiple-Target problems effectively and has better performance in F1-score than traditional Decision Tree. In addition, the result of the features selection of DT-MTPSO for different targets shows the relationship between the psychological health level and behavioural characteristics of students for different evaluation indicators, providing guidance to the school managers and educational psychologist.","2324-9013","978-1-6654-1658-0","10.1109/TrustCom53373.2021.00195","National Key R&D Program of China(grant numbers:2018YFB1800800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9724518","Multi-Source Big Data;Multi-Target Particle Swarm Optimization;Psychological Health;Machine Learning","Psychology;Manuals;Computer architecture;Big Data;Predictive models;Prediction algorithms;Feature extraction","","4","","33","IEEE","9 Mar 2022","20-22 Oct. 2021","20-22 Oct. 2021","IEEE","IEEE Conferences"
"On mixing high-speed updates and in-memory queries: A big-data architecture for real-time analytics","T. Zhong; K. A. Doshi; X. Tang; T. Lou; Z. Lu; H. Li","Software and Services Group, Intel; Software and Services Group, Intel; Software and Services Group, Intel; Software and Services Group, Intel; Software and Services Group, Intel; Software and Services Group, Intel",2013 IEEE International Conference on Big Data,"23 Dec 2013","2013","","","102","109","Up-to-date business intelligence has become a critical differentiator for the modern data-driven highly engaged enterprise. It requires rapid integration of new information on a continuous basis for subsequent analyses. ETL-based and traditionally batch-processing oriented methods of absorbing changes into a relational database schema take time, and are therefore incompatible with very low-latency demands of realtime analytics. Instead, in-memory clustered stores that employ tunable consistency mechanisms are becoming attractive since they dispense with the need to transform and transit data between storage layouts and tiers. When data is updated infrequently, in-memory approaches such as RDD transformations in Spark can suffice, but as updates become frequent, such in-memory approaches need to be extended to support dynamic datasets. This paper describes a few key additional requirements that result from having to support in-memory processing of data while updates proceed concurrently. The paper describes Real-time Analytics Foundation (RAF), an architecture to meet the new requirements. Performance of an early implementation of RAF is also described: for an unaudited TPC-H derived workload, RAF shows a node-to-node scaling ratio of 88% at 8 nodes, and for a query equivalent to Q6 in the TPC-H set, RAF is able to show 9x improvement over that of Hive-Hadoop. The paper also describes two RAF based solutions that are being put together by two independent software vendors in China.","","978-1-4799-1293-3","10.1109/BigData.2013.6691704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691704","Big Data;Real-time;Low-latency;Analytics;Resilient Distributed Datasets;CRUD;Clustering","Distributed databases;Memory management;Software;Information management;Data handling;Data storage systems;Real-time systems","","9","","19","IEEE","23 Dec 2013","6-9 Oct. 2013","6-9 Oct. 2013","IEEE","IEEE Conferences"
"A Zone Reference Model for Enterprise-Grade Data Lake Management","C. Giebler; C. Gröger; E. Hoos; H. Schwarz; B. Mitschang","University of Stuttgart, Stuttgart, Germany; Robert Bosch GmbH, Stuttgart, Germany; Robert Bosch GmbH, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany",2020 IEEE 24th International Enterprise Distributed Object Computing Conference (EDOC),"23 Oct 2020","2020","","","57","66","Data lakes are on the rise as data platforms for any kind of analytics, from data exploration to machine learning. They achieve the required flexibility by storing heterogeneous data in their raw format, and by avoiding the need for pre-defined use cases. However, storing only raw data is inefficient, as for many applications, the same data processing has to be applied repeatedly. To foster the reuse of processing steps, literature proposes to store data in different degrees of processing in addition to their raw format. To this end, data lakes are typically structured in zones. There exists various zone models, but they are varied, vague, and no assessments are given. It is unclear which of these zone models is applicable in a practical data lake implementation in enterprises. In this work, we assess existing zone models using requirements derived from multiple representative data analytics use cases of a real-world industry case. We identify the shortcomings of existing work and develop a zone reference model for enterprise-grade data lake management in a detailed manner. We assess the reference model's applicability through a prototypical implementation for a real-world enterprise data lake use case. This assessment shows that the zone reference model meets the requirements relevant in practice and is ready for industry use.","2325-6362","978-1-7281-6473-1","10.1109/EDOC49727.2020.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233155","Data Lake;Zones;Reference Model;Industry Case;Industry Experience","Lakes;Data models;Data analysis;Analytical models;Industries;Business;Real-time systems","","18","","25","IEEE","23 Oct 2020","5-8 Oct. 2020","5-8 Oct. 2020","IEEE","IEEE Conferences"
"Exploring a Framework for Identity and Attribute Linking across Heterogeneous Data Systems","N. Wilder; J. M. Smith; A. Mockus","University of Tennessee, Knoxville, Tennessee; University of Tennessee, Knoxville, Tennessee; University of Tennessee, Knoxville, Tennessee",2016 IEEE/ACM 2nd International Workshop on Big Data Software Engineering (BIGDSE),"16 Jan 2017","2016","","","19","25","Online-activity-generated digital traces provide opportunities for novel services and unique insights as demonstrated in, for example, research on mining software repositories. The inability to link these traces within and among systems, such as Twitter, GitHub, or Reddit, inhibit the advances in this area. Furthermore, no single approach to integrate data from these disparate sources is likely to work. We aim to design Foreseer, an extensible framework, to design and evaluate identity matching techniques for public, large, and low-accuracy operational data. Foreseer consists of three functionally independent components designed to address the issues of discovery and preparation, storage and representation, and analysis and linking of traces from disparate online sources. The framework includes a domain specific language for manipulating traces, generating insights, and building novel services. We have applied it in a pilot study of roughly 10TB of data from Twitter, Reddit, and StackExchange including roughly 6M distinct entities and, using basic matching techniques, found roughly 83,000 matches among these sources. We plan to add additional entity extraction and identification algorithms, data from other sources, and design tools for facilitating dynamic ingestion and tagging of incoming data on a more robust infrastructure using Apache Spark or another distributed processing framework. We will then evaluate the utility and effectiveness of the framework in applications ranging from identifying malicious contributors in software repositories to the evaluation of the utility of privacy preservation schemes.","","978-1-4503-4152-3","10.1145/2896825.2896833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811382","Entity Extraction;Entity Identification;Identity Linking;Domain Specific Language;Big Data Architecture","Joining processes;Data mining;Data processing;Twitter;Software;C languages;Pattern matching","","1","","21","","16 Jan 2017","16-16 May 2016","16-16 May 2016","IEEE","IEEE Conferences"
"Data Architecture: A Sustainable Foundation for Data Exploitation","S. Skhiri; C. Duverne","Eura Nova, Brussels, Belgium; Toyota Motor Europe",IEEE Potentials,"12 Nov 2020","2020","39","6","15","21","Many of companies have launched digital transformation programs. Such programs must support the evolution of businesses toward the digital age. Data and their exploitation are at the core of these transformation programs. The ability to use, explore, and analyze data as well as create value within a short time to market are becoming major challenges.","1558-1772","","10.1109/MPOT.2020.3014589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9258461","","Data models;Big Data;Lakes;Real-time systems;Companies;Databases","","1","","13","IEEE","12 Nov 2020","Nov.-Dec. 2020","","IEEE","IEEE Magazines"
"QoS lake: Challenges, design and technologies","F. Ahmad; A. Sarkar; N. C. Debnath","Tata Consultancy services (T.C.S), Newark, NJ, USA; Department of Computer Applications, National Institute of Technology, Durgapur, India; Department of Computer Applications, Winona State University, MN, USA","2017 International Conference on Recent Advances in Signal Processing, Telecommunications & Computing (SigTelCom)","13 Feb 2017","2017","","","65","70","QoS evaluation based on their historical data not only helps in getting more accurate QoS, but also helps in making future QoS prediction, recommendation and knowledge discovery. [1] designed a generic QaaS (Quality as a service) model in the same line as PaaS and SaaS, where users can provide QoS attributes as inputs and the model returns services satisfying the user's QoS. It uses historical data to evaluate accurate QoS. Storing and evaluating QoS based on historical data and managing QoS for all services on the internet is challenging. This paper proposed a QoS lake in the same line of Data Lake for implementing QaaS model using big data technologies like Hadoop, Spark, and Yarn etc. The QoS Lake is a very large repository that stores all logs generated from services and its evaluated QoS data in its original context for all services on internet. The log data are processed to evaluate QoS either in batch or real time. QoS Lake is integrated with cutting-edge analytics, automation, orchestration and machine intelligence tools and languages which are used for future prediction, recommendation and knowledge discovery. QoS Lake has four loosely coupled layers namely; Ingestion layer, data layer, Analysis layer and Visualization layer. The challenges and advantages of the data lake are also discussed. The paper also presented the technologies available today to realize each layer and functionalities of the QoS Lake.","","978-1-5090-2291-5","10.1109/SIGTELCOM.2017.7849797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849797","Big data;QoS Lake;Data lake;Data Warehouse;Hadoop","Quality of service;Lakes;Web services;Data models;Knowledge discovery;Fault tolerant systems","","2","","14","IEEE","13 Feb 2017","9-11 Jan. 2017","9-11 Jan. 2017","IEEE","IEEE Conferences"
"Salesforce Data Architecture and Management: A pragmatic guide for aspiring Salesforce architects and developers to manage, govern, and secure their data effectively","A. Zafar",NA,"Salesforce Data Architecture and Management: A pragmatic guide for aspiring Salesforce architects and developers to manage, govern, and secure their data effectively","","2021","","","","","Learn everything you need to become a successful data architect on the Salesforce platformKey FeaturesAdopt best practices relating to data governance and learn how to implement themLearn how to work with data in Salesforce while maintaining scalability and security of an instanceGain insights into managing large data volumes in SalesforceBook DescriptionAs Salesforce orgs mature over time, data management and integrations are becoming more challenging than ever. Salesforce Data Architecture and Management follows a hands-on approach to managing data and tracking the performance of your Salesforce org. You’ll start by understanding the role and skills required to become a successful data architect. The book focuses on data modeling concepts, how to apply them in Salesforce, and how they relate to objects and fields in Salesforce. You’ll learn the intricacies of managing data in Salesforce, starting from understanding why Salesforce has chosen to optimize for read rather than write operations. After developing a solid foundation, you’ll explore examples and best practices for managing your data. You’ll understand how to manage your master data and discover what the Golden Record is and why it is important for organizations. Next, you'll learn how to align your MDM and CRM strategy with a discussion on Salesforce’s Customer 360 and its key components. You’ll also cover data governance, its multiple facets, and how GDPR compliance can be achieved with Salesforce. Finally, you'll discover Large Data Volumes (LDVs) and best practices for migrating data using APIs. By the end of this book, you’ll be well-versed with data management, data backup, storage, and archiving in Salesforce.What you will learnUnderstand the Salesforce data architectureExplore various data backup and archival strategiesUnderstand how the Salesforce platform is designed and how it is different from other relational databasesUncover tools that can help in data management that minimize data trust issues in your Salesforce orgFocus on the Salesforce Customer 360 platform, its key components, and how it can help organizations in connecting with customersDiscover how Salesforce can be used for GDPR complianceMeasure and monitor the performance of your Salesforce orgWho this book is forThis book is for aspiring architects, Salesforce admins, and developers. You will also find the book useful if you’re preparing for the Salesforce Data Architecture and Management exam. A basic understanding of Salesforce is assumed.","","9781801076906","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163289.pdf&bkn=10163289&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"DataCockpit: A Toolkit for Data Lake Navigation and Monitoring Utilizing Quality and Usage Information","A. Narechania; S. Chakraborty; S. Agarwal; A. R. Sinha; R. A. Rossi; F. Du; J. Hoffswell; S. Guo; E. Koh; A. Endert; S. Navathe","Georgia Institute of Technology, Atlanta, USA; Georgia Institute of Technology, Atlanta, USA; Georgia Institute of Technology, Atlanta, USA; Adobe Research, Bengaluru, India; Adobe Research, San Jose, USA; Databricks, San Francisco, USA; Adobe Research, Seattle, USA; Adobe Research, San Jose, USA; Adobe Research, San Jose, USA; Georgia Institute of Technology, Atlanta, USA; Georgia Institute of Technology, Atlanta, USA",2023 IEEE International Conference on Big Data (BigData),"22 Jan 2024","2023","","","5305","5310","Modern organizations amass their datasets into centralized repositories called data lakes, affording analytics as needed. The resultant scale and complexity of these data lakes, however, can make data navigation and monitoring challenging for users. We present DataCockpit, a Python toolkit that leverages datasets, usage logs, and associated meta-data to provision data usage and quality characteristics. DataCockpit computes these characteristics for each attribute (e.g., number of times it was queried for subsequent use in downstream applications) and record (e.g., number of non-missing, valid values) and aggregates them at the level of datasets. We develop a visual monitoring tool, powered by DataCockpit, and demonstrate how it can assist data / system administrators as well as end-users to effectively navigate and monitor a data lake. DataCockpit and the monitoring tool are available as open source software for developers to build custom monitoring applications on top of data lakes.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386133","data usage;data quality;monitoring;navigation;visualization;toolkit","Visualization;Navigation;Aggregates;Relational databases;Organizations;Big Data applications;Complexity theory","","1","","38","IEEE","22 Jan 2024","15-18 Dec. 2023","15-18 Dec. 2023","IEEE","IEEE Conferences"
"Ontology for Structuring a Digital Databases for Decision Making in Grain Production","R. A. Neves; P. E. Cruvinel","Federal Institute of São Paulo, São João da Boa Vista, SP, Brazil; Post-Graduation Program in Computer Science - Federal University of São Carlos, SP, Brazil",2021 IEEE 15th International Conference on Semantic Computing (ICSC),"3 Mar 2021","2021","","","386","392","This paper presents an ontology for the structuring of digital databases with the objective of acting in a cloud environment and meeting big data sources in the agricultural context of grain production. Its conception is structured in three stages: the first stage presents an ontological architecture aimed at public and private cloud environments, the second stage deals with a semantic model at process level, and a pseudocode for ontological application is elaborated in the third stage, considering the technologies applied to the cloud. This work combines advanced features to support decision making from Data Lake storage solutions, semantic treatment of big data, as well as the presentation of strategies based on machine learning and data quality analysis to obtain data and metadata organized for application in a decision model. The configuration of the ontology presented meets the diversity of big data projects in the grain production context, the characteristics of which are based on interoperability in the use of heterogeneous data and its integration, elasticity of computational resources, and high availability of cloud access.","2325-6516","978-1-7281-8899-7","10.1109/ICSC50631.2021.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364425","Ontology;Agriculture;Digital Database;Cloud Computing;Big Data;Decision Making","Cloud computing;Databases;Semantics;Decision making;Production;Ontologies;Big Data","","1","","33","IEEE","3 Mar 2021","27-29 Jan. 2021","27-29 Jan. 2021","IEEE","IEEE Conferences"
"Toward Sustainable Data Practices: Integrating Open Data With SDG-Based Data Lake Frameworks","A. Kulkarni; C. Ramanathan; V. E. Venugopal","International Institute of Information Technology, Bangalore, Bengaluru, India; International Institute of Information Technology, Bangalore, Bengaluru, India; International Institute of Information Technology, Bangalore, Bengaluru, India",IEEE Technology and Society Magazine,"11 Apr 2024","2024","43","1","62","69","Achieving sustainable development goals (SDGs) necessitates the adoption of sustainable policies, which entails a crucial task of policy formulation. Policymakers must consider multiple factors, such as the present development status, which can be assessed using diverse data points, as well as the policy’s impact and an action plan outlining its implementation [1]. These data points typically originate from various sources, primarily governmental bodies encompassing statistics, budgets, legislation, public services, and geospatial data (maps, satellite imagery), along with domain users comprising individuals, organizations, and governments [2]. The SDGs are intricately crafted, taking into account a multitude of factors and pinpointing key indicators that influence these factors. These factors typically span across diverse data points sourced from various sectors. For instance, in assessing the student dropout rate, it is imperative to consider factors such as the availability of transportation facilities, basic hygiene amenities, access to drinking water, and the effectiveness of government-organized schemes in utilization and impact. Employing an open data framework coupled with advanced artificial intelligence (AI) models has the potential to facilitate in-depth exploration and analysis, providing valuable insights into the complex interplay of these factors and contributing to a more comprehensive understanding of SDG-related challenges and opportunities.","1937-416X","","10.1109/MTS.2024.3365591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10496885","","Transportation;Legislation;Big Data applications;Data models;Satellite images;Geospatial analysis;Artificial intelligence;Sustainable development;Water resources;Open data;Climate change","","1","","14","IEEE","11 Apr 2024","March 2024","","IEEE","IEEE Magazines"
"Data Driven-based Operational Risk Control System for Whole Process Risk Prevention","J. Yu; J. Zhao; W. Xing; J. Xu","State Grid Customer Service Center, Tianjin, China; Tianjin Puxun Power Information Technology Co., Ltd, Tianjin, China; State Grid Customer Service Center, Tianjin, China; Wuhan Institute of Shipbuilding Technology, Wuhan, China",2020 IEEE 4th Conference on Energy Internet and Energy System Integration (EI2),"15 Feb 2021","2020","","","2827","2831","Mobile Internet and its applications have greatly promoted the process of social development and facilitated people's production and life. However, the dark industry chain attached to the network is also undermining the dividends brought by the Mobile Internet to the whole society, bringing risks that cannot be ignored by the operation and application of the Mobile Internet. Therefore, it is very necessary to establish a sound risk control system by Mobile Internet operators to avoid and resist the risks that may occur in the operation process. In this paper, a certain type of App is taken as an example to elaborate the elements and significance of establishing an operational risk control system based on big data. Through the study and discussion of data architecture, model, rules and flow involved in the process of operational risk control, the method of operational risk warning and prevention through data analysis is proposed.","","978-1-7281-9606-0","10.1109/EI250167.2020.9346808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9346808","Big data;risk control;operational risk;dark industry","Industries;Process control;Production;System integration;Big Data;Control systems;Internet","","","","15","IEEE","15 Feb 2021","30 Oct.-1 Nov. 2020","30 Oct.-1 Nov. 2020","IEEE","IEEE Conferences"
"Optimizing Multimodal Data Queries in Data Lakes","R. Xiong; S. Zhao; C. Chen; Z. Xu","School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Computer Software Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China",Tsinghua Science and Technology,"4 Jul 2025","2025","30","6","2625","2637","This paper addresses the challenge of efficiently querying multimodal related data in data lakes, a large-scale storage and management system that supports heterogeneous data formats, including structured, semi-structured, and unstructured data. Multimodal data queries are crucial because they enable seamless retrieval of related data across modalities, such as tables, images, and text, which has applications in fields like e-commerce, healthcare, and education. However, existing methods primarily focus on single-modality queries, such as joinable or unionable table discovery, and struggle to handle the heterogeneity and lack of metadata in data lakes while balancing accuracy and efficiency. To tackle these challenges, we propose a Multimodal data Query mechanism for Data Lakes (MQDL), which employs a modality-adaptive indexing mechanism raleted and contrastive learning based embeddings to unify representations across modalities. Additionally, we introduce product quantization to optimize candidate verification during queries, reducing computational overhead while maintaining precision. We evaluate MQDL using a table-image dataset across multiple business scenarios, measuring metrics such as precision, recall, and F1-score. Results show that MQDL achieves an accuracy rate of approximately 90%, while demonstrating strong scalability and reduced query response time compared to traditional methods. These findings highlight MQDL's potential to enhance multimodal data retrieval in complex data lake environments.","1007-0214","","10.26599/TST.2025.9010022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072065","multimodal data query;data lake;contrastive learning;related data query","Quantization (signal);Accuracy;Scalability;Contrastive learning;Medical services;Metadata;Data retrieval;Big Data applications;Time factors;Indexing","","1","","36","","4 Jul 2025","December 2025","","TUP","TUP Journals"
"Passenger reviews reference architecture using big data lakes","H. B. Sankaranarayanan; J. Lalchandani","Amadeus Software Labs, Bangalore, India; International Institute of Information Technology, Bangalore, India","2017 7th International Conference on Cloud Computing, Data Science & Engineering - Confluence","8 Jun 2017","2017","","","204","209","Passenger reviews are quite popular in social media, e-commerce, and dedicated review websites. It is commonly referred as word of mouth which provides positive, neutral and negative sentiments from passengers about travel services. It helps other travelers to get insights through objective review ratings, subjective textual feedback and in cases along with media content like photos, audios, and videos. Processing passenger reviews is a key aspect for determining sentiments and gauging the pulse of passengers. Travel domain application systems are generally complex, diverse and typically managed by different stakeholders like airlines, airports, travel agencies, immigration, security and other services providers like cars, bus, trains, hotels, events. In this paper, we will propose a reference architecture using data lakes for managing passenger reviews where multiple stakeholders are involved along with challenges on volume, velocity, variety, and veracity. The end goal of the reference architecture is to provide a holistic approach to manage reviews with data gathering, processing and disseminating to a diverse set of stakeholders in the travel ecosystem for actionable insights.","","978-1-5090-3519-9","10.1109/CONFLUENCE.2017.7943150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7943150","reference architecture;passenger reviews;travel;big data;data lakes","Handheld computers;Cloud computing;Data science;Airports;Delays","","","","14","IEEE","8 Jun 2017","12-13 Jan. 2017","12-13 Jan. 2017","IEEE","IEEE Conferences"
"ADLS Gen 2 for web server log data analysis","E. Zagan; M. Danubianu","Faculty of Electrical Engineering and Computer Science, Stefan cel Mare University, Suceava, Romania; Faculty of Electrical Engineering and Computer Science, Stefan cel Mare University, Suceava, Romania",2022 International Conference on Development and Application Systems (DAS),"3 Jun 2022","2022","","","161","166","Before the advent of Big Data, there were few possibilities for processing TB of data sets or more. As data generation capacity has grown, so has the need to store and process large volumes of data. The web server log files contain important and valuable information about events related to customer activities in the online environment, server activities and its response to customer requests, and much more. It is well known that web server log files are files that contain large volumes of data and grow very quickly in size, servers having to delete them once they reach a certain size. Thus, many valuable data are lost, data on which various analyzes can be made in order to obtain valuable information that will later lead to improvements on several levels. It is important to find cost-effective and easily accessible techniques for storing and analyzing these files, which are also considered to be of a high privacy level holding information classified as personal data. The main objective is the research for the development and implementation of an innovative solution for storing and analyzing large volumes of web server log files using cloud storage - ADLS Gen2.","","978-1-6654-8162-5","10.1109/DAS54948.2022.9786071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9786071","Data Lake;web server log data;cloud Data Lake;ADLS Gen2","Cloud computing;Data privacy;Data analysis;Costs;Memory;Transforms;Big Data applications","","","","15","IEEE","3 Jun 2022","26-28 May 2022","26-28 May 2022","IEEE","IEEE Conferences"
"DATAWiSE: A Scalable Big Data Reference Architecture for Smart Building","E. Stamatopoulos; D. Stoian; H. Neofytou; P. Kouloukakis; A. Sianni; V. Marinakis","Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece; Electrical & Computer Engineering, NTUA, Athens, Greece","2025 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)","13 Aug 2025","2025","","","1","9","The emergence of Digital Twin technology has dramatically changed operational and managerial practices in intelligent buildings by enabling real-time monitoring, predictive maintenance, and performance improvement. However, the management of large and heterogeneous data produced by Internet of Things (IoT) sensors, Building Information Models (BIM), and environmental systems poses a challenge in terms of interoperability, scalability, and real-time processing capability. This paper presents the DATAWiSE architecture, a modular and scalable big data framework that is designed to integrate disparate building data sources while ensuring both secure and efficient data management. A detailed account of the process followed, from user requirements collection to the design of the proposed reference architecture. The proposed multi-layered architecture combines distributed storage technologies, AI-based analytics, and standardized communication protocols to provide strong data governance while enabling informed decision-making. Explainable AI approaches also assist in increasing system transparency and stakeholder trust. Future development areas include further enhancements in federated learning, edge computing, and harmonization with international data-sharing protocols to increase the architecture's applicability within larger smart city infrastructures.","2693-8855","979-8-3315-8534-1","10.1109/ICE/ITMC65658.2025.11106585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106585","big data architecture;interoperability;building digital twin;AI-driven analytics;smart buildings","Smart buildings;Smart cities;Architecture;Soft sensors;Scalability;Computer architecture;Big Data;Real-time systems;Digital twins;Interoperability","","","","20","IEEE","13 Aug 2025","16-19 June 2025","16-19 June 2025","IEEE","IEEE Conferences"
"Efficient analytical architecture for sensor networks using Hadoop","K. Lavanya; G. Murali","Computer Science and Engineering, JNTUAC of Engineering (Autonomous), Pulivendula; Computer Science and Engineering, JNTUA college of Engineering (Autonomous), Pulivendula",2016 International Conference on Communication and Electronics Systems (ICCES),"30 Mar 2017","2016","","","1","6","Big Data is the new experience curve in the new economy driven by huge data with larger volume, velocity and variety. The real time application processing of remote sensing of large volumes of Big Data seems at first, and provide extracting and analysis in useful information with an effective manner leads a advanced system toward a novel computational challenges, such as to analyze, aggregate, and store, where data are remotely gathered. The three main units comprise the proposed architecture the three units are The proposed architecture can store raw data for the analysis of the offline data when required. The proposed architecture comprises three main units, such as 1) remote sensing Big Data acquisition unit (RSDU); 2) data processing unit (DPU); and 3) data analysis decision unit (DADU). First, RSDU acquires data from the satellite and sends this data to the Base Station, where initial processing takes place. Second, DPU plays a vital role in architecture for efficient processing of real-time Big Data by providing filtration, load balancing, and parallel processing. Third, DADU is the upper layer unit of The proposed structure, which is liable for compilation, storage of the results, and generation of determination founded on the outcome obtained from DPU. The proposed architecture has the ability of dividing, load balancing, and concurrent processing of only useful data. For that reason, it outcome in effectively analyzing real time remote sensing tremendous data utilizing earth observatory method. Additionally, the proposed big data architecture provides the capacity of storing and making analysis of incoming raw knowledge to perform offline evaluation on mostly stored dumps, when required. Ultimately, a targeted analysis of remotely sensed earth observatory tremendous data for land and sea field is supplied making use of Hadoop. In addition, more than a few algorithms are proposed for each and every stage of RSDU, DPU, and DADU to detect land as good as sea discipline to complicated the working of architecture.","","978-1-5090-1066-0","10.1109/CESYS.2016.7889966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889966","Data analysis decision unit (DADU);data processing unit (DPU);Hadoop;mapreduce;offline;realtime;remote senses;remote sensing Big Data acquisition unit (RSDU)","Big Data;Remote sensing;Servers;Computer architecture;Earth;Satellites","","","","13","IEEE","30 Mar 2017","21-22 Oct. 2016","21-22 Oct. 2016","IEEE","IEEE Conferences"
"An overview about data integration in data lakes","J. C. Couto; D. D. Ruiz","School of Technology, PUCRS University, Porto Alegre, Brazil; School of Technology, PUCRS University, Porto Alegre, Brazil",2022 17th Iberian Conference on Information Systems and Technologies (CISTI),"14 Jul 2022","2022","","","1","7","Integrating data in data lakes is essential so we can perform more complex analyses. However, data lakes are mainly composed of raw data, from structured, semi-structured, and even unstructured data. It turns out that traditional data integration algorithms usually expect to receive structured data as input, so those different types of data jeopardize big data integration. This paper presents a systematic literature review that generates a broad landscape about data integration in data lakes. We searched for papers in eight well-known search engines, following a structured process. From the 298 papers we retrieved, we selected 22 papers that answer our research questions. We identify examples of data lake integration models, how they calculate the similarity among the datasets, how the models are evaluated, the most common type of data they integrate, and the challenges inherent to the area, which points to future research directions in data integration in data lakes.","2166-0727","978-9-8933-3436-2","10.23919/CISTI54924.2022.9820576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9820576","data integration;data lake","Measurement;Systematics;Scalability;Bibliographies;Semantics;Data integration;Search engines","","3","","29","","14 Jul 2022","22-25 June 2022","22-25 June 2022","IEEE","IEEE Conferences"
"Architecture Description Framework For Data-Intensive Applications","M. Abughazala; H. Muccini; M. Sharaf","DISIM Department, University of L'Aquila, L'Aquila, Italy; DISIM Department, University of L'Aquila, L'Aquila, Italy; Computer Science Department, An Najah N. University, Nablus, Palestine",2023 Fourth International Conference on Intelligent Data Science Technologies and Applications (IDSTA),"20 Nov 2023","2023","","","99","106","Managing data has become increasingly difficult due to its exponential growth and multiple sources. In the business world, Data Architecture provides a systematic approach to describing, collecting, storing, processing, and analyzing data to meet business needs. It plays a crucial role in transforming data into valuable information by providing an abstract view of data-intensive applications. A framework for data-intensive applications is presented in this article, which utilizes model-driven engineering to achieve this goal. The framework's effectiveness was evaluated through five thorough case studies, with valuable feedback provided by seven practitioners and two prominent companies on its capabilities.","","979-8-3503-3925-3","10.1109/IDSTA58916.2023.10317869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10317869","Data Architecture;Modeling Data Architecture;Big Data. Data-Intensive applications","Systematics;Companies;Data science;Model driven engineering;Business","","2","","33","IEEE","20 Nov 2023","24-26 Oct. 2023","24-26 Oct. 2023","IEEE","IEEE Conferences"
"The discussion on data system in the era of big data","F. Miao; W. Yang; Y. Xie; W. Fan","The Big Data Research Institute, Chengdu University, Chengdu, China; College of Computer & Network, Chengdu University of Technology, Chengdu, China; Department of gov-Technology, Big Data Center of Sichuan Province, Chengdu, China; The Big Data Research Institute, Chengdu University, Chengdu, China",2023 International Conference on Computer Applications Technology (CCAT),"5 Feb 2024","2023","","","222","228","For a long time, people have been using information technology to improve the quality and efficiency of various business operations in enterprises, economy, government, society, etc., and have achieved remarkable benefits. This has also formed a mindset and habitual practices, which is business-centric, process-conduct, business-oriented and business-driven informative methods. With the development of the big data era and digital economy, the emergence of new technologies, the expectation of new demands, the generation of new ideas, and the exploration of new methods will break the outdated understanding and limitations of traditional methods in the past, and will open up a new pattern of information system construction and digital transformation that is centered on data, solidify the foundation of data resource system, and promote the circulation of data elements. This paper starts with the impact of data on the future of humanity, and analyzes and discusses the role, scope, composition, and implementation paths of new information system, namely data system, through comparing information and data. It proposes feasible and valuable solutions for the new digital transformation at various levels, the construction and capacity enhancement of data system supported by the ""one-body-two-wings"" data architecture.","","979-8-3503-0154-0","10.1109/CCAT59108.2023.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10410380","Digital transformation;data platform;information system;data system;data resource system;data architecture","Humanities;Digital transformation;Computer architecture;Big Data;Data systems;Information technology;Business","","","","12","IEEE","5 Feb 2024","15-17 Sept. 2023","15-17 Sept. 2023","IEEE","IEEE Conferences"
"Development and Evaluation of a Big Data Framework for Performance Management in Mobile Networks","D. Martinez-Mosquera; R. Navarrete; S. Luján-Mora","Department of Informatics and Computer Science, Escuela Politécnica Nacional, Quito, Ecuador; Department of Informatics and Computer Science, Escuela Politécnica Nacional, Quito, Ecuador; Department of Software and Computing Systems, University of Alicante, Alicante, Spain",IEEE Access,"29 Dec 2020","2020","8","","226380","226396","In telecommunications, Performance Management (PM) data are collected from network elements to a centralized system, the Network Management System (NMS), which acts as a business intelligence tool specialized in monitoring and reporting network performance. Performance Management files contain the metrics and named counters used to quantify the performance of the network. Current NMS implementations have limitations in scalability and support for volume, variety, and velocity of the collected PM data, especially for 5G and 6G mobile network technologies. To overcome these limitations, we proposed a Big Data framework based on an analysis of the following components: software architecture, ingestion, data lake, processing, reporting, and deployment. Our work analyzed the PM files’ format on a real data set from four different vendors and 2G, 3G, 4G, and 5G technologies. Then, we experimentally assessed our proposed framework’s feasibility through a case study involving 5G PM files. Test results of the ingestion and reporting components are presented, identifying the hardware and software required to support up to one billion counters per hour. This proposal can help telecommunications operators to have a reference Big Data framework to face the current and future challenges in the NMS, for instance, the support of data analytics in addition to the well-known services.","2169-3536","","10.1109/ACCESS.2020.3045175","Unidad de Gestión de Investigación y Proyección Social from the Escuela Politécnica Nacional; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9296310","Big data;framework;mobile networks;network management system;performance management","Big Data;5G mobile communication;Proposals;Monitoring;Lakes;Computer architecture;6G mobile communication","","7","","53","CCBY","16 Dec 2020","2020","","IEEE","IEEE Journals"
"Archigraphs As A Promising Concept For The Development Of Data And Knowledge Storage Systems","A. A. Sukhobokov; A. A. Vetoshkin; A. R. Mironova; A. C. Zenger; V. Baklikov","SAP America, Inc., Newtown Square, PA, USA; Dep. Information Processing and Management Systems, Bauman Moscow State Technical University, Moscow, Russia; Dep. Information Processing and Management Systems, Bauman Moscow State Technical University, Moscow, Russia; OZON Marketplace Kazakhstan LLP, Almaty, Kazakhstan; Skyward, Inc., North Bethesda, MD, USA",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","3508","3521","The article describes one of the types of complex graphs – an archigraph, which, unlike conventional graphs with only vertices and edges, can contain an arbitrary number of different types of elements and has advanced means of structuring and encapsulating its individual parts. Due to these properties, an archigraph can become a good conceptual model for creating new generations of data and knowledge storage systems. This is especially relevant for systems that store a large number of elements, or systems which elements are diverse in their characteristics. The transition to the use of the archigraph model is demonstrated for the file systems, database management systems, data warehouses, blockchain platforms, data lake management systems and various architectures derived from data lakes: Data Lakehouse, Data Space, Data Fabric, Data Mesh, in which Data Lake is an integral component. Moreover, we show the possibility of expanding the basic capabilities of an archigraph by making its elements more complex and ensuring work with sets and logical operations. Such advanced archigraphs are proposed to be used in constructing knowledge lakes used by intelligent systems. An approximate composition of the Knowledge Lake elements we show in this work.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825028","archigraph;File System;Database Management System;Data Lake;Data Lakehouse;Data Space;Data Fabric;Data Mesh;Knowledge Lake;Blockchain Platform","File systems;Buffer storage;Lakes;Data warehouses;Big Data applications;Data models;Fabrics;Database systems;Blockchains;Intelligent systems","","","","90","IEEE","16 Jan 2025","15-18 Dec. 2024","15-18 Dec. 2024","IEEE","IEEE Conferences"
"From big data to smart data: A genomic information systems perspective","A. L. Palacio; Ó. P. López","Universitat Politecnica de Valencia, Valencia, Valenciana, ES; Universitat Politecnica de Valencia, Valencia, Valenciana, ES",2018 12th International Conference on Research Challenges in Information Science (RCIS),"9 Jul 2018","2018","","","1","11","During the last two decades, data generated by Next Generation Sequencing Technologies have revolutionized our understanding of human biology and improved the study on how changes (variations) in the DNA are involved in the risk of suffering a certain disease. A huge amount of genomic data is publicly available and frequently used by the research community in order to extract meaningful and reliable gene-disease relationships. However, management of this exponential growth of data has become a challenge for biologists; under such a big data problem perspective, they are forced to delve into a lake of complex data spread in over thousand heterogeneous repositories, represented in multiple formats and with different levels of quality; but when data are used to solve a concrete problem only a small part of that “data lake” is really significant; this is what we call the “smart” data perspective. Using conceptual models and the principles of data quality management, adapted to the genomic domain, we propose a systematic approach to move from a big data to a smart data perspective. The aim of this approach is to populate an Information System with genomic data which must be accessible, informative and actionable enough to extract valuable knowledge.","2151-1357","978-1-5386-6517-6","10.1109/RCIS.2018.8406658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8406658","Conceptual Modelling;Data Quality;Big Data;Smart Data;Genomics","Genomics;Bioinformatics;Big Data;Data integrity;Diseases;Data models","","7","","","IEEE","9 Jul 2018","29-31 May 2018","29-31 May 2018","IEEE","IEEE Conferences"
"BigDataBench: A big data benchmark suite from internet services","L. Wang; J. Zhan; C. Luo; Y. Zhu; Q. Yang; Y. He; W. Gao; Z. Jia; Y. Shi; S. Zhang; C. Zheng; G. Lu; K. Zhan; X. Li; B. Qiu","State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; Dropbox; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; Huawei; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; Tencent; Baidu; Yahoo!",2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA),"19 Jun 2014","2014","","","488","499","As architecture, systems, and data management communities pay greater attention to innovative big data systems and architecture, the pressure of benchmarking and evaluating these systems rises. However, the complexity, diversity, frequently changed workloads, and rapid evolution of big data systems raise great challenges in big data benchmarking. Considering the broad use of big data systems, for the sake of fairness, big data benchmarks must include diversity of data and workloads, which is the prerequisite for evaluating big data systems and architecture. Most of the state-of-the-art big data benchmarking efforts target evaluating specific types of applications or system software stacks, and hence they are not qualified for serving the purposes mentioned above. This paper presents our joint research efforts on this issue with several industrial partners. Our big data benchmark suite-BigDataBench not only covers broad application scenarios, but also includes diverse and representative data sets. Currently, we choose 19 big data benchmarks from dimensions of application scenarios, operations/ algorithms, data types, data sources, software stacks, and application types, and they are comprehensive for fairly measuring and evaluating big data systems and architecture. BigDataBench is publicly available from the project home page http://prof.ict.ac.cn/BigDataBench. Also, we comprehensively characterize 19 big data workloads included in BigDataBench with varying data inputs. On a typical state-of-practice processor, Intel Xeon E5645, we have the following observations: First, in comparison with the traditional benchmarks: including PARSEC, HPCC, and SPECCPU, big data applications have very low operation intensity, which measures the ratio of the total number of instructions divided by the total byte number of memory accesses; Second, the volume of data input has non-negligible impact on micro-architecture characteristics, which may impose challenges for simulation-based big data architecture research; Last but not least, corroborating the observations in CloudSuite and DCBench (which use smaller data inputs), we find that the numbers of L1 instruction cache (L1I) misses per 1000 instructions (in short, MPKI) of the big data applications are higher than in the traditional benchmarks; also, we find that L3 caches are effective for the big data applications, corroborating the observation in DCBench.","2378-203X","978-1-4799-3097-5","10.1109/HPCA.2014.6835958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835958","","Benchmark testing;Computer architecture;Social network services;System software;Search engines","","404","1","31","IEEE","19 Jun 2014","15-19 Feb. 2014","15-19 Feb. 2014","IEEE","IEEE Conferences"
"A Comprehensive Big Data Framework for Energy Markets: Oil and Gas Demand Forecasting","A. Bayar; B. Koç; M. O. Gökalp; B. Özden; Y. Yeldan; P. E. Eren; A. Koçyiğit","Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Data Analytics Center Tüpraş, Ankara, Turkey; Data Analytics Center Tüpraş, Ankara, Turkey; Data Analytics Center Tüpraş, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey",2022 3rd International Informatics and Software Engineering Conference (IISEC),"29 Dec 2022","2022","","","1","6","Demand forecasting in the energy sector is essential for both countries and companies to plan their supply and demand. Agents in the highly volatile oil markets have to act fast and data-driven. In the literature, studies on oil or gasoline demand forecasting are carried out using traditional econometric and AI-based models, using static data for long periods. In this paper, short-term gasoline demand forecasting literature has been investigated. We focus on short-term demand prediction based on big data analytics and investigate potential data sources and architectures to collect data. To this end, several iterative meetings were conducted between the Data Science department, the Oil Trading department of an Oil & Gas company, and researchers within an industry-academia cooperation project. Traditional data sources used for the problem are presented, and the applicability of real-time data to the problem is discussed. A big data architecture is proposed that can be used to predict the demand for petroleum products, mainly for gasoline in the U.S., for the transparency, amplitude, and availability of open data.","","978-1-6654-5995-2","10.1109/IISEC56263.2022.9998216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9998216","oil;gasoline;demand;forecasting;big data analytics","Supply and demand;Oils;Soft sensors;Demand forecasting;Computer architecture;Companies;Big Data","","1","","36","IEEE","29 Dec 2022","15-16 Dec. 2022","15-16 Dec. 2022","IEEE","IEEE Conferences"
"Parquet Compression in Windows with Big data-An Enhanced Storage Style","K. Wankhede; B. Colabawalla","K J Somaiya Institute of Management Studies and Research, Mumbai; K J Somaiya Institute of Management Studies and Research, Mumbai",2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV),"31 Mar 2021","2021","","","1244","1249","The paper focusses on highlighting compression utilities/applications used in generic operating systems and enhancing those using a Big Data Architecture-based engine. Storage is a compelling factor in commonly used machines and using such techniques, low storage capacity issues in machines can be reduced and hence efficiency will be improved. The focus is on creating a proof of concept that such an efficient compression type can also be used on files on an operating system like windows and not only in the big data infrastructure and hence going on ahead with its uses and enhancements. Research work also aims at achieving compression of the files into parquet files into Windows which is not being done currently.","","978-1-6654-1960-4","10.1109/ICICV50876.2021.9388437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388437","","Operating systems;Cluster computing;Big Data;Communications technology;Sparks;Engines;Graphical user interfaces","","","","22","IEEE","31 Mar 2021","4-6 Feb. 2021","4-6 Feb. 2021","IEEE","IEEE Conferences"
"Artificial Intelligence in Finance: Coffee Commodity Trading Big Data for Informed Decision Making","N. -B. -v. Le; Y. -S. Seo; J. -H. Huh","Department of Data Informatics, National Korea Maritime and Ocean University, Busan, Republic of Korea; School of Computer Science and Engineering, Yeungnam University, Gyeongsan, Republic of Korea; Interdisciplinary Major of Ocean Renewable Energy Engineering, National Korea Maritime and Ocean University, Busan, Republic of Korea",IEEE Access,"10 Jul 2024","2024","12","","91780","91792","Coffee, the second-largest global soft commodity, can take advantage of a comprehensive mining of daily and historical market data for more effective informed trading decisions. Advanced ICT and data mining technologies can change the trading market operation. The existing systems are confronted with certain constraints, including incomplete data, insufficient documentation for storage, and a requirement for a scalable infrastructure for big data analytics, such as a data warehouse or data lakehouse. To address this issue, the paper presents a design and implementation of a coffee commodity trading big data warehouse capable of analyzing various essential parameters for supporting informed decision-making. First, the designed system can automatically collect coffee trading data for New York Arabica coffee futures prices from selected worldwide reports and financial data portals. Next, the Extract, transform, and load (ETL) process is adopted to ingest coffee futures trading crawled data into the 3 layers data warehouse. Finally, the analytical system will extract and visualize selected key dimensions that influence coffee futures prices within different observation windows and perspectives. As a result, we implement a prototype of a coffee trading data warehouse on the crawled data from January 2000 to October 2022 and visualize trends in coffee futures prices based on the collected data for informed decision-making. The construction system is capable of stably operating and processing large volumes of transaction data. This paper will be valuable documentation for reference and decision support for coffee commodity trading enterprises and contribute to the development of future forecasting algorithms.","2169-3536","","10.1109/ACCESS.2024.3409762","National Research Foundation of Korea (NRF); Korea Government (MSIT)(grant numbers:NRF-2023R1A2C1008134); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549867","Coffee big data;data warehouse;coffee commodity trading;ETL process;informed decision-making;data visualization;big data","Data warehouses;Contracts;Data visualization;Predictive models;Data models;Data mining;Big Data;Market research;Pricing;Stock markets;Financial services","","6","","40","CCBYNCND","5 Jun 2024","2024","","IEEE","IEEE Journals"
"Concept of a data centralization system for a railway transportation and station management systems","W. Bauer; K. Grobler-Dębska; W. Woźniak","Dep. of Automatic Control and Robotics, AGH University of Science and Technology Krakow, Poland; Dep. of Automatic Control and Robotics, AGH University of Science and Technology Krakow, Poland; Łukasiewicz Research Network - PoznańInstitute of Technology, Poznan, Poland",2024 28th International Conference on Methods and Models in Automation and Robotics (MMAR),"19 Sep 2024","2024","","","510","514","This paper advocates for the digitization of transportation enterprises, focusing on the railway industry’s need for integrated ticketing and asset management systems. It introduces Data Lake technology as a solution for centralized data management, enabling railway companies to enhance operational efficiency and improve decision-making processes. By integrating diverse data sources within the Data Lake framework, the paper demonstrates the potential for achieving holistic insights and predictive analytics to optimize railway operations. Practical implementation of Data Lake in the MOTIONAL project exemplifies its efficacy in real-world applications, underscoring its pivotal role in modernizing railway transportation and station management systems.","2835-2807","979-8-3503-6234-3","10.1109/MMAR62187.2024.10680822","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10680822","Transportation digitization;Data Lake technology;Railway operations optimization;Asset management","Soft sensors;Decision making;Transportation;Focusing;Lakes;Big Data applications;Rail transportation","","1","","13","IEEE","19 Sep 2024","27-30 Aug. 2024","27-30 Aug. 2024","IEEE","IEEE Conferences"
"Real-Time Maintaining of Social Distance in Covid-19 Environment using Image Processing and Big Data","S. Melenli; A. Topkaya","Technology Itelligence Turkey, Istanbul, Turkey; Enterprise Analytics Itelligence Turkey, Istanbul, Turkey",2020 Innovations in Intelligent Systems and Applications Conference (ASYU),"23 Nov 2020","2020","","","1","5","Recent research in computer vision is increasingly focusing on developing systems to understand people's appearance, movements and activities, provide advanced interfaces for interacting with people, create human models. For any of these systems to work, they need methods to identify people from a particular input image or video. Today, real-time object detection and sizing of objects is an important issue in many areas of the industry. This is a vital issue of computer vision problems. With Covid-19's healing process, it will be very important to maintain social distance. In this research and development, it is aimed to maintain social distance with proposed big data architecture. This article provides an advanced technique to detect objects in video streams in real time and calculate their distance. The system composed research and developments to perform a stream from the camera, such as video stream, distance and object detection model, incoming data stream, data stream collection and report generation. The video stream from the camera is processed with GStream. The frames from the video stream are taken by OpenCV, YOLOV3 is trained by distance and object detection model and developed by Python. Video streaming data trained with Kubeflow is published with Apache Kafka and Apache Spark. It uses HDFS used to store published data. It is used to query and analyze data in Hive, Impala, Hbase HDFS. After that Analytical reports are created. E-mail notifications can be created according to the data in the database using by Apache Oozie. Through the proposed real time big data architecture, people can be safe in closed areas.","","978-1-7281-9136-2","10.1109/ASYU50717.2020.9259891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259891","Computer Vision;Image Processing;Big Data;Stream;Detection","Streaming media;Sparks;Real-time systems;Tools;Object detection;Structured Query Language;Pipelines","","11","","19","IEEE","23 Nov 2020","15-17 Oct. 2020","15-17 Oct. 2020","IEEE","IEEE Conferences"
"An Automated Metadata Generation Method for Data Lake of Industrial WoT Applications","H. Yu; H. Cai; Z. Liu; B. Xu; L. Jiang","School of Software, Shanghai Jiao Tong University, Shanghai, China; School of Software, Shanghai Jiao Tong University, Shanghai, China; School of Software, Shanghai Jiao Tong University, Shanghai, China; College of Economics and Management, Shanghai Jiao Tong University, Shanghai, China; School of Software, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","18 Jul 2022","2022","52","8","5235","5248","Recent trends in the Web of Things (WoT) have led to data explosion. Data lake (DL), as a flexible on-demand heterogeneous data management architecture, has become a feasible solution in data management. Metadata modeling for DLs is the key basis for smart analysis and processing. However, the varieties in structures and semantics of industrial WoT data hinder metadata modeling and maintenance. Moreover, the lack of textual descriptions and the semantics hidden in value streams make it hard to automatically construct semantic metadata. The dynamic nature of WoT requires on-time evolution on metadata. To overcome these challenges, we propose an automated bottom-up metadata generation approach for DL of WoT applications. Applying a data-driven framework, raw data are notated as linked data and self-organizing map-based online clustering is applied to real timely extract data characteristics. To recognize entities, concepts and relations, semantics-based entity discovery approach from short texts is proposed according to the feature of WoT data. The numerical analysis is performed to find the hidden relations from raw values. Full-dimensional metadata with rich semantic knowledge are finally built. Experiments on a real-world dataset are conducted to verify the effectiveness of methods and a case study on an energy WoT system is provided to demonstrate the feasibility of the approach.","2168-2232","","10.1109/TSMC.2021.3119871","National Natural Science Foundation of China(grant numbers:61972243); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583606","Data lake (DL);data modeling;entity recognition;metadata generation;stream processing;Web of Things (WoT)","Metadata;Semantics;Runtime;Data mining;Ontologies;Text recognition;Conferences","","11","","33","IEEE","21 Oct 2021","Aug. 2022","","IEEE","IEEE Journals"
"Hybrid Framework: Balancing Data Utility in Privacy-Preserving Big Data Processing (PPBDP)","V. Chauhan; R. Gupta","Department of Computer Science and Engineering, Chandigarh University, Punjab, India; Department of Computer Science and Engineering, Chandigarh University, Punjab, India",2025 IEEE Guwahati Subsection Conference (GCON),"26 Sep 2025","2025","","","1","6","Big data is a rapidly growing form of information, leading to significant concerns about data privacy. Conventional privacy-preserving methodologies, including anonymization and encryption, exhibit inherent constraints in optimizing the trade-off between data utility and privacy. This study introduces an advanced hybrid privacy preservation framework for big data dissemination, integrating anonymization methodologies to provide comprehensive privacy protection. The proposed framework rigorously maintains the inherent data architecture while simultaneously safeguarding the information’s confidentiality. This methodology is especially pertinent for domains where the integrity and privacy of data are paramount, including health-care, finance, and governmental operations. The proposed model aspires to augment data privacy while concurrently preserving its applicability for analytical and research endeavours.","","979-8-3315-1345-0","10.1109/GCON65540.2025.11173317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11173317","Big Data Publishing;Differential Privacy;Privacy-Preserving Data Publishing;Big Data Anonymization","Differential privacy;Analytical models;Technological innovation;Publishing;Finance;Big Data;Data models;Information filtering;Protection;Information integrity","","","","18","IEEE","26 Sep 2025","18-20 June 2025","18-20 June 2025","IEEE","IEEE Conferences"
"12 Thick Data vs Big Data","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","59","64","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933576.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"Improving High data rates in Milli meter Wave Communication networks via Long short term memory Technique","P. Govindhan; K. Kumar","Electronics and Communication Engineering, Puducherry Technological University, Puducherry, India; Electronics and Communication Engineering, Puducherry Technological University, Puducherry, India",2023 International Conference on Advancement in Computation & Computer Technologies (InCACCT),"8 Jun 2023","2023","","","1","4","In present scenarios the mobile users except for Seamless communication, mobile esports gaming, hybrid classrooms, and playground parks, massive mobile performance, no lag video with best 5G Connections. This huge volume of data transmission is supported by big data architecture as a backbone of the internet. Big data architecture is modelled with handling processing, recovery, breakdown and analysis of information that is high volume or with complex design pattern when compared with traditional database systems, with this existing design in this paper we are integrating the mixed-mode millimeter -wave data transmission design for better network capacity with high data rates, throughput, coverage, and performance in both indoor and outdoor environments. Machine Learning has the potential to resolve the problems in the design of communication networks, In particular, we create a network design with our theoretical approach that evaluates the download speed of the user equipment by modeling the connection between a big data system and mm-wave antenna system. Long Short-term memory algorithm is used to predict the mm-wave antenna group in a time-series manner for data transmission to improve the performance of a network. The result proves the better throughput when compared with non-big data architecture and with this proposed","","979-8-3503-9648-5","10.1109/InCACCT57535.2023.10141767","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10141767","millimeter-wave;5G;ML LSTM;and big data","Solid modeling;Transmitting antennas;Computer architecture;Big Data;Throughput;Prediction algorithms;Data models","","1","","12","IEEE","8 Jun 2023","5-6 May 2023","5-6 May 2023","IEEE","IEEE Conferences"
"Research on Digital Forensics Framework for Malicious Behavior in Cloud","G. Chen; D. Wu; G. Chen; P. Qin; L. Zhang; Q. Liu","Key Laboratory of Public Security Information Application Based on Big Data Architecture, MPS, Zhejiang Police College, Hangzhou, China; The People’s Procuratorate of Hangzhou, Hangzhou, China; Wenzhou Public Security Bureau, Wenzhou, China; Henan Polytechnic University, Jiaozuo, China; Joint Services Academy, National Defence University, Beijing, China; Key Laboratory of Public Security Information Application Based on Big Data Architecture, MPS, Zhejiang Police College, Hangzhou, China","2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","13 Feb 2020","2019","","","1375","1379","The difficult of detecting, response, tracing the malicious behavior in cloud has brought great challenges to the law enforcement in combating cybercrimes. This paper presents a malicious behavior oriented framework of detection, emergency response, traceability, and digital forensics in cloud environment. A cloud-based malicious behavior detection mechanism based on SDN is constructed, which implements full-traffic flow detection technology and malicious virtual machine detection based on memory analysis. The emergency response and traceability module can clarify the types of the malicious behavior and the impacts of the events, and locate the source of the event. The key nodes and paths of the infection topology or propagation path of the malicious behavior will be located security measure will be dispatched timely. The proposed IaaS service based forensics module realized the virtualization facility memory evidence extraction and analysis techniques, which can solve volatile data loss problems that often happened in traditional forensic methods.","2381-0947","978-1-7281-1907-6","10.1109/IAEAC47372.2019.8997702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8997702","malicious behavior;digital forensics;cyber crime;privacy leakage","Cloud computing;Digital forensics;Computer crime;Emergency services;Virtual machining","","3","","21","IEEE","13 Feb 2020","20-22 Dec. 2019","20-22 Dec. 2019","IEEE","IEEE Conferences"
"Electronic Passport as the Basis of the Digital Twin","D. Topolsky; A. Belyakov; V. Pochinskaia","Dep. of Electronic Computing Machines, South Ural State University (National Research University), Chelyabinsk, Russia; Dep. of Electronic Computing Machines, South Ural State University (National Research University), Chelyabinsk, Russia; Dep. of Electronic Computing Machines, South Ural State University (National Research University), Chelyabinsk, Russia",2023 International Russian Smart Industry Conference (SmartIndustryCon),"1 May 2023","2023","","","152","157","During the process of decision support system development there is a problem associated with the heterogeneity of the data in terms of relevance, quality and completeness of the research objects description. The solution to this problem is digital twins based on data lake technology implementation. The aim of the work is to create a prototype of an electronic passport (e-passport) of materials as the basis of their digital twin. The digital twin is to contain a set of data on the composition, structure, calculated and experimentally measured properties, participation in the composition of chemical reactions, constructed models and ""structure-property"" patterns as well. It is proposed to combine the information on a specific material or compound into an information structure — electronic passports of the research object. At the same time, it is advisable to consider the electronic passport as a comprehensive description of the object, including information about the static and dynamic parameters of the atomic-molecular system of the research object. The e-passport as an information object gives a systematic data on the composition of a substance, structure, calculated and experimentally measured properties, the participation of elements in the composition of chemical reactions, constructed models and ""structure-property"" patterns, thus acting as a generalizing tool convenient for users to present information available in the database of digital twins of materials.","","978-1-6654-6429-1","10.1109/SmartIndustryCon57312.2023.10110811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10110811","electronic passport;digital twin;data lake;full-text search;big data;decision support system","Industries;Decision support systems;Systematics;Atmospheric measurements;Databases;Prototypes;Particle measurements","","6","","20","IEEE","1 May 2023","27-31 March 2023","27-31 March 2023","IEEE","IEEE Conferences"
"Revolutionizing Healthcare Management: Architecture of a Web-based Medical Triage Service","A. A. Harby; E. ElKhodary; R. Almeida; D. Sharma; F. Zulkernine; F. Alaca; K. Elgazzar; A. Almarzouqi; N. Al-Yateem; S. A. Rahman","School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; Faculty of Engineering and Applied Science, Ontario Tech University, Oshawa, Ontario, Canada; University of Sharjah, Sharjah, United Arab Emirates; University of Sharjah, Sharjah, United Arab Emirates; University of Sharjah, Sharjah, United Arab Emirates","2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)","26 Aug 2024","2024","","","1887","1894","During the COVID-19 pandemic, the traditional emergency healthcare systems faced unprecedented strain due to the sharp rise in demands for urgent care, scarcity of resources, and increased risks of people getting infected while waiting at the emergency care facility. We present Triage-Bot, an online medical triage provisioning service, that can revolutionize emergency care by decreasing the load on emergency departments (ED), reducing healthcare expenses, and improving the quality of care. Empowered by artificial intelligence and natural language processing, the Triage-Bot service assesses and prioritizes patients' needs based on symptoms, medical history, and perceived conditions from multimodal video, audio, and text data captured during patients' interactions. The captured summarized information with a severity ranking is sent to a human expert to suggest the next action on the user's part. The diverse data types used by the Triage-Bot in communication, authentication, data collection, storage, and analytics requires a robust and scalable system architecture for online service provisioning. In this paper, we specifically focus on the system design and architecture of the Triage-Bot for emergency healthcare settings. With integrated electronic medical records (EMR) and online platforms, the bot fosters collaboration among healthcare professionals and enables swift and informed decision-making even in the face of crises. By partially automating and offering a hybrid triage process, the Triage-Bot improves resource allocation, reduces healthcare management costs for emergency care, minimizes patient waiting times, and improves wellbeing. To address the complexities and demands of healthcare data management, our proposed system incorporates MongoDB database for flexibility, scalability, and versatility in supporting different types of data. Additionally, we implement a data linking and analytics pipeline utilizing a data Lakehouse system to effectively ingest, manage, process, and generate knowledge from heterogeneous data sources.","2836-3795","979-8-3503-7696-8","10.1109/COMPSAC61105.2024.00299","NSERC Canada; IBM; Mitacs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10633674","Database;Triage bot;Healthcare Management;Data Lakehouse","Hospitals;Databases;Soft sensors;Authentication;Systems architecture;Computer architecture;Chatbots","","1","","32","IEEE","26 Aug 2024","2-4 July 2024","2-4 July 2024","IEEE","IEEE Conferences"
"Optimizing Cloud Data Lake Queries With a Balanced Coverage Plan","G. Weintraub; E. Gudes; S. Dolev; J. D. Ullman","Computer Science Department, Ben-Gurion University of the Negev, Beer-Sheva, Israel; Computer Science Department, Ben-Gurion University of the Negev, Beer-Sheva, Israel; Computer Science Department, Ben-Gurion University of the Negev, Beer-Sheva, Israel; Stanford University, Stanford, CA, USA",IEEE Transactions on Cloud Computing,"7 Mar 2024","2024","12","1","84","99","Cloud data lakes emerge as an inexpensive solution for storing very large amounts of data. The main idea is the separation of compute and storage layers. Thus, cheap cloud storage is used for storing the data, while compute engines are used for running analytics on this data in “on-demand” mode. However, to perform any computation on the data in this architecture, the data should be moved from the storage layer to the compute layer over the network for each calculation. Obviously, that hurts calculation performance and requires huge network bandwidth. In this paper, we study different approaches to improve query performance in a data lake architecture. We define an optimization problem that can provably speed up data lake queries. We prove that the problem is NP-hard and suggest heuristic approaches. Then, we demonstrate through the experiments that our approach is feasible and efficient (up to ×30 query execution time improvement based on the TPC-H benchmark).","2168-7161","","10.1109/TCC.2023.3339208","Council for Higher Education; Data Science Research Center; Israel Data Science Initiative; Rita Altura trust chair; Israel Science Foundation(grant numbers:465/22); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342737","Cloud storage;data lakes;query optimization","Big Data applications;Cloud computing;Costs;Measurement;Engines;Computer architecture;Standards","","1","","50","IEEE","5 Dec 2023","Jan.-March 2024","","IEEE","IEEE Journals"
"A Scalable Data Model for Signalized Intersection Performance Measures","C. M. Gartner; R. S. Sakhare; J. C. Desai; J. Sturdevant; D. M. Bullock","Joint Transportation Research Program, Purdue University, West Lafayette, IN, USA; Joint Transportation Research Program, Purdue University, West Lafayette, IN, USA; Joint Transportation Research Program, Purdue University, West Lafayette, IN, USA; Indiana Department of Transportation, Indianapolis, IN, USA; Joint Transportation Research Program, Purdue University, West Lafayette, IN, USA",IEEE Access,"25 Nov 2025","2025","13","","197851","197863","Traditionally, traffic signal management has been largely tactical and operated from the “bottom-up,” focusing on individual intersection performances influenced by public suggestions, field observation, and in some cases high-resolution controller data. Connected vehicle trajectory data now enables a scalable, complementary “top-down” approach for system-wide performance analysis, even for locations with no detection or communication. This paper proposes a data architecture for derived performance measures that can be used for both strategic (top-down) and tactical (bottom-up) management of traffic signals. To leverage a “top-down” approach, large amounts of data must be processed into smaller datasets. For efficiency and interoperability between performance measures and the tools used to derive the same, a scalable data management architecture is essential. This paper discusses and demonstrates a framework developed for the Indiana Department of Transportation, which contains the derived information from over 177 billion records per year for the state, covering more than 2,500 signalized intersections in just 80,000 or so rows of derived performance measures. This framework collects data using a combination of a fixed time period, date, movement, approach, and intersection identifier. The structured model of derived performance measures supports both tactical applications, such as green-time allocation, and top-down, strategic management applications such as identifying capacity-constrained signals that are candidates for capital improvements. This framework is applicable to other tools used to derive performance measures, such as high-resolution or LiDAR datasets.","2169-3536","","10.1109/ACCESS.2025.3635007","Joint Transportation Research Program; Indiana Department of Transportation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11258624","Big data;capability maturity framework (CMM);data architecture;intersection performance measures","Data models;Transportation;Big Data;Systematics;Soft sensors;Decision making;Capability maturity model;Pedestrians;Laser radar;Delays","","","","18","CCBY","19 Nov 2025","2025","","IEEE","IEEE Journals"
"Lakehouse Data Platform Technology Overview","Y. Liu; J. Tian; S. Yu; X. Han; X. Jia","China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China",2024 International Conference on Ubiquitous Computing and Communications (IUCC),"2 Jul 2025","2024","","","499","504","Since the concept of ‘Lakehouse’ was first introduced in Gartner's Maturity Model report in the field of data management in 2021, it has attracted significant attention as an innovative technology in the context of enterprise digital transformation. An increasing number of enterprises are viewing ‘Lakehouse’ as a crucial infrastructure for their digital transformation. The construction of the lakehouse platform addresses challenges related to the integration of streaming and batch processing, such as atomic transactions, consistent updates, and metadata performance bottlenecks. This enables the lakehouse platform to not only fulfill short-term business needs but also to support long-term data application requirements. This paper elaborates on the development history of data platform, the evolution path of the lakehouse data platform, its implementation solutions, standardization, and future development trends.","","979-8-3315-1199-9","10.1109/IUCC65928.2024.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11049315","data platform;data warehouse;data lake;lakehouse","Digital transformation;Standardization;Metadata;Data warehouses;Big Data applications;Ubiquitous computing;Market research;History;Context modeling;Business","","2","","16","IEEE","2 Jul 2025","20-22 Dec. 2024","20-22 Dec. 2024","IEEE","IEEE Conferences"
"An Approach to Assessing the Maturity of ESG Practices in Industrial Enterprises in the Energy Sector","O. S. Drobkova; M. E. Kulikova","Department of Business Informatics, Bauman Moscow State Technical University, BMSTU, Moscow, Russian Federation; Department of Business Informatics, Bauman Moscow State Technical University, BMSTU, Moscow, Russian Federation","2025 7th International Youth Conference on Radio Electronics, Electrical and Power Engineering (REEPE)","30 Apr 2025","2025","","","1","5","The relevance of the research is due to the need to collect, store and analyze huge amounts of data in order to form a sustainable development strategy and assess the maturity of environmental, social, and governance (ESG) practices. The object of the research is approaches to assessing the maturity of ESG practices in industrial companies. The subject of the research is the analysis of data collection, storage and analysis technologies that allow to increase the maturity of ESG practices in the energy sector. This article provides a patent analysis of the development of data lake technology, the interrelation of analytics types, ESG goals and applied data organization technologies. Based on the analysis, an approach to assessing the maturity of ESG practices in industrial companies is proposed. The results of a study of the maturity of ESG practices in industrial companies in the energy sector are presented.","2831-7262","979-8-3315-3183-6","10.1109/REEPE63962.2025.10970888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10970888","ESG-practice;data lake;industrial enterprise;energy sector","Industries;Power engineering;Patents;Companies;Data collection;Big Data applications;Market research;Stakeholders;Artificial intelligence;Sustainable development","","","","26","IEEE","30 Apr 2025","8-10 April 2025","8-10 April 2025","IEEE","IEEE Conferences"
"Optimizing SaaS Metrics with Advanced Data Processing and Machine Learning Techniques","R. M. Chetan; G. S. Mamatha","Department of Information Science & Engineering, RV College of Engineering, Bengaluru, India; Department of Information Science & Engineering, RV College of Engineering, Bengaluru, India",2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS),"1 Jan 2025","2024","","","1","6","In SaaS applications, optimizing metrics is essential for enhancing efficiency, user satisfaction, and performance. This paper presents a framework integrating advanced data processing and intelligent algorithms within a scalable data lake architecture, leveraging AWS services like Kinesis for real-time data ingestion, Glue for ETL, S3 for storage, and Redshift for warehousing. Amazon SageMaker enables predictive analytics and real-time anomaly detection, with Athena and QuickSight supporting querying and visualization. Experimental results show improved data processing, anomaly detection, and predictive accuracy, contributing to efficient resource allocation and customer retention. This framework provides SaaS providers with a robust solution for achieving performance and scalability in multi-tenant environments.","2767-1097","979-8-3315-0546-2","10.1109/CSITSS64042.2024.10816850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10816850","SaaS;Data Lake;Machine Learning;Real-Time Analytics;Anomaly Detection;Amazon Web Services (AWS) [13];Kinesis Streams;AWS Glue;Amazon S3 [13];Amazon Redshift [13];Amazon SageMaker;Amazon Athena;Amazon QuickSight;Predictive Analytics;Multi-Tenant Environments;Data Processing;ETL (Extract, Transform, Load);Resource Optimization;Customer Retention","Measurement;Web services;Scalability;Computer architecture;Data processing;Big Data applications;Real-time systems;Resource management;Anomaly detection;Optimization","","","","15","IEEE","1 Jan 2025","7-9 Nov. 2024","7-9 Nov. 2024","IEEE","IEEE Conferences"
"Simplify Big Data Analytics with Amazon EMR: A beginner’s guide to learning and implementing Amazon EMR for building data analytics solutions","S. Mishra",NA,Simplify Big Data Analytics with Amazon EMR: A beginner’s guide to learning and implementing Amazon EMR for building data analytics solutions,"","2022","","","","","Design scalable big data solutions using Hadoop, Spark, and AWS cloud native servicesKey FeaturesBuild data pipelines that require distributed processing capabilities on a large volume of dataDiscover the security features of EMR such as data protection and granular permission managementExplore best practices and optimization techniques for building data analytics solutions in Amazon EMRBook DescriptionAmazon EMR, formerly Amazon Elastic MapReduce, provides a managed Hadoop cluster in Amazon Web Services (AWS) that you can use to implement batch or streaming data pipelines. By gaining expertise in Amazon EMR, you can design and implement data analytics pipelines with persistent or transient EMR clusters in AWS. This book is a practical guide to Amazon EMR for building data pipelines. You'll start by understanding the Amazon EMR architecture, cluster nodes, features, and deployment options, along with their pricing. Next, the book covers the various big data applications that EMR supports. You'll then focus on the advanced configuration of EMR applications, hardware, networking, security, troubleshooting, logging, and the different SDKs and APIs it provides. Later chapters will show you how to implement common Amazon EMR use cases, including batch ETL with Spark, real-time streaming with Spark Streaming, and handling UPSERT in S3 Data Lake with Apache Hudi. Finally, you'll orchestrate your EMR jobs and strategize on-premises Hadoop cluster migration to EMR. In addition to this, you'll explore best practices and cost optimization techniques while implementing your data analytics pipeline in EMR. By the end of this book, you'll be able to build and deploy Hadoop- or Spark-based apps on Amazon EMR and also migrate your existing on-premises Hadoop workloads to AWS.What you will learnExplore Amazon EMR features, architecture, Hadoop interfaces, and EMR StudioConfigure, deploy, and orchestrate Hadoop or Spark jobs in productionImplement the security, data governance, and monitoring capabilities of EMRBuild applications for batch and real-time streaming data analytics solutionsPerform interactive development with a persistent EMR cluster and NotebookOrchestrate an EMR Spark job using AWS Step Functions and Apache AirflowWho this book is forThis book is for data engineers, data analysts, data scientists, and solution architects who are interested in building data analytics solutions with the Hadoop ecosystem services and Amazon EMR. Prior experience in either Python programming, Scala, or the Java programming language and a basic understanding of Hadoop and AWS will help you make the most out of this book.","","9781801077729","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163079.pdf&bkn=10163079&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Aviation Data Lake: Using Side Information to Enhance Future Air-Ground Vehicle Networks","J. Sun; G. Gui; H. Sari; H. Gacanin; F. Adachi","Nanjing University of Posts and Telecommunications, China; Nanjing University of Posts and Telecommunications, China; Nanjing University of Posts and Telecommunications, China; RWTH Aachen University, Germany; Research Organization of Electrical Communication, Sendai, Japan",IEEE Vehicular Technology Magazine,"9 Feb 2021","2021","16","1","40","48","Future denser air-ground vehicle networks (AGVNs) face challenges such as resource allocation, mobility management, secure transmission, and so on. At the same time, surveillance is a must for modern air traffic management. This motivates us to find opportunities in the aerial vertical by forming a conceptual surveillance plane for aerial vehicles. In this article, we propose an enhanced software-defined network architecture where the surveillance plane can provide local and global surveillance information to macro stations, acting as a side system for the communication links. We review air- ground communications and, by summarizing challenges and opportunities, propose the enhanced architecture of side-information-assisted networks in detail. We then present how we obtain, organize, manage, and utilize the local and global side information by a so-called aviation data lake (ADL). The data lake can be easily connected with advanced machine learning schemes and, thus, provide timely, context-aware metrics and predictions.","1556-6080","","10.1109/MVT.2020.3014598","Industrial Internet Innovation and Development Project of the Ministry of Industry and Information Technology of China(grant numbers:TC190A3WZ-2); National Natural Science Foundation of China(grant numbers:61901228); Six Top Talents Program of Jiangsu(grant numbers:XYDXX-010); 1311 Talent Plan of Nanjing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199550","","Surveillance;Drones;Computer architecture;Aircraft;Collision avoidance;Handover","","23","","15","IEEE","17 Sep 2020","March 2021","","IEEE","IEEE Magazines"
"Connection of Dynamic and Static Data: A Data Lake for Building Digitalisation","J. L. Hernández; D. Arévalo; S. Martín; K. Katsigarakis; G. N. Lilis; D. Rovas; I. De Miguel","Energy Division, CARTIF technology centre, Boecillo, Spain; Energy Division, CARTIF technology centre, Boecillo, Spain; Energy Division, CARTIF technology centre, Boecillo, Spain; IEDE University College London, London, UK; IEDE University College London, London, UK; IEDE University College London, London, UK; Universidad de Valladolid, Valladolid, Spain",2024 IEEE International Workshop on Metrology for Living Environment (MetroLivEnv),"6 Aug 2024","2024","","","262","267","The landscape of building data is expanding, with heterogeneous sources that are often treated as isolated silos across different building domains such as energy, architecture elements, or automation networks. This siloed approach creates a lock-in scenario, limiting the potential for effective data exploitation, including the provision of added-value services, artificial intelligence, or machine-learning activities. To overcome this challenge, ensuring data integration through interoperability mechanisms becomes crucial within building data management frameworks. In line with this perspective, this work introduces a data lake that harmonizes heterogeneous data sources from various building domains. The primary goal is to standardize datasets, ensuring the delivery of high-quality services to facilitate better decision-making. These datasets are enriched by interactions between static and dynamic datasets. This holistic approach aims to break down silos and unlock the full potential of building data for informed decision-making processes.","","979-8-3503-8501-4","10.1109/MetroLivEnv60384.2024.10615827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615827","","Soft sensors;Buildings;Semantics;Decision making;Sociology;Data collection;Big Data applications","","","","13","IEEE","6 Aug 2024","12-14 June 2024","12-14 June 2024","IEEE","IEEE Conferences"
"Processing FHIR in modern Data Lakehouse","S. Patil; A. S. Z. A. Belloum","Department of Science, Universiteit Van Amsterdam, Amsterdam, Netherlands; Faculty of Science & Netherlands eScience Center, Universiteit Van Amsterdam, Amsterdam, Netherlands",2024 IEEE 20th International Conference on e-Science (e-Science),"20 Sep 2024","2024","","","1","7","Healthcare data exchange standard, FHIR is becoming the widely adopted standard for data exchange and storage of health data. However, there is still some learning curve involved when it comes to using the data for analytical purpose. In our research we have devised a generic approach to ingest FHIR data into tabular format that is suited for analytical purpose. Our approach reduces the learning barrier involved in processing FHIR and formatting it for secondary usage.","2325-3703","979-8-3503-6561-0","10.1109/e-Science62913.2024.10678734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678734","FHIR;Lakehouse;Iceberg;Spark;Healthcare analytics","Codes;Process control;Production;Medical services;Manuals;Big Data applications;Sparks","","1","","18","IEEE","20 Sep 2024","16-20 Sept. 2024","16-20 Sept. 2024","IEEE","IEEE Conferences"
"Crossing analytics systems: A case for integrated provenance in data lakes","I. Suriarachchi; B. Plale","School of Informatics and Computing, Indiana University, Bloomington, IN, USA; School of Informatics and Computing, Indiana University, Bloomington, IN, USA",2016 IEEE 12th International Conference on e-Science (e-Science),"6 Mar 2017","2016","","","349","354","The volumes of data in Big Data, their variety and unstructured nature, have had researchers looking beyond the data warehouse. The data warehouse, among other features, requires mapping data to a schema upon ingest, an approach seen as inflexible for the massive variety of Big Data. The Data Lake is emerging as an alternate solution for storing data of widely divergent types and scales. Designed for high flexibility, the Data Lake follows a schema-on-read philosophy and data transformations are assumed to be performed within the Data Lake. During its lifecycle in a Data Lake, a data product may undergo numerous transformations performed by any number of Big Data processing engines leading to questions of traceability. In this paper we argue that provenance contributes to easier data management and traceability within a Data Lake infrastructure. We discuss the challenges in provenance integration in a Data Lake and propose a reference architecture to overcome the challenges. We evaluate our architecture through a prototype implementation built using our distributed provenance collection tools.","","978-1-5090-4273-9","10.1109/eScience.2016.7870919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870919","","Lakes;Big data;Prototypes;Sparks;Standards;Data warehouses;Computer architecture","","23","","20","IEEE","6 Mar 2017","23-27 Oct. 2016","23-27 Oct. 2016","IEEE","IEEE Conferences"
"Design and Research of Analog Data Pool of Intelligent Manufacturing Oriented to Impeller","G. Li; Y. Cao; Y. Bao; H. Chen; S. Zhao","School of Mechanical Engineering, Nanjing Institute of Technology, Nanjing, Jiangsu, China; School of Automotive and Rail transit, Nanjing Institute of Technology, Nanjing, Jiangsu, China; School of Information and Communication engineering, Nanjing Institute of Technology, Nanjing, Jiangsu, China; School of Mechanical Engineering, Nanjing Institute of Technology, Nanjing, Jiangsu, China; School of Automotive and Rail transit, Nanjing Institute of Technology, Nanjing, Jiangsu, China",2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA),"19 May 2020","2020","","","561","565","Impeller data is investigated and understood including the data information content, data type and characteristics in the process of intelligent manufacturing of enterprises. The data information of the whole life cycle of impeller is the research object. The characteristics and functions of data pool are analyzed based on the analysis of data Lake structure. It is analyzed and designed of the big data analog data pool of intelligent manufacturing for impeller. And the framework of the data pool is constructed for impeller. It is achieved of the design requirements of big data analog data pool processing system by Hadoop, Java, MapReduce and other components. They are processed for data merging, data sorting, data extraction and other functions. A lot of data is analyzed and extracted more clearly in the process of impeller intelligent manufacturing, which achieve the purpose of data processing. The establishment of analog data pool not only plays an important role in the research of data storage and processing, but also plays an important role in improving the efficiency of intelligent manufacturing industry.","","978-1-7281-6024-5","10.1109/ICCCBDA49378.2020.9095678","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095678","impeller;intelligent manufacturing;analog data pool;data processing","Impellers;Data mining;Inspection;Big Data","","","","12","IEEE","19 May 2020","10-13 April 2020","10-13 April 2020","IEEE","IEEE Conferences"
"A Vision for Data Alignment and Integration in Data Lakes","",,2022 IEEE International Conference on Big Data (Big Data),"26 Jan 2023","2022","","","2","2","Summary form only. The requirements for integration over massive, heterogeneous table repositories (aka data lakes) are fundamentally different than they are for federated data integration (where the data owned by an enterprise is integrated into a cohesive whole) or data exchange (where data is exchanged and shared among a small set of autonomous peers). In this talk, I will outline a vision for data alignment and integration in data lakes. Data lakes afford new opportunities for using new methods, from network science and other areas, to discover emergent semantics from large heterogeneous collections of data sets. I will illustrate these ideas by discussing the problem of data lake disambiguation, work which received the best paper award in EDBT 2021.","","978-1-6654-8045-1","10.1109/BigData55660.2022.10020635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020635","","Data lakes","","","","","IEEE","26 Jan 2023","17-20 Dec. 2022","17-20 Dec. 2022","IEEE","IEEE Conferences"
"Aggregating financial services data without assumptions: A semantic data reference architecture","S. Gollapudi","Vice President Technology, Broadridge Financial Solutions (India) Pvt. Ltd, Hyderabad, India",Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015),"2 Mar 2015","2015","","","312","315","We are seeing a sea change down the pike in terms of financial information aggregation and consumption; this could potentially be a game changer in financial services space with focus on ability to commoditize data. Financial Services Industry deals with a tremendous amount of data that varies in its structure, volume and purpose. The data is generated in the ecosystem (its customers, its own accounts, partner trades, securities transactions etc.), is handled by many systems - each having its own perspective. Front-office systems handle transactional behavior of the data, middle office systems which typically work with a drop-copy of the data subject it to intense processing, business logic, computations (such as inventory positions, fee calculations, commissions) and the back office systems deal with reconciliation, cleansing, exception management etc. Then there are the analytic systems which are concerned with auditing, compliance reporting as well as business analytics. Data that flows through this ecosystem gets aggregated, transformed, and transported time and again. Traditional approaches to managing such data leverage Extract-Transform-Load (ETL) technologies to set up data marts where each data mart serves a specific purpose (such as reconciliation or analytics). The result is proliferation of transformations and marts in the Organization. The need is to have architectures and IT systems that can aggregate data from many such sources without making any assumptions on HOW, WHERE or WHEN this data will be used. The incoming data is semantically annotated and stored in the triple store within storage tier and offers the ability to store, query and draw inferences using the ontology. There is a probable need for a Big Data Solution here that helps ease data liberation and co-location. This paper is a summary of one such business case of the Financial Services Industry where traditional ETL silos was broken to support the structurally dynamic, ever expanding and changing data usage needs employing Ontology and Semantic techniques like RDF/RDFS, SPARQL, OWL and related stack.","","978-1-4799-7935-6","10.1109/ICOSC.2015.7050825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050825","Financial Reference Data Management;Semantic Meta-data;Business Data Lake Reference Architecture;Semantics and Big Data;Layered Databases","Resource description framework;Security;Semantics;Databases;Communities;Lakes;Visualization","","7","","6","IEEE","2 Mar 2015","7-9 Feb. 2015","7-9 Feb. 2015","IEEE","IEEE Conferences"
"Research on intelligent recommendation system model supported by data mining and algorithm optimization","X. Jia; F. Liu","School of North China University of Science and Technology, Tangshan, China; School of North China University of Science and Technology, Tangshan, China",2021 IEEE International Conference on Emergency Science and Information Technology (ICESIT),"8 Feb 2022","2021","","","766","769","With the rapid development of China's mobile Internet and the advent of 5g era, employees from all walks of life will basically use websites to buy all kinds of goods needed in life. As we all know, big data has become a key direction in the work of various Internet companies and the recommendation system can be said to be one of the best landing applications of big data. The benefits it brings to Internet companies are real and visible. Especially for e-commerce, intelligent recommendation system can directly affect the sales performance of an e-commerce enterprise[1]. How to store these massive data and efficiently mine valuable user information is the real challenge of big data technology[2]. In this paper, based on the modified Chinese Amazon e-commerce data set well-known in the field of recommendation system construction, and based on the real business data architecture of an e-commerce website, the project constructs an integrated e-commerce recommendation system, offline recommendation service and real-time recommendation service provide a variety of methods to achieve mixed recommendation effect. It provides a variety of off-line analysis methods and clever and accurate real-time recommendation model to realize data mining.","","978-1-6654-3531-4","10.1109/ICESIT53460.2021.9696972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9696972","big data;intelligent recommendation;offline recommendation;data mining;real-time recommendation","Analytical models;Companies;Big Data;Real-time systems;Data models;Internet;Electronic commerce","","2","","8","IEEE","8 Feb 2022","22-24 Nov. 2021","22-24 Nov. 2021","IEEE","IEEE Conferences"
"Research on Ubiquitous Power Internet of Things Architecture","Z. Zhai; L. Jia; Y. Wang; Y. Ma; W. Jing; Z. Zhang","School of Electrical Engineering, Xi'an Jiaotong University, Xi'an, China; School of Electrical Engineering, Xi'an Jiaotong University, Xi'an, China; School of Electrical Engineering, Xi'an Jiaotong University, Xi'an, China; School of Electrical Engineering, Xi'an Jiaotong University, Xi'an, China; School of Electrical Engineering, Xi'an Jiaotong University, Xi'an, China; School of Electrical Engineering, Xi'an Jiaotong University, Xi'an, China",2019 IEEE 3rd Conference on Energy Internet and Energy System Integration (EI2),"9 Apr 2020","2019","","","435","439","In short, the ubiquitous power Internet of Things is the connection of the various devices and people in the power system. Specifically, firstly, it uses sensor technology to collect device-related data. Then, the data is sent to the server via communication technology. Finally, data is processed and stored through big data, cloud computing, artificial intelligence and other technologies. Therefore, the user and the power supply company can grasp the relevant data of each link of the power grid, and realize the transparency and sharing of the data. The power system is a large system with many related equipments and complicated connections. Therefore, in order to meet the relevant requirements, a large structure is needed to cover all aspects of the ubiquitous power Internet of Things. In this paper, an architecture for ubiquitous power Internet of Things is proposed, covered from the collection of underlying data, to the encryption and transmission of data, to the storage of data. This architecture brings great convenience to the collection, transmission, processing and storage of data.","","978-1-7281-3137-5","10.1109/EI247390.2019.9061975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9061975","ubiquitous power Internet of Things;device;data;architecture;technology","Internet of Things;Systems architecture;Big Data;Encryption;Ubiquitous computing;Power grids;Data security","","14","","9","IEEE","9 Apr 2020","8-10 Nov. 2019","8-10 Nov. 2019","IEEE","IEEE Conferences"
"Data Engineering: An Overview from a Future Perspective","A. Jain; Sumit; C. Monga; S. Mittal","Chitkara University Institute of Engineering and Technology Chitkara University, Rajpura, Punjab, India; Chitkara University Institute of Engineering and Technology Chitkara University, Rajpura, Punjab, India; Chitkara University Institute of Engineering and Technology Chitkara University, Rajpura, Punjab, India; Chitkara University Institute of Engineering and Technology Chitkara University, Rajpura, Punjab, India",2023 6th International Conference on Contemporary Computing and Informatics (IC3I),"26 Jan 2024","2023","6","","653","659","Data engineering is now an essential subject for handling, processing, and analysing big data as the amount of data collected is increasing exponentially. This paper gives a future-focused overview of data engineering. The creation, building, upkeep, and optimization of data architecture, infrastructure, and pipelines are all essential components of data engineering, a field within data science. Data pipelines that can effectively process massive volumes of data from diverse sources and formats must be built using data engineering techniques that are reliable, scalable, and flexible. Data warehousing, data modelling, SQL databases, NoSQL databases, and Apache Hadoop and Spark are just a few examples of the tools and technologies that fall under the broad umbrella of data engineering. Data scientists, analysts, and business users should have rapid access to correct data, which is the main objective of data engineering. In addition to optimizing data storage and performance, data engineering also entails guaranteeing the quality, integrity, and security of the data. Data engineering is an essential phase in the workflow for data scientists since it enables them to carry out advanced analytics, machine learning, and other data-driven operations. In conclusion, data engineering is a vital part of the ecosystem for data science, which offers the tools and infrastructure required for data processing and analysis. Companies may build strong, scalable data pipelines that foster business insights and innovation by utilizing best practices in data engineering. Data engineering is an important field that will continue to grow and transform in the coming years. Data engineers and organizations that can adapt to change and take advantage of emerging technologies and trends will be in the best position to succeed in a data-driven future.","","979-8-3503-0448-0","10.1109/IC3I59117.2023.10398128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10398128","Data Engineering;Data Architecture;Pipelines;Data -Scientists;Data Science","Technological innovation;Databases;Pipelines;Machine learning;Big Data;Data science;Data engineering","","3","","41","IEEE","26 Jan 2024","14-16 Sept. 2023","14-16 Sept. 2023","IEEE","IEEE Conferences"
"Enabling Self-Service OLAP on NoSQL Data Lakes","D. Boukraa; H. Sellamna; Y. Chidekh","LaRIA Faculty of Exact Sc. & Computing, University of Jijel, Jijel, Algeria; University of Jijel, Jijel, Algeria; Faculty of Exact Sc. & Computing, University of Jijel, Jijel, Algeria",2024 6th International Conference on Pattern Analysis and Intelligent Systems (PAIS),"3 Jun 2024","2024","","","1","8","Online analytical processing plays a crucial role in data analysis by providing a powerful framework for efficiently exploring and understanding multidimensional data. With the increasing complexity and volume of data in modern organisations, the main challenge is to build OLAP cubes from distributed heterogeneous sources while considering attribute and relationship overlapping across the sources and to let analysts create their cubes on-demand to maximise their usefulness. We propose a self-service, metadata-driven approach for designing and generating OLAP cubes from heterogeneous NoSQL sources composing a data lake. We illustrate our approach through a realistic scenario where the data is scattered and overlaps across different sources. We present a proof-of-concept application that implements our proposed approach. An assessment of our proposal is conducted to highlight the efficacy and usefulness of the generated cubes for analytical purposes.","","979-8-3503-5026-5","10.1109/PAIS62114.2024.10541190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10541190","OLAP cubes;Self-service;NoSQL;Metadata;Data Lake","Data analysis;Distributed databases;Metadata;Lakes;Big Data applications;Proposals;Pattern analysis","","","","22","IEEE","3 Jun 2024","24-25 April 2024","24-25 April 2024","IEEE","IEEE Conferences"
"Discovery and Matching Numerical Attributes in Data Lakes","P. Sukprasert; G. Y. -Y. Chan; R. A. Rossi; F. Du; E. Koh",Northwestern University; Adobe Research; Adobe Research; Databricks; Adobe Research,2023 IEEE International Conference on Big Data (BigData),"22 Jan 2024","2023","","","423","432","In data platforms with thousands of data tables available for exploration, users often need to retrieve some data based on limited knowledge of the data sources and schema. The task that automates retrieving attributes from an online data lake given a set of entities from users is called “entity augmentation”. The key for successful entity augmentation is an accurate construction of semantic relationships between data tables. Current techniques either focus on retrieving categorical values or numerical values with pre-defined rules. Further, they assume there are meta-data available for each table, such as texts and tags. In this paper, we introduce a semantic graph for numerical data augmentation that (i) matches columns with similar semantic relationships without any meta-data from the tables; (ii) infer the conversion rules among different numerical columns based on the values. The approach is designed to be highly scalable and parallel for large-scale data lakes with millions of large datasets. We also propose efficient algorithms to construct the semantic graph on a distributed computing environment (i.e. Spark) and conduct numerical data augmentation using the graph. Through comprehensive experiments on real-world datasets, the approach is shown to (1) achieve better accuracy on semantic matches and value conversions and (2) scales to the tractable computation time on large-scale data. Finally, we also present an interface to apply the semantic graph for real-world scenarios.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386080","Data lake;datasets;data discovery;attribute discovery","Soft sensors;Semantics;Oral communication;User interfaces;Big Data applications;Data augmentation;Sparks","","","","78","IEEE","22 Jan 2024","15-18 Dec. 2023","15-18 Dec. 2023","IEEE","IEEE Conferences"
"High-Performance Fusion Storage Technology for Massive Power Grid Dispatching and Operation Data","Z. Zhang; L. Tao; L. Xie; S. Wu; R. Ye; J. Wang","Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology, China Electric Power Research Institute, Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology, China Electric Power Research Institute, Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology, China Electric Power Research Institute, Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology, China Electric Power Research Institute, Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology, China Electric Power Research Institute, Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology, China Electric Power Research Institute, Beijing, China",2025 10th Asia Conference on Power and Electrical Engineering (ACPEE),"27 Jun 2025","2025","","","33","37","With the progression of new type power system infrastructures, grid control and operational data have begun to exhibit characteristics of voluminousness, multi-source origins, heterogeneity, and stringent real-time demands. Conventional data storage and processing methodologies are increasingly inadequate to address these requirements. This paper introduces a high-performance storage and processing framework for the extensive operational data of grid control, leveraging the integration of data lake and data warehouse technologies. By implementing stratified storage and refined scheduling algorithms, the framework achieves enhanced real-time throughput and superior processing capabilities for massive datasets. The proposed solution employs data lakes for the retention of raw data and data warehouses for the storage of refined and transformed data, integrating both streaming and batch computing to fulfill the real-time and precision exigencies of grid control. Empirical results demonstrate that the proposed framework significantly augments data storage and processing efficiency, thereby furnishing robust support for grid control operations.","2996-2951","979-8-3315-0407-6","10.1109/ACPEE64358.2025.11041192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11041192","lakehouse integration;powergrid dispatching and control;massive data;high-performance storage;real-time processing","Electrical engineering;Scheduling algorithms;Process control;Memory;Data warehouses;Big Data applications;Throughput;Real-time systems;Dispatching;Power grids","","","","13","IEEE","27 Jun 2025","15-19 April 2025","15-19 April 2025","IEEE","IEEE Conferences"
"Enabling Big Data Query with Modern CAD Systems Redundant Data Stores","M. Brazhenenko; V. Petrivskyi; O. Bychkov; I. Sinitcyn; V. Shevchenko","Program system and technologies Department, Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Program system and technologies Department, Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Program system and technologies Department, Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Head of Department at the Institute of Software Systems, National Academy of Sciences of Ukraine., Kyiv, Ukraine; Program system and technologies Department, Taras Shevchenko National University of Kyiv, Kyiv, Ukraine",2021 IEEE 16th International Conference on the Experience of Designing and Application of CAD Systems (CADSM),"2 Apr 2021","2021","","","5","9","This paper review trends in Modern Computer-Aided Design Systems design enterprise integration and bring light to some of the adoption challenges aspects. The research aims to lay out the consequences of the industry-wide move of Computer-Aided Design Systems into the Cloud environment and building a roadmap of cross-cloud enterprise systems integration. We adopt an approach of building data redundancy storages as one of the possible ways to reduce dependability of enterprise software systems, improve performance and reduce maintenance costs for software systems that integrate with Computer-Aided Design Systems solutions.","2572-7591","978-1-6654-3894-0","10.1109/CADSM52681.2021.9385265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385265","redundancy;curation;architecture;data lake;big data","Design automation;Buildings;Warehousing;System integration;Software systems;Market research;System analysis and design","","2","","18","IEEE","2 Apr 2021","22-26 Feb. 2021","22-26 Feb. 2021","IEEE","IEEE Conferences"
"15 What is a Data Lake?","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","73","78","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933565.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"Anatomy of Big Iot Data analytics","S. k. Bidhan; L. Ahuja; S. K. Khatri; S. Som","Amity University, UP, India; Amity University, UP, India; Amity University, UP, India; Amity University, UP, India",2019 Third International Conference on Inventive Systems and Control (ICISC),"16 Mar 2020","2019","","","123","127","A large quantity of statistics is generated because of the explosive boom inside the wide variety of devices connected to the Internet of Things. However, such data large amount of data is not useful without the power of analytics. Different IOT, big data, and analytics have enable individuals to get significant understanding into vast measure of information produced by IoT gadgets. Nonetheless, these arrangements are still in their underlying state, and the area comes up short on a far reaching overview. The contribution of this paper is to purpose a five layer architecture for big IOT data. The functionality of five different layers of big IOT data architecture is explained. The opportunities for big IoT data architecture are discussed. Further more challenges face by the architecture are also explained.","","978-1-5386-3950-4","10.1109/ICISC44355.2019.9036426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9036426","IOT;big data;big iot architecture;five layers of architecture","Big Data;Sensors;Technological innovation;Organizations;Internet of Things;Transportation","","3","","6","IEEE","16 Mar 2020","10-11 Jan. 2019","10-11 Jan. 2019","IEEE","IEEE Conferences"
"8 Smart grid–based big data analytics using machine learning and artificial intelligence: a survey","S. Koshy; S. Rahul; R. Sunitha; E. P. Cheriyan",NA; NA; NA; NA,Artificial Intelligence and Internet of Things for Renewable Energy Systems,"","2022","","","241","278","Exhilarating developments in the renewable energy generation portfolio and the widespread introduction of microgrids have contributed to significant reforms in the existing power grid’s power flow patterns. Power grids around the world have upgraded to smart grid (SG) by introducing advanced monitoring technologies such as Advanced Metering Infrastructure (AMI), smart meters and Phasor Measurement Units (PMUs), which collect high-resolution electrical measurements across the system. This has brought in a massive amount of data, termed big data, that needs to be efficiently processed to derive valuable insights. Specifically, technical sophistication, security, and integration of datasets are the main concerns that need to be tackled to transform the massive dataset into useful insights. This chapter surveys big data analytics (BDA) and its related benefits, challenges, and advancements in SG’s perspective. BDA in combination with visualization tools, help in the predictive decision-making process in the SG. Thus, data analytics play a significant part in the efficient monitoring of the SG. Powered with the integration of information and communication technologies, an information layer has been introduced to the traditional power systems to collect, store, and process data from smart meters and sensor implementations. Big data architecture involves data aggregation, storing, and analytics, which integrates the SG’s need for a range of frameworks with outstanding computational skills to respond to the customer’s needs. Characterization of big data, SGs, and massive volumes of data processing is first addressed as a preface to demonstrate the motivation and possible benefits of integrating advanced data mining in smart grids. Specific principles and standard data analytics techniques for general concerns are also discussed. The chapter’s key section discusses the advanced uses of various data analytics in SG, leveraging machine learning (ML) and artificial intelligence (AI). SG is benefited from the inherent capacity of ML to generalize, delivering reliable and quick power flow predictions from dispersed measurement units, with superior computing performance and interoperability. The chapter explores numerous literary works that utilize various ML methods to enhance SG activity and management. We will present big data analytics and cloud infrastructure in this chapter and address their importance to SG. Specifically, we would concentrate on relevant computational concerns and solutions linked to SG cyber-physical protection and safety.","","9783110714159","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10789589.pdf&bkn=10783464&pdfType=chapter","","Big Data;Power system reliability;Monitoring;Renewable energy sources;Real-time systems;Electrical engineering;Telecommunication network reliability;Smart grids;Power system stability;Load flow","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"Empowering the Tribal people with the use of big data processing expert system in animal Husbandry and Poultry Farming application","R. Saravanan; V. Nehru; S. Muthuselvi","Department of Computer Science & Engineering, Vel Tech Multi Tech Dr. Rangarajan & Dr. Sakunthala Engineering College, Chennai, Avadi, India; Department of Computer Science & Engineering, Vel Tech Multi Tech Dr. Rangarajan & Dr. Sakunthala Engineering College, Chennai, Avadi, India; Department of Computer Science & Engineering, Vel Tech Multi Tech Dr. Rangarajan & Dr. Sakunthala Engineering College, Chennai, Avadi, India","2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)","3 Jan 2024","2023","","","1","8","The population of the tribal people has been decreased day by day in India due to the lack of awareness in health related issues and there is a series challenges in their sustainable livelihood. The Particularly Vulnerable People from tribal groups (PVTGs) engaged in animal husbandry and poultry farming as their primary source of income, which improves their standard of living. Maintain and safeguard poultry and animals from diseases is a cumbersome process. Providing enough medical facility is still a challenging task due to the geographical location and unavailability of the infrastructure and human resources. The proposed framework uses Apache Kafka-Apache Storm-NoSQL Mongo DB architecture to process enormous volume of sensor data in real time and it receives the sensor data and uses it to create the various disease identification models. The processed data are stored in Mongo DB as a historical data. The system provides a Web-based monitoring system for continuos monitoring the health conditions of cattles and poultry through the Smart Health Care Centre. Smartness in operation is performed through System on Chip (SoC) IoT system, the proposed big data expert system model transcends from the traditional functionalities of disease identification by the real time field visit analysis by the medical professionals. The proposed system is more suitable for the remote hill area. Smart Health Care system improves the disease identification accuracy and provides a powerful Big Data architecture for data analytics and data storage. The big data expert system frame work is underwent successful functional testing of ""SoC-IoT smart devices"" connected with the network and the performance of the network in terms of CPU, memory usage and the network delay is analyzed. Further the frame work uses the big data processing with the machine learning approach ""Hybrid diseases identification Model"" with the combination of DBSCAN for outlier detection together with Random Forest classification, which improves the disease identification accuracy of the various disease attacked the cattles and poultry.","","979-8-3503-0570-8","10.1109/RMKMATE59243.2023.10369174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10369174","Apache Kafka;Apache Storm;Mongo DB;DBSCAN;Random Forest","Animals;Smart healthcare;Big Data;Data models;Real-time systems;Expert systems;Monitoring","","","","9","IEEE","3 Jan 2024","1-2 Nov. 2023","1-2 Nov. 2023","IEEE","IEEE Conferences"
"Index","M. Beckner",NA,"Quick Start Guide to Azure Data Factory, Azure Data Lake Server, and Azure Data Warehouse","","2019","","","99","102","","","9781547401291","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10785623.pdf&bkn=10783667&pdfType=chapter","","Big Data applications;Pipelines;Navigation;Servers;Portals;Databases;Production facilities;Monitoring;Indexes;Data warehouses","","","","","","16 Jan 2025","","","De Gruyter","De Gruyter eBook Chapters"
"Meta-modeling of Zookeeper and MapReduce processing","A. Erraissi; A. Belangour","Faculty of sciences Ben M'Sik, Hassan II University, Casablanca, Morocco; Faculty of sciences Ben M'Sik, Hassan II University, Casablanca, Morocco","2018 International Conference on Electronics, Control, Optimization and Computer Science (ICECOCS)","13 Jan 2019","2018","","","1","5","Nowadays, businesses and governments face a huge and varied amount of data that needs to be stored and analyzed. Yet, At the Big Data architecture level, the management layer is very important and plays a key role since it allows the management of different types of data. Obviously, we based this work on our previous research in which we identified the key concepts of Hadoop management through comparative studies of major Big Data distributions. Hadoop management layer is located directly above Data Sources, Ingestion and Storage layers, for which we have already proposed meta-models. In our continuous effort to achieve good results, we apply in this paper techniques related to Model Driven Engineering “MDE” to provide a universal meta-model for MapReduce processing, which is the essential component of the management layer; and also to build a meta-model for Zookeeper coordination system.","","978-1-5386-7868-8","10.1109/ICECOCS.2018.8610630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610630","Meta-model;Model Driven Engineering;Big Data;Management layer;MapReduce;Zookeeper","Task analysis;Big Data;Servers;File systems;Analytical models;Data models;Model driven engineering","","5","","17","IEEE","13 Jan 2019","5-6 Dec. 2018","5-6 Dec. 2018","IEEE","IEEE Conferences"
"Research on Computer Intelligent Whole Process Construction Information System in Large International Hub Airport Project","L. Zheng","Silpakorn University, Bangkok, Thailand","2023 International Conference on Computers, Information Processing and Advanced Education (CIPAE)","14 Dec 2023","2023","","","391","395","In order to meet the information security performance requirements of large hub airports in the era of big data, the platform adopts advanced big data architecture. The Logistic mapping technology is used to digitize the database information of the international hub airport, so that the information can be folded and transformed repeatedly in the region, and the hash encryption algorithm is used to encrypt and decrypt the database information, so as to realize the security management and storage of the database information. The intrusion system provides all-weather and all-day real-time monitoring and protection of the perimeter through video surveillance and sensor network system. The system timely obtains and records the image information in the case of alarms. At the same time, without losing data packets, the peak value of single type log entry can reach 15,000 pieces per second. The packet loss rate of the system database is also low, and good information security management effect is achieved.","","979-8-3503-4271-0","10.1109/CIPAE60493.2023.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10350245","Hub airport;safety monitoring platform;big data analysis;situational awareness;hash encryption algorithm;information security","Databases;Security management;Information security;Big Data;Airports;Video surveillance;Encryption","","","","8","IEEE","14 Dec 2023","26-28 Aug. 2023","26-28 Aug. 2023","IEEE","IEEE Conferences"
"MaXCept -- Decision Support in Exception Handling through Unstructured Data Integration in the Production Context: An Integral Part of the Smart Factory","L. B. Kassner; B. Mitschang","Graduate School advanced Manufacturing Engineering, Universität Stuttgart; Graduate School advanced Manufacturing Engineering, Universität Stuttgart",2015 48th Hawaii International Conference on System Sciences,"30 Mar 2015","2015","","","1007","1016","Today, data from different sources and different phases of the product life cycle are usually analyzed in isolation and with considerable time delay. Real-time integrated analytics is especially beneficial in a production context. We present an architecture for data- and analytics-driven exception escalation in manufacturing and show the advantages of integrating unstructured data.","1530-1605","978-1-4799-7367-5","10.1109/HICSS.2015.124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069929","decision support systems;flexible manufacturing systems;ubiquitous computing;context-aware services;natural language processing;problem solving","Production facilities;Manufacturing;Computer architecture;Data mining;Context;Real-time systems","","8","","50","IEEE","30 Mar 2015","5-8 Jan. 2015","5-8 Jan. 2015","IEEE","IEEE Conferences"
"One Stone, Three Birds: Finer-Grained Encryption with Apache Parquet @ Large Scale","X. Shang; P. Subenderan; M. Islam; J. Xu; J. Zhang; N. Gupta; A. Panda","Apache Parquet PMC Chair, Uber Technologies; Software Engineer, Uber Technologies; Software Engineer, Uber Technologies; Software Engineer, Uber Technologies; Software Engineer, Uber Technologies; Software Engineer, Uber Technologies; Engineer Manager, Uber Technologies",2022 IEEE International Conference on Big Data (Big Data),"26 Jan 2023","2022","","","5802","5811","Data access control, retention, and encryption-at-rest are fundamental security goals for data privacy and compliance. Often each of these three goals are implemented independently and in various layers of the Big Data stack. For example, Big data query engines may add custom support for access control at the engine level but the underlying stored data is not necessarily secured. In the modern Data Lakehouse, there is open access to the underlying data in many companies’ data lakes and therefore it is not sufficient to implement security and compliance at an engine level.In this paper we present a unified way to address all three security goals at once through the shared lower layer of Apache Parquet which ensures these controls are enforced by higher level Big Data tools. We introduce performant file format level encryption with both column level and cell level granularity controlled by schema tagging. We achieve less than 8% write and less than 5% read performance overhead in most common scenarios of file format encryption by minimizing RPC calls required to perform encryption / decryption, leveraging AESNI and choosing optimal encryption options. Lastly we present a novel high throughput method for rewriting existing Apache Parquet data with encryption which is critical for practical onboarding of a data lake to Apache Parquet encryption.","","978-1-6654-8045-1","10.1109/BigData55660.2022.10020987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020987","encryption;access control;retention;compliance;security;privacy","Access control;Open Access;Manuals;Tagging;Throughput;Big Data applications;Encryption","","4","","29","IEEE","26 Jan 2023","17-20 Dec. 2022","17-20 Dec. 2022","IEEE","IEEE Conferences"
"Towards Information Profiling: Data Lake Content Metadata Management","A. Alserafi; A. Abelló; O. Romero; T. Calders","Universitat Politècnica de Catalunya (UPC), Barcelona, Catalunya, Spain; Universitat Politècnica de Catalunya (UPC), Barcelona, Catalunya, Spain; Universitat Politècnica de Catalunya (UPC), Barcelona, Catalunya, Spain; Université Libre de Bruxelles (ULB), Belgium & Universiteit Antwerpen (UAntwerp), Antwerp, Brussels, Belgium",2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW),"2 Feb 2017","2016","","","178","185","There is currently a burst of Big Data (BD) processed and stored in huge raw data repositories, commonly called Data Lakes (DL). These BD require new techniques of data integration and schema alignment in order to make the data usable by its consumers and to discover the relationships linking their content. This can be provided by metadata services which discover and describe their content. However, there is currently a lack of a systematic approach for such kind of metadata discovery and management. Thus, we propose a framework for the profiling of informational content stored in the DL, which we call information profiling. The profiles are stored as metadata to support data analysis. We formally define a metadata management process which identifies the key activities required to effectively handle this. We demonstrate the alternative techniques and performance of our process using a prototype implementation handling a real-life case-study from the OpenML DL, which showcases the value and feasibility of our approach.","2375-9259","978-1-5090-5910-2","10.1109/ICDMW.2016.0033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836664","","Metadata;Ontologies;Data mining;Prototypes;Systematics;Lakes;Resource description framework","","27","","20","IEEE","2 Feb 2017","12-15 Dec. 2016","12-15 Dec. 2016","IEEE","IEEE Conferences"
"Transformation of Locally Implemented Data Warehouses to the Cloud","P. Kovačovič; R. Pirník; P. Peniak; L. Hrmo; J. Krško; M. Míkvy","Dpt. of Control and Information Systems, University of Zilina, Žilina, Slovakia; Dpt. of Control and Information Systems, University of Zilina, Žilina, Slovakia; Dpt. of Control and Information Systems, University of Zilina, Žilina, Slovakia; Dpt. of Control and Information Systems, University of Zilina, Žilina, Slovakia; Dpt. of Control and Information Systems, University of Zilina, Žilina, Slovakia; Dpt. of Digital Factory, Asseco CEIT, Žilina, Slovakia",2025 26th International Carpathian Control Conference (ICCC),"10 Jun 2025","2025","","","1","6","Most companies around the world have their sensitive data stored in databases that are stored in different data warehouses, and companies need to migrate this data between data warehouses. There are various tools that enable such migration. These tools work on different principles and approaches and it is difficult to choose the right tool to perform the migration. The aim of this paper is to compare different migration tools, to create a reference architecture for the migration process, to perform the migration process and finally to perform the verification of the performed migration. We have created two reference architectures using which we have performed the migration process. We created two workstations on which we tested the selected migration tools Azure Synapse Analytics and SQL Server Migration Assistant (SSMA). The migration process was successful on both sites. The reference architecture and migration tool that was used for the first site was deployed to Continental. The verification process of the migration was performed at both sites, at the first site it was performed by company personnel and the implementation of row level security (RLS) and at the second site the verification was performed using the SQL Server Migration Assistant (SSMA) tool and SQL queries.","","979-8-3315-0127-3","10.1109/ICCC65605.2025.11022843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11022843","data migration;data warehouse;data lake;reference architecture;migration tools","Databases;Publishing;Companies;Data warehouses;Big Data applications;Workstations;Servers;Security;Synapses;Testing","","2","","10","IEEE","10 Jun 2025","19-21 May 2025","19-21 May 2025","IEEE","IEEE Conferences"
"PDS4: A model-driven planetary science data architecture for long-term preservation","J. S. Hughes; D. Crichton; S. Hardman; E. Law; R. Joyner; P. Ramirez","Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, U.S.A; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, U.S.A; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, U.S.A; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, U.S.A; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, U.S.A; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, U.S.A",2014 IEEE 30th International Conference on Data Engineering Workshops,"19 May 2014","2014","","","134","141","The goal of the Planetary Data System (PDS) is the digital preservation of scientific data for long-term use by the scientific research community. After two decades of successful operation, the PDS found itself in a new era of big data, international cooperation, distributed nodes, and multiple ways of analysing and interpreting data. A project was formed to develop a disciplined architectural approach that would drive the design and implementation of a scalable data system that could evolve to meet the demands of this new era. PDS4, the next generation system, uses an explicit model-driven architectural approach coupled with modern information technologies and standards to meet these challenges in order to ensure the planetary data assets can be mined for scientific knowledge for years to come.","","978-1-4799-3481-2","10.1109/ICDEW.2014.6818317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818317","","Object oriented modeling;Data models;XML;Unified modeling language;Computer architecture;Communities;Standards","","9","","23","IEEE","19 May 2014","31 March-4 April 2014","31 March-4 April 2014","IEEE","IEEE Conferences"
"The Gravity Principle in Data Lakes","A. Laurent; T. Libourel; C. Madera; A. Miralles",NA; NA; NA; NA,Data Lakes,"","2020","","","187","199","The data lake solutions are now more complex to design, from an architecture point of view, and really need to explore several technologies and approaches. This chapter explores some factors which can force, from an architecture angle, alternative solutions to the “physical” data movement from data sources to data lakes. An interesting perspective to explore the data lake is the data gravity concept. The chapter investigates what the data gravity influence could be on the data lake design architecture and which are the parameters that could influence the data gravity concept. Like universal gravitation in physics, gravitation in information systems concerns two types of object, namely data and processes. The force can thus be exerted either between data, between processes, or between data and processes. By usage, operational systems are the principal data source for Decision support Information Systems.","","9781119720423","10.1002/9781119720430.ch9","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821702.pdf&bkn=9820901&pdfType=chapter","","Gravity;Big Data applications;Earth;Random access memory;Physics;Information systems;Space vehicles","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Seaport Data Space for Improving Logistic Maritime Operations","D. Sarabia-Jácome; C. E. Palau; M. Esteve; F. Boronat","Communication Department, Universitat Politècnica de València, Valencia, Spain; Communication Department, Universitat Politècnica de València, Valencia, Spain; Communication Department, Universitat Politècnica de València, Valencia, Spain; Communication Department, Universitat Politècnica de València at Campus Gandia, Gandia, Spain",IEEE Access,"9 Jan 2020","2020","8","","4372","4382","The maritime industry expects several improvements to efficiently manage the operation processes by introducing Industry 4.0 enabling technologies. Seaports are the most critical point in the maritime logistics chain because of its multimodal and complex nature. Consequently, coordinated communication among any seaport stakeholders is vital to improving their operations. Currently, Electronic Data Interchange (EDI) and Port Community Systems (PCS), as primary enablers of digital seaports, have demonstrated their limitations to interchange information on time, accurately, efficiently, and securely, causing high operation costs, low resource management, and low performance. For these reasons, this contribution presents the Seaport Data Space (SDS) based on the Industrial Data Space (IDS) reference architecture model to enable a secure data sharing space and promote an intelligent transport multimodal terminal. Each seaport stakeholders implements the IDS connector to take part in the SDS and share their data. On top of SDS, a Big Data architecture is integrated to manage the massive data shared in the SDS and extract useful information to improve the decision-making. The architecture has been evaluated by enabling a port authority and a container terminal to share its data with a shipping company. As a result, several Key Performance Indicators (KPIs) have been developed by using the Big Data architecture functionalities. The KPIs have been shown in a dashboard to allow easy interpretability of results for planning vessel operations. The SDS environment may improve the communication between stakeholders by reducing the transaction costs, enhancing the quality of information, and exhibiting effectiveness.","2169-3536","","10.1109/ACCESS.2019.2963283","European Commission(grant numbers:769355); Secretaría de Educación Superior, Ciencia, Tecnología e Innovación; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946609","Analytics;big data;industry 4.0;industrial data spaces;Internet of Things;maritime;seaport;intelligent transport","Seaports;Big Data;Industries;Stakeholders;Logistics;Data models;Data mining","","37","","50","CCBY","31 Dec 2019","2020","","IEEE","IEEE Journals"
"29 Network Security Needs Big Data","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","151","154","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933540.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"Data Lake Strategy for Data Science Workflows","E. A. VillaseñOr García; A. A. Coronado Iruegas; A. E. Pimentel Alarcón; R. R. SuáRez Ponce De León; A. Figueroa Martínez; A. Esquer Martínez; V. Silva Cuevas; I. G. Cabrera Zamora; E. O. Díaz","Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México; Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México; Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México; Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México; Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México; Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México; Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México; Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México; Dirección del Laboratorio de Ciencia de Datos y Métodos, Modernos de Producción de Información, Instituto Nacional de Estadística y Geografía (INEGI), Aguascalientes, México",2022 11th International Conference On Software Process Improvement (CIMPS),"10 Feb 2023","2022","","","219","223","This paper details the research and technological strategy carried out to implement a Data Lake and Sandboxes of the Data Science Laboratory at the National Institute of Statistics and Geography (INEGI) Mexico. This project seeks to integrate digital information from different repositories, data sources internal and external, which exist by the various entities that generate statistical and geographic information, in various formats to combine them in a unified storage environment (temporary or permanent), which allows advanced processes to be carried out with techniques oriented towards analytics and data science.","","979-8-3503-9896-0","10.1109/CIMPS57786.2022.10035694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035694","data lake;sandbox;data science","Software;Hardware;Data science;Computational modeling;Big Data applications;Process control;Data models","","1","","","IEEE","10 Feb 2023","19-21 Oct. 2022","19-21 Oct. 2022","IEEE","IEEE Conferences"
"A Comprehensive Approach to Real-Time and Batch Processing for Energy-Efficient IoT Homes: Leveraging Lambda Architecture and Data Lakes","F. Serepas; I. Papias; N. Bellos; V. Marinakis","Holistic IKE, Athens, Greece; Decision Support Systems Laboratory, School of Electrical & Computer Engineering, National Technical University of Athens, Athens, Greece; Decision Support Systems Laboratory, School of Electrical & Computer Engineering, National Technical University of Athens, Athens, Greece; Decision Support Systems Laboratory, School of Electrical & Computer Engineering, National Technical University of Athens, Athens, Greece","2024 15th International Conference on Information, Intelligence, Systems & Applications (IISA)","18 Dec 2024","2024","","","1","6","The incorporation of IoT technology into energy-efficient home systems has resulted in a surge in data volume, prompting the need for sophisticated storage and processing solutions. This paper proposes a system that integrates the Lambda Architecture with data lakes to address real-time and batch processing needs in the context of energy-efficient homes. By leveraging technologies such as TimescaleDB for short-term storage and Apache Hudi for long-term storage, coupled with Kafka for data streaming, the system ensures efficient data management and analysis. Real-time insights are provided through GraphQL-powered visualizations, while batch processing facilitates advanced analytics and machine learning model training. The proposed system addresses the dual demands of end-users seeking real-time insights and data scientists requiring extensive datasets for analysis.","","979-8-3503-6883-3","10.1109/IISA62523.2024.10786715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10786715","Data Lake;Data Analytics;Smart Homes;IoT Devices;Big Data;MQTT;Apache Hudi;Apache Kafka;TimescaleDB;Time Series","Training;Analytical models;Batch production systems;Data visualization;Machine learning;Big Data applications;Real-time systems;Energy efficiency;Surges","","5","","27","IEEE","18 Dec 2024","17-19 July 2024","17-19 July 2024","IEEE","IEEE Conferences"
"An Edge Intelligence Empowered Recommender System Enabling Cultural Heritage Applications","X. Su; G. Sperlì; V. Moscato; A. Picariello; C. Esposito; C. Choi","College of Internet of Things Engineering, Hohai University, Changzhou Campus, Changzhou, China; Department of Information Technology and Electrical Engineering, University of Naples “Federico II”, Naples, Italy; Department of Information Technology and Electrical Engineering, University of Naples “Federico II”, Naples, Italy; Department of Information Technology and Electrical Engineering, University of Naples “Federico II”, Naples, Italy; School of Computer Science, Shaanxi Normal University, Xi’an, China; IT Research Institute, Chosun University, Gwangju, South Korea",IEEE Transactions on Industrial Informatics,"5 Jul 2019","2019","15","7","4266","4275","Recommender systems are increasingly playing an important role in our life, enabling users to find “what they need” within large data collections and supporting a variety of applications, from e-commerce to e-tourism. In this paper, we present a Big Data architecture supporting typical cultural heritage applications. On the top of querying, browsing, and analyzing cultural contents coming from distributed and heterogeneous repositories, we propose a novel user-centered recommendation strategy for cultural items suggestion. Despite centralizing the processing operations within the cloud, the vision of edge intelligence has been exploited by having a mobile app (Smart Search Museum) to perform semantic searches and machine-learning-based inference so as to be capable of suggesting museums, together with other items of interest, to users when they are visiting a city, exploiting jointly recommendation techniques and edge artificial intelligence facilities. Experimental results on accuracy and user satisfaction show the goodness of the proposed application.","1941-0050","","10.1109/TII.2019.2908056","National Basic Research Program of China (973 Program)(grant numbers:YS2017YFGH001945); National Natural Science Foundation of China(grant numbers:61801166); National Research Foundation of Korea; Korean Government (Ministry of Science and ICT)(grant numbers:2017R1E1A1A01077913); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8675979","Big Data;cultural heritage (CH);edge artificial intelligence (AI);recommender system","Cultural differences;Recommender systems;Big Data;Social networking (online);Informatics;Collaboration;Engines","","88","","31","IEEE","28 Mar 2019","July 2019","","IEEE","IEEE Journals"
"Civil aircraft health management research based on big data and deep learning technologies","S. Li; G. Zhang; J. Wang","Chinese Academy of Sciences, Institute of Automation, Beijing, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China",2017 IEEE International Conference on Prognostics and Health Management (ICPHM),"3 Aug 2017","2017","","","154","159","The coupling and correlation degree between aircraft systems is higher, and the diagnosis and prognosis of aircraft are more complex. Building a platform for storing and analyzing the aviation big data becomes an important task for civil aviation. This paper proposes a civil aircraft health management big data architecture. The civil aircraft health management system includes airborne PHM, ground PHM, remote diagnosis system, portable maintenance assistant system, maintenance center, automatic test equipment, special test equipment. Airborne PHM collects data from multiple types of data sources. Ground PHM provides decision making support for civil aircrafts including real-time alarm, health management, maintenance plan, spare parts. The paper introduces deep learning algorithm and aircraft fault diagnosis and prognosis implementation.","","978-1-5090-5710-8","10.1109/ICPHM.2017.7998321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7998321","civil aircraft;health management;big data;deep learning","Aircraft;Prognostics and health management;Maintenance engineering;Aerospace electronics;Fault diagnosis;Monitoring;Aircraft propulsion","","17","","18","IEEE","3 Aug 2017","19-21 June 2017","19-21 June 2017","IEEE","IEEE Conferences"
"Towards an Effective Monitoring, Evaluation and Learning (MEL) System: Challenges and Solutions in a Data Science Perspective","J. Mwitirehe; C. W. Kipruto; C. Ruranga","African Centre of Excellence in Data Science, University of Rwanda, Kigali, Rwanda; Jomo Kenyatta University of Agriculture and Technology, Nairobi, Kenya; African Centre of Excellence in Data Science, University of Rwanda, Kigali, Rwanda",2022 12th International Conference on Advanced Computer Information Technologies (ACIT),"12 Oct 2022","2022","","","130","135","This paper aims at addressing some challenges that prevent monitoring, evaluation and learning systems from effectively supporting the adaptive management. Using a case study of monitoring the drinking water quality compliance in Rwanda, a proposed four-step approach illustrated how big data can be integrated and leveraged to guarantee accurate and timely data insights as well as reliable predictions and user-friendly reporting. That approach capitalized on Hadoop data lake and R/RStudio to ingest and store structured and unstructured data from different sources, process them, and finally to consume them into interactive dashboards created in Microsoft Power Business Intelligence. Compared to the traditional practice of considering only measurable indicators, more quality key performance indicators were introduced to support the acquisition of additional and triangulated evidence on performance, which should satisfy the information needs of stakeholders.","2770-5226","978-1-6654-1050-2","10.1109/ACIT54803.2022.9912749","University of Rwanda; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912749","big data;dashboard;Hadoop;MEL;Power BI","Learning systems;Key performance indicator;Water quality;Big Data applications;Market research;Real-time systems;Stakeholders","","3","","21","IEEE","12 Oct 2022","26-28 Sept. 2022","26-28 Sept. 2022","IEEE","IEEE Conferences"
"Data Discovery","Y. Aytas",NA,"Designing Big Data Platforms: How to Use, Deploy, and Maintain Big Data Systems","","2021","","","179","197","This chapter discusses the importance of data discovery for a modern Big Data platform, finds the link between data discovery and data governance, and explore tooling used in Big Data discovery. Disparate data sources in Big Data systems make accessing metadata troublesome. A single source of metadata makes metadata available for further processing. The data lineage is partially available in workflow orchestration. Data lineage consists of multiple directed acyclic graphs where each node in the dag corresponds to a table or a data structure. Responsibility and accountability are the driving factors for data ownership. A good presentation layer helps in completing the feedback loop for data discovery. There is a close relationship between data discovery and data governance. Big Data governance depends on the data architecture and data source integration, and factors for data governance. Apache Atlas is a data governance software designed to collect, organize, and store metadata.","","9781119690948","10.1002/9781119690962.ch9","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822354.pdf&bkn=9820885&pdfType=chapter","","Metadata;Measurement;Pipelines;Soft sensors;Resists;Periodic structures;Directed acyclic graph","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Managing Personal Identifiable Information in Data Lakes","D. Oreščanin; T. Hlupić; B. Vrdoljak","Legit Software d.o.o., Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia",IEEE Access,"4 Mar 2024","2024","12","","32164","32180","Privacy is a fundamental human right according to the Universal Declaration of Human Rights of the United Nations. Adoption of the General Data Protection Regulation (GDPR) in European Union in 2018 was turning point in management of personal data, specifically personal identifiable information (PII). Although there were many previous privacy laws in existence before, GDPR has brought privacy topic in the regulatory spotlight. Two most important novelties are seven basic principles related to processing of personal data and huge fines defined for violation of the regulation. Many other countries have followed the EU with the adoption of similar legislation. Personal data management processes in companies, especially in analytical systems and Data Lakes, must comply with the regulatory requirements. In Data Lakes, there are no standard architectures or solutions for the need to discover personal identifiable information, match data about the same person from different sources, or remove expired personal data. It is necessary to upgrade the existing Data Lake architectures and metadata models to support these functionalities. The goal is to study the current Data Lake architecture and metadata models and to propose enhancements to improve the collection, discovery, storage, processing, and removal of personal identifiable information. In this paper, a new metadata model that supports the handling of personal identifiable information in a Data Lake is proposed.","2169-3536","","10.1109/ACCESS.2024.3365042","European Regional Development Fund (Digital Platform for Ensuring Data Privacy and Prevention of Malicious Manipulation of the Personal Data–AIPD2)(grant numbers:KK.01.2.1.02.0038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10431740","Data lake;personal identifiable information metadata;personal data;data discovery;entity linking;data removal","Big Data applications;Metadata;Computer architecture;General Data Protection Regulation;Feature extraction;Privacy;Data lakes;Identification of persons;Knowledge discovery;Data collection","","6","","34","CCBYNCND","9 Feb 2024","2024","","IEEE","IEEE Journals"
"Optimizing Big Data Workloads in Hybrid Cloud Environments: Evaluating File Formats and Compression Codecs","A. Kanto; A. C. Marosi","Cloudera, Budapest, Hungary; Laboratory of Parallel and Distributed Systems, HUN-REN SZTAKI, Budapest, Hungary",2025 IEEE 23rd Jubilee International Symposium on Intelligent Systems and Informatics (SISY),"21 Oct 2025","2025","","","000031","000036","Hybrid cloud architectures offer a practical way for enterprises to handle peak big data workloads by extending on-premise systems into the public cloud and bursting workloads there when needed. However, limited network bandwidth between the two environments can become a performance bottleneck. This paper investigates the influence of various file formats and compression codecs on query execution time and data transfer in bandwidth-constrained hybrid clouds, utilizing the TPC-DS benchmark and Apache Spark. We introduce new performance metrics and simulate realistic hybrid cloud conditions using traffic shaping. In our experiments, execution time degradation reached 233.81% for uncompressed data compared to the baseline on-premise workload execution. With Gzip compression, this was reduced to 134.91%.","1949-0488","979-8-3315-9657-6","10.1109/SISY67000.2025.11205406","Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11205406","columnar storage;data lake;data locality;hybrid cloud;traffic shaping;tpc-ds;spark;parquet;orc;compression","Degradation;Cloud computing;Codecs;Bandwidth;Pricing;Benchmark testing;Predictive models;Data transfer;Performance metrics;Sparks","","","","22","IEEE","21 Oct 2025","25-27 Sept. 2025","25-27 Sept. 2025","IEEE","IEEE Conferences"
"A mobile agent team works model for HPC big data analysis: Fuzzy logic application","F. Z. Benchara; M. Youssfi; O. Bouattane; H. Ouajji","Laboratory SSDIA, ENSET Mohammedia, Hassan II University of Casablanca, Mohammedia, Morocco; Laboratory SSDIA, ENSET Mohammedia, Hassan II University of Casablanca, Mohammedia, Morocco; Laboratory SSDIA, ENSET Mohammedia, Hassan II University of Casablanca, Mohammedia, Morocco; Laboratory SSDIA, ENSET Mohammedia, Hassan II University of Casablanca, Mohammedia, Morocco",2015 5th International Conference on Information & Communication Technology and Accessibility (ICTA),"10 Mar 2016","2015","","","1","6","The aim of this paper is to present a distributed implementation of the Type-2 Fuzzy Logic (T2FL) algorithm in a mobile agent based distributed computing platform. The proposed algorithm is assigned to be implemented on an SPMD (Single Program Multiple Data) architecture which is based on a cooperative mobile agent model. It is constituted by a set of mobile agents as AVPEs (Agent Virtual Processing Elements) in order to improve the processing resources needed for performing the big data image segmentation. In this work we focused on the application of this algorithm to process the big data MRI (Magnetic Resonance Images) image. The input image is splitted into elementary images by the Mobile Team leader Agent and encapsulated one per AVPE. Each AVPE perform and exchange the segmentation results and maintain asynchronous communication with their Team leader agent until the convergence of this algorithm. The obtained experimental results in terms of accuracy and efficiency analysis of the proposed distributed implementation are achieved thanks to the mobile agents several interesting skills introduced in this distributed computational model.","","978-1-4673-8749-1","10.1109/ICTA.2015.7426917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426917","Distributed Type-2 Fuzzy algorithm;Image Processing;Mobile Agents;Parallel and Distributed Computing","Computational modeling;Image segmentation;Mobile agents;Algorithm design and analysis;Mobile communication;Convergence;Fuzzy logic","","","","14","IEEE","10 Mar 2016","21-23 Dec. 2015","21-23 Dec. 2015","IEEE","IEEE Conferences"
"A Two-Stage Method for Ultra-Short-Term PV Power Forecasting Based on Data-Driven","H. Zhou; J. Wang; F. Ouyang; C. Cui; X. Li","Laboratory of Big Data and Artificial Intelligence, College of Information and Engineering, China Jiliang University, Hangzhou, China; Laboratory of Big Data and Artificial Intelligence, College of Information and Engineering, China Jiliang University, Hangzhou, China; Laboratory of Big Data and Artificial Intelligence, College of Information and Engineering, China Jiliang University, Hangzhou, China; Key Laboratory of Public Security Information Application Based on Big Data Architecture, Zhejiang Police College, Hangzhou, China; Laboratory of Big Data and Artificial Intelligence, College of Information and Engineering, China Jiliang University, Hangzhou, China",IEEE Access,"1 May 2023","2023","11","","41175","41189","To promote the real-time dispatching of a power grid and balanced decision-making of power producers, accuracy and real-time forecasting are two main problems that need to be solved in ultra-short-term photovoltaic (PV) forecasting. Focusing on the problems of slow model training speed and low forecasting accuracy due to the redundancy of training data samples and insufficient long periodic capture of data in complex weather, this paper proposes a two-stage method for ultra-short-term PV power forecasting based on data-driven. In the meteorological analysis stage, the generation power samples similar to the forecast day were extracted by inputting daily meteorological features and using maximal information coefficient (MIC) weighted grey correlation degree to form the corresponding forecast data set. In the power forecasting stage, the temporal convolutional used network (TCN) extracts local features to maintain the sequence of extracted features. Then the bidirectional gating unit (BiGRU) combined with the Skip connection strategy was used to fully learn the long and the short time sequence of photovoltaic sequences, and the attention mechanism was used to pay adaptive attention to the more important historical states. This study experimented on the measured data from a photovoltaic power station in Southeastern China. The experimental results show that this method is effective in photovoltaic power short-term forecasts. In addition, compared with the latest model, this method has smaller forecasting errors and higher robustness in the time scales of 15 minutes, 30 minutes, 45 minutes, and 60 minutes. Specifically, indicator R2 increased by an average of 5.4%, while indicators RMSE and MAE decreased by 8.6% and 7.3%, respectively.","2169-3536","","10.1109/ACCESS.2023.3267515","Zhejiang Province Public Welfare Technology Application Research Project(grant numbers:LGG22E070003); Ministry of Public Security Open Subjects of the Key Laboratory of Public Security Information Application Based on Big Data Architecture(grant numbers:2021DSJSYS004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103522","Bidirectional gating unit;temporal convolutional network;maximal information coefficient;skip connection;photovoltaic power forecasting","Forecasting;Feature extraction;Predictive models;Photovoltaic systems;Training;Time series analysis;Correlation","","17","","36","CCBYNCND","17 Apr 2023","2023","","IEEE","IEEE Journals"
"Secured AI guided Architecture for D2D Systems of Massive MIMO deployed in 5G Networks","A. Vijay; K. Umadevi","Department of Electronics and Communication Engineering, Ambal Professional Group of Institutions, Palladam, Tamil Nadu, India; Sengunthar Engineering College, Tiruchengode, Tamil Nadu, India",2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI),"11 Oct 2019","2019","","","468","472","Security issues arises with the massive elevation in quantity of mobile users along with high data rate services proposed by 5G networks. D2D communication technique is an optimized method to support various demands on massive data transfer rates among the users in 5G networks. Massive MIMO (Multiple-input and Multiple-output) based antenna systems are deployed to achieve these huge data demands in 5G technology. However, the drawbacks owing to expanding computational overhead in methods of allocating resource, reducing interference, energy optimization and several other problems in D2D networks are compromised with the help of emerging technology of Explainable Artificial Intelligence (XAI). Furthermore, a novel approach based on AI is implemented with an Architectural design for D2D network in decision making over the implementation of techniques based on the persisting situation in the D2D network. Finally, Security protocols based on network demands are implemented through AI in D2D Communications of Massive MIMO based 5G Networks.","","978-1-5386-9439-8","10.1109/ICOEI.2019.8862712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862712","Explainable Artificial Intelligence;Massive MIMO;Big Data Lake;Software-Defined Radio;Cloud Server;COBRA Technology","Device-to-device communication;Artificial intelligence;5G mobile communication;Protocols;Security;Servers","","9","","36","IEEE","11 Oct 2019","23-25 April 2019","23-25 April 2019","IEEE","IEEE Conferences"
"Data-Driven Analysis of Skeet Shooting Training: Multi-Modal Data Collection and Lake-Warehouse Unified Architecture Design","X. Shu; J. Wu; Z. Li; Y. Liu","Shenyang Institute of Computing Technology, University of Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Computing Technology, University of Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Computing Technology, University of Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Computing Technology, University of Chinese Academy of Sciences, Shenyang, China",2024 10th International Conference on Computer and Communications (ICCC),"2 Apr 2025","2024","","","41","46","As times evolve and technology advances, the speed and scale of data generation have increased dramatically, giving rise to new technologies for big data processing and analysis. The Bidirectional Skeet Shooting Analysis Project aims to enhance the training levels of skeet shooters. Traditional training methods primarily rely on coaches' experiences and lack systematic data analysis. To address this issue, this paper applies big data technologies by comprehensively collecting data from athletes' training processes and constructing a data warehouse based on a lake-warehouse architecture. This approach assists coaches in accurately understanding each athlete's training status while providing analysis and visualization capabilities. It promotes the shift of skeet shooting training towards a data-driven direction, thereby enhancing training effectiveness and offering significant theoretical and practical references for improving traditional training methods in skeet shooting.","2837-7109","979-8-3315-0707-7","10.1109/ICCC62609.2024.10941963","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10941963","data lake;data analysis;shooting sports analytics;big data","Training;Data analysis;Systematics;Soft sensors;Psychology;Memory;Computer architecture;Real-time systems;Trajectory;Sports","","","","6","IEEE","2 Apr 2025","13-16 Dec. 2024","13-16 Dec. 2024","IEEE","IEEE Conferences"
"Scalable Analytics Platform for Machine Learning in Smart Production Systems","K. Al-Gumaei; A. Müller; J. N. Weskamp; C. S. Longo; F. Pethig; S. Windmann","Fraunhofer IOSB-INA Fraunhofer Center for Machine Learning, Lemgo, Germany; Fraunhofer IOSB-INA Fraunhofer Center for Machine Learning, Lemgo, Germany; Fraunhofer IOSB-INA Fraunhofer Center for Machine Learning, Lemgo, Germany; University of Modena and Reggio Emilia, Italy; Fraunhofer IOSB-INA Fraunhofer Center for Machine Learning, Lemgo, Germany; Fraunhofer IOSB-INA Fraunhofer Center for Machine Learning, Lemgo, Germany",2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA),"17 Oct 2019","2019","","","1155","1162","Manufacturing industry is facing major challenges to meet customer requirements, which are constantly changing. Therefore, products have to be manufactured with efficient processes, minimal interruptions, and low resource consumptions. To achieve this goal, huge amounts of data generated by industrial equipment needs to be managed and analyzed by modern technologies. Since the big data era in manufacturing industry is still at an early stage, there is a need for a reference architecture that incorporates big data and machine learning technologies and aligns with the Industrie 4.0 standards and requirements. In this paper, requirements for designing a scalable analytics platform for industrial data are derived from Industrie 4.0 standards and literature. Based on these requirements, a reference big data architecture for industrial machine learning applications is proposed and compared to related works. Finally, the proposed architecture has been implemented in the Lab Big Data at the SmartFactoryOWL and its scalability and performance have been evaluated on parallel computation of an industrial PCA model. The results show that the proposed architecture is linearly scalable and adaptable to machine learning use cases and will help to improve the industrial automation processes in production systems.","1946-0759","978-1-7281-0303-7","10.1109/ETFA.2019.8869075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869075","Big Data;Machine Learning;Industrie 4.0;Industrial Automation","Big Data;Industries;Machine learning;Computer architecture;Data models;Tools;Standards","","14","","36","IEEE","17 Oct 2019","10-13 Sept. 2019","10-13 Sept. 2019","IEEE","IEEE Conferences"
"Big data analysis architecture for multi IDS sensors using memory based processor","F. A. Saputra; M. Salman; K. Ramli; A. Abdillah; I. Syarif","Department of Electrical Engineering, Universitas Indonesia, Jakarta, Indonesia; Department of Electrical Engineering, Universitas Indonesia, Jakarta, Indonesia; Department of Electrical Engineering, Universitas Indonesia, Jakarta, Indonesia; Department of Informatics and Computer Engineering, Politeknik Elektronika Negeri Surabaya Surabaya, Indonesia; Department of Informatics and Computer Engineering, Politeknik Elektronika Negeri Surabaya Surabaya, Indonesia",2017 International Electronics Symposium on Knowledge Creation and Intelligent Computing (IES-KCIC),"21 Dec 2017","2017","","","40","45","The massive internet usage is followed by the rise of cyber-related crime such as information stealing, denial-of-service (DoS) attack, trojan and malware. To cope with the threats, one of most popular choice is using Intrusion Detection System (IDS). The logs produced by IDS in a day is huge and the limitation of computing power is the main problem to process that logs files. In this paper, we propose a big data analysis architecture of multi IDS sensors using in-memory data processing. Deployed IDS sensors are taking an extra role as computation slave to build scalable data analysis platform for network security analysis. So, adding more sensors means expanding computational resources. Adding to three sensors are helping data computation of clustering algorithm faster up to 27% comparing to the computation by using only one sensor. This research also introduces the use of memory-based processor, this system provides 7,9 times faster data processing than conservative MapReduce operation. And moreover, we also have performed botnets classification over Spark RDD that give high accuracy result to 99%.","","978-1-5386-0716-9","10.1109/KCIC.2017.8228456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8228456","intrusion detection system;big data architecture;network data analysis;Memory-based Processor","Data analysis;Machine learning algorithms;Accuracy;Intrusion detection;Clustering algorithms;Computer architecture;Big Data;Sensors;Trojan horses;Sparks","","1","","16","IEEE","21 Dec 2017","26-27 Sept. 2017","26-27 Sept. 2017","IEEE","IEEE Conferences"
"Temporal Event Tracing on Big Healthcare Data Analytics","C. -H. Lin; L. -C. Huang; S. -C. T. Chou; C. -H. Liu; H. -F. Cheng; I. -J. Chiang","Department of Information Management, National Taiwan University, Taipei, Taiwan, R.O.C.; Department of Information Management, National Taiwan University, Taipei, Taiwan, R.O.C.; Department of Information Management, National Taiwan University, Taipei, Taiwan, R.O.C.; Institute of Biomedical Engineering, National Taiwan University, Taipei, Taiwan, R.O.C.; Institute of Biomedical Engineering, National Taiwan University, Taipei, Taiwan, R.O.C.; Institute of Biomedical Engineering, National Taiwan University, Taipei, Taiwan, R.O.C.",2014 IEEE International Congress on Big Data,"25 Sep 2014","2014","","","281","287","This study presents a comprehensive method for rapidly processing, storing, retrieving, and analyzing big healthcare data. Based on NoSQL (not only SQL), a patient-driven data architecture is suggested to enable the rapid storing and flexible expansion of data. Thus, the schema differences of various hospitals can be overcome, and the flexibility for field alterations and addition is ensured. The timeline mode can easily be used to generate a visual representation of patient records, providing physicians with a reference for patient consultation. The sharding-key is used for data partitioning to generate data on patients of various populations. Subsequently, data reformulation is conducted as a first step, producing additional temporal and spatial data, providing cloud computing methods based on query-MapReduce-shard, and enhancing the search performance of data mining. Target data can be rapidly searched and filtered, particularly when analyzing temporal events and interactive effects.","2379-7703","978-1-4799-5057-7","10.1109/BigData.Congress.2014.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906791","big medical data;NoSQL;temporal event analysis;shard;data mining;medical record","Drugs;Biomedical imaging;Databases;Sociology;Statistics;Diseases","","26","","30","IEEE","25 Sep 2014","27 June-2 July 2014","27 June-2 July 2014","IEEE","IEEE Conferences"
"Effective Big Data Caching through Reinforcement Learning","M. Tracolli; M. Baioletti; V. Poggioni; D. Spiga","INFN Sezione di Perugia, Università degli Studi di Perugia Università degli Studi di Firenze, Perugia, Italy; Università degli Studi di Perugia, Perugia, Italy; Università degli Studi di Perugia, Perugia, Italy; INFN Sezione Perugia, Perugia, Italy",2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA),"23 Feb 2021","2020","","","1499","1504","In the era of big data, data volumes continue to grow in several different domains, from business to scientific fields. Sensors, edge devices, scientific applications and detectors generate huge amounts of data that are distributed for their nature. In order to extract value from such data requires a typical pipeline made of two main steps: first, the processing and then the data access. One of the main features for data access is fast response time, whose order of magnitude can vary a lot depending on the specific type of processing as well as processing patterns. The optimization of the access layer becomes more and more important while dealing with a geographically distributed environment where data must be retrieved from remote servers of a data lake. From the infrastructural perspectives, caching systems are used to mitigate latency and to serve better popular data. Thus, the role of the cache becomes a key to have an effective and efficient data access. In this article, we propose a Reinforcement Learning approach, using the Q-Learning technique, to improve the performances of a cache system in terms of data management. The proposed method uses two agents with different objectives and actions to control the addition and the eviction of files in the cache. The aim of this system is to increase the throughput reducing, at the same time, the cache costs, such as the amount of data written, and network utilization. Moreover, we tested our method in a context of data analysis, with information taken from High Energy Physics (HEP) workflow.","","978-1-7281-8470-8","10.1109/ICMLA51294.2020.00231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356236","cache;optimization;intelligent system;big data;data science workflow;reinforcement learning;addition policy;eviction policy","Distributed databases;Reinforcement learning;Lakes;Big Data;Throughput;Time factors;Servers","","1","","23","IEEE","23 Feb 2021","14-17 Dec. 2020","14-17 Dec. 2020","IEEE","IEEE Conferences"
"Towards the Specification and Generation of Time Series Datasets from Data Lakes","B. Sal; A. de la Vega; P. López-Martínez; D. García-Saiz; A. Grande; D. López; P. Sánchez","Software Engineering and Real-Time Group, Universidad de Cantabria, Santander, Cantabria, Spain; Software Engineering and Real-Time Group, Universidad de Cantabria, Santander, Cantabria, Spain; Software Engineering and Real-Time Group, Universidad de Cantabria, Santander, Cantabria, Spain; Software Engineering and Real-Time Group, Universidad de Cantabria, Santander, Cantabria, Spain; LIS Data Solutions, Santander, Cantabria, Spain; LIS Data Solutions, Santander, Cantabria, Spain; Software Engineering and Real-Time Group, Universidad de Cantabria, Santander, Cantabria, Spain",2023 IEEE 31st International Requirements Engineering Conference Workshops (REW),"28 Sep 2023","2023","","","302","306","These days, more and more organizations are building data lakes as a mechanism to store the information they generate. This information is considered as a valuable asset that, if properly analyzed, can help to make more informed decisions. However, since the analyses to be performed are often not known in advance, these data are stored in a raw format. This means that any application built on top of a data lake must carefully elicit what data will be used for a particular analysis and how those data will be transformed to make them all fit together into a dataset. This data selection and preparation task is typically performed by data scientists that write large and complicated scripts in data management languages to extract and transform the required data. This reduces the productivity of data scientists, who must write large pieces of highly similar code. It also makes it difficult for domain experts to participate in this process because they have little understanding of these scripts. To alleviate this problem, this work introduces a work-in-progress version of a high-level declarative language for specifying the requirements that a dataset coming from a data lake must satisfy. This language is then processed to automatically generate the specified dataset, allowing data scientists and domain experts to be agnostic about the details of how data are exactly retrieved and transformed.","2770-6834","979-8-3503-2691-8","10.1109/REW57809.2023.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260908","Data Lake;Dataset;Data Wrangling;Time Series","Productivity;Codes;Time series analysis;Data visualization;Transforms;Syntactics;Big Data applications","","","","14","IEEE","28 Sep 2023","4-5 Sept. 2023","4-5 Sept. 2023","IEEE","IEEE Conferences"
"Collaboration of Digital Twins Through Linked Open Data: Architecture With FIWARE as Enabling Technology","J. Conde; A. Munoz-Arcentales; Á. Alonso; G. Huecas; J. Salvachúa","Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain",IT Professional,"16 Jan 2023","2022","24","6","41","46","The collaboration of the real world and the virtual world, known as Digital Twin, has become a trend with numerous successful use cases. However, there are challenges mentioned in the literature that must be addressed. One of the most important issues is the difficulty of collaboration of Digital Twins due to the lack of standardization in their implementation. This article continues a previous work that proposed a generic architecture based on the FIWARE components to build Digital Twins in any field. Our work proposes the use of Linked Open Data as a mechanism to facilitate the communication of Digital Twins. We validate our proposal with a use case of an urban Digital Twin that collaborates with a parking Digital Twin. We conclude that Linked Open Data in combination with the FIWARE ecosystem is a real reference option to deploy Digital Twins and to enable the collaboration between Digital Twins.","1941-045X","","10.1109/MITP.2022.3224826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017408","","Ecosystems;Collaboration;Standardization;Market research;Digital twins;Proposals;Open data","","17","","15","IEEE","16 Jan 2023","1 Nov.-Dec. 2022","","IEEE","IEEE Magazines"
"An Advanced Sustainment Modeling Approach for Global Defense Data Architecture","V. V. Suthar","Raytheon, Integrated Defense Systems 1001 Boston Post Road E, Marlborough, Massachusetts, USA",2020 Annual Reliability and Maintainability Symposium (RAMS),"31 Jul 2020","2020","","","1","4","Summary & Conclusions: The traditional methodology of collecting critical sustainment data through isolated databases allows users to pull data on-demand; however, this requires manual efforts to merge data to see it in meaningful ways. Hence, this approach does not provide data at the point of need to satisfy warfighter demand. This weakness is due to having various disparate databases across the globe. This approach makes it difficult for an individual to perform analyses that influence support decisions related to the Integrated Logistics Support (ILS) elements as shown in Figure 1 below. Figure 1Integrated Logistics Support Elements1Raytheon employs Model-based Systems Engineering techniques to the Advanced Sustainment Model (ASM) architecture. ASM centralizes, optimizes and automates the collection and distribution of critical sustainment related data across a range of Prime Mission Systems Integrators, Government Logisticians, Original Equipment Manufacturers (OEM) and end-user consumers. The ASM architecture focuses on a software toolkit that runs on user-provided hardware and datalink infrastructure.","2577-0993","978-1-7281-3690-5","10.1109/RAMS48030.2020.9153659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9153659","","Real-time systems;Tools;Maintenance engineering;Logistics;Modeling;Computer architecture;Training","","1","","2","IEEE","31 Jul 2020","27-30 Jan. 2020","27-30 Jan. 2020","IEEE","IEEE Conferences"
"Cloud data governance maturity model","G. Cheng; Y. Li; Z. Gao; X. Liu","CEPREI Certification Body, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, P. R. China; CEPREI Certification Body, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, P. R. China; CEPREI Certification Body, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, P. R. China; CEPREI Certification Body, China Electronic Product Reliability and Environmental Testing Research Institute, Guangzhou, P. R. China",2017 8th IEEE International Conference on Software Engineering and Service Science (ICSESS),"23 Apr 2018","2017","","","517","520","Data governance is essential to ensure the accuracy, moderate sharing and protection of data, and to support data to play an important role in various decisions. However, with the development of cloud computing and big data technology, the characteristics of data are undergoing many changes, so traditional data governance theories cannot fully meet the governance requirements of data in era of cloud computing and big data. Learning from traditional data governance theories and intensively analyzing data characteristics in cloud computing, we put forward the cloud data governance maturity model (CDGM) innovatively. The CDGM includes lots of policies focusing on data strategy, data management, data optimization, data operations, data architecture and data security & privacy protection, and a continuous improvement loop governance system of planning, implementation, evaluation and optimization. At the same time, this paper also defines the cloud data governance maturity levels and explains their main features, and at last presents the cloud data governance maturity assessment methods. So, the CDGM can provide an overall guidance for an organization to manage their cloud data.","2327-0594","978-1-5386-0497-7","10.1109/ICSESS.2017.8342968","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8342968","data gvernance;cloud data;cloud computing;maturity model","Cloud computing;Distributed databases;Organizations;Data security;Data privacy;Data models;Data integrity","","13","","4","IEEE","23 Apr 2018","24-26 Nov. 2017","24-26 Nov. 2017","IEEE","IEEE Conferences"
"Retrieval of Large Data From Medical Lake Repository-Heart Note","D. Babu; G. S; K. K; M. PT; P. S","Department of Information Technology, Panimalar Engineering College, Chennai, India; Department of Information Technology, Panimalar Engineering College, Chennai, India; Department of Information Technology, Panimalar Engineering College, Chennai, India; Department of Information Technology, Panimalar Engineering College, Chennai, India; Department of Information Technology, Panimalar Engineering College, Chennai, India",2022 1st International Conference on Computational Science and Technology (ICCST),"14 Feb 2023","2022","","","518","522","The data lake was built from scratch for the size and performance of the cloud. The Azure Data Lake Store allows any company to analyze all their data in one place without any human restrictions. A data lake store can store trillions of files, and one file is 200 times larger than other cloud storages. This means that there is no need rewrite the code as the size of the stored data increases or decreases or the amount of processing power spun up increases. Data Lake also removes the complexity normally associated with big data in the cloud, enabling it to meet current and future business needs. In this project, we will create an Azure account that uses Data Lake, store electronic medical records / electronic health records (EMR / EHR) for patients, and use machine learning to classify (EMR / EHR) data types. increase. Here the KNN algorithm is used for classification to retrieve and download the data stored in the data lake. Usercan also delete the data if the user no longer needs to change the data or system.","","978-1-6654-7655-3","10.1109/ICCST55948.2022.10040351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10040351","","Cloud computing;Machine learning algorithms;Scientific computing;Machine learning;Lakes;Data science;Big Data applications","","1","","7","IEEE","14 Feb 2023","9-10 Nov. 2022","9-10 Nov. 2022","IEEE","IEEE Conferences"
"AIOps Essential to Unified Resiliency Management in Data Lakehouses","R. Jin; P. Muench; V. Deenadhayalan; B. Hatfield","IBM Almaden Research Center, Hybrid Cloud Storage Research, San Jose, USA; IBM Almaden Research Center, Hybrid Cloud Storage Research, San Jose, USA; IBM Almaden Research Center, Hybrid Cloud Storage Research, San Jose, USA; IBM Almaden Research Center, Hybrid Cloud Storage Research, San Jose, USA",2022 IEEE International Conference on Big Data (Big Data),"26 Jan 2023","2022","","","4777","4781","AIOps can provide essential value for data lake-houses as lakehouses pose complex operational challenges for Site Reliability Engineers (SRE). This paper proposes that the unified approach of data lakehouses creates a unique opportunity for unified data resiliency management. We focus on AIOps applied to disaster recovery and backup/restore. In particular, we focus on managing data lakehouse hardware resources to ensure that lakehouse data Recovery Point Objectives (RPO) are met with a high degree of accuracy. The goal is to warn an SRE about an impending RPO violation and to suggest adding given amounts of hardware resources before a given time to avoid violation of the lakehouse data’s RPO. We claim AIOps can achieve this goal with an ensemble of machine learning and time series analysis.","","978-1-6654-8045-1","10.1109/BigData55660.2022.10020986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020986","AIOps;Data Resiliency;Disaster Recovery;Backup/Restore;RPO;Supervised Learning;SRE","Time series analysis;Machine learning;Big Data;Reliability engineering;Hardware;Resilience","","2","","23","IEEE","26 Jan 2023","17-20 Dec. 2022","17-20 Dec. 2022","IEEE","IEEE Conferences"
"DIGO: An Open Data Architecture for e-Government","A. L. Machado; J. M. Parente de Oliveira","Divisão de Ciencia da Computação (IEC), Instituto Tecnológico De Aeronáutica, Sao Jose dos Campos, Brazil; Divisão de Ciência da Computação (IEC), Instituto Tecnológico De Aeronáutica, Sao Jose dos Campos, Brazil",2011 IEEE 15th International Enterprise Distributed Object Computing Conference Workshops,"10 Oct 2011","2011","","","448","456","Currently most governing bodies publish their data on the World Wide Web (WWW). These data are available on e-Government Web Portals in unstructured formats using current Web languages, making them difficult to reuse and to generate new information. In this context, access to relevant, accurate public information, and possible reuse by other applications become increasingly complex. Open Government Data (OGD) means the publication of data in open raw formats (open data). There are tools to put open data on the WWW. However, this tools doesn't work with an architecture covering all aspects of data reuse. The aim of this paper is to show an architecture called Delivering Information of Government (DIGO) to allow access to primary data by machines in open data so that citizens interested in doing so can combine them (linked open data) and produce new information and mashup applications, consequently, enabling OGD and data fusion on the Linking Open Data (LOD) cloud.","2325-6605","978-0-7695-4426-7","10.1109/EDOCW.2011.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037649","open data;open government data;linked open data;ontologies;e-Government","Semantics;Portals;Electronic government;Data mining;Context;Resource description framework","","18","","24","IEEE","10 Oct 2011","29 Aug.-2 Sept. 2011","29 Aug.-2 Sept. 2011","IEEE","IEEE Conferences"
"Introduction to Data Lakes: Definitions and Discussions","A. Laurent; D. Laurent; C. Madera",NA; NA; NA,Data Lakes,"","2020","","","1","20","This chapter reviews existing work on data lakes and then introduces a global architecture for information systems in which data lakes appear as a new additional component, when compared to existing systems. It also reviews the industrial and academic literature about data lakes, aiming to better understand the emergence of this concept. The most successful work about data lake architecture, components and positioning is presented, because the emphasis is on data governance and more specifically on the metadata catalog. Initially regarded as low‐cost storage environments, data lakes are now considered by companies as strategic tools due to their potential ability to give data a high value. The chapter explores how to position data lakes in information systems, based on Le Moigne's approach. It emphasizes the differences between data lakes and decision‐making systems.","","9781119720423","10.1002/9781119720430.ch1","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822035.pdf&bkn=9820901&pdfType=chapter","","Big Data applications;Computer architecture;Fans;Cluster computing;Data warehouses;Costs;Proposals","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"TensorBank: Tensor Lakehouse for Foundation Model Training","R. Kienzler; J. Schmude; N. Simumba; B. Blumenstiel; M. Freitag; D. Kimura; Z. A. Nagy; M. Behrendt; H. Hamann; S. K. Mukkavilli; D. S. Civitarese",IBM Research Europe; IBM Research; IBM Research; IBM Research Europe; IBM Research; IBM Research; IBM Research Europe; IBM Research and Development; IBM Research; IBM Research Europe; IBM Research,2023 IEEE International Conference on Big Data (BigData),"22 Jan 2024","2023","","","3350","3354","Storing and streaming high dimensional data for foundation model training became a critical requirement with the rise of foundation models beyond natural language. In this paper we introduce TensorBank – a petabyte scale tensor lakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU memory at wire speed based on complex relational queries. We use Hierarchical Statistical Indices (HSI) for query acceleration. Our architecture allows to directly address tensors on block level using HTTP range reads. Once in GPU memory, data can be transformed using PyTorch transforms. We provide a generic PyTorch dataset type with a corresponding dataset factory translating relational queries and requested transformations as an instance. By making use of the HSI, irrelevant blocks can be skipped without reading them as those indices contain statistics on their content at different hierarchical resolution levels. This is an opinionated architecture powered by open standards and making heavy use of open-source technology. Although, hardened for production use using geospatial-temporal data, this architecture generalizes to other use cases like computer vision, computational neuroscience, biological sequence analysis and more.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386912","data lakehouse;data streaming;database indexing;foundation models;tensor streaming;tensor query","Training;Acute respiratory distress syndrome;Tensors;Computational modeling;Wires;Graphics processing units;Computer architecture","","3","","29","IEEE","22 Jan 2024","15-18 Dec. 2023","15-18 Dec. 2023","IEEE","IEEE Conferences"
"An Adaptive RPC Mechanism for Performance and Node Fault Tolerance Optimization in HDFS","J. Zhang; Z. Shu; L. Luo","School of Computer & Communication Engineering, Changsha University of Science & Technology, Changsha, China; School of Computer & Communication Engineering, Changsha University of Science & Technology, Changsha, China; Science and Technology on Information Systems Engineering Laboratory, School of Systems Engineering, National University of Defense Technology, Changsha, China","2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","28 Mar 2023","2022","","","1789","1794","With the rapid development and evolution of information technologies, the big data industry has been experiencing exponential explosive data growth. Since the huge business and research value behind the large-scale data, big data technology has become one of the hotest research fields in academia and industry. To the big data, storing and processing the data is core function of the file systems. Hadoop Distributed File System (HDFS) is the most typical distributed big data architecture, which has the characteristics of high reliability, high fault tolerance, and low hardware cost. HDFS provides the efficient task implementation and fault tolerance among nodes by Remote Procedure Call (RPC) mechanism. However, the traditional RPC mechanism has remarkable defects with the fixed timing method, and cannot quickly establish the relationship between node downtime and network congestion. In this paper, we propose an improved adaptive RPC mechanism for node fault tolerance and performance. The proposed method classifies nodes by the data block access statistic, and dynamically adjusts the RPC interval time. This method can be used to reduce the networking traffic and processing pressure of NameNode nodes, and improve the I/O and task performance. Through the node classification, an inrack method is used to achieve better performance on fault tolerance. Eventually, we design the extensive experiments to evaluate the proposed method, and experimental results show it improves the performance compared with state-of-the-art method.","","979-8-3503-1993-4","10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00270","National Natural Science Foundation of China(grant numbers:62172058); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074913","Hadoop Distributed File System;Remote Procedure Call;Task Performance;Fault Tolerance","Industries;Fault tolerance;Adaptive systems;Heart beat;File systems;System performance;Fault tolerant systems","","2","","15","IEEE","28 Mar 2023","18-20 Dec. 2022","18-20 Dec. 2022","IEEE","IEEE Conferences"
"Design of a six-layer data architecture based on OT/IT convergence in the context of Industry 4.0","K. Fakir; C. Ennawaoui; M. El Mouden","Laboratory of Engineering Sciences for Energy (LabSIPE)., University Research Center (CUR) in Renewable Energies & Intelligent Systems for Energy, El Jadida, Morocco; Laboratory of Engineering Sciences for Energy (LabSIPE)., University Research Center (CUR) in Renewable Energies & Intelligent Systems for Energy, El Jadida, Morocco; Laboratory of Engineering Sciences for Energy (LabSIPE)., University Research Center (CUR) in Renewable Energies & Intelligent Systems for Energy, El Jadida, Morocco","2023 3rd International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)","21 Jun 2023","2023","","","1","8","To support digital transition of industrial companies, it is imperative to prepare a strong technical infrastructure to implement cyber-physical systems, that should be a corner stone to build smart factory models. Our article has the target of proposing a key element of this imperative, by elaborating a data-driven architecture relying on automation of production lines, given that data should be placed at the center of digital manufacturing. Furthermore, the advent of Industry 4.0 technologies has imposed their integration into any modern architecture model, thanks to their ability to enhance the properties of real-time, mobility and connectivity. Thus, we have ensured that our multi-layer proposed model be hybrid in nature, combining both traditional technologies and those of Industry 4.0 generation, so that could serve digital mutations progressively, Also, the suggestion of this work has been fortified by resilient measures to face some serious challenges, such as: cybersecurity threats, agility in implementation, energy saving and investment optimization.","","979-8-3503-9836-6","10.1109/IRASET57153.2023.10152971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152971","Industry 4.0;Data architecture;Internet of Things;Digital manufacturing;Smart factory;Cybersecurity","Industries;Production;Data models;Real-time systems;Hybrid power systems;Fourth Industrial Revolution;Optimization","","4","","16","IEEE","21 Jun 2023","18-19 May 2023","18-19 May 2023","IEEE","IEEE Conferences"
"Cloud Native Data Platform for Network Telemetry and Analytics","D. Tovarňák; M. Raček; P. Velan","Masaryk University, Brno, Czech Republic; Masaryk University, Brno, Czech Republic; Masaryk University, Brno, Czech Republic",2021 17th International Conference on Network and Service Management (CNSM),"2 Dec 2021","2021","","","394","396","In this manuscript, we present a prototype of a modular data platform that is able to continuously ingest, process, retain, and analyse large amounts of network telemetry data in a scalable and straightforward manner. It follows a recently proposed Data Lakehouse architectural pattern, which is an evolution of two well-known approaches used in this area – data warehouses and data lakes. The platform is based on open standards and open-source components, and it follows cloud native principles in order to be able to run in modern computing environments such as public, private, and hybrid clouds. The primary focus of the prototype is network telemetry and analytics over traffic flows and infrastructure logs for the purposes of cyber-security digital forensics and incident response. During the demonstration part, we will further describe internal workings of the presented data platform and showcase its capabilities and possible applications on a public dataset.","2165-963X","978-3-903176-36-2","10.23919/CNSM52442.2021.9615568","Ministry of the Interior of the Czech Republic(grant numbers:VI20202022164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615568","Data Lakehouse;Network Flows;Log Data","Digital forensics;Prototypes;Data warehouses;Big Data applications;Telemetry;Standards;Open source software","","9","","5","","2 Dec 2021","25-29 Oct. 2021","25-29 Oct. 2021","IEEE","IEEE Conferences"
"Improved Asset, Process and Safety Performance with Machine Learning and Data Analytics","J. A. Kay; D. Mazur; R. Entzminger; S. N. Sandler","Independent Consultant, Kitchener, Canada; Rockwell Automation, Milwaukee, WI, USA; Rockwell Automation, Lenexa, KS, USA; Rockwell Automation, Mayfield Heights, OH, USA",2023 IEEE IAS Pulp and Paper Industry Conference (PPIC),"27 Mar 2025","2023","","","10","18","The pulp and paper industry has struggled through the last decade with rising costs, reducing demand and industry consolidations. However, the industry continues to demonstrate some notable resiliency during these challenging periods. With the limited growth opportunities of the past, within a very mature market space, global pulp and paper manufacturers have been forced to focus even more on improvements in their operational efficiencies and production utilization rates. As the cost of local and cloud-based computational power continues to come down in cost, Industrial Analytics and Machine Learning capabilities are now playing a significant role in helping facilities trim operational costs and run more effectively while utilizing their existing hardware.","2575-7555","979-8-3503-0206-6","10.1109/PPIC50668.2023.10925696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10925696","Data;Analytics;Machine Learning;Data Lake;Big Data;Wide Data;Artificial Intelligence","Pulp and paper industry;Industries;Condition monitoring;Schedules;Costs;Data analysis;Machine learning;Maintenance;Smart devices;Investment","","","","6","IEEE","27 Mar 2025","11-15 June 2023","11-15 June 2023","IEEE","IEEE Conferences"
"Enabling Industrial Data Space Architecture for Seaport Scenario","D. Sarabia-Jácome; I. Lacalle; C. E. Palau; M. Esteve","Department of Communications, Universitat Politècnica de València, Valencia, Spain; Department of Communications, Universitat Politècnica de València, Valencia, Spain; Department of Communications, Universitat Politècnica de València, Valencia, Spain; Department of Communications, Universitat Politècnica de València, Valencia, Spain",2019 IEEE 5th World Forum on Internet of Things (WF-IoT),"22 Jul 2019","2019","","","101","106","The evolution of seaports to smart ports is the most important revolution they must face in order to meet the high requirements of efficiency, economy, and security. Achieving this evolution is a task full of challenges. One of these challenges is the interoperability of the stakeholders' information systems. Interoperability has been widely studied but there is still some reluctance to adopt the solutions because the stakeholders are afraid of sharing their data. Recently, the Industrial Data Space (IDS) reference architecture proposes several recommendations and specifications to solve this issue based on data sovereignty concept. This architecture has not been studied nor implemented for the seaport use case yet. For this reason, this paper presents a seaport data space based on IDS architecture to share information in a secure and interoperable manner. Along with this, a big data architecture is added to exploit the shared data. The seaport data space is implemented using the FIWARE IoT platform. The seaport data space is tested by sharing the data of the port authority to the port terminal and analyzing the large shared data through descriptive analysis. The results show that by using the seaport data space, the shared data allow improving the decision making in the planning operations of the seaport.","","978-1-5386-4980-0","10.1109/WF-IoT.2019.8767216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8767216","Interoperability;IDS;Industry;Big Data;seaport;Internet of Things","Seaports;Big Data;Connectors;Security;Stakeholders;Interoperability","","23","","16","IEEE","22 Jul 2019","15-18 April 2019","15-18 April 2019","IEEE","IEEE Conferences"
"Data Ingestion, Transformation, and Analytics","B. Piper; D. Clinton",NA; NA,AWS Certified Solutions Architect Study Guide with 900 Practice Test Questions: Associate (SAA-C03) Exam,"","2023","","","243","253","This chapter focuses on the following services: Amazon Web Services (AWS) Data Lake; AWS Glue; AWS Transfer Family; Kinesis Video Streams; Kinesis Data Streams; and Kinesis Data Firehose. A data lake is a centralized database that collects and stores massive amounts of structured and unstructured data from any number of places. AWS Transfer Family lets one to transfer data into and out of S3 and Elastic File System using three time‐tested, familiar protocols: File Transfer Protocol; Secure Shell File Transfer Protocol; and File Transfer Protocol over SSL. Amazon Kinesis is a collection of services that let one to collect, process, store, and deliver streaming data. Kinesis can perform real‐time ingestion of gigabytes per second from thousands of sources, making it perfect for things like audio and video feeds, application logs, and telemetry data.","","9781119982647","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10334338.pdf&bkn=10322576&pdfType=chapter","","Streams;Streaming media;Big Data applications;Databases;Lakes;Protocols;Feeds","","","","","","29 Nov 2023","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Towards real-time customer experience prediction for telecommunication operators","E. Diaz-Aviles; F. Pinelli; K. Lynch; Z. Nabi; Y. Gkoufas; E. Bouillet; F. Calabrese; E. Coughlan; P. Holland; J. Salzwedel","IBM Research, Ireland; IBM Research, Ireland; IBM Research, Ireland; IBM Research, Ireland; IBM Research, Ireland; IBM Research, Ireland; IBM Research, Ireland; IBM Now Factory, Ireland; IBM Now Factory, Ireland; Vodacom, South Africa",2015 IEEE International Conference on Big Data (Big Data),"28 Dec 2015","2015","","","1063","1072","Telecommunications operators (telcos) traditional sources of income, voice and SMS, are shrinking due to customers using over-the-top (OTT) applications such as WhatsApp or Viber. In this challenging environment it is critical for telcos to maintain or grow their market share, by providing users with as good an experience as possible on their network. But the task of extracting customer insights from the vast amounts of data collected by telcos is growing in complexity and scale everey day. How can we measure and predict the quality of a user's experience on a telco network in real-time? That is the problem that we address in this paper. We present an approach to capture, in (near) real-time, the mobile customer experience in order to assess which conditions lead the user to place a call to a telco's customer care center. To this end, we follow a supervised learning approach for prediction and train our Restricted Random Forest model using, as a proxy for bad experience, the observed customer transactions in the telco data feed before the user places a call to a customer care center. We evaluate our approach using a rich dataset provided by a major African telecommunication's company and a novel big data architecture for both the training and scoring of predictive models. Our empirical study shows our solution to be effective at predicting user experience by inferring if a customer will place a call based on his current context. These promising results open new possibilities for improved customer service, which will help telcos to reduce churn rates and improve customer experience, both factors that directly impact their revenue growth.","","978-1-4799-9926-2","10.1109/BigData.2015.7363860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363860","Telecom operators;Customer Care;Big Data;Predictive Analytics","Mobile communication;Real-time systems;Feeds;Predictive models;Context;Big data","","19","","23","IEEE","28 Dec 2015","29 Oct.-1 Nov. 2015","29 Oct.-1 Nov. 2015","IEEE","IEEE Conferences"
"DHT-Backed Ancestor-Assisted Merkle Verification for Scalable and Real-Time Log Integrity in Cloud Data Lakes","V. Saengthong; T. Mantharngkul; C. Wongsuwan; K. Ritthaisong; S. Fugkaew","Sirindhorn International Institute of Technology, Thammasat University, Pathum Thani, Thailand; Sirindhorn International Institute of Technology, Thammasat University, Pathum Thani, Thailand; Sirindhorn International Institute of Technology, Thammasat University, Pathum Thani, Thailand; Sirindhorn International Institute of Technology, Thammasat University, Pathum Thani, Thailand; Sirindhorn International Institute of Technology, Thammasat University, Pathum Thani, Thailand",IEEE Open Journal of the Computer Society,"","2026","PP","99","1","12","Cloud data lakes accumulate massive volumes of append-only, high-frequency logs from web servers, gateways, security appliances, and databases. Ensuring their integrity is challenging because existing blockchain-assisted auditing schemes are primarily optimized for static or periodically updated data and provide limited support for continuous ingestion, real-time verification, and auditor access control. These limitations lead to high recomputation overhead, delayed tamper detection, and the lack of reusable proofs required for scalable log publishing.This paper introduces a verifiable log publishing framework based on a newly proposed ancestor-assisted Merkle Tree with stride-based checkpoints for efficient verification of encrypted logs. Each log record is canonically formatted, AEAD-encrypted with metadata binding, and producer-attested prior to storage. Parent-node records and ancestor certificates are distributed via a private Distributed Hash Table (DHT) to enable proof reuse, while only an epoch-level root-of-roots is anchored on a public blockchain to provide tamper-evident integrity guarantees. The framework further supports auditor authorization using certification-authority-issued tokens and incorporates micro-root commitments for near real-time verification. Experimental results demonstrate substantial performance improvements: single-record verification is significantly faster than the strongest baseline, verification throughput is markedly higher, commit latency is greatly reduced, and on-chain storage remains constant across all evaluated epoch sizes. These results confirm that the proposed architecture enables scalable, low-latency, and compliance-aware log integrity verification suitable for modern cloud data lake environments.","2644-1268","","10.1109/OJCS.2026.3663463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11389188","Blockchain;Integrity;Data Lake;Merkle Tree;DHT;AEAD","Blockchains;Big Data applications;Trees (botanical);Cryptography;Real-time systems;Metadata;Cloud computing;Publishing;Databases;Semantics","","","","","CCBYNCND","10 Feb 2026","","","IEEE","IEEE Early Access Articles"
"High-efficient Joinable Tables Discovery in Data Lakes: A Grey Relational Model-based Approach","Z. Yu; R. Xiong; F. Dong; Z. Wu","School of Computer Science and Engineering, Southeast University, Nanjing, P.R.China; School of Computer Science and Engineering, Southeast University, Nanjing, P.R.China; School of Computer Science and Engineering, Southeast University, Nanjing, P.R.China; School of Computer Science, Nanjing Audit University, Nanjing, P.R.China",2023 Eleventh International Conference on Advanced Cloud and Big Data (CBD),"8 May 2024","2023","","","223","228","Finding required datasets in a data lake that stores a vast amount of messy and disordered data is a challenge in data management. This paper addresses the problem of joinable tables discovery, which has many applications in scenarios such as augmenting training data, data cleaning, and extracting machine learning features. However, existing methods usually consider only one factor or assign equal weights to multiple factors in joinable tables discovery, resulting in low optimization precision and ignoring joinable tables discovery purpose. We propose GRMA, a joinable tables discovery method based on a grey relational model considering multiple factors. First, we select different factors according to the purpose of joinable tables discovery and calculate their scores for each table in the data lake. Then, we set weights for different factors using Analytic Hierarchy Process. Finally, we substitute the scores and weights into the grey relational analysis method to determine the final score and perform a top-k query. We also design a unique pruning method, screening pruning, for joinable tables discovery based on multi-factor problems and apply it to GRMA. Our experiments show that GRMA outperforms the best current joinable tables discovery methods by 28%, 13%, and 24% in precision, recall, and F1-score, respectively.","","979-8-3503-5337-2","10.1109/CBD63341.2023.00047","National Natural Science Foundation of China; Key Laboratory of Computer Network and Information Integration; Southeast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10516514","","Education;Training data;Machine learning;Analytic hierarchy process;Big Data applications;Feature extraction;Data models","","","","26","IEEE","8 May 2024","18-19 Dec. 2023","18-19 Dec. 2023","IEEE","IEEE Conferences"
"Strategic Maintenance Optimization for Enhanced Operational Efficiency of Railway Station Infrastructure","K. Grobler-Dębska; R. Mularczyk; W. Bauer; E. Kucharska","Dep. of Automatic Control and Robotics, AGH University of Krakow, Krakow, Poland; Dep. of Automatic Control and Robotics, AGH University of Krakow, Krakow, Poland; Dep. of Automatic Control and Robotics, AGH University of Krakow, Krakow, Poland; Dep. of Automatic Control and Robotics, AGH University of Krakow, Krakow, Poland",2024 28th International Conference on Methods and Models in Automation and Robotics (MMAR),"19 Sep 2024","2024","","","504","509","Effective maintenance is a hard but very important task allowing keeping assets in operation. In particular this is something very relevant for critical infrastructure that are railways and railway stations. European wide analyses show, that there is no harmonization in data standards nor there are good solutions allowing to assist station operators in maintenance management. In this paper we focus on handling available data streams, integrating them with a data lake based centralisation and using it to provide a decision support system. Such system, based on dashboards created with Business Intelligence software, can provide significant help in managing of assets. As an example we provide appropriate routing mechanisms allowing to use the available maintenance personnel with more efficiency.","2835-2807","979-8-3503-6234-3","10.1109/MMAR62187.2024.10680845","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10680845","dispersed assets;railway decision support;data lake;optimization;business intelligence","Routing;Rail transportation;Software;Maintenance;Personnel;Streams;Standards","","","","7","IEEE","19 Sep 2024","27-30 Aug. 2024","27-30 Aug. 2024","IEEE","IEEE Conferences"
"Chapter 8: Data Lakes","A. Khan",NA,Business Intelligence and Data Analysis in the Age of AI,"","2025","","","111","124","","","9781501523014","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11049750.pdf&bkn=11049583&pdfType=chapter","","","","","","","","24 Jun 2025","","","De Gruyter","De Gruyter eBook Chapters"
"A System-Dynamics-Based Model to Study the Implementation of Big Data with ETL Process in the Automobile Manufacturing Industry","M. A. Negrete-Rodriguez; C. M. Martinez-Soto; A. Elizondo-Noriega; D. Güemes-Castorena","School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, N.L., Mexico; School of Social Sciences and Government, Tecnologico de Monterrey, Monterrey, N.L., Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, N.L., Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, N.L., Mexico",2024 Portland International Conference on Management of Engineering and Technology (PICMET),"4 Sep 2024","2024","","","1","9","Industry 4.0 marks a transformative paradigm, heralding a new era for the production and service sectors by integrating Big Data technologies. This progression unlocks latent knowledge within vast datasets, empowering decision-making through advanced analytics. However, the literature lacks a comprehensive understanding of the impact of such integration on organizational structures. Despite Big Data's maturation, its economic influence on industry operations is not fully understood and warrants further investigation. Understanding the implications of technology adoption is crucial to minimize the risks associated with capital investments. This study proposes a System-Dynamics-based model of Big Data architecture utilizing vehicular sensor data warehouses. The model delineates the application of the Extract, Transform, Load (ETL) process via Amazon Web Services (AWS), employing the Glue service for data integration and Quicksight to visualize insights. This approach aims to understand the advantages and disadvantages of Big Data in the automobile manufacturing industry. Also, it provides a strategic foresight into technology investment and enhances the analytical capabilities within the manufacturing domain.","2159-5100","978-1-890843-45-8","10.23919/PICMET64035.2024.10653145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10653145","","Manufacturing industries;Web services;Transforms;Production;Big Data;Data models;Fourth Industrial Revolution","","2","","20","","4 Sep 2024","4-8 Aug. 2024","4-8 Aug. 2024","IEEE","IEEE Conferences"
"CrossEM: A Prompt Tuning Framework for Cross-Modal Entity Matching","Q. Yuan; Y. Yuan; Z. Wen; C. Chen; G. Wang",Beijing Institute of Technology; Beijing Institute of Technology; Zhejiang University of Technology; Beijing Institute of Technology; Beijing Institute of Technology,2025 IEEE 41st International Conference on Data Engineering (ICDE),"20 Aug 2025","2025","","","627","640","Entity matching (EM) aims to identify equivalent entities across different data sources. Current EM assumes that these data are either homogeneous with aligned schema or heterogeneous but can be transformed into a unified modality. There is an urgent need to consider the entities with different modalities to support practical application scenarios over data lakes such as multi-modal data integration and recommendation system. It is impractical to unify their data modalities. To support EM on heterogeneous entity with different data formats and modalities, we propose cross-modal entity matching in this paper. Inspired by the promising performance achieved by recent pre-trained models, we perform cross-modal entity matching by prompt-tuning pre-trained multi-modal large models (MMLMs) in an unsupervised manner. However, the prompt-tuning faces three challenging issues: (i) objective gap between pre-training and tuning of MMLMs; (ii) data modality gap between the inputs of MMLMs and our matching task; (iii) prompt efficiency on large data. Therefore, we firstly propose a novel EM framework (namely, CrossEM) that addresses cross-modal EM as a matching probability problem with specific prompt-tuning. Secondly, two alternative prompt generation methods are designed to extract structural knowledge from heterogeneous data to overcome the data modality gap with pre-trained models. Thirdly, we present an improved matching framework (namely, CrossEM+) to boost the prompt efficiency on large heterogeneous data. Experimental evaluations verify that our methods significantly outperform the state-of-the-art approaches on three benchmarks. Furthermore, our case study highlights the considerable potential of cross-modal EM in improving the performance of downstream tasks, thereby benefitting a wider range of research areas.","2375-026X","979-8-3315-3603-9","10.1109/ICDE65448.2025.00053","National Key R&D Program of China(grant numbers:2022YFB2702100); NSFC(grant numbers:61932004,62225203,U21A20516); NSFC(grant numbers:62472387); Postdoctoral Science Foundation of China(grant numbers:2023M743403); Zhejiang Provincial Natural Science Foundation of Major Program(grant numbers:LDQ24F02000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113143","data lake;cross-modal entity matching;prompt tuning","Training;Soft sensors;Scalability;Data integration;Data models;Data mining;Tuning;Recommender systems;Optimization;Faces","","1","","62","IEEE","20 Aug 2025","19-23 May 2025","19-23 May 2025","IEEE","IEEE Conferences"
"DeFraudify4ALL: Prototyping and Validation of a System for Fraud Detection with Big Data and Cloud Technology","E. -C. Popovici; C. Stalidi; D. -A. Teodoras; G. Suciu; I. Cosma","Telecommunication Department, POLITEHNICA University of Bucharest ETTI Faculty, Bucharest, Romania; R&D Department, Beia Consult International, Bucharest, Romania; R&D Department, Beia Consult International, Bucharest, Romania; R&D Department, Beia Consult International, Bucharest, Romania; R&D Department, Beia Consult International, Bucharest, Romania",2024 IEEE 30th International Symposium for Design and Technology in Electronic Packaging (SIITME),"30 Dec 2024","2024","","","466","470","This paper presents the prototyping and validation of a Financial Data Management and Analysis System designed to enhance fraud detection using advanced Big Data and Cloud technologies. The system incorporates a Java-based worker for data retrieval and analysis from various sources, including external APIs. The processed data is efficiently stored in a Data Lake utilizing Dremio, Apache Arrow, and Apache Parquet technologies. By leveraging cloud platforms such as AWS, the system ensures scalability, security, and flexibility. Additionally, the integration of sophisticated data visualization tools and AI algorithms, particularly Random Forest, enhances the system’s ability to detect fraudulent activities.","2642-7036","979-8-3315-3951-1","10.1109/SIITME63973.2024.10814887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10814887","Fraud Detection;Financial Data Management;Cloud Computing;Prototyping;System Validation","Solid modeling;Java;Scalability;Microservice architectures;Prototypes;Real-time systems;Data models;Fraud;Security;Random forests","","","","6","IEEE","30 Dec 2024","16-18 Oct. 2024","16-18 Oct. 2024","IEEE","IEEE Conferences"
"Distributed Data Storage Architecture Model and Data Platform Design for Power Grid Dispatching","Y. Xu; Y. Su; L. Zhao; B. Zhou; Y. Tang; G. Huang; J. Hu; K. Li","State Key Laboratory of HVDC Technology, CSG Electric Power Research Institute, Guangzhou, China; CSG Power Dispatching and Control Center, Guangzhou, China; State Key Laboratory of HVDC Technology, CSG Electric Power Research Institute, Guangzhou, China; State Key Laboratory of HVDC Technology, CSG Electric Power Research Institute, Guangzhou, China; State Key Laboratory of HVDC Technology, CSG Electric Power Research Institute, Guangzhou, China; State Key Laboratory of HVDC Technology, CSG Electric Power Research Institute, Guangzhou, China; School of Electric Power Engineering, South China University of Technology, Guangzhou, China; School of Electric Power Engineering, South China University of Technology, Guangzhou, China",2024 3rd International Conference on Energy and Electrical Power Systems (ICEEPS),"4 Oct 2024","2024","","","859","863","The construction of a distributed heterogeneous data platform for power grid dispatching faces challenges of diversity, large scale, and high performance. However, existing data platform design methods in both the power and computer science fields struggle to meet practical production requirements effectively. This paper constructs a distributed data storage architecture model for power grid dispatching, defining the elements and their relationships within the architecture. Additionally, it proposes methods for managing massive source data and distributed heterogeneous database clusters. Based on these findings, a power grid dispatching business data platform is designed. Test results indicate that the proposed architecture effectively supports the efficient execution of power grid dispatching business, providing a specialized data platform design paradigm for the power industry.","","979-8-3503-7513-8","10.1109/ICEEPS62542.2024.10693170","China Southern Power Grid Co., Ltd.(grant numbers:ZBKJXM20232436); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10693170","data architecture model;distributed heterogeneous database cluster;power grid dispatching;data platform design;metadata","Distributed databases;Memory;Computer architecture;Production;Power grids;Dispatching;Data models;Power industry;Time factors;Business","","1","","11","IEEE","4 Oct 2024","14-16 July 2024","14-16 July 2024","IEEE","IEEE Conferences"
"A Spam Classification Method Based on Naive Bayes","F. Ye; G. Chen; Q. Liu; L. Zhang; Q. Qi; B. Hu; X. Fan","Zhejiang Police College, Institute for Cyberspace Intelligence and Crime Governance, Hangzhou, China; Zhejiang Police College, Institute for Cyberspace Intelligence and Crime Governance, Hangzhou, China; Zhejiang Police College, Institute for Cyberspace Intelligence and Crime Governance, Hangzhou, China; Joint Logistics College of National Defence University, Beijing, China; Zhejiang Police College, Institute for Cyberspace Intelligence and Crime Governance, Hangzhou, China; Zhejiang Police College, Institute for Cyberspace Intelligence and Crime Governance, Hangzhou, China; Joint Logistics College of National Defence University, Beijing, China",2022 IEEE 6th Information Technology and Mechatronics Engineering Conference (ITOEC),"23 Mar 2022","2022","6","","1856","1861","Currently, spam will do everything possible to bypass or destroy the spam classifier. This paper proposes a naive Bayesian spam classification method, and designs Bernoulli naive Bayes algorithm and polynomial naive Bayes algorithm to classify English spam and Chinese spam respectively. Experiments show that the method proposed in this paper has a high precision rate and recall rate, and can classify spam simply, accurately and efficiently.","2693-289X","978-1-6654-3185-9","10.1109/ITOEC53115.2022.9734386","Basic Public Welfare Research Program of Zhejiang Natural Science Foundation of China(grant numbers:LGF19F020006); National Social Science Foundation of China(grant numbers:21BSH051); NSFC program(grant numbers:62002362); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9734386","Naive Bayes;Spams;Accuracy Rate;Recall Rate","Training;Representation learning;Mechatronics;Unsolicited e-mail;Design methodology;Neural networks;Support vector machine classification","","3","","15","IEEE","23 Mar 2022","4-6 March 2022","4-6 March 2022","IEEE","IEEE Conferences"
"LakeHarbor: Making Structures First-Class Citizens in Data Lakes","H. Yamada; M. Kitsuregawa; K. Goda","The University of Tokyo, Tokyo, Japan; The University of Tokyo, Tokyo, Japan; The University of Tokyo, Tokyo, Japan",2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","5583","5592","This paper introduces LakeHarbor, a new data management paradigm that makes structures (e.g., indexes) first-class citizens in data lakes. The LakeHarbor paradigm enables a data lake system to flexibly construct structures based on registered access method functions and execute data processing jobs efficiently with the potential parallelism that the structures inherently hold by exploiting the functions while not sacrificing flexible data processing such as schema-on-read. This paper also presents ReDe, a prototype data processing engine that implements LakeHarbor, and a motivating evaluation and a case study of ReDe to explore the potential of LakeHarbor.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10597783","Data Lakes;Parallel Query Processing;Parallel Databases;Distributed Query Processing;Data Warehouse","Prototypes;Parallel processing;Data warehouses;Data processing;Big Data applications;Data engineering;Indexes","","1","","46","IEEE","23 Jul 2024","13-16 May 2024","13-16 May 2024","IEEE","IEEE Conferences"
"Big Data Tasks","D. Ryzko",NA,Modern Big Data Architectures: A Multi-Agent Systems Perspective,"","2020","","","51","66","Summary <p>Using searching, through social media analysis, to smart grid control, today's real life systems require new approaches to handle big data. This chapter presents some of the most challenging big data tasks in various branches of industry and science. Recommender systems are one of the key e‐commerce tools for increasing revenue by providing a personalized offer to its users. For the world's largest marketplaces and other e‐commerce sites the dimensions of the recommendations problem can be very big, with millions or even tens of millions of users and items. The ad‐tech industry ecosystem is a highly distributed, cross‐company big data architecture by itself and can be a great case study for building high load systems. Forecasting is a common data science task, which boils down to prediction of the future, based on historical data and any other available information.</p>","","9781119597940","10.1002/9781119597926.ch4","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10954543.pdf&bkn=10950342&pdfType=chapter","","Indexes;Big Data;Search engines;Recommender systems;Feature extraction;Electronic commerce;Buildings;Query processing;Motion pictures;Internet","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Semantic-Aware Representation of Multi-Modal Data for Data Ingress: A Literature Review","P. Lamart; Y. Yu; C. Berger","Computer Science and Engineering, University of Gothenburg, Gothenburg, Sweden; Computer Science and Engineering, Chalmers University of Technology, Gothenburg, Sweden; Computer Science and Engineering, University of Gothenburg, Gothenburg, Sweden",2024 50th Euromicro Conference on Software Engineering and Advanced Applications (SEAA),"27 Dec 2024","2024","","","122","125","Machine Learning (ML) is continuously permeating a growing amount of application domains. Generative AI such as Large Language Models (LLMs) also sees broad adoption to process multi-modal data such as text, images, audio, and video. While the trend is to use ever-larger datasets for training, managing this data efficiently has become a significant practical challenge in the industry-double as much data is certainly not double as good. Rather the opposite is important since getting an understanding of the inherent quality and diversity of the underlying data lakes is a growing challenge for application-specific ML as well as for fine-tuning foundation models. Furthermore, information retrieval (IR) from expanding data lakes is complicated by the temporal dimension inherent in time-series data which must be considered to determine its semantic value. This study focuses on the different semantic-aware techniques to extract embeddings from mono-modal, multi-modal, and cross-modal data to enhance IR capabilities in a growing data lake. Articles were collected to summarize information about the state-of-the-art techniques focusing on applications of embedding for three different categories of data modalities.","2376-9521","979-8-3503-8026-2","10.1109/SEAA64295.2024.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10803407","data lake;data modality;multi-modal data;information retrieval;embedding;literature review","Training;Reviews;Generative AI;Large language models;Semantics;Machine learning;Big Data applications;Market research;Information retrieval;Software engineering","","1","","33","IEEE","27 Dec 2024","28-30 Aug. 2024","28-30 Aug. 2024","IEEE","IEEE Conferences"
"Rottnest: Indexing Data Lakes for Search","Z. Wang; S. Krassovsky; C. Kennedy; A. Aiken; W. Pace; R. Jiang; H. Zhang; C. Jiang; W. Xu","Stanford University; Anthropic PBC; Stanford University; Stanford University; LanceDB, Inc.; Bytedance Inc.; Bytedance Inc.; Bytedance Inc.; Bytedance Inc.",2025 IEEE 41st International Conference on Data Engineering (ICDE),"20 Aug 2025","2025","","","1814","1827","Data lakes have become widely popular in managing enterprise data. Their widespread integration with query engines has allowed them to displace specialized data warehouses as the single source of truth for enterprise data. While the columnar storage format and block min-max indices allow query engines to achieve competitive performance on relational data analytics queries, they are not yet suitable for other search-oriented queries like full text and vector nearest neighbor search. We present Rottnest, a general system that builds additional lightweight indices on top of data lakes. We show that our system is more cost efficient compared to un-indexed data lakes or specialized databases across several orders of magnitude of total query loads and operating time horizons.","2375-026X","979-8-3315-3603-9","10.1109/ICDE65448.2025.00139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113229","data lake;search;indexing","Data analysis;Costs;Databases;Nearest neighbor methods;Data warehouses;Big Data applications;Data engineering;Vectors;Engines;Indexing","","1","","60","IEEE","20 Aug 2025","19-23 May 2025","19-23 May 2025","IEEE","IEEE Conferences"
"Leveraging Scalable Cloud Infrastructure for Autonomous Driving Data Lakes and Real-Time Decision Making","J. Chen","Graduate School of Arts and Sciences, Columbia University, New York, United States",2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA),"1 Jul 2025","2025","","","1750","1753","Autonomous driving technology relies heavily on the effective management of vast datasets generated by various sensors and vehicle systems. As such, leveraging scalable cloud infrastructure becomes paramount for improving data handling and decision-making capabilities. In this paper, we introduce the Autonomous Driving Data Lakes (ADDL) framework, designed to streamline the storage, retrieval, and processing of extensive driving data in real-time. By utilizing cloud technology, ADDL ensures tight integration of data from diverse sources to enhance situational awareness for autonomous systems. Our architecture features robust data pipelines that support real-time analytics and machine learning applications, which are crucial for timely and accurate decision-making. Extensive experiments with large-scale datasets demonstrate how our approach significantly boosts processing efficiency, data accessibility, and decision-making reliability. The findings highlight advancements in autonomous driving technologies, addressing the challenges associated with data management and enhancing operational effectiveness in changing driving environments.","","979-8-3315-0976-7","10.1109/AIITA65135.2025.11048068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048068","Cloud Infrastructure;Autonomous Driving;Decision Making","Decision making;Pipelines;Machine learning;Big Data applications;Real-time systems;Sensor systems;Telemetry;Reliability;Autonomous vehicles;Intelligent sensors","","","","18","IEEE","1 Jul 2025","28-30 March 2025","28-30 March 2025","IEEE","IEEE Conferences"
"AI-Driven Zero-Trust Cloud Security: Automated Threat Response Leveraging Multi-Cloud Data Lakes and LLMS","S. Srivastava; R. Kohli","Independent Researcher, Grand Prairie, TX, USA; Independent Researcher, Carmel, IN, USA",2025 20th International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP),"12 Jan 2026","2025","","","1","6","Zero-Trust architectures have become the foundation of modern enterprise security, requiring continuous authentication, least-privilege enforcement, and pervasive monitoring. However, as organizations increasingly adopt multi-cloud infrastructures, traditional Zero-Trust implementations struggle with scale, data silos, and evolving adversarial tactics. This paper explores how artificial intelligence (AI) and large language models (LLMs) can enhance Zero-Trust principles by automating threat detection and response across multi-cloud data lakes. We propose an integrated architecture where multi-modal telemetry feeds AI-driven analytics pipelines, producing explainable, automated security actions that reduce analyst fatigue while strengthening compliance. By leveraging LLMs for context enrichment and response orchestration, enterprises can operationalize Zero Trust at scale, aligning automation with trustworthiness. Case studies, experimental results, and analyst-centric explainability approaches demonstrate that AI-enhanced Zero-Trust is not only feasible but necessary for defending against increasingly sophisticated threats.","2831-4565","979-8-3315-0217-1","10.1109/iSAI-NLP66160.2025.11320545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11320545","Zero-Trust;Multi-Cloud;Data Lakes;Threat Response;LLMs;Explainable AI;Automation;Cloud Security;SOC","Automation;Cloud computing security;Computer architecture;Organizations;Big Data applications;Threat assessment;Zero Trust;Telecommunications;Telemetry;Sustainable development","","","","16","IEEE","12 Jan 2026","12-14 Nov. 2025","12-14 Nov. 2025","IEEE","IEEE Conferences"
"Ontology Building for Cyber–Physical Systems: Application in the Manufacturing Domain","C. Hildebrandt; A. Köcher; C. Küstner; C. -M. López-Enríquez; A. W. Müller; B. Caesar; C. S. Gundlach; A. Fay","Department of Mechanical Engineering, Institute of Automation Technology, Helmut Schmidt University, Hamburg, Germany; Department of Mechanical Engineering, Institute of Automation Technology, Helmut Schmidt University, Hamburg, Germany; Data Architecture Team, Digital Innovation Hub, Schaeffler Technologies, Herzogenaurach, Germany; Data Architecture Team, Digital Innovation Hub, Schaeffler Technologies, Herzogenaurach, Germany; Data Architecture Team, Digital Innovation Hub, Schaeffler Technologies, Herzogenaurach, Germany; Department of Mechanical Engineering, Institute of Automation Technology, Helmut Schmidt University, Hamburg, Germany; Department of Mechanical Engineering, Institute of Automation Technology, Helmut Schmidt University, Hamburg, Germany; Department of Mechanical Engineering, Institute of Automation Technology, Helmut Schmidt University, Hamburg, Germany",IEEE Transactions on Automation Science and Engineering,"1 Jul 2020","2020","17","3","1266","1282","Cyber-physical systems (CPSs) in the manufacturing domain can be deployed to support monitoring and analysis of production systems of a factory in order to improve, support, or automate processes, such as maintenance or scheduling. When a network of CPS is subject to frequent changes, the semantic interoperability between the CPSs is of special interest in order to avoid manual, tedious, and error-prone information model alignments at runtime. Ontologies are a suitable technology to enable semantic interoperability, as they allow the building of information models that lank machine-readable meaning to information, thus enabling CPSs to mutually understand the shared information. The contribution of this article is twofold. First, we present an ontology building method that is tailored toward the needs of CPSs in the manufacturing domain. For this purpose, we introduce the requirements regarding this method and discuss related research concerning ontology building. The method itself is designed to begin with ontological requirements and to yield a formal ontology. As the reuse of ontologies and other information resources (IRs) is crucial to the success of ontology building projects, we put special emphasis on how to reuse IRs in the CPS domain. Second, we present a reusable set of ontology design patterns that have been developed with the aforementioned method in an industrial use case and illustrate their application in the considered industrial environment. The contribution of this article extends the method introduced, as a postconference paper, by a detailed industrial application. Note to Practitioners-With growing digitalization in industry, the exchange and use of manufacturing-related data are becoming increasingly important to improve, support, or automate processes. Thus, it is necessary to combine information from different data sources that have been designed by different vendors and may, therefore, be heterogeneous in structure and semantics. A system that plans a maintenance worker's daily schedule, for instance, requires information about the status of machines, production plans, and inventory, which resides in other systems, such as programmable logic controllers (PLCs) or databases. When creating such information systems, accessing, searching, and understanding the different data sources is a time-intensive and error-prone procedure due to the heterogeneities of the data sources. Even worse, this procedure has to be repeated for every newly built system and for every newly introduced data source. To allow for eased access, searching, and understanding of these heterogeneous data sources, ontology can be used to integrate all heterogeneous data sources in one schema. This article contributes a method for building such ontologies in the manufacturing domain. Furthermore, a set of ontology design patterns is presented, which can be reused when building ontologies for a domain.","1558-3783","","10.1109/TASE.2020.2991777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097408","Cyber–physical systems (CPSs);manufacturing domain knowledge;ontology building;ontology;ontology-based data access (OBDA);semantic heterogeneity","Ontologies;Buildings;Semantics;Manufacturing;Unified modeling language;Interoperability;Task analysis","","88","","57","IEEE","20 May 2020","July 2020","","IEEE","IEEE Journals"
"Exploiting IoT Data and Smart City Services for Chronic Obstructive Pulmonary Diseases Risk Factors Monitoring","D. Sarabia-Jacome; A. Belsa; C. E. Palau; M. Esteve","Communications Department, Universitat Politècnica de València (UPV), Valencia, España; Communications Department, Universitat Politècnica de València (UPV), Valencia, España; Communications Department, Universitat Politècnica de València (UPV), Valencia, España; Communications Department, Universitat Politècnica de València (UPV), Valencia, España",2018 IEEE International Conference on Cloud Engineering (IC2E),"17 May 2018","2018","","","351","356","Chronic Obstructive Pulmonary Disease (COPD) is a wide concept to describe a group of diseases which affect a normal respiratory function and cause a considerable impact on patients' life quality and healthcare costs. There are few IoT systems in the present literature that are focused on monitoring and management of COPD patients, but they are not focused on the vast amount of data that IoT generates in a large scale deployment, and the integration of Smart City services. For these reasons, this paper presents an innovative system based on Cloud Computing and Big Data technologies to integrate Smart City services into a large scale scenario. To do so, this system proposes a Big Data architecture based on Apache Spark libraries to provide data integration, storage, descriptive and predictive analysis. Also, the system provides a web interface application where users can visualize the data analysis results. They show that the data enrichment function performed on the Big Data architecture provides more information about the environment to improve decisionmaking. This way, the system helps COPD patients to get more involved into decision making process and promote an active and healthy life by recommending the least polluted area to performance their daily activities.","","978-1-5386-5008-0","10.1109/IC2E.2018.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360353","component;Internet of Things;Big Data;Chronic Obstructive Pulmonary Disease;Smart City","Monitoring;Smart cities;Big Data;Cloud computing;Computer architecture;Sensors;Diseases","","11","","21","IEEE","17 May 2018","17-20 April 2018","17-20 April 2018","IEEE","IEEE Conferences"
"Scalable Data Lakes for AI Workloads: A Multitenant Architecture for Big Data Orchestration","K. K. Goyal","Independent Researcher, California, USA",2025 IEEE International Conference on Computing (ICOCO),"13 Jan 2026","2025","","","266","271","As artificial intelligence (AI) keeps expanding into workloads in real time, high volume, and various domains, traditional data architectures fall short of keeping pace with the overflow of data—structured and unstructured—that exceeds the thresholds of processing power they were designed to handle. This paper takes a step toward introducing a scalable, multitenant data layer specifically made to manage what is termed ""AI overflow""—the big bursts of data that arrive from all directions when using AI, especially when using it within enterprises. This paper presents an orchestration-focused architecture that supports governance of the all-important metadata, provides the necessary ""modular"" components to build a pipeline that operates within real time, and serves up AI-specific ""lineage tracking"" to enable end-to-end data observability, while guaranteeing seamless reusability across multiple tenancies within the same framework without compromising performance.","","979-8-3315-7539-7","10.1109/ICOCO67189.2025.11334100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11334100","AI data overflow;multitenancy;data orchestration;scalable data layers;real-time pipelines","Scalability;Pipelines;Computer architecture;Metadata;Solids;Big Data applications;Real-time systems;Artificial intelligence;Observability;Engines","","","","10","IEEE","13 Jan 2026","6-8 Oct. 2025","6-8 Oct. 2025","IEEE","IEEE Conferences"
"Research on Data Quality Detection Technology Based on Ubiquitous State Grid Internet of Things Platform","B. Peng; F. Shang; Y. Wang; G. Chen; Z. Zhou; L. He","State Grid Jibei Information & Telecommunication Compay, Beijing, China; State Grid Jibei Information & Telecommunication Compay, Beijing, China; State Grid Jibei Information & Telecommunication Compay, Beijing, China; NARI Group Corporation(State Grid Electric Power Research Institute), Nanjing, China; State Grid Jibei Information & Telecommunication Compay, Beijing, China; State Grid Jibei Information & Telecommunication Compay, Beijing, China",2019 IEEE 3rd International Electrical and Energy Conference (CIEEC),"27 Apr 2020","2019","","","1018","1023","At present, the ubiquitous power Internet of Things platform has various problems, such as diversified technical components, difficult application, difficult data search, high data application threshold, and imperfect data management control mechanism. To support the ubiquitous power IoT data sharing and the value of grid data, this paper designs the overall framework and functional architecture of the data in the ubiquitous power IoT platform. And proposes the real-time data quality anomaly detection and improved algorithm based on isolated forest. Finally, the feasibility of the ubiquitous power IoT platform data quality detection algorithm is verified by two scenarios simulations of repair failure and power failure.","","978-1-7281-1675-4","10.1109/CIEEC47146.2019.CIEEC-2019384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9077175","State Grid Internet of Things;quality inspection;isolated forest;acquisition measurement","Power measurement;Power supplies;Data integrity;Forestry;Maintenance engineering;Inspection;Search problems;Real-time systems;Internet of Things;Monitoring","","","","16","IEEE","27 Apr 2020","7-9 Sept. 2019","7-9 Sept. 2019","IEEE","IEEE Conferences"
"Comparing Implementation Variants Of Distributed Spatial Join on Spark","G. Heiler; A. Hanbury","Complexity Science Hub, Vienna, Austria; Institute of Information Systems Engineering, Vienna, TU Wien, Austria",2019 IEEE International Conference on Big Data (Big Data),"24 Feb 2020","2019","","","6071","6073","As an increasing number of sensor devices (Internet of Things) is used, more and more spatio-temporal data becomes available. Being able to process and analyze large quantities of such datasets is therefore critical. Spatial joins in classical geo-information systems do not scale well. Nevertheless, distributed implementations are promising to solve this. Various implementation variants for distributed spatial joins are documented in literature, with some being only suitable for specific use cases. We compared broadcast and multiple variants of a distributed spatially partitioned join. We anticipate that this comparison will give guidance to when to use which implementation strategy.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9006524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006524","Spatial databases and GIS;Data Architecture;Distributed databases","Distributed databases;Sparks;Spatial databases;Trajectory;Internet of Things;Spatial indexes","","3","","11","IEEE","24 Feb 2020","9-12 Dec. 2019","9-12 Dec. 2019","IEEE","IEEE Conferences"
"Uncovering the evolution history of data lakes","M. Klettke; H. Awolin; U. Störl; D. Müller; S. Scherzinger","University of Rostock, Rostock, Germany; University of Rostock, Rostock, Germany; University of Applied Sciences, Darmstadt, Germany; University of Applied Sciences, Darmstadt, Germany; OTH Regensburg, Regensburg, Germany",2017 IEEE International Conference on Big Data (Big Data),"15 Jan 2018","2017","","","2462","2471","Data accumulating in data lakes can become inaccessible in the long run when its semantics are not available. The heterogeneity of data formats and the sheer volumes of data collections prohibit cleaning and unifying the data manually. Thus, tools for automated data lake analysis are of great interest. In this paper, we target the particular problem of reconstructing the schema evolution history from data lakes. Knowing how the data is structured, and how this structure has evolved over time, enables programmatic access to the lake. By deriving a sequence of schema versions, rather than a single schema, we take into account structural changes over time. Moreover, we address the challenge of detecting inclusion dependencies. This is a prerequisite for mapping between succeeding schema versions, and in particular, detecting nontrivial changes such as a property having been moved or copied. We evaluate our approach for detecting inclusion dependencies using the MovieLens dataset, as well an adaption of a dataset containing botanical descriptions, to cover specific edge cases.","","978-1-5386-2715-0","10.1109/BigData.2017.8258204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258204","NoSQL databases;schema version extraction;evolution operations;integrity constraints;inclusion dependencies","Protocols;Lakes;Grippers;NoSQL databases;History;Data mining;Tools","","19","","25","IEEE","15 Jan 2018","11-14 Dec. 2017","11-14 Dec. 2017","IEEE","IEEE Conferences"
"Implementing Shared Data Services (SDS): A Proposed Approach","S. Kumar; S. Anand; S. Kumar; S. Anand","Infosys Technologies Ltd., India; Infosys Technologies Ltd., India; NA; NA",2006 IEEE International Conference on Services Computing (SCC'06),"11 Dec 2006","2006","","","365","372","Database related spending is always a significant cost sink for most CIOs. One component of this spending may be related to maintenance, upgrades, physical hardware costs and other routine items that may not be avoidable. However, a large chunk of the spending may be due to inefficiencies in the data storage mechanism, redundancies in the storage of critical data elements, replication of data access logic and proliferation in the specific data storage technology used. Some of these issues may be addressed by a comprehensive data architecture strategy that attempts to tackle these inconsistencies and redundancies. In this paper, we present architecture for shared data services that may be implemented at an enterprise level to tackle issues associated with data scatter, redundancy and replication. We discuss in detail the various components of such architecture and their applicability towards specific problem areas.","","0-7695-2670-5","10.1109/SCC.2006.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4026953","","Costs;Memory;Web services;Service oriented architecture;Databases;Hardware;Logic;Scattering;Portfolios;Corporate acquisitions","","1","","10","IEEE","11 Dec 2006","18-22 Sept. 2006","18-22 Sept. 2006","IEEE","IEEE Conferences"
"Machine Learning Techniques for Enhancing Maritime Surveillance Based on GMTI Radar and AIS","K. Dästner; B. von Haßler zu Roseneckh-Köhler; F. Opitz; M. Rottmaier; E. Schmid","AIRBUS, Wörthstraße 85, Ulm, Germany; AIRBUS, Wörthstraße 85, Ulm, 89077, Germany; AIRBUS, Wörthstraße 85, Ulm, Germany; AIRBUS, Wörthstraße 85, Ulm, Germany; AIRBUS, Wörthstraße 85, Ulm, Germany",2018 19th International Radar Symposium (IRS),"30 Aug 2018","2018","","","1","10","Classical maritime surveillance systems are enhanced with disruptive elements comingf om big data and machine learning. Available receiver networks deliver a huge amount of worldwide maritime traffc data. The information includes the position as well as signifcant attributes of all vessels, which are equipped with AIS. The processing of this data lake with modern machine learning and big data techniques offer improved decision support for the user. This is especially the case, when AIS is not available and only sensor information, e.g., GMTI is gathered. New design concepts – e.g. the lambda architecture offer the modular integration of these new assets within existing surveillance systems.","2155-5753","978-3-7369-9545-1","10.23919/IRS.2018.8447961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447961","","Marine vehicles;Surveillance;Machine learning;Clustering algorithms;Big Data;Radar","","12","","20","","30 Aug 2018","20-22 June 2018","20-22 June 2018","IEEE","IEEE Conferences"
"Master Data and Reference Data in Data Lake Ecosystems","C. Madera",NA,Data Lakes,"","2020","","","123","143","The data lake relies more on the data‐governance domain than the analytics domain in the information system. This chapter presents the concepts of master data management (MDM) and reference data management, and then, discusses their roles in the data lake concept and the values they bring. The MDM concept comes from organizations that are experiencing issues and difficulties around consistent reporting, regulatory compliance and all cross‐projects based on data. This has prompted a great deal of interest in MDM. Master data can be described by the way it interacts with other data. In transaction systems, master data is almost always involved with transactional data. As cardinality (the number of elements in a set) decreases, the likelihood of an element being treated as a master data element (even a commonly accepted subject area, such as the customer) decreases.","","9781119720423","10.1002/9781119720430.ch6","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9823213.pdf&bkn=9820901&pdfType=chapter","","Big Data applications;Companies;Codes;Metadata;Industries;Ecosystems;XML","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"New Data Network Architecture: From Reactive Post-collecting to Intelligent Proactive Pre-sensing","P. Li; Y. Xing","6G Research Center China, Telecom Research Institute, Beijing, China; 6G Research Center China, Telecom Research Institute, Beijing, China",2023 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB),"16 Aug 2023","2023","","","1","6","With the emergence of scenarios that consume large amounts of data such as AI/ML (artificial intelligence and machine learning) and ISAC (Integrated sensing and communication) technologies, how to efficiently utilize data while protecting data privacy and security, reducing communication overhead, and improving data utilization efficiency have become one of the major research interests for 6G network technologies. Current mobile communication networks only use external data service nodes, and the sensing of data is based on consumer subscription, which cannot meet the data service requirements of 6G networks. We propose a data service network architecture for mobile communication networks that supports intelligent collaboration of distributed data service nodes; transforms reactive subscription mode into proactive sensing mode with the assistance of AI/ML analysis; enhances data sensing, processing and storage mechanisms through the flexible use of data rules and knowledge, thus effectively improving the overall data service capability; further, with this architecture, possible solutions are discussed in detail with emphasis on data sensing difficulties.","2155-5052","979-8-3503-2152-4","10.1109/BMSB58369.2023.10211235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10211235","6G;data architecture;AI;core network","6G mobile communication;Data privacy;Distributed databases;Collaboration;Memory;Transforms;Network architecture","","1","","7","IEEE","16 Aug 2023","14-16 June 2023","14-16 June 2023","IEEE","IEEE Conferences"
"A Big Data Approach for Health Data Information Retrieval","M. Ciampi; E. Masciari; G. de Pietro; S. Silvestri","ICAR-CNR, Naples, NA, Italy; University Federico II, Naples, NA, Italy; ICAR-CNR, Naples, NA, Italy; ICAR-CNR, Naples, NA, Italy",2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),"6 Feb 2020","2019","","","2533","2540","In this paper we address the problem of analyzing biomedical data collection with the purpose of searching for semantic similarity among textual documents. In details, we leverage Word Embeddings models obtained by word2vec algorithm and a specific Big Data architecture for their management, defining an approach able to permit the retrieving of semantic similar texts among a huge biomedical text corpus. The proposed architecture has been developed with the purpose of improving a previous implementation, lowering the computational time and allowing in this way the use of the whole PubMed library as dataset, proving also the usability of this methodology in a real context.","","978-1-7281-1867-3","10.1109/BIBM47256.2019.8983302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8983302","","Semantic search;Biological system modeling;Natural languages;Computer architecture;Big Data;Information retrieval;Libraries;Data models;Bioinformatics;Usability","","","","29","IEEE","6 Feb 2020","18-21 Nov. 2019","18-21 Nov. 2019","IEEE","IEEE Conferences"
"Addressing the Small Files Issue in Hadoop","S. Yadav; S. Gali; S. Bangarusamy; M. Mahmoud","Department of Computer Science and Engineering, Oakland University, Rochester, MI, USA; Department of Computer Science and Engineering, Oakland University, Rochester, MI, USA; Department of Computer Science and Engineering, Oakland University, Rochester, MI, USA; Department of Computer Science and Engineering, Oakland University, Rochester, MI, USA",2021 International Conference on Computational Science and Computational Intelligence (CSCI),"22 Jun 2022","2021","","","392","396","With the advancement of cloud technologies, Distributed File Systems (DFSs) are getting more attention. Recently, Hadoop Distributed File System (HDFS) has become the most popular Distributed File System based on a map-reduce framework to store very large-scale data. However, it has various shortcomings in handling small-sized file metadata, I/O performance, security issues, etc. In this paper, we address the small size file storage failure of HDFS, discuss and evaluate the various possible solutions for the same. Analysis of these solutions led to the conclusion of using more robust cloud options in the industry for storing very large-scale data in terms of scalability and cost. The major goal of this paper is to explore the strategies for overcoming the issues of handling small-sized files in HDFS, potentially known for handling large datasets faster, and discuss the reliability of its alternatives (AWS S3, DynamoDB, Azure Data Lake, Azure Blob Storage) by comparing their performance and security measures.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799044","Deep Learning;Distributed File System (DFS);Hadoop Distributed File System (HDFS);DynamoDB;Azure Data Lake;Azure Blob Storage","Industries;Costs;File systems;Scientific computing;Scalability;Distributed databases;Metadata","","","","17","IEEE","22 Jun 2022","15-17 Dec. 2021","15-17 Dec. 2021","IEEE","IEEE Conferences"
"Towards a Hybrid Imputation Approach Using Web Tables","A. Ahmadov; M. Thiele; J. Eberius; W. Lehner; R. Wrembel","Faculty of Computer Science, Dresden University of Technology, Dresden, Germany; Faculty of Computer Science, Dresden University of Technology, Dresden, Germany; Faculty of Computer Science, Dresden University of Technology, Dresden, Germany; Faculty of Computer Science, Dresden University of Technology, Dresden, Germany; Poznan University of Technology, Institute of Computing Science, Poznan, Poland",2015 IEEE/ACM 2nd International Symposium on Big Data Computing (BDC),"15 Feb 2016","2015","","","21","30","Data completeness is one of the most important data quality dimensions and an essential premise in data analytics. With new emerging Big Data trends such as the data lake concept, which provides a low cost data preparation repository instead of moving curated data into a data warehouse, the problem of data completeness is additionally reinforced. While traditionally the process of filling in missing values is addressed by the data imputation community using statistical techniques, we complement these approaches by using external data sources from the data lake or even the Web to lookup missing values. In this paper we propose a novel hybrid data imputation strategy that, takes into account the characteristics of an incomplete dataset and based on that chooses the best imputation approach, i.e. either a statistical approach such as regression analysis or a Web-based lookup or a combination of both. We formalize and implement both imputation approaches, including a Web table retrieval and matching system and evaluate them extensively using a corpus with 125M Web tables. We show that applying statistical techniques in conjunction with external data sources will lead to a imputation system which is robust, accurate, and has high coverage at the same time.","","978-0-7695-5696-3","10.1109/BDC.2015.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7406326","Web mining;Data preprocessing;Machine learning","Indexes;Lakes;Companies;Big data;Data mining;Industries;Data analysis","","18","","18","IEEE","15 Feb 2016","7-10 Dec. 2015","7-10 Dec. 2015","IEEE","IEEE Conferences"
"An efficient and scalable recommender system for the smart web","A. Baldominos; Y. Saez; E. Albacete; I. Marrero",Computer Science Dept. Universidad Carlos III de Madrid; Computer Science Dept. Universidad Carlos III de Madrid; Computer Science Dept. Universidad Carlos III de Madrid; Zed Worldwide,2015 11th International Conference on Innovations in Information Technology (IIT),"14 Jan 2016","2015","","","296","301","This work describes the development of a web recommender system implementing both collaborative filtering and content-based filtering. Moreover, it supports two different working modes, either sponsored or related, depending on whether websites are to be recommended based on a list of ongoing ad campaigns or in the user preferences. Novel recommendation algorithms are proposed and implemented, which fully rely on set operations such as union and intersection in order to compute the set of recommendations to be provided to end users. The recommender system is deployed over a real-time big data architecture designed to work with Apache Hadoop ecosystem, thus supporting horizontal scalability, and is able to provide recommendations as a service by means of a RESTful API. The performance of the recommender is measured, resulting in the system being able to provide dozens of recommendations in few milliseconds in a single-node cluster setup.","","978-1-4673-8511-4","10.1109/INNOVATIONS.2015.7381557","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381557","","Recommender systems;Uniform resource locators;Collaboration;Computer architecture;Big data;Algorithm design and analysis;Real-time systems","","3","","21","IEEE","14 Jan 2016","1-3 Nov. 2015","1-3 Nov. 2015","IEEE","IEEE Conferences"
"Towards an Architecture to Support Data Access in Research Data Spaces","J. Möller; D. Jankowski; A. Hahn","Department of Computer Science, Carl von Ossietzky University Oldenburg, Oldenburg, Germany; R&D Division Transportation OFFIS, Institute for Computer Science, Oldenburg, Germany; Department of Computer Science, Carl von Ossietzky University Oldenburg, Oldenburg, Germany",2021 IEEE 22nd International Conference on Information Reuse and Integration for Data Science (IRI),"17 Nov 2021","2021","","","310","317","Using data from different data sources is a common procedure in data-driven research. As required data is often not available from centrally managed sources, the concept of data spaces has more and more frequently been utilized to integrate decentral data sources and supporting the access to these. However, decentrally organized data management leads to differences in data models, formats and technologies and the problem of matching data from different sources most often still requires significant manual work, either from the provider or the consumer of the data. Especially in research data spaces, properties of data sources are often dynamically modified or extended, and complex queries are formulated to access the data. In this paper, we present an architecture to approach this problem by automatically exploring the different data sources and searching for similar attributes. Matching attributes are then assembled to so-called vocabularies, that represent common concepts in the data space independently from their actual representations. This dynamic knowledge base is then used to efficiently query and access data in the data space. Finally, an application of the concept is presented to demonstrate the applicability of our architectural framework.","","978-1-6654-3875-9","10.1109/IRI51335.2021.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599115","data space access;data architecture;research data management;data vocabulary","Vocabulary;Runtime;Knowledge based systems;Systems architecture;Manuals;Machine learning;Search problems","","2","","42","IEEE","17 Nov 2021","10-12 Aug. 2021","10-12 Aug. 2021","IEEE","IEEE Conferences"
"A Smart Shop Floor Information System Architecture Based on the Unified Namespace","F. Salcher; S. Finck; M. Hellwig","JR-Centre for Robust Decision Making, Vorarlberg University of Applied Sciences, Dornbirn, Austria; JR-Centre for Robust Decision Making, Vorarlberg University of Applied Sciences, Dornbirn, Austria; JR-Centre for Robust Decision Making, Vorarlberg University of Applied Sciences, Dornbirn, Austria","2024 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)","18 Dec 2024","2024","","","1","9","Modern research in the field of Smart Manufacturing often focuses on the big data aspect, where the goal is to obtain actionable insights from the data. In this paper, the focus is shifted back to the Smart Shop Floor and how to efficiently derive information with the big data tasks that follow as simple as possible. A condensed literature review of the existing architectures and frameworks for Smart Manufacturing is combined with the experience of practitioners to assess the requirements for a Smart Shop Floor Information System Architecture. On this basis, an architecture is proposed that consists of eight modular building blocks. After a detailed description of the roles and functionalities of these building blocks, a reference implementation using readily available, open-source tools and technologies is laid out. This reference implementation intends to strike the right balance between generality and specificity. It provides the reader with a tangible starting point for implementing and adapting the proposed architecture to their own needs.","2693-8855","979-8-3503-6243-5","10.1109/ICE/ITMC61926.2024.10794387","Christian Doppler Research Association; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794387","Smart Manufacturing;Information System Architecture;Data Architecture;Industry 4.0;IIoT","Technological innovation;Event detection;Architecture;Bibliographies;Big Data;Fourth Industrial Revolution;Complexity theory;Smart manufacturing;Information systems","","2","","47","IEEE","18 Dec 2024","24-28 June 2024","24-28 June 2024","IEEE","IEEE Conferences"
"Key Technical Points Analysis of the Civil Aviation Data Governance System","T. Yuan; Y. Liu; X. Liu","Big Data and Artificial Intelligence Department, Civil Aviation Management Institute of China, Beijing, China; Big Data and Artificial Intelligence Department, Civil Aviation Management Institute of China, Beijing, China; Big Data and Artificial Intelligence Department, Civil Aviation Management Institute of China, Beijing, China",2024 4th International Conference on Intelligent Communications and Computing (ICICC),"11 Dec 2024","2024","","","213","216","As a new type of production factor, data is a crucial foundation for the digital transformation of the civil aviation industry. In the past two years, the Civil Aviation Administration of China (CAAC) has successively issued the “7+1” series of Smart Civil Aviation Data Governance Standards, providing guidance for industry data governance and offering solutions for “how to manage and use data” in civil aviation. This article combines national development trends and the current state of industry data to analyze the civil aviation data governance system and its construction key points through the interpretation of these series of standards.","","979-8-3315-3036-5","10.1109/ICICC63565.2024.10780590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10780590","Civil aviation data;Data governance;Data architecture;Data quality;Data security;Data services;Data sharing","Industries;Systematics;Digital transformation;Data security;Information sharing;Production;Market research;Data governance;Standards;Engines","","","","7","IEEE","11 Dec 2024","18-20 Oct. 2024","18-20 Oct. 2024","IEEE","IEEE Conferences"
"Exposing Military Sensor Data using SpatioTemporal Asset Catalog (STAC)","S. E. Rustad; B. J. Hansen; M. G. Bjørndal; T. Haugen","Sensor and Surveillance Systems Division, Norwegian Defence Research Establishment (FFI), Kjeller, Norway; Strategic Analyses and Joint Systems Division, Norwegian Defence Research Establishment (FFI), Kjeller, Norway; Sensor and Surveillance Systems Division, Norwegian Defence Research Establishment (FFI), Kjeller, Norway; Sensor and Surveillance Systems Division, Norwegian Defence Research Establishment (FFI), Kjeller, Norway",2023 International Conference on Military Communications and Information Systems (ICMCIS),"20 Sep 2023","2023","","","1","7","Providing relevant sensor data for military decision makers to build and maintain their situational awareness is a persistent problem, preventing proper utilization of collected sensor data. In this paper, we propose to mitigate this by using a data lake solution controlled by a data catalog modelling its metadata according to SpatioTemporal Asset Catalog (STAC), a specification from the satellite imagery community. The feasibility of this setup is illustrated by a military maritime use case backed by an experimental sensor data infrastructure.","","979-8-3503-4385-4","10.1109/ICMCIS59922.2023.10253573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10253573","data catalog;data lake;metadata;sensor data","Military communication;Metadata;Big Data applications;Spatiotemporal phenomena;Satellite images;Information systems","","3","","28","IEEE","20 Sep 2023","16-17 May 2023","16-17 May 2023","IEEE","IEEE Conferences"
"MeWP: Meta-learning based Water-Level Prediction","J. Mao; O. Yun; H. Kim; H. Chang; X. Sun",Shanghai American School; Shanghai American School; Shanghai American School; Shanghai American School; University of Oxford Peter,2022 IEEE International Conference on Big Data (Big Data),"26 Jan 2023","2022","","","1886","1891","Recently, extreme heat waves have swept the world, exacerbating the pressing issue of increased drought occurrences. Accurate water level prediction is crucial in combating droughts. However, current water level prediction models lack interchangeability between different bodies of water and ultimately fail to consider the relevance between different hydrological systems, rendering them inaccurate and ineffective. Therefore, a generalized, adaptable, and reliable water level prediction model is crucial.In this paper, we propose a meta-learning based model called MeWP to address such issues. To incorporate meta-learning methods, we initially embed and compile different lake data and subsequently generate global optimal initial parameters. We also design a scalable meta-trained learning based on dataset size to assist convergence efficiency on different water systems. The conclusions of our extensive experiments on five public datasets demonstrate the superior stability, accuracy, and flexibility of MeWP compared to other state-of-the-art methods.","","978-1-6654-8045-1","10.1109/BigData55660.2022.10020854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020854","Water level Prediction;Meta-Learning","Training;Adaptation models;Water storage;Droughts;Training data;Predictive models;Lakes","","1","","23","IEEE","26 Jan 2023","17-20 Dec. 2022","17-20 Dec. 2022","IEEE","IEEE Conferences"
"Data Engineering with AWS: Learn how to design and build cloud-based data transformation pipelines using AWS","G. Eagar",NA,Data Engineering with AWS: Learn how to design and build cloud-based data transformation pipelines using AWS,"","2021","","","","","The missing expert-led manual for the AWS ecosystem — go from foundations to building data engineering pipelines effortlessly Purchase of the print or Kindle book includes a free eBook in the PDF format.Key FeaturesLearn about common data architectures and modern approaches to generating value from big dataExplore AWS tools for ingesting, transforming, and consuming data, and for orchestrating pipelinesLearn how to architect and implement data lakes and data lakehouses for big data analytics from a data lakes expertBook DescriptionWritten by a Senior Data Architect with over twenty-five years of experience in the business, Data Engineering for AWS is a book whose sole aim is to make you proficient in using the AWS ecosystem. Using a thorough and hands-on approach to data, this book will give aspiring and new data engineers a solid theoretical and practical foundation to succeed with AWS. As you progress, you’ll be taken through the services and the skills you need to architect and implement data pipelines on AWS. You'll begin by reviewing important data engineering concepts and some of the core AWS services that form a part of the data engineer's toolkit. You'll then architect a data pipeline, review raw data sources, transform the data, and learn how the transformed data is used by various data consumers. You’ll also learn about populating data marts and data warehouses along with how a data lakehouse fits into the picture. Later, you'll be introduced to AWS tools for analyzing data, including those for ad-hoc SQL queries and creating visualizations. In the final chapters, you'll understand how the power of machine learning and artificial intelligence can be used to draw new insights from data. By the end of this AWS book, you'll be able to carry out data engineering tasks and implement a data pipeline on AWS independently.What you will learnUnderstand data engineering concepts and emerging technologiesIngest streaming data with Amazon Kinesis Data FirehoseOptimize, denormalize, and join datasets with AWS Glue StudioUse Amazon S3 events to trigger a Lambda process to transform a fileRun complex SQL queries on data lake data using Amazon AthenaLoad data into a Redshift data warehouse and run queriesCreate a visualization of your data using Amazon QuickSightExtract sentiment data from a dataset using Amazon ComprehendWho this book is forThis book is for data engineers, data analysts, and data architects who are new to AWS and looking to extend their skills to the AWS cloud. Anyone new to data engineering who wants to learn about the foundational concepts while gaining practical experience with common data engineering services on AWS will also find this book useful. A basic understanding of big data-related topics and Python coding will help you get the most out of this book but it’s not a prerequisite. Familiarity with the AWS console and core services will also help you follow along.","","9781800569041","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10162399.pdf&bkn=10162399&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Essential PySpark for Scalable Data Analytics: A beginner's guide to harnessing the power and ease of PySpark 3","S. Nudurupati",NA,Essential PySpark for Scalable Data Analytics: A beginner's guide to harnessing the power and ease of PySpark 3,"","2021","","","","","Get started with distributed computing using PySpark, a single unified framework to solve end-to-end data analytics at scaleKey FeaturesDiscover how to convert huge amounts of raw data into meaningful and actionable insightsUse Spark's unified analytics engine for end-to-end analytics, from data preparation to predictive analyticsPerform data ingestion, cleansing, and integration for ML, data analytics, and data visualizationBook DescriptionApache Spark is a unified data analytics engine designed to process huge volumes of data quickly and efficiently. PySpark is Apache Spark's Python language API, which offers Python developers an easy-to-use scalable data analytics framework. Essential PySpark for Scalable Data Analytics starts by exploring the distributed computing paradigm and provides a high-level overview of Apache Spark. You'll begin your analytics journey with the data engineering process, learning how to perform data ingestion, cleansing, and integration at scale. This book helps you build real-time analytics pipelines that help you gain insights faster. You'll then discover methods for building cloud-based data lakes, and explore Delta Lake, which brings reliability to data lakes. The book also covers Data Lakehouse, an emerging paradigm, which combines the structure and performance of a data warehouse with the scalability of cloud-based data lakes. Later, you'll perform scalable data science and machine learning tasks using PySpark, such as data preparation, feature engineering, and model training and productionization. Finally, you'll learn ways to scale out standard Python ML libraries along with a new pandas API on top of PySpark called Koalas. By the end of this PySpark book, you'll be able to harness the power of PySpark to solve business problems.What you will learnUnderstand the role of distributed computing in the world of big dataGain an appreciation for Apache Spark as the de facto go-to for big data processingScale out your data analytics process using Apache SparkBuild data pipelines using data lakes, and perform data visualization with PySpark and Spark SQLLeverage the cloud to build truly scalable and real-time data analytics applicationsExplore the applications of data science and scalable machine learning with PySparkIntegrate your clean and curated data with BI and SQL analysis toolsWho this book is forThis book is for practicing data engineers, data scientists, data analysts, and data enthusiasts who are already using data analytics to explore distributed and scalable data analytics. Basic to intermediate knowledge of the disciplines of data engineering, data science, and SQL analytics is expected. General proficiency in using any programming language, especially Python, and working knowledge of performing data analytics using frameworks such as pandas and SQL will help you to get the most out of this book.","","9781800563094","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10162348.pdf&bkn=10162348&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"FaaS and Furious: abstractions and differential caching for efficient data pre-processing","J. Tagliabue; R. Curtin; C. Greco","Bauplan Labs, New York, US; Bauplan Labs, Atlanta, US; Bauplan Labs, New York, US",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","3562","3567","Data pre-processing pipelines are the bread and butter of any successful AI project. We introduce a novel programming model for pipelines in a data lakehouse, allowing users to interact declaratively with assets in object storage. Motivated by real-world industry usage patterns, we exploit these new abstractions with a columnar and differential cache to maximize iteration speed for data scientists, who spent most of their time in pre-processing – adding or removing features, restricting or relaxing time windows, wrangling current or older datasets. We show how the new cache works transparently across programming languages, schemas and time windows, and provide preliminary evidence on its efficiency on standard data workloads.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825377","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825377","faas;data processing;data pipelines;cache;lakehouse","Industries;Computer languages;Dairy products;Pipelines;Programming;Big Data;Data models;Artificial intelligence;Standards","","1","","25","IEEE","16 Jan 2025","15-18 Dec. 2024","15-18 Dec. 2024","IEEE","IEEE Conferences"
"Enterprise Data Strategy: A Decentralized Data Mesh Approach","V. K. Butte; S. Butte","NA; University of Idaho, Idaho Falls, ID, USA",2022 International Conference on Data Analytics for Business and Industry (ICDABI),"14 Feb 2023","2022","","","62","66","As the enterprises experience exponential growth of data, the centralized approach of data lakes is falling short of meeting dynamic business needs. This has given rise to a data mesh approach focusing on data as a product thinking, distributed domain driven architectures, federated governance and self-serving data infrastructure. This paper provides an overview of data mesh concepts, reference architectures and guidance on practical implementation to make data mesh a success.","","978-1-6654-9058-0","10.1109/ICDABI56818.2022.10041672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041672","Cloud;Data strategy;data mesh;data lake architecture;Cloud computing;enterprise data strategy","Industries;Data analysis;Distributed databases;Focusing;Computer architecture;Lakes;Big Data applications","","19","","7","IEEE","14 Feb 2023","25-26 Oct. 2022","25-26 Oct. 2022","IEEE","IEEE Conferences"
"Metadata in Data Lake Ecosystems","A. Zgolli; C. Collet; C. Madera",NA; NA; NA,Data Lakes,"","2020","","","57","96","The notion of metadata has been used in information management long before the emergence of computer science, in fields related to documentation or cataloguing. The National Information Security Organization classification of metadata encompasses the following four types: descriptive metadata, structural metadata, administrative metadata, and markup languages. A metadata schema consists of a labeling, marking or encoding system, used for storing information about the way data is organized and structured. Business metadata define the information content that the data provide in a business context. Business metadata are an important aspect in any successful information governance program. Navigational integration metadata describe the data linkage and data movement within the environments. Operational metadata describes the data integration applications and supporting job runs. Primary sources of operational metadata include data integration job logs and data quality checks. In a data lake ecosystem, as well as other information systems, metadata are varied and pervasive.","","9781119720423","10.1002/9781119720430.ch4","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822310.pdf&bkn=9820901&pdfType=chapter","","Metadata;Business;Big Data applications;Organizations;Interoperability;Knowledge based systems;Standards organizations","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Freyja: Efficient Join Discovery in Data Lakes","M. Maynou; S. Nadal; R. Panadero; J. Flores; O. Romero; A. Queralt","Universitat Politècnica de Catalunya, Barcelona, Spain; Universitat Politècnica de Catalunya, Barcelona, Spain; Universitat Politècnica de Catalunya, Barcelona, Spain; Universitat Politècnica de Catalunya, Barcelona, Spain; Universitat Politècnica de Catalunya, Barcelona, Spain; Universitat Politècnica de Catalunya, Barcelona, Spain",IEEE Transactions on Knowledge and Data Engineering,"","2026","PP","99","1","12","We study the problem of efficiently computing rankings of joinable attributes in data lakes. Traditional set-overlap measures produce numerous false positives in this scenario, while modern, more accurate Table Representation Learning (TRL) techniques incur prohibitive computational costs. In contrast to the state-of-the-art, we adopt a novel notion of join quality tailored to data lakes relying on a metric that combines multiset Jaccard and cardinality proportion. The proposed metric merges the best of both worlds by leveraging syntactic measures while achieving accuracy scores comparable to those of TRL approaches. Generating rankings of joinable pairs is highly scalable at both preparation and query time, since we train a general-purpose predictive model. Predictions are based on data profiles, succinct and efficiently computed representations of dataset characteristics. Our experiments show that our system, Freyja, matches and improves upon, the results obtained by the state-of-the-art while reducing execution costs by orders of magnitude.","1558-2191","","10.1109/TKDE.2026.3656786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11361183","Data Discovery;Join Discovery;Big Data Processing;Data Lakes;Data Profiling","Measurement;Semantics;Big Data applications;Syntactics;Indexes;Accuracy;Predictive models;Costs;Computational modeling;Toy manufacturing industry","","","","","CCBY","22 Jan 2026","","","IEEE","IEEE Early Access Articles"
"Java Programming Implementation of Hierarchical Sharing Architecture of Multimedia Materials and Network Resources in English Training","R. Zhang","Xinjiang University, Urumqi, China",2022 International Conference on Inventive Computation Technologies (ICICT),"16 Aug 2022","2022","","","1368","1372","Java programming implementation of the hierarchical sharing architecture of multimedia materials and network resources in English training is presented in this paper. As a new network architecture for the deep integration of computing networks, CAN is based on the existing network technologies and connects distributed computing nodes through a ubiquitous network to realize automatic deployment of services, optimal routing and load balancing, so as to build perceptual computing. Powerful new network infrastructure ensures that the network schedules computing resources in different locations on demand and in real time, and improves the utilization of network and computing resources. Even so, the basic computing resources, types of general microservices and their instance states in the microservice cluster may still be perceived by the external network. Hence, this paper integrates the novel technologies to further analyze the comprehensive model. The simulation results have proven the effectiveness.","2767-7788","978-1-6654-0837-0","10.1109/ICICT54344.2022.9850777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850777","Java Programming;Hierarchical Sharing;Data Architecture;Multimedia Materials;Network Resources","Training;Java;Schedules;Simulation;Microservice architectures;Computer architecture;Programming","","1","","29","IEEE","16 Aug 2022","20-22 July 2022","20-22 July 2022","IEEE","IEEE Conferences"
"Discrete Jaya algorithm to solve the police resource deployment problem in emergency traffic accident","Z. Jing; D. Weijie","Department of computer and information security, Zhejiang Police College, Hangzhou; Big-data and Network Security Research Institute, Zhejiang Police College, Hangzhou",2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),"3 Aug 2022","2022","10","","2542","2545","Aiming at the high frequency of urban traffic accidents and the relative shortage of police resources, a multi-objective discrete Jaya algorithm is proposed to solve the problem of police resource deployment in emergency traffic accident handling. The purpose is to make timely response and handling of traffic accidents through the rational allocation of police deployment points in the jurisdiction. Taking the coverage of accident points and the average response time of accidents as the optimization objectives, the discrete Jaya algorithm is used as the global search strategy to approach the Pareto front by constantly approaching the optimal solution and far away from the worst solution, and then the neighborhood search strategy is used to improve the local search ability of the algorithm. Finally, a practical example is given to verify the effectiveness of the proposed method.","2693-2865","978-1-6654-2207-9","10.1109/ITAIC54216.2022.9836927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836927","resources deployment;discrete Jaya algorithm;multi-objective;location problem","Law enforcement;Conferences;Force;Search problems;Time factors;Resource management;High frequency","","","","13","IEEE","3 Aug 2022","17-19 June 2022","17-19 June 2022","IEEE","IEEE Conferences"
"Cloud data architecture applied to urban management","F. Devin; A. Jourdan; D. Laffly; Y. Le Nir","EISTI, pau, France; EISTI, pau, France; University of toulouse, Toulouse, France; EISTI, pau, France",2016 Eighth International Conference on Knowledge and Systems Engineering (KSE),"1 Dec 2016","2016","","","327","332","Open Data now provides access to updated data dedicated to urban development. The traditional approach of using production data for decision on land management needs to be rethought in the light of these new opportunities and should therefore addressed towards dynamic management of geographic information. Institutional sites such as INSEE semantically annotate their data facilitating the discovery of contextual data. Linked Open Data cloud network offers semantic access to a huge amount of thematic data including an important geographic subset. These new opportunities always generate a greater amount of usable data. Big Data tools, like Spark, make it easy to handle this amount unbounded data via conventional data-mining algorithms. We group all these issues under the generic name of Cloud Data that has sense only if it is integrated perfectly into a cloud computing environment for efficient processing and reactive application (SaaS application, Restfull services, D3JS library, …). We offer an example of a dedicated application for the Pau urban community in which all Cloud Data is integrated as a SaaS (Software as a Service).","","978-1-4673-8929-7","10.1109/KSE.2016.7758075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7758075","","Predictive models;Computational modeling;Clustering algorithms;Cloud computing;Semantics;Sparks;Urban areas","","","","16","IEEE","1 Dec 2016","6-8 Oct. 2016","6-8 Oct. 2016","IEEE","IEEE Conferences"
"Multi-Chain Model and Cross-Chain Communication Protocol for Financial Transactions","C. Li; G. Zhang; X. Mao; J. Zhang; C. Xing","Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China","2022 IEEE 22nd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)","30 Mar 2023","2022","","","547","551","Aiming at the cross-chain problems faced by financial transactions, study the cross-chain communication protocols of the financial-oriented autonomous panda model and golden monkey model, and study the construction of a new scalable and credible multi-chain model that supports homogeneous blockchains and heterogeneous blockchains. The models and protocols that support financial transactions in the blockchain environment need to be able to meet the SSL or SET security protocols similar to traditional Internet transactions, and meet various requirements such as transaction integrity, reliability, and privacy protection.","2693-9371","979-8-3503-1991-0","10.1109/QRS-C57518.2022.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10077058","Multi-chain model;cross-chain communication;data lake;financial transaction","Privacy;Protocols;Prototypes;Software quality;Blockchains;Internet;Software reliability","","2","","13","IEEE","30 Mar 2023","5-9 Dec. 2022","5-9 Dec. 2022","IEEE","IEEE Conferences"
"Fog Computing","A. Ioualalen",NA,Data Lakes,"","2020","","","171","186","The Internet of Things (IoT) has changed the concept of data acquisition into the data lake environment, and for some data lakes, volume limits could be reached in the near future. One main characteristic of fog computing is the sharing of data ingestion steps between the sensors which produce data, and the data lake which consumes data. This chapter explains the concept of fog computing and the associated challenges and then discusses the different options to be taken into account when dealing with a data lake. The main origin of the volume paradox comes from the fact that every communicating object is speaking freely and directly to potentially the whole network. Fog, cloud and edge computing may appear similar, but they are in fact different layers of the IoT. Most enterprises are familiar with cloud computing, which is now a de facto standard in many industries.","","9781119720423","10.1002/9781119720430.ch8","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821517.pdf&bkn=9820901&pdfType=chapter","","Automobiles;Cloud computing;Big Data applications;Roads;Internet of Things;Edge computing;Production facilities","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Empowering Data Mesh with Federated Learning","H. Li; S. Toor","Department of Industrial Design, Eindhoven University of Technology, Eindhoven, Netherlands; Department of Information Technology, Uppsala University Scaleout Systems, Uppsala, Sweden",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","2340","2342","The evolution of data architecture has seen the rise of data lakes, aiming to solve the bottlenecks of data management and promote intelligent decision-making. However, this centralized architecture is limited by the proliferation of data sources and the growing demand for timely analysis and processing. A new data paradigm, Data Mesh, is proposed to overcome these challenges. In this decentralized architecture where data is locally preserved by each domain team, traditional centralized machine learning cannot conduct effective analysis across multiple domains, especially for security-sensitive organizations. To this end, we introduce a pioneering approach that incorporates Federated Learning into Data Mesh. This applied research article emphasizes the benefits of combining two distinct domains to achieve the best outcomes for industrial use cases.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825390","Data Mesh;Federated Learning;Domain-Intelligence","Federated learning;Soft sensors;Decision making;Collaboration;Organizations;Big Data applications;Fraud","","3","","8","IEEE","16 Jan 2025","15-18 Dec. 2024","15-18 Dec. 2024","IEEE","IEEE Conferences"
"Correlation analysis on real-time tab-delimited network monitoring data","A. Pan; J. Majumdar; A. Bansal; B. White; R. L. A. Cottrell","Department of CSE, Amity University, Noida, India; Department of CSE, Amity University, Noida, India; Department of CSE, Amity University, Noida, India; SLAC National Accelerator Laboratory, Stanford, CA, USA; Department of CSE, Amity University, Noida, India",2016 6th International Conference - Cloud System and Big Data Engineering (Confluence),"9 Jul 2016","2016","","","263","267","The PingER End-End performance monitoring of the Internet, is led by the SLAC National Accelerator Laboratory. It was created to answer the growing need to monitor the network both to analyze current performance and to designate resources to optimize execution between research centers, and the universities and institutes co-operating on present and future operations. The monitoring support reflects the broad geographical area of the collaborations and requires a comprehensive number of research and resources. The data architecture retrieval and methodology of the interpretation have emerged over numerous years. Analyzing this data is the main challenge due to its high volume. By using correlation analysis, we can make crucial conclusions about how the network data affects the performance of the hosts and how it depends from countries to countries.","","978-1-4673-8203-8","10.1109/CONFLUENCE.2016.7508126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7508126","Correlation;Network Monitoring;Ping;Tab-Delimited;PingER","Decision support systems;Big data","","2","","15","IEEE","9 Jul 2016","14-15 Jan. 2016","14-15 Jan. 2016","IEEE","IEEE Conferences"
"CLODA: A Crowdsourced Linked Open Data Architecture","G. Larkou; J. Metochi; G. Chatzimilioudis; D. Zeinalipour-Yazti","Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus",2013 IEEE 14th International Conference on Mobile Data Management,"29 Jul 2013","2013","2","","104","109","In this paper we present our Crowdsourced Linked Open Data Architecture (CLODA), a first attempt to combine crowdsourcing, localization and location-based services to generate, collect, validate and relate real-world, geo-spatial and multidimensional information using smartphones and other mobile devices. CLODA focuses on the construction of URI addressable, interlinked and semi-structured data following the Linked-Open Data (LOD) paradigm. The validity of the constructed data is then contributed by a participating crowd. We present our prototype implementation on top of Google Maps and a blend of in-house technologies, particularly our indoor positioning framework, coined Airplace, our trajectory similarity framework, coined SmartTrace, our neighborhood detection framework, coined Proximity and our smartphone testing platform coined SmartLab.","2375-0324","978-0-7695-4973-6","10.1109/MDM.2013.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6569072","Linked Open Data;Crowdsourcing;Smartphones","Smart phones;Prototypes;Google;Trajectory;Mobile communication;Libraries;Androids","","4","","29","IEEE","29 Jul 2013","3-6 June 2013","3-6 June 2013","IEEE","IEEE Conferences"
"Robust SmartCityAI Lakehouse: IKN (New Capital City of Indonesia) Case Study","D. R. Hermanus; D. R. Hermanus; F. Hidayat; S. H. Supangat","Computer Science Department, Research Interest Group in Educational Technology, Bina Nusantara University, Bandung, Indonesia; Doctor of Informatic Technology (DIT), Walden University, Minneapolis, USA; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",2024 International Conference on ICT for Smart Society (ICISS),"19 Nov 2024","2024","","","1","7","The rapid advancement of smart cities, driven by innovative communication and information technologies (ICT), has transformed urban management. This paper introduces the Robust SmartCityAI Lakehouse, a hybrid framework specifically designed to implement smart city solutions in IKN, the New Capital City of Indonesia. The proposed architecture seamlessly integrates diverse data sources and supports a wide range of applications, including real-time AI-driven transportation management, energy optimization, public safety enhancement, waste and water management, environmental monitoring, and air quality control. By leveraging both on-premises processing and scalable cloud infrastructure, this framework enhances urban sustainability and improves the quality of life for citizens. The paper also explores the key benefits and challenges of deploying this architecture, providing practical strategies for its implementation in complex urban environments.","","979-8-3503-8965-4","10.1109/ICISS62896.2024.10751179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10751179","Smart City;Big Data;Data Lakehouse;IoT Integration;Urban Management;Predictive Analytic;AI","Smart cities;Soft sensors;Transportation;Real-time systems;Public security;Information and communication technology;Security;Environmental monitoring;Water resources;Optimization","","1","","32","IEEE","19 Nov 2024","4-5 Sept. 2024","4-5 Sept. 2024","IEEE","IEEE Conferences"
"SpatialSSJP: QoS-Aware Adaptive Approximate Stream-Static Spatial Join Processor","I. M. A. Jawarneh; P. Bellavista; A. Corradi; L. Foschini; R. Montanari","Dipartimento di Informatica – Scienza e Ingegneria (DISI), University of Bologna, Bologna, Italy; Dipartimento di Informatica – Scienza e Ingegneria (DISI), University of Bologna, Bologna, Italy; Dipartimento di Informatica – Scienza e Ingegneria (DISI), University of Bologna, Bologna, Italy; Dipartimento di Informatica – Scienza e Ingegneria (DISI), University of Bologna, Bologna, Italy; Dipartimento di Informatica – Scienza e Ingegneria (DISI), University of Bologna, Bologna, Italy",IEEE Transactions on Parallel and Distributed Systems,"28 Nov 2023","2024","35","1","73","88","The widespread adoption of Internet of Things (IoT) motivated the emergence of mixed workloads in smart cities, where fast arriving geo-referenced big data streams are joined with archive tables, aiming at enriching streams with descriptive attributes that enable insightful analytics. Applications are now relying on finding, in real-time, to which geographical regions data streaming tuples belong. This problem requires a computationally intensive stream-static join for joining a dynamic stream with a disk-resident static table. In addition, the time-varying nature of fluctuation in geospatial data arriving online calls for an approximate solution that can trade-off QoS constraints while ensuring that the system survives sudden spikes in data loads. In this paper, we present SpatialSSJP, an adaptive spatial-aware approximate query processing system that specifically focuses on stream-static joins in a way that guarantees achieving an agreed set of Quality-of-Service goals and maintains geo-statistics of stateful online aggregations over stream-static join results. SpatialSSJP employs a state-of-art stratified-like sampling design to select well-balanced representative geospatial data stream samples and serve them to a stream-static geospatial join operator downstream. We implemented a prototype atop Spark Structured Streaming. Our extensive evaluations on big real datasets show that our system can survive and mitigate harsh join workloads and outperform state-of-art baselines by significant magnitudes, without risking rigorous error bounds in terms of the accuracy of the output results. SpatialSSJP achieves a relative accuracy gain against plain Spark joins of approximately 10% in worst cases but reaching up to 50% in best case scenarios.","1558-2183","","10.1109/TPDS.2023.3330669","H2020 SimDOME—Digital Ontology-Based Modelling Environment for Simulation of Materials(grant numbers:814492); OntoTrans EU Horizon 2020 Project(grant numbers:862136); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10309986","Algorithms for data and knowledge management;Data Architecture;Spatial databases and GIS;QoS Data Management;Spatial Join;Spatial Indexes;Geospatial Analysis;Apache Spark;Query Processing;Big Data Applications","Streams;Geospatial analysis;Quality of service;Urban areas;Smart cities;Sparks;Pipelines","","11","","33","CCBY","6 Nov 2023","Jan. 2024","","IEEE","IEEE Journals"
"Data Marketplace for Efficient Data Placement","H. Maruyama; D. Okanohara; S. Hido","The Institute of Statistical Mathematics, The Research Organization of Information and Systems, Japan; Preferred Infrastructure, Inc., Japan; Preferred Infrastructure, Inc., Japan",2013 IEEE 13th International Conference on Data Mining Workshops,"6 Mar 2014","2013","","","702","705","Data values are uneven. Some data have higher (financial) values than others. Data with low value-density should be reduced in size or removed in order to make room for new data with higher values. Okanohara et al. [9] argued that the data values will determine the placement of data in the network so as to maximize the utilization of the storage capacity (and the processing power) of the entire network, and proposed an architecture called Krill. Determining data values, however, is not an easy task because the data values are speculative, meaning that the future values are usually unknown. This paper discusses an attempt to adopt the marketplace concept for determining the data values. It is expected the market efficiency guarantees the best possible value is assigned to each data item. We consider two models with different complexity and show that the overall utilization of the network is maximized.","2375-9259","978-1-4799-3142-2","10.1109/ICDMW.2013.146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6753988","Big Data;Architecture;Data Values;Krill;Jubatus","Cameras;Data models;Biological system modeling;Conferences;Time series analysis;Mathematical model;Surveillance","","5","","10","IEEE","6 Mar 2014","7-10 Dec. 2013","7-10 Dec. 2013","IEEE","IEEE Conferences"
"Comparative study of xAPI validation tools","T. Rabelo; M. Lama; J. C. Vidal; R. Amorim","Faculdade de Ciências Aplicadas e Sociais de Petrolina (FACAPE); Centro de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; Centro de Investigación en Tecnoloxías da Información (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; Universidade do - Estado da Bahia (UNEB), Brasil",2017 IEEE Frontiers in Education Conference (FIE),"14 Dec 2017","2017","","","1","5","Learning Analytics (LA) is currently the most effective way of achieving better information and in-depth insights of the learning processes. Specifications like Experience API (xAPI) have been defined as part of LA initiatives to add interoperability among LA-aware applications. Tools that validate the conformance of data to these specifications are key components to assure the interoperability among applications. In this paper, a comparative evaluation of relevant validation tools of the xAPI specification is presented. This comparison focus specially on the structural and semantic features of the xAPI specification, revealing that most of the currently available tools do not support the semantic constraints of the specification.","","978-1-5090-5920-1","10.1109/FIE.2017.8190729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8190729","Big data architecture;Learning analytics;Experience API","Tools;Semantics;Libraries;Ontologies;Licenses;Interoperability;OWL","","1","","14","IEEE","14 Dec 2017","18-21 Oct. 2017","18-21 Oct. 2017","IEEE","IEEE Conferences"
"Shared Services Common Data Model to Deliver Advanced Analytics","B. Gall; C. Tucker; B. Massey","Strategic Innovations, The Energy Authority, Jacksonville, FL, United States; Strategic Innovations, The Energy Authority, Jacksonville, FL, United States; Strategic Innovations, The Energy Authority, Jacksonville, FL, United States",2022 IEEE International Smart Cities Conference (ISC2),"26 Oct 2022","2022","","","1","5","Smart cities generate large amounts of data from various services and hardware. Data is generated and collected from Advanced Meter Infrastructure (AMI), Weather Stations, SCADA systems, and transportation systems for example. Within each of these data domains cities have many hardware and software vendors to pick from, each with their own proprietary method to store and share data. High resolution data provided by technologies such as AMI meters create the opportunity to deliver new distribution network and customer analysis that were not possible previously; however, the delivery of these advanced analytics projects has been challenging. While the identification of advanced analytics use cases is generally agreed upon across utilities, execution of these services is typically delivered in a case-by-case basis depending on chosen vendors and ability to integrate the necessary systems and data. For smaller utilities this often renders the service costs out of reach. By creating and leveraging a standardized analytical data model focused on delivery of advanced analytics services rather than the vendor's software and hardware needs, economies of scale are realized across large and small utilities, reducing costs and the barrier of entry into advanced analytics and data driven decision making.","2687-8860","978-1-6654-8561-6","10.1109/ISC255366.2022.9922563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9922563","data architecture;common data model;shared services;cloud;data modelling","Meters;Analytical models;Costs;Smart cities;Transportation;SCADA systems;Data models","","","","16","IEEE","26 Oct 2022","26-29 Sept. 2022","26-29 Sept. 2022","IEEE","IEEE Conferences"
"Management, Storage, and Retrieval of Complex Data Comprising Multiple Formats Collected from Different Sources: A Systems Engineering Approach","B. C. White; R. R. Patel; L. K. Walker; M. D. Bray","Information Technology Laboratory, USACE Engineering Research and Development Center, Vicksburg, MS; Information Technology Laboratory, USACE Engineering Research and Development Center, Vicksburg, MS; Information Technology Laboratory, USACE Engineering Research and Development Center, Vicksburg, MS; Geotechnical and Structures Laboratory, USACE Engneering Research and Development Center, Vicksburg, MS","2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)","9 Apr 2024","2023","","","1419","1424","Physical modeling procedures, with intermediate data, are being developed for the large-scale generation of synthetic imagery for automated target recognition (ATR) machine learning (ML) algorithms. This imagery is typically combined with collected data for generating robust training sets. The management and retrieval of this data requires large-scale storage and a means to query data of different types. Queries need to be performed for selection of data sets to the single file. The goal of this study is the creation of managed system for storing and retrieving this information using high-performance computing resources with the integrated Rule Oriented Data System (iRODS). Search oriented metadata tags are created for query searches based on locality, time-of-day, and other factors. When possible, metadata generation will be automated based on information in the data file. Use cases for the import and query operations are created. Simple scalable problems have been processed and are presented for this data set procedure and the proposed architecture is presented. This data storage and retrieval system will serve to provide locality specific data for ATR ML data-sets from a large set of collected and synthetic imagery and the processes to create that imagery.","","979-8-3503-2759-5","10.1109/CSCE60160.2023.00236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487394","big data;data lake;infrared imagery;ATR;machine learning;iRODS","Training;Machine learning algorithms;Target recognition;High performance computing;Memory;Computer architecture;Machine learning","","","","11","USGov","9 Apr 2024","24-27 July 2023","24-27 July 2023","IEEE","IEEE Conferences"
"Deep Neural Query Understanding System at Expedia Group","R. Chandrasekaran; H. N. Pathak; T. Yano","Expedia Group, Seattle, Washington; Expedia Group, Seattle, Washington; Expedia Group, Seattle, Washington",2020 IEEE International Conference on Big Data (Big Data),"19 Mar 2021","2020","","","1476","1484","Understanding customer intent expressed through search queries is necessary to not only provide the best shopping experience to Expedia Group customers but also to maximize marketing returns. Natural language Understanding (NLU) has ubiquitous commercial application in search, conversational platforms and more. Search queries are notoriously terse, noisy and lack grammatical cues making NLU a challenging task. Multi-lingual market scalability - a highly desirable feature for global travel agent - further add complexity. In this work, we present our NLU System for such search queries in the travel domain using multi-lingual deep learning models that perform these broad tasks: intent classification, named entity recognition and linking. We propose an alternate framework that significantly improves recognition and resolution of ill-defined sparse entities. Our system also includes cross-lingual transfer learning components featuring active learning loop to scale these models to multiple languages with minimal but high quality annotation by localization experts. We explain the business problem these models address, idiosyncrasies of our data, architecture details and implementation trade-offs.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378495","","Deep learning;Annotations;Scalability;Transfer learning;Big Data;Noise measurement;Task analysis","","","","34","IEEE","19 Mar 2021","10-13 Dec. 2020","10-13 Dec. 2020","IEEE","IEEE Conferences"
"Part 3 Big Data, Dark Data, Thick Data, and Small Data","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","57","58","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933562.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"Knowledge Graph-based Data Transformation Recommendation Engine","G. Natani; S. Watanabe","Center for Technology Innovation - Digital Platform, Hitachi Ltd., Tokyo, Japan; Center for Technology Innovation - Digital Platform, Hitachi Ltd., Tokyo, Japan",2021 IEEE International Conference on Big Data (Big Data),"13 Jan 2022","2021","","","4617","4623","Demand for data transformation has increased with the rapid growth of data. To ensure improvements in production line efficiency, Internet of Things (IoT) data analytics demand data transformations that include changing the format, structure, or values of the data stored in a data lake. Data transformations are generally not reused due to the complexity of data transformation files and the lack of knowledge on previous data transformation flows developed by other Extract Transform Load (ETL) developers who develop data transformations. For a naive developer, it is time consuming and difficult to find relevant existing data transformations that can be modified as per new requirements. To solve this problem, we developed a knowledge graph-based data transformation recommendation system featuring a data similarity component that helps to provide explainable results. This system, can improve the mean average precision 26% and the mean average recall by 24% while reducing the mean average root mean squared error by 69% which implies that it can significantly increase the effectiveness of the of recommendations. With the help of this recommendation engine, data transformation tasks can be done by naive developers with little knowledge on existing data transformation flows and continuous improvement projects can be speeded up.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671905","Knowledge graph;Recommendation engine;Extract Transform Load;IoT analytics;Data transformation;Data similarity","Knowledge based systems;Estimation;Transforms;Production;Tagging;Feature extraction;Data mining","","2","","20","IEEE","13 Jan 2022","15-18 Dec. 2021","15-18 Dec. 2021","IEEE","IEEE Conferences"
"Intelligent scheduling algorithm and big data analysis for cross-border e-commerce supply chain optimization","G. Yu","Jiangxi College of Foreign Studies, Nanchang, 330099, Jiangxi, People's Republic of China",4th International Conference on Artificial Intelligence and Autonomous Robot Systems (AIARS 2025),"11 Nov 2025","2025","2025","","716","720","This paper focuses on the optimization of cross-border e-commerce supply chain, and proposes an innovative method that integrates intelligent scheduling algorithm and big data analysis. Cross-border e-commerce supply chain faces many challenges, such as global logistics complexity, demand fluctuation, data island and so on, because it involves complex links such as transnational logistics, multi-currency settlement and customs clearance. In order to solve these problems, an algorithm framework including data integration layer, algorithm core layer and application layer is constructed. The data integration layer builds a unified data lake based on Delta Lake to collect multi-source heterogeneous data, The core layer of the algorithm adopts hierarchical reinforcement learning (RL) architecture, which covers markov decision processes modeling, dynamic constraint satisfaction optimization and real-time feedback control. The application layer realizes the integrated processing of streams and batches through Flink, and supports a variety of application scenarios. In the design of intelligent scheduling algorithm, LSTM-Transformer hybrid model is used for demand forecasting, logistics path optimization is realized by multi-objective function, and Q-learning algorithm is used for inventory scheduling. The key technologies of big data analysis include using Isolation Forest algorithm to build a dynamic threshold model for real-time anomaly detection, and using GraphSAGE technology for multimodal data fusion. The experiment uses Ali Tianchi cross-border e-commerce data set and related external data sources. The results show that this research method is superior to the traditional method in terms of demand forecasting accuracy, logistics optimization effect and anomaly detection accuracy, which significantly improves key indicators such as order fulfillment cycle, inventory turnover rate, logistics cost ratio and customer satisfaction, and hierarchical RL algorithm shows superior performance in solving large-scale complex problems.","","978-1-80705-020-7","10.1049/icp.2025.3137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11238231","","","","","","","","11 Nov 2025","29-31 July 2025","29-31 July 2025","IET","IET Conferences"
"Countering Real-Time Stream Poisoning: An Architecture for Detecting Vessel Spoofing in Streams of AIS Data","I. Kontopoulos; G. Spiliopoulos; D. Zissis; K. Chatzikokolakis; A. Artikis","Department of Product and Systems Design Engineering, University of the Aegean, Syros, Greece; MarineTraffic, United Kingdom; Department of Informatics and Telematics, Harokopio University, Athens, Greece; MarineTraffic, United Kingdom; Institute of Informatics & Telecommunications, National Centre for Scientific Research (NCSR) Demokritos, Athens, Greece","2018 IEEE 16th Intl Conf on Dependable, Autonomic and Secure Computing, 16th Intl Conf on Pervasive Intelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)","28 Oct 2018","2018","","","981","986","Well poisoning is an ancient war stratagem which was frequently used as a ""scorched earth tactic"". Today this tactic has been adapted by malicious attackers to the digital world and evolved into ""stream poisoning"", in which corrupt or fallacious data is injected into a data lake, so as to corrupt the integrity of the information stored there. Numerous maritime surveillance systems nowadays rely on the Automatic Identification System (AIS), which is compulsory for vessels over 299 Gross Tones, for vessel tracking purposes. Ship AIS spoofing involves creating a nonexistent vessel or masquerading a vessel's true identity, resulting in hiding or transmitting false positional data, so that a vessel appears to behave legitimately, thus deceiving stakeholders and authorities. Due to the volume and velocity of data received traditional approaches fail to automatically detect these spoofing events in real time. We focus on an industrial use case of detecting spoofing events in AIS streams and validate our approach in real world conditions.","","978-1-5386-7518-2","10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8512006","distributed stream processing;big data;AIS vessel monitoring;anomaly detection","Artificial intelligence;Real-time systems;Radar tracking;Trajectory;Distributed databases;Big Data;Surveillance","","26","","15","IEEE","28 Oct 2018","12-15 Aug. 2018","12-15 Aug. 2018","IEEE","IEEE Conferences"
"How To RAMI 4.0: Towards An Agent-based Information Management Architecture","A. Kirmse; V. Kraus; T. Langer; A. Pomp; T. Meisen","Institute of Information Management in Mechanical Engineering, RWTH Aachen University Dennewartstr. 27, Aachen; Institute of Information Management in Mechanical Engineering, RWTH Aachen University Dennewartstr. 27, Aachen; Institute of Information Management in Mechanical Engineering, RWTH Aachen University Dennewartstr. 27, Aachen; Institute of Information Management in Mechanical Engineering, RWTH Aachen University Dennewartstr. 27, Aachen; Chair of Technologies and Management of Digital Transformation, University of Wuppertal Rainer-Gruenter-Str. 21, Wuppertal",2019 International Conference on High Performance Computing & Simulation (HPCS),"9 Sep 2020","2019","","","961","968","With the latest advances in digitalization and Industry 4.0, the manufacturing industry is collecting more and more production data. However, with the increasing interconnection of machines, not only the volume but also the variety of data is being expanded. The data life cycles of collection, processing, combining, analyzing and feeding new findings back into sources are becoming increasingly challenging for data scientists to complete. Reference architectures such as the RAMI 4.0 provide conceptual guidelines to address these problems. In this paper, we focus on the implementation of an agent-based architecture that is in line with RAMI 4.0. This architecture implements the guidelines provided by RAMI 4.0 by applying modern approaches from the areas of data lake based data acquisition, semantic description, look up and processing as well as information utilization.","","978-1-7281-4484-9","10.1109/HPCS48598.2019.9188087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9188087","Data acquisition;Data integration;Information management;Multi-agent systems;Big Data applications;Industry applications;RAMI 4.0","Semantics;Industries;Lakes;Interoperability;Data warehouses;Production;Guidelines","","3","","31","IEEE","9 Sep 2020","15-19 July 2019","15-19 July 2019","IEEE","IEEE Conferences"
"A Compressed Deep Convolutional Neural Networks for Face Recognition","L. Yao","Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China",2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA),"19 May 2020","2020","","","144","149","Recent years, deep convolutional neural network has led to significant improvements in face recognition and becomes one of the most popular techniques in computer vision community. However, deep CNN model requires vast amounts of data and time for training and deploying. To solve this problem, we present a deep compact convolutional neural network for face representation. First we apply PCA for initializing convolution filter. Then we adopt DCT and binary hashing for extracting face features. The models are trained on the CASIA-webFace datasets under Caffe framework. Experimental results show that the proposed methods achieve competitive accuracy on the LFW verification benchmark.","","978-1-7281-6024-5","10.1109/ICCCBDA49378.2020.9095672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095672","convolution neural network;deep learning;face recognition","Feature extraction;Convolution;Face recognition;Convolutional neural networks;Face;Principal component analysis;Biological neural networks","","2","","30","IEEE","19 May 2020","10-13 April 2020","10-13 April 2020","IEEE","IEEE Conferences"
"A Knowledge Enhanced Pre-Training Model for Chinese Weibo Sentiment Analysis","L. Yao","Key Laboratory of Public Security Information Application Based on Big-data Architecture Ministry of Public Security, Zhejiang Police College, Hangzhou, China",2024 9th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA),"28 Jun 2024","2024","","","33","39","Sentiment analysis aims to automatically identify and extract subjective information such as tendencies, stances, evaluations, and opinions from text. Current state-of-the-art Natural Language Processing (NLP) methods, primarily based on large-scale pre-trained language models (PLM), have significantly advanced the field of sentiment analysis. However, these methods often struggle due to the scarcity of annotated data. To address these challenges, we present a knowledge-enhanced pre-trained model for the Chinese social media platform. This model employs a phrase-based masking strategy and incorporates knowledge-related information by making adjustments to the structure of the intermediate encoder layer. We validated the model's performance through comparative experiments with other baseline methods, demonstrating the effectiveness of integrating sentiment resources into pre-trained language models.","2832-3734","979-8-3503-7355-4","10.1109/ICCCBDA61447.2024.10569319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10569319","sentiment analysis;pre-trained language models;BERT;sentiment lexicon","Training;Sentiment analysis;Analytical models;Social networking (online);Computational modeling;Knowledge based systems;Linguistics","","3","","35","IEEE","28 Jun 2024","25-27 April 2024","25-27 April 2024","IEEE","IEEE Conferences"
"Pixels: An Efficient Column Store for Cloud Data Lakes","H. Bian; A. Ailamaki",EPFL; EPFL,2022 IEEE 38th International Conference on Data Engineering (ICDE),"2 Aug 2022","2022","","","3078","3090","To benefit from the cloud's higher elasticity and price-efficiency, most modern data-lake engines support S3-like cloud object storage (COS) services as their optional or preferred underlying storage. Meanwhile, the widespread column stores, such as Parquet, are applied in these data lakes to improve analytical performance. However, as these column stores were designed for on-premise HDFS, they often suffer from the high latency of COS and deliver sub-optimal query performance. We observe that by optimizing the storage layout and data access pattern, we can effectively hide and mitigate the high latency. In this paper, we present Pixels, a column store optimized for the cloud that solves the problem by (1) the workload-driven storage layout optimization within and across the row group boundaries; (2) the I/O scheduling concerning the optimized storage layout and the performance characteristics of COS. They collectively improve the analytical performance in a transparent way that does not affect data ingestion and query execution in data lakes. Evaluations show that Pixels outperforms the state-of-the-art column store on COS by more than one order of magnitude on real-world workload and by 1.93x on TPC-H. Moreover, the performance of Pixels is also portable to HDFS.","2375-026X","978-1-6654-0883-7","10.1109/ICDE53745.2022.00276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835615","cloud storage;column store;data analytics","Conferences;Layout;Elasticity;Benchmark testing;Big Data applications;Data engineering;Optimization","","6","","56","IEEE","2 Aug 2022","9-12 May 2022","9-12 May 2022","IEEE","IEEE Conferences"
"A Study on Efficient Indexing for Table Search in Data Lakes","I. Taha; M. Lissandrini; A. Simitsis; Y. Ioannidis","Athena RC, & AAU, NKUA, Athens, Greece; University of Verona, Verona, Italy; Athena Research Center, Athens, Greece; NKUA & Athena RC, Athens, Greece",2024 IEEE 18th International Conference on Semantic Computing (ICSC),"22 Mar 2024","2024","","","245","252","Data lakes store diverse and large volumes of datasets. One of the core challenges in data lakes is dataset discovery, which involves tasks such as finding related tables, domain discovery, and column clustering. In this paper, we focus on a popular approach for finding related tables in public or private data lakes, namely table search. Given the heterogeneity of the tables in a data lake, recent methods adopt table-representation learning and produce dense vector representations for every row, column, or even cell value. This enables advanced indexing techniques, such as HSNW, LSH, and DiskANN, which implement efficient data-structures to speed-up the core operation of approximate k-NN search in such vector spaces. However, while many indexing techniques have been employed so far, their practical value and effectiveness governed by the tradeoff of accuracy vs. performance have not been explored yet. In this paper, we aim at shedding light on this gap. We start with an overview of state-of-the-art techniques for table search in data lakes that are based on vector-search operations. Then, we present an in-depth analysis of the performances of the k-ANN indexes and techniques they adopt. This allows us to map for the first time the space of alternative implementations for these techniques when applied to data lakes, revealing strengths and weaknesses of each option, and further delineating exciting novel research directions.","2472-9671","979-8-3503-8535-9","10.1109/ICSC59802.2024.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10475618","Data Exploration;Data Discovery;Data Lakes","Representation learning;Semantics;Focusing;Lakes;Big Data applications;Vectors;Task analysis","","3","","34","IEEE","22 Mar 2024","5-7 Feb. 2024","5-7 Feb. 2024","IEEE","IEEE Conferences"
"Fido: A String-Based Fuzzy Logic Mechanism for Content Extraction from UAV Data Lakes","P. K. Deb; A. Mukherjee; S. Misra","Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India",IEEE Internet of Things Magazine,"14 Feb 2022","2021","4","4","24","29","In this article, we propose Fido, a fuzzy-based string comparison method for extracting content from data lakes in a camera-based Internet of Drones (IoD) environment. Data lakes support data dumping in their native format, which makes them suitable for real-time deployments such as IoD. However, parsing through these unstructured databases has its concerns, particularly data extraction. Existing works on image-based content extraction focus on complex geometric and matrix mathematical operations, which are expensive in terms of both computation and time. A straightforward and fast solution is necessary for overcoming such challenges. Toward this, we limit our operations to string comparisons between the user's request and tags in the data lake. In particular, we adopt a fuzzy-based approach as it is capable of efficiently handling spelling variations, out-of-order words, and partial matchings, compared to conventional string comparison methods. Through lab-scale experiments, we demonstrate the efficacy of Fido with an almost 80 percent similarity ratio between the request and response images and processing time of 80 µs. Further, we observe minuscule deviations between the coordinates of the request and response images (0.005 units).","2576-3199","","10.1109/IOTM.001.2100084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712449","","Out of order;Measurement;Fuzzy logic;Image resolution;Big Data applications;Real-time systems;Data mining;Drones","","1","","15","IEEE","14 Feb 2022","December 2021","","IEEE","IEEE Magazines"
"Linked Data Principles for Data Lakes","A. Adamou; M. D'Aquin",NA; NA,Data Lakes,"","2020","","","145","169","Linked Data are based on a set of principles and technologies to exploit the architecture of the Web in order to represent and provide access to machine‐readable, globally integrated information. This chapter provides an overview of what Linked Data means, and of the general approach to create and consume Linked Data resources. It shows how this approach can be used at different levels in a data lake, including basic graph‐based data storage and querying, data integration and data cataloging. To exemplify the application of Linked Data principles and technologies for data lakes, a demonstrating scenario is given in the context of the creation and application of a large data platform for a smart city: the Milton Keynes Data Hub. Both Linked Data and data lakes operate under principles that could be interpreted as an assumption of levity towards the traditional rigor of database systems.","","9781119720423","10.1002/9781119720430.ch7","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822439.pdf&bkn=9820901&pdfType=chapter","","Linked data;Big Data applications;Resource description framework;Vocabulary;Standards;Publishing;Ontologies","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Azure Data and AI Architect Handbook: Adopt a structured approach to designing data and AI solutions at scale on Microsoft Azure","O. Mertens; B. V. Baelen",NA; NA,Azure Data and AI Architect Handbook: Adopt a structured approach to designing data and AI solutions at scale on Microsoft Azure,"","2023","","","","","Master core data architecture design concepts and Azure Data & AI services to gain a cloud data and AI architect’s perspective to developing end-to-end solutions Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesTranslate and implement conceptual architectures with the right Azure servicesInject artificial intelligence into data solutions for advanced analyticsLeverage cloud computing and frameworks to drive data science workloadsBook DescriptionWith data’s growing importance in businesses, the need for cloud data and AI architects has never been higher. The Azure Data and AI Architect Handbook is designed to assist any data professional or academic looking to advance their cloud data platform designing skills. This book will help you understand all the individual components of an end-to-end data architecture and how to piece them together into a scalable and robust solution. You’ll begin by getting to grips with core data architecture design concepts and Azure Data & AI services, before exploring cloud landing zones and best practices for building up an enterprise-scale data platform from scratch. Next, you’ll take a deep dive into various data domains such as data engineering, business intelligence, data science, and data governance. As you advance, you’ll cover topics ranging from learning different methods of ingesting data into the cloud to designing the right data warehousing solution, managing large-scale data transformations, extracting valuable insights, and learning how to leverage cloud computing to drive advanced analytical workloads. Finally, you’ll discover how to add data governance, compliance, and security to solutions. By the end of this book, you’ll have gained the expertise needed to become a well-rounded Azure Data & AI architect.What you will learnDesign scalable and cost-effective cloud data platforms on Microsoft AzureExplore architectural design patterns with various use casesDetermine the right data stores and data warehouse solutionsDiscover best practices for data orchestration and transformationHelp end users to visualize data using interactive dashboardingLeverage OpenAI and custom ML models for advanced analyticsManage security, compliance, and governance for the data estateWho this book is forThis book is for anyone looking to elevate their skill set to the level of an architect. Data engineers, data scientists, business intelligence developers, and database administrators who want to learn how to design end-to-end data solutions and get a bird’s-eye view of the entire data platform will find this book useful. Although not required, basic knowledge of databases and data engineering workloads is recommended.","","9781803230733","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251227.pdf&bkn=10251227&pdfType=book","","","","","","","","14 Sep 2023","","","Packt Publishing","Packt Publishing eBooks"
"23 Myths and Facts About Cloud Computing","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","113","118","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933601.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"Comparative Analysis of Machine Learning Methods Application for Financial Fraud Detection","A. Menshchikov; V. Perfilev; D. Roenko; M. Zykin; M. Fedosenko",ITMO University; ITMO University; ITMO University; ITMO University; ITMO University,2022 32nd Conference of Open Innovations Association (FRUCT),"28 Nov 2022","2022","","","178","186","This paper addresses the fraud detection problem in the context of Big Data used in remote banking systems. The paper aims to propose a new algorithm for automatic detection of fraudulent transactions using machine learning with a performance that allows to apply it in big data systems. The article identifies promising directions for optimizing the operation of methods for fraudulent transactions detection in anti-fraud systems. Architectural approaches to the operation of anti-fraud systems have been studied. Based on this, an architecture for illegal actions prediction in a near real-time mode was proposed. The research task of the article is to find the most suitable machine learning algorithm, with the least training and prediction time, demonstrating high classification performance. To achieve this goal, an analysis of the supervised and ensemble machine learning algorithms was made. The dataset was preprocessed for the experiment with SMOTE resampling and robust scaling techniques. The chosen methods were compared using different metrics: $F$1 score, AUC and time consumption for training and classification. As a result of a metrics comparison, it was found that multilayer perceptron (MLP) and boosting methods (Adaptive, Gradient, XGBoost) has the highest classification, but MLP outperforms boosting methods in terms of time consumption for classification. Thus, MLP was selected as the most appropriate algorithm for further integration to proposed Big Data architecture. Based on the data obtained during the experiments, the degree of their implementation in fraud detection systems was assessed and architecture for the anti-fraud detection system for big data was proposed.","2305-7254","978-952-69244-8-9","10.23919/FRUCT56874.2022.9953872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9953872","","Training;Measurement;Machine learning algorithms;Software algorithms;Computer architecture;Big Data;Boosting","","2","","25","","28 Nov 2022","9-11 Nov. 2022","9-11 Nov. 2022","IEEE","IEEE Conferences"
"Collecting the Tourism Contextual Information data to support the tourism recommendation system","R. Y. Saputra; L. E. Nugroho; S. S. Kusumawardani","Dept. of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia; Dept. of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia; Dept. of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia",2019 International Conference on Information and Communications Technology (ICOIACT),"23 Dec 2019","2019","","","79","84","Recommendation system requires supporting data that sometimes are heterogeneous either from its sources or from its data format. In the context of tourism recommendation system, a previous research resulted in the concept of collecting the Tourism Contextual Information (TCI) data to determine the relevant information as the support of tourism recommendation system. However, what things and how the data were collected have not been explained yet. By adopting the global Extract Transform Load (ETL) process, this research aims to show how the supporting data including the database structure, the data architecture, and the data representation in the tourism recommendation system are collected. The result of the research can be used for the need of further research - particularly on the tourism recommendation system considering the change of weather or traffic condition and its effect on making decision when planning a travel or a tour.","","978-1-7281-1655-6","10.1109/ICOIACT46704.2019.8938546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938546","data collection;weather;tourism;recommendation system","Meteorology;Data collection;Decision making;Tourism industry;Recommender systems","","6","","14","IEEE","23 Dec 2019","24-25 July 2019","24-25 July 2019","IEEE","IEEE Conferences"
"Long Text Classification Based on BERT","D. Weijie; L. Yunyi; Z. Jing; S. Xuchen","Zhejiang Police College, Big-data and Network Security Research Institute, Hangzhou; Department of Investigation, Zhejiang Police College, Hangzhou; Department of computer and information security, Zhejiang Police College, Hangzhou; Science and technology management section, Hangzhou","2021 IEEE 5th Information Technology,Networking,Electronic and Automation Control Conference (ITNEC)","4 Nov 2021","2021","5","","1147","1151","Existing text classification algorithms generally have limitations in terms of text length and yield poor classification results for long texts. To address this problem, we propose a BERT-based long text classification method. First, we slice the long text and use BERT to encode the sliced clauses to obtain the local semantic information. Second, we use BiLSTM to fuse the local semantic information and adopt the attention mechanism to increase the weight of important clauses in the long text, so as to obtain the global semantic information. Finally, the global semantic information is input to the softmax layer for classification. Experimental results show that the proposed method achieves higher accuracy than commonly used models.","2693-3128","978-1-6654-1599-6","10.1109/ITNEC52019.2021.9587007","Natural Science Foundation of Zhejiang Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9587007","long text classification;BERT;BiLSTM","Training;Law enforcement;Fuses;Conferences;Text categorization;Semantics;Bit error rate","","7","","17","IEEE","4 Nov 2021","15-17 Oct. 2021","15-17 Oct. 2021","IEEE","IEEE Conferences"
"Visual Bayesian fusion to navigate a data lake","K. Singh; K. Paneri; A. Pandey; G. Gupta; G. Sharma; P. Agarwal; G. Shroff","TCS Research, Tata Consultancy Service Ltd., Gurgaon, India; TCS Research, Tata Consultancy Service Ltd., Gurgaon, India; TCS Research, Tata Consultancy Service Ltd., Gurgaon, India; TCS Research, Tata Consultancy Service Ltd., Gurgaon, India; TCS Research, Tata Consultancy Service Ltd., Gurgaon, India; TCS Research, Tata Consultancy Service Ltd., Gurgaon, India; TCS Research, Tata Consultancy Service Ltd., Gurgaon, India",2016 19th International Conference on Information Fusion (FUSION),"4 Aug 2016","2016","","","987","994","The evolution from traditional business intelligence to big data analytics has witnessed the emergence of `Data Lakes' in which data is ingested in raw form rather than into traditional data warehouses. With the increasing availability of many more pieces of information about each entity of interest, e.g., a customer, often from diverse sources (social-media, mobility, internet-of-things), fusing, visualizing and deriving insights from such data pose a number of challenges: First, disparate datasets often lack a natural join key. Next, datasets may describe measures at different levels of granularity, e.g., individual vs. aggregate data, and finally, different datasets may be derived from physically distinct populations. Moreover, once data has been fused, queries are often an inefficient and inaccurate mechanism to derive insight from high-dimensional data. In this paper we describe iFuse, a data-fusion based visual analytics platform for navigating a data lake to derive insights. We rely on Bayesian graphical models to provide useful rudder with which to fuse and analyze disparate islands of data in a systematic manner. Our platform allows for rich interactive visualizations, querying and keyword-based search within and across datasets or models, as well as intuitive visual interfaces for value-imputation or model-based predictions. We illustrate the use of our platform in multiple scenarios, including two public data challenges as well as a real-life industry use-case involving the probabilistic fusion of datasets that lack a natural join-key.","","978-0-9964-5274-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7527993","","Data visualization;Bayes methods;Diseases;Lakes;Probabilistic logic;Context;Navigation","","1","1","17","","4 Aug 2016","5-8 July 2016","5-8 July 2016","IEEE","IEEE Conferences"
"On the Design of Medical Data Ecosystem for Improving Healthcare Research and Commercial Incentive","Z. -Y. Shae; J. J. P. Tsai","Department of Computer Science and Information Engineering, Asia University, Taichung, Taiwan; Department of Bioinformatics and Medical Engineering, Asia University, Taichung, Taiwan",2021 IEEE Third International Conference on Cognitive Machine Intelligence (CogMI),"13 Apr 2022","2021","","","124","131","This paper outlines a visionary approach for building a distributed federated medical data lake and ecosystem with commercial incentive across hospitals and personal health data generated from wearable medical devices at home. This article creates the ownership enforcement guideline as the basis for building the blockchain based ecosystem platform by reviewing various aspects of studies of data ownership rights. This blockchain based platform can enforce the data ownership, patient privacy, and provide a controlled and secure access to the medical data. It can also perform owner centric medical data exchange and effectively aggregate various related medical data sets from various distributed data sets from various hospitals. Moreover, this blockchain platform unlocks the academic and business value of the medical data by modeling medical data as Non-Fungible Token (NFT) which can provide incentives for all data driven value chain entities to make a medical data ecosystem possible.","","978-1-6654-1621-4","10.1109/CogMI52975.2021.00024","Ministry of Science and Technology Taiwan(grant numbers:MOST 110-2321-B-468-001,MOST 110-2S11-H-468-005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9750303","Blockchain;data ownership;health data privacy;healthcare data ecosystem;electronic medical record;medical data exchange;medical data sharing;medical data NFT;medical data commercialization;distributed federated medical data lake;AI;federated learning","Technical requirements;Law;Hospitals;Ecosystems;Buildings;Big Data applications;Data models","","17","","46","IEEE","13 Apr 2022","13-15 Dec. 2021","13-15 Dec. 2021","IEEE","IEEE Conferences"
"LIFTus: An Adaptive Multi-Aspect Column Representation Learning for Table Union Search","E. Qiu; J. Gao; Y. Tu; J. Yang","Key Laboratory of High Confidence Software Technologies, CS, Peking University, China; Key Laboratory of High Confidence Software Technologies, CS, Peking University, China; ZTE Corporation; National Key Laboratory of Data Space Technology and System",2025 IEEE 41st International Conference on Data Engineering (ICDE),"20 Aug 2025","2025","","","2174","2187","Table union search (TUS) represents a fundamental operation in data lakes to find tables unionable to the given one. Recent approaches to TUS mainly learn column representations for searching by introducing Pre-trained Language Models (PLMs), especially on columns with linguistic data. However, a significant amount of non-linguistic data, notably represented by domain-specific strings and numerical data in the data lake, are still under-explored in the existing methods. To address this issue, we propose LIFTus, an adaptive multi-aspect column representation for table unionable search, where aspect refers to a concept more flexible than data types, so that a single column can exhibit multiple aspects simultaneously. LIFTus aims at combining different aspects of a column (including both linguistic and non-linguistic aspects) to promote the effectiveness and generalization of TUS in a self-supervised manner. Specifically, besides employing PLMs to extract the linguistic aspects from an individual column, LIFTus trains a pattern encoder to learn possible character-level sequential patterns for the column, and builds a number encoder to capture numerical aspects of the column, including the distribution and magnitude features. LIFTus further utilizes a hierarchical cross-attention aided by aspect-relevant statistics to combine these aspects adaptively in producing the final column representations, which are indexed by vector retrieval techniques to achieve efficient search. Extensive experimental results demonstrate that LIFTus has outperformed the current state-of-the-art methods in terms of effectiveness, and achieved much better generalization capability to support unseen data.","2375-026X","979-8-3315-3603-9","10.1109/ICDE65448.2025.00165","NSFC(grant numbers:62272008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113165","Table Union Search;Data Lake;Aspect;Non-Linguistic Column;Generalization","Representation learning;Adaptation models;Linguistics;Feature extraction;Big Data applications;Data engineering;Vectors;Data models;Numerical models;Data mining","","","","58","IEEE","20 Aug 2025","19-23 May 2025","19-23 May 2025","IEEE","IEEE Conferences"
"Enabling Efficient Distributed Spatial Join on Large Scale Vector-Raster Data Lakes","S. Villarroya; J. R. R. Viqueira; J. M. Cotos; J. A. Taboada","COGRADE, Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; COGRADE, Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; COGRADE, Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; COGRADE, Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain",IEEE Access,"21 Mar 2022","2022","10","","29406","29418","Both the increasing number of GPS-enabled mobile devices and the geographic crowd-sourcing initiatives, such as Open Street Map, are determinants for the large amount of vector spatial data that is currently being produced. On the other hand, the automatic generation of raster data by remote sensing devices and environmental modeling processes was always leading to very large datasets. Currently, huge data generation rates are reached by improved sensor observation systems and data processing infrastructures. As an example, the Sentinel Data Access System of the Copernicus Program of the European Space Agency (ESA) was publishing 38.71 TB of data per day during 2020. This paper shows how the assumption of a new spatial data model that includes multi-resolution parametric spatial data types, enables achieving an efficient implementation of a large scale distributed spatial analysis system for integrated vector-raster data lakes. In particular, the proposed implementation outperforms the state-of-the-art Spark-based spatial analysis systems by more than one order of magnitude during vector-raster spatial join evaluation.","2169-3536","","10.1109/ACCESS.2022.3157405","Spanish Ministry of Science and Innovation through Storage and Processing of Massive Geospatial Data for Smart and Sustainable Urban Transport (MaGIST) under National Project(grant numbers:PID2019-105221RB-C42); Galician Government(grant numbers:ED431B 2021/16); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729731","Large-scale data analysis;spatial analytics;spatial data management;vector-raster data analysis","Spatial databases;Data models;Distributed databases;Big Data applications;Data analysis;Cluster computing;Arrays","","8","","28","CCBY","8 Mar 2022","2022","","IEEE","IEEE Journals"
"Gen-T: Table Reclamation in Data Lakes","G. Fan; R. Shraga; R. J. Miller","Northeastern University, Boston, United States; Worcester Polytechnic Institute, Worcester, United States; Northeastern University, Boston, United States",2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","3532","3545","We introduce the problem of Table Reclamation. Given a Source Table and a large table repository, reclamation finds a set of tables that, when integrated, reproduce the source table as closely as possible. Unlike query discovery problems like Query-by-Example or by-Target, Table Reclamation focuses on reclaiming the data in the Source Table as fully as possible using real tables that may be incomplete or inconsistent. To do this, we define a new measure of table similarity, called error-aware instance similarity, to measure how close a reclaimed table is to a Source Table, a measure grounded in instance similarity used in data exchange. Our search covers not only Select-project-join queries, but integration queries with unions, outerjoins, and the unary operators subsumption and complementation that have been shown to be important in data integration and fusion. Using reclamation, a data scientist can understand if any tables in a repository can be used to exactly reclaim a tuple in the Source. If not, one can understand if this is due to differences in values or to incompleteness in the data. Our solution, Gen-T, performs table discovery to retrieve a set of candidate tables from the table repository, filters these down to a set of originating tables, then integrates these tables to reclaim the Source as closely as possible. We show that our solution, while approximate, is accurate, efficient and scalable in the size of the table repository with experiments on real data lakes containing up to 15K tables, where the average number of tuples varies from small (web tables) to extremely large (open data tables) up to 1M tuples.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00272","NSF(grant numbers:IIS-2107248,IIS-1956096,IIS-2325632); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10597787","Data lakes;Table Discovery","Filters;Accuracy;Measurement uncertainty;Data integration;Big Data applications;Data engineering;Open data","","1","","88","IEEE","23 Jul 2024","13-16 May 2024","13-16 May 2024","IEEE","IEEE Conferences"
"TabSketchFM: Sketch-Based Tabular Representation Learning for Data Discovery Over Data Lakes","A. Khatiwada; H. Kokel; I. Abdelaziz; S. Chaudhury; J. Dolby; O. Hassanzadeh; Z. Huang; T. Pedapati; H. Samulowitz; K. Srinivas",Northeastern University; IBM Research; IBM Research; IBM Research; IBM Research; IBM Research; Rensselaer Polytechnic Institute; IBM Research; IBM Research; IBM Research,2025 IEEE 41st International Conference on Data Engineering (ICDE),"20 Aug 2025","2025","","","1523","1536","Enterprises have a growing need to identify relevant tables in data lakes; e.g. tables that are unionable, joinable, or subsets of each other. Tabular neural models can be help-ful for such data discovery tasks. In this paper, we present TabSketchFM, a neural tabular model for data discovery over data lakes. First, we propose novel pre-training: a sketch-based approach to enhance the effectiveness of data discovery in neural tabular models. Second, we finetune the pretrained model for identifying unionable, joinable, and subset table pairs and show significant improvement over previous tabular neural models. Third, we present a detailed ablation study to highlight which sketches are crucial for which tasks. Fourth, we use these finetuned models to perform table search; i.e., given a query table, find other tables in a corpus that are unionable, joinable, or that are subsets of the query. Our results demonstrate significant improvements in F1 scores for search compared to state-of-the-art techniques. Finally, we show significant transfer across datasets and tasks establishing that our model can generalize across different tasks and over different data lakes.","2375-026X","979-8-3315-3603-9","10.1109/ICDE65448.2025.00118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113110","tabular foundational model;data discovery;data lakes;tabular transformer;tabular neural network","Representation learning;Big Data applications;Data engineering;Data models","","","","60","IEEE","20 Aug 2025","19-23 May 2025","19-23 May 2025","IEEE","IEEE Conferences"
"Autonomous Data Quality Monitoring with AI Agents: Integrating ML with Cloud Warehouses and Data Lakes","S. Chippagiri; K. Alang; A. Gumber; S. G. Thomas",NA; NA; NA; NA,2025 International Conference on Computing Technologies & Data Communication (ICCTDC),"22 Sep 2025","2025","","","1","7","Since storing data in cloud warehouses and lakes has increased, it is now important to rely on automation for keeping data accurate and trustworthy. It outlines an autonomous way of monitoring data quality by using AI agents with botnet techniques and cloud architecture. Key features of the system are that it constantly scans the data, finds unusual activities, detects any changes in the structure, and responds to any data updates without someone needing to act. Missed values, duplication, inconsistency, and noticing outliers on both structured and semi-structured data is done by using both supervised and unsupervised ML models. AI agents interact by way of a network pipeline and use reinforcement learning to pick the best solutions. easily set up Cloud Genomics in any leading cloud environment, and it works well with data warehouses as well as data lakes. Experimental evidence shows that AI-driven analysis is better at detecting errors, offering faster results, and being more adaptable than hand-made and rule-based ones. In this research, data pipelines can become more flexible and easier to manage in today's business architecture.","","979-8-3315-2798-3","10.1109/ICCTDC64446.2025.11157955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11157955","Data quality;AI agents;machine learning;data lakes;cloud data warehouse;autonomous systems;data monitoring;anomaly detection","Cloud computing;Data integrity;Pipelines;Genomics;Reinforcement learning;Data warehouses;Lakes;Big Data applications;Feature extraction;Monitoring","","","","18","IEEE","22 Sep 2025","4-5 July 2025","4-5 July 2025","IEEE","IEEE Conferences"
"Approximation of the Objective Functional in a Partially Defined Optimization Problem","Y. Kalinin; N. Kuchuk; D. Lysytsia","Tractors, Cars and Bioenergy Resources Department, National University of life and environmental sciences of Ukraine, Kyiv, Ukraine; Department of Computer Engineering and Programming, National Technical University «Kharkiv Polytechnic Institute», Kharkiv, Ukraine; Department of Computer Engineering and Programming, National Technical University «Kharkiv Polytechnic Institute», Kharkiv, Ukraine",2022 IEEE 3rd KhPI Week on Advanced Technology (KhPIWeek),"26 Oct 2022","2022","","","1","5","The reliable operation of today's complex technical systems often relies on remote software solutions for predicting their performance. To solve these tasks, client-server architectures, based on the database server, used to store the obtained data, as well as server-based data analyzers are taken advantage of. Due to the increasing complexity of tasks of diagnosing the state of complex technical systems, associated with the generation of higher volumes of data for assessing the current state of the diagnostic objects, the use of classical relational storage resulted in a significant increase in the requirements for cluster architectures. With the increasing use of technological solutions based on the “Big Data” architecture, there is a contradiction associated with the need to store large amounts of unstructured data for further structuring by methods of database schema development. The mission of Data Mining is the implementation of search operations applied to the laws of behavior and overall functioning of the system under study, consisting of numerical data. An obligatory condition that arises when using Data Mining methodologies is to interpret the resulting patterns formed as a consequence of determining the practical utility of the data. In this regard, there is a need to develop a method for optimizing large amounts of data, especially in partially defined tasks, allowing the distribution of the readings of the state of complex technical systems. Thus, the paper considers the problem of objective function approximation by the linear functional in a partially defined optimization problem, when the objective function is partially defined by comparing its values on some set of vectors from the acceptance region. Necessary and sufficient conditions for the existence of the approximating linear functional and the method of recovery of its coefficients through a linear correction procedure are formulated.","","979-8-3503-9920-2","10.1109/KhPIWeek57572.2022.9916497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9916497","optimization problem;approximation;reliable operation;linear functional;algorithm","Sufficient conditions;Databases;Computer architecture;Linear programming;Software;Software reliability;Data mining","","2","","22","IEEE","26 Oct 2022","3-7 Oct. 2022","3-7 Oct. 2022","IEEE","IEEE Conferences"
"Data-Driven Transformation in Investment Banks","B. Iraqi; L. Benhiba; M. A. Janati Idrissi","ENSIAS Mohammed V University in Rabat, Rabat, Morocco; ENSIAS Mohammed V University in Rabat, Rabat, Morocco; ENSIAS Mohammed V University in Rabat, Rabat, Morocco",2023 IEEE 6th International Conference on Cloud Computing and Artificial Intelligence: Technologies and Applications (CloudTech),"29 Dec 2023","2023","","","01","09","Digital transformation has become a major concern to all companies, and with data being at the center of this transformation, enterprises are increasingly shifting to a data-driven transformation where decision-making is based on facts and data. In sectors where data has always been in the center of all work processes, such as investment banking, data-driven transformation has even more importance as it allows a more tangible result generation. This paper aims to provide guidance to investment banks on their data-driven transformation journey by providing insights on the target culture, the patterns that could be adopted and phases that should be followed to roadmap this transformation. The paper also discusses when data architecture work starts, its drivers, challenges and risks to mitigate in order to ensure the highest performance levels possible. The objective is to getbetter sense of all dimensions to inspire investment banks to engage in this process.","","979-8-3503-0306-3","10.1109/CloudTech58737.2023.10366132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366132","investment banking;data analytics;data-driven transformation;data-driven enterprise;data architecture","Cloud computing;Data analysis;Digital transformation;Decision making;Computer architecture;Companies;Banking","","1","","19","IEEE","29 Dec 2023","21-23 Nov. 2023","21-23 Nov. 2023","IEEE","IEEE Conferences"
"Becoming a Salesforce Certified Technical Architect: Build a strong command of architectural principles and strategies to prepare for the CTA review board","T. Bahri",NA,Becoming a Salesforce Certified Technical Architect: Build a strong command of architectural principles and strategies to prepare for the CTA review board,"","2023","","","","","Gain practical experience designing and building high-performance, secure, and scalable Salesforce solutions using real-world scenarios. Purchase of the book unlocks access to web-based exam prep resource like flashcards. Purchase of the print or Kindle book includes a free eBook in PDF format.Key FeaturesMaster each knowledge domain by applying key concepts to a real-world scenarioPut all the skills covered in the book into action with two full mock scenariosGain access to additional online assets including flashcards and exam tipsBook DescriptionThis book is a complete guide to learning essential architectural concepts that’ll enable you to deliver secure, high-performant Salesforce solutions and pass the Salesforce CTA review board exam with confidence. This second edition comes with updated content, additional supporting material such as cheat sheets, and detailed practical examples, and helps you learn key soft skills to craft a winning presentation. You’ll begin by reviewing vital architectural concepts needed to create a scalable end-to-end Salesforce solution. Next, you’ll find out how to identify requirements and break down a problem into smaller, more solvable parts. As you advance, you’ll gain practical experience in managing design decisions and defending them using real-world scenarios. The book also helps familiarize you with the correct methodology to structure your solution presentation and the necessary supporting artifacts. Finally, you’ll practice providing solutions for two full hypothetical scenarios and structuring your playback step by step. By the end of this Salesforce book, you’ll be able to design a highly scalable Salesforce solution and create suitable material to comfortably explain the end-to-end solution to the CTA review board and potentially your customer, and have a higher chance of passing.What you will learnExplore core architectural concepts essential for any Salesforce architectUnderstand Salesforce knowledge domains using practical examplesPractice creating solutions using scenarios focusing on particular knowledge domainsDiscover key artifacts needed to document and explain an end-to-end solutionApply data life cycle management effectively in the Salesforce ecosystemDesign appropriate enterprise integration interfaces to build your connected solutionKnow what to expect on the day of the review board along with valuable tips and tricksWho this book is forThis book is for Salesforce architects who want to design secure, performant, and scalable technical solutions for their organizations and ultimately become Salesforce Certified Technical Architects. A solid understanding of the Salesforce platform is required, ideally combined with three to five years of practical experience as an application architect, system architect, enterprise architect, or solution architect.","","9781803239095","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251295.pdf&bkn=10251295&pdfType=book","","","","","","","","14 Sep 2023","","","Packt Publishing","Packt Publishing eBooks"
"Azure Data Factory Cookbook: Build ETL, Hybrid ETL, and ELT pipelines using ADF, Synapse Analytics, Fabric and Databricks","D. Foshin; T. Chernyshova; D. Anoshin; X. Ireton",NA; NA; NA; NA,"Azure Data Factory Cookbook: Build ETL, Hybrid ETL, and ELT pipelines using ADF, Synapse Analytics, Fabric and Databricks","","2024","","","","","Data Engineers guide to solve real-world problems encountered while building and transforming data pipelines using Azure's data integration toolKey FeaturesSolve real-world data problems and create data-driven workflows with ease using Azure Data FactoryBuild an ADF pipeline that operates on pre-built ML model and Azure AIGet up and running with Fabric Data Explorer and extend ADF with Logic Apps and Azure functionsBook DescriptionThis new edition of the Azure Data Factory book, fully updated to reflect ADS V2, will help you get up and running by showing you how to create and execute your first job in ADF. There are updated and new recipes throughout the book based on developments happening in Azure Synapse, Deployment with Azure DevOps, and Azure Purview. The current edition also runs you through Fabric Data Factory, Data Explorer, and some industry-grade best practices with specific chapters on each. You’ll learn how to branch and chain activities, create custom activities, and schedule pipelines, as well as discover the benefits of cloud data warehousing, Azure Synapse Analytics, and Azure Data Lake Gen2 Storage. With practical recipes, you’ll learn how to actively engage with analytical tools from Azure Data Services and leverage your on-premises infrastructure with cloud-native tools to get relevant business insights. You'll familiarize yourself with the common errors that you may encounter while working with ADF and find out the solutions to them. You’ll also understand error messages and resolve problems in connectors and data flows with the debugging capabilities of ADF. By the end of this book, you’ll be able to use ADF with its latest advancements as the main ETL and orchestration tool for your data warehouse projects.What you will learnBuild and Manage data pipelines with ease using the latest version of ADFConfigure, load data, and operate data flows with Azure SynapseGet up and running with Fabric Data FactoryWorking with Azure Data Factory and Azure PurviewCreate big data pipelines using Databricks and Delta tablesIntegrate ADF with commonly used Azure services such as Azure ML, Azure Logic Apps, and Azure FunctionsLearn industry-grade best practices for using Azure Data FactoryWho this book is forThis book is for ETL developers, data warehouse and ETL architects, software professionals, and anyone else who wants to learn about the common and not-so-common challenges faced while developing traditional and hybrid ETL solutions using Microsoft's Azure Data Factory. You’ll also find this book useful if you are looking for recipes to improve or enhance your existing ETL pipelines. Basic knowledge of data warehousing is a prerequisite.","","9781803241821","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10460868.pdf&bkn=10460868&pdfType=book","","","","","","","","6 Mar 2024","","","Packt Publishing","Packt Publishing eBooks"
"Enabling Unified and Scalable IoT Ecosystems: A Customisable Data Framework for Interoperability Across Heterogeneous Devices","P. G. Joshi; B. M. Deshpande","Department of Computer Science & Information Systems, BITS Pilani K K Birla Goa Campus, Goa, India; Department of Computer Science & Information Systems, BITS Pilani K K Birla Goa Campus, Goa, India",2024 International Conference on Computer and Applications (ICCA),"26 Mar 2025","2024","","","1","7","Managing the growing diversity of IoT devices and data formats presents significant challenges for integration and consistency within interconnected ecosystems. To address these, we propose a customizable JSON framework for unified data representation, enabling seamless communication between heterogeneous devices and IoT platforms. The framework defines a flexible JSON grammar that encapsulates device-specific attributes and metadata, ensuring interoperability and consistency. Devices communicate either directly or via gateways, with the structured data transmitted to a modular Data Collection Platform (DCP). The DCP validates and organizes the data for database integration, supporting dynamic adaptability to new device types and sensor inputs with minimal reconfiguration. Our experiments across domains such as environmental monitoring, industrial automation, automotive telematics, and smart home systems highlight the framework's ability to simplify data representation while maintaining consistency across platforms. By standardizing data formats, the framework enhances ease-of-use for analytics tools, enabling seamless interpretation and application of insights across diverse use cases. This paper presents a detailed implementation of the JSON framework and its architecture, emphasizing its ability to address device heterogeneity, ensure interoperability, and provide a consistent foundation for scalable IoT ecosystems.","","979-8-3503-6756-0","10.1109/ICCA62237.2024.10927793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10927793","Heterogeneous data;IoT Data Framework;IoT ecosystems;Unified data format;Scalable data architecture;Customisable data format;Dynamic adaptability;Data Interoperability;Data-centric IOT","Ecosystems;Data visualization;Smart homes;Logic gates;Metadata;Telematics;Internet of Things;Vehicle dynamics;Interoperability;Standards","","","","13","IEEE","26 Mar 2025","17-19 Dec. 2024","17-19 Dec. 2024","IEEE","IEEE Conferences"
"Experiences with Managing Data Ingestion into a Corporate Datalake","S. Rooney; D. Bauer; L. Garcés-Erice; P. Urbanetz; F. Froese; S. Tomic","Zurich Laboratory, IBM Research, Ruschlikon, Switzerland; Zurich Laboratory, IBM Research, Ruschlikon, Switzerland; Zurich Laboratory, IBM Research, Ruschlikon, Switzerland; Zurich Laboratory, IBM Research, Ruschlikon, Switzerland; Zurich Laboratory, IBM Research, Ruschlikon, Switzerland; Zurich Laboratory, IBM Research, Ruschlikon, Switzerland",2019 IEEE 5th International Conference on Collaboration and Internet Computing (CIC),"13 Feb 2020","2019","","","101","109","We explain our experiences in designing, building and running a large corporate Datalake. Our platform has been running for over two years and makes a wide variety of corporate data assets, such as sales, marketing, customer information, as well as data from less conventional sources such as weather, news and social media available for analytics purposes to many teams across the company. We focus on describing the management of data and in particular how it is transferred and ingested into the platform.","","978-1-7281-6739-8","10.1109/CIC48465.2019.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998484","Data Lake;data ingestion;Hadoop;Enterprise","Tools;Companies;Distributed databases;Standards;Relational databases;Sparks","","7","","25","IEEE","13 Feb 2020","12-14 Dec. 2019","12-14 Dec. 2019","IEEE","IEEE Conferences"
"CCIR: An Architecture for Collecting and Storing Connnected Corridor Infrastructure and Mobility Data","L. Bonilla; J. López-De-Armentia; G. Zarate; A. I. Torre-Bastida; L. Vigo; P. Bidaguren; O. Alonso; A. Capelastegui","TECNALIA, Basque Research Technology Alliance (BRTA) Parque Científico y Tecnológico de Bizkaia, Derio, Spain; TECNALIA, Basque Research Technology Alliance (BRTA) Parque Científico y Tecnológico de Bizkaia, Derio, Spain; TECNALIA, Basque Research Technology Alliance (BRTA) Parque Científico y Tecnológico de Bizkaia, Derio, Spain; TECNALIA, Basque Research Technology Alliance (BRTA) Parque Científico y Tecnológico de Bizkaia, Derio, Spain; TECNALIA, Basque Research Technology Alliance (BRTA) Parque Científico y Tecnológico de Bizkaia, Derio, Spain; TECNALIA, Basque Research Technology Alliance (BRTA) Parque Científico y Tecnológico de Bizkaia, Derio, Spain; TECNALIA, Basque Research Technology Alliance (BRTA) Parque Científico y Tecnológico de Bizkaia, Derio, Spain; TECNALIA, Basque Research Technology Alliance (BRTA) Parque Científico y Tecnológico de Bizkaia, Derio, Spain",2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC),"13 Feb 2024","2023","","","5344","5350","Connected corridors are programs and initiatives that emerge under the umbrella of major paradigms such as SmartCities, Big Data, Artificial Intelligence or Internet of Things (IoT). Their main objective is to provide environments for testing, validating and demonstrating all kinds of technologies related to Cooperative, Connected and Autonomous Mobility, and Intelligent and Digital Infrastructures, within a real scenario. These corridors need to equip themselves with new intelligent and extremely powerful systems, based on technologies such as intelligent traffic systems. They aim to enhance and evolve these systems by leveraging the possibilities and solutions offered by this new wave of disruptive technologies allows. In this article, we describe the needs of a crucial component for connected corridors, such as the information repository, and we propose its possible technological implementation using the Data Lake paradigm, with a focus on data interoperability as a primary requirement. Finally, we validate the significant usefulness of the proposed architecture for the connected corridor information repository, called CCIR, through the concrete implementation of a specific collaborative corridor, such as the Bizkaia Connected Corridor - BCC is. To demonstrate it, we present different use cases that exploit the data generated and collected in the BCC environment relative to the infrastructure and mobility domain.","2153-0017","979-8-3503-9946-2","10.1109/ITSC57777.2023.10422103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10422103","","Data visualization;Big Data applications;Internet of Things;Time factors;Interoperability;Testing;Geographic information systems","","","","18","IEEE","13 Feb 2024","24-28 Sept. 2023","24-28 Sept. 2023","IEEE","IEEE Conferences"
"Development of the Concept and Architecture of an Automated System for Updating Physical Knowledge for Information Support of Search Design","A. Bobunov; D. Korobkin; S. Fomenkov","CAD Department, Volgograd State Technical University, Volgograd, Russia; CAD Department, Volgograd State Technical University, Volgograd, Russia; CAD Department, Volgograd State Technical University, Volgograd, Russia",2023 International Russian Smart Industry Conference (SmartIndustryCon),"1 May 2023","2023","","","281","288","For developing an automated system for updating physical knowledge for information support of search design, it is necessary to choose a technology stack that would meet the implementation requirements. In view of the sanctions currently imposed on the Russian Federation, it is worth considering mainly open projects and/or domestic developments. We will highlight the main criteria that it is desirable to take into account when designing the architecture of an automated system to support the synthesis of new technical systems and technologies: (a) ability to store and process large amounts of data; (b) unification access for all data analysis procedures; (c) maximum automation of all stages; (d) modularity of the structure, focus on the expansion of functionality; (e) focus on open source solutions and software of domestic manufacturers, excluding rigid binding to paid foreign solutions. As a result of the work done, various aspects of the implementation of the required automated system were analyzed. A review of various software systems and cloud products showed that the concept of building data lakes (Data Lake) in conjunction with the distributed processing tools of the Apache Hadoop ecosystem is used for big data processing. An architecture framework based on a centralized data warehouse and Hadoop components is proposed. It will be possible to increase the functionality of the platform by adding new microservices that connect to the storage and distributed processing tools via the API, as well as using a single web service for managing and displaying data analysis results from these microservices.","","978-1-6654-6429-1","10.1109/SmartIndustryCon57312.2023.10110764","Russian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10110764","architecture;physical knowledge;information support;search design","Distributed processing;Data analysis;Web services;Architecture;Ecosystems;Microservice architectures;Computer architecture","","3","","20","IEEE","1 May 2023","27-31 March 2023","27-31 March 2023","IEEE","IEEE Conferences"
"Research and implementation of customizable automated deployment methods in cloud PaaS","M. Wang","Guangzhou Huashang Vocational College, Guangzhou, China","2023 IEEE International Conference on Sensors, Electronics and Computer Engineering (ICSECE)","29 Sep 2023","2023","","","1162","1166","This paper proposes an automatic PaaS deployment method for secret-related form attachments. Block processing model is introduced to simplify vector relational data architecture. Establish a contiguous neighbor relationship with scattered data to determine the direction and spatial value of specific parts. The system can upload, register, encrypt, store, download and manage secret-related attachments. This paper completes the overall architecture, realizing capability integration, layered scheduling of multi-application types, multi-tenant and resource scheduling management, and automatic deployment of global optimization. System simulation shows that the average storage time of this scheme is better. The data space is small.","","979-8-3503-1373-4","10.1109/ICSECE58870.2023.10263579","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10263579","PaaS;Automated deployment;Average time spent;Redundant data;Form attachment","Computer architecture;Aerospace electronics;Data models;Systems simulation;Sensors;Registers;Servers","","","","11","IEEE","29 Sep 2023","18-20 Aug. 2023","18-20 Aug. 2023","IEEE","IEEE Conferences"
"A Machine Learning-based Approach for Advanced Monitoring of Automated Equipment for the Entertainment Industry","M. Berno; M. Canil; N. Chiarello; L. Piazzon; F. Berti; F. Ferrari; A. Zaupa; N. Ferro; M. Rossi; G. A. Susto","Department of Information Engineering, Padova, Italy; Department of Information Engineering, Padova, Italy; Department of Information Engineering, Padova, Italy; Department of Information Engineering, Padova, Italy; Antonio Zamperla S.p.A., Italy; Antonio Zamperla S.p.A., Italy; Antonio Zamperla S.p.A., Italy; Department of Information Engineering, Padova, Italy; Department of Information Engineering, Padova, Italy; Department of Information Engineering, Padova, Italy",2021 IEEE International Workshop on Metrology for Industry 4.0 & IoT (MetroInd4.0&IoT),"27 Jul 2021","2021","","","386","391","Machine Learning-based approaches are revolutionizing the way in which complex systems and machines are monitored and controlled. In this work, we present a smart monitoring system that combines a Big Data architecture with an unsupervised anomaly detection technique, targeting the automated equipment in the entertainment industry. Anomaly detection uses state-of-the-art univariate and multivariate algorithms, as well as recently proposed techniques in the field of explainable artificial intelligence, to achieve enhanced monitoring capabilities and optimize service operations. The monitoring system is here presented and tested on a real world case study, i.e., an amusement park ride.","","978-1-6654-1980-2","10.1109/MetroInd4.0IoT51437.2021.9488481","MIUR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9488481","anomaly detection;big data;entertainment industry;explainable artificial intelligence;industry 4.0;predictive maintenance;unsupervised learning","Machine learning algorithms;Entertainment industry;Learning (artificial intelligence);Big Data;Complex systems;Monitoring;Anomaly detection","","7","","14","IEEE","27 Jul 2021","7-9 June 2021","7-9 June 2021","IEEE","IEEE Conferences"
"AWS for Solutions Architects: The definitive guide to AWS Solutions Architecture for migrating to, building, scaling, and succeeding in the cloud","S. Shrivastava; N. Srivastav; A. Artasanchez; I. Sayed; D. S. C. Ph.D",NA; NA; NA; NA; NA,"AWS for Solutions Architects: The definitive guide to AWS Solutions Architecture for migrating to, building, scaling, and succeeding in the cloud","","2023","","","","","Become a master Solutions Architect with this comprehensive guide, featuring cloud design patterns and real-world solutions for building scalable, secure, and highly available systems Purchase of the print or Kindle book includes a free eBook in PDF format.Key FeaturesGain expertise in automating, networking, migrating, and adopting cloud technologies using AWSUse streaming analytics, big data, AI/ML, IoT, quantum computing, and blockchain to transform your businessUpskill yourself as an AWS solutions architect and explore details of the new AWS certificationBook DescriptionAre you excited to harness the power of AWS and unlock endless possibilities for your business? Look no further than the second edition of AWS for Solutions Architects! Packed with all-new content, this book is a must-have guide for anyone looking to build scalable cloud solutions and drive digital transformation using AWS.  This updated edition offers in-depth guidance for building cloud solutions using AWS. It provides detailed information on AWS well-architected design pillars and cloud-native design patterns. You'll learn about networking in AWS, big data and streaming data processing, CloudOps, and emerging technologies such as machine learning, IoT, and blockchain. Additionally, the book includes new sections on storage in AWS, containers with ECS and EKS, and data lake patterns, providing you with valuable insights into designing industry-standard AWS architectures that meet your organization's technological and business requirements. Whether you're an experienced solutions architect or just getting started with AWS, this book has everything you need to confidently build cloud-native workloads and enterprise solutions.What you will learnOptimize your Cloud Workload using the AWS Well-Architected FrameworkLearn methods to migrate your workload using the AWS Cloud Adoption FrameworkApply cloud automation at various layers of application workload to increase efficiencyBuild a landing zone in AWS and hybrid cloud setups with deep networking techniquesSelect reference architectures for business scenarios, like data lakes, containers, and serverless appsApply emerging technologies in your architecture, including AI/ML, IoT and blockchainWho this book is forThis book is for application and enterprise architects, developers, and operations engineers who want to become well versed with AWS architectural patterns, best practices, and advanced techniques to build scalable, secure, highly available, highly tolerant, and cost-effective solutions in the cloud. Existing AWS users are bound to learn the most, but it will also help those curious about how leveraging AWS can benefit their organization. Prior knowledge of any computing language is not needed, and there’s little to no code. Prior experience in software architecture design will prove helpful.","","9781803244822","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251173.pdf&bkn=10251173&pdfType=book","","","","","","","","14 Sep 2023","","","Packt Publishing","Packt Publishing eBooks"
"BLEND: A Unified Data Discovery System","M. Esmailoghli; C. Schnell; R. J. Miller; Z. Abedjan","TU Berlin & BIFOLD, Berlin, Germany; Leibniz Universität Hannover, Hannover, Germany; University of Waterloo, Waterloo, Canada; TU Berlin & BIFOLD, Berlin, Germany",2025 IEEE 41st International Conference on Data Engineering (ICDE),"20 Aug 2025","2025","","","737","750","Most research on data discovery has so far focused on improving individual discovery operators such as join, correlation, or union discovery. However, in practice, a combination of these techniques and their corresponding indexes may be necessary to support arbitrary discovery tasks. We propose BLEND, a comprehensive data discovery system that supports existing operators and enables their flexible pipelining. BLEND is based on a set of lower-level operators that serve as fundamental building blocks for more complex and sophisticated user tasks. To reduce the execution runtime of discovery pipelines, we propose a unified index structure and a rule- and cost-based optimizer that rewrites SQL statements into low-level operators when possible. We show the superior flexibility and efficiency of our system compared to ad-hoc discovery pipelines and stand-alone solutions.","2375-026X","979-8-3315-3603-9","10.1109/ICDE65448.2025.00061","German Research Foundation(grant numbers:387872445); NSF(grant numbers:IIS-2107248,IIS-1956096,IIS-2325632); Canada Excellence Research Chairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112882","join discovery;join;union;data discovery system;correlation search;data lake;index structure;keyword search;data discovery","Correlation;Runtime;Keyword search;Data engineering;Big Data applications;Indexes;Pipeline processing","","1","","70","IEEE","20 Aug 2025","19-23 May 2025","19-23 May 2025","IEEE","IEEE Conferences"
"Transformative education Web 2.0 systems for enriching high school STEM education","R. G. Qiu; D. Lee","Division of Engineering, USA & NUAA-IBM Logistics and Service Science Lab NUAA, Nanjing, China; Division of Education, Great Valley, Malvern, PA, USA",2013 IEEE 4th International Conference on Software Engineering and Service Science,"30 Sep 2013","2013","","","352","356","There are currently over a hundred STEM (Science, Technology, Engineering, and Mathematics) programs in the U.S., aimed at encouraging students to enter a STEM-related career. Of the fields encompassed by STEM, mathematics is the foundation. However, American teens have demonstrated less ability and aptitude for mathematics than the teens in many other countries. Efforts to reduce this ability gap have focused on building a better communal structure within schools, creating more cohesive math curricula, offering smaller classes, encouraging cooperative learning, and helping students overcome math anxiety at school. There is very little published literature on the potential of guided cyber-based self-learning in STEM education, although there are a variety of online STEM learning web sites available for students to access at or after school. In particular, no scientific approach exists to address STEM education challenges in an outside-school setting. The paper briefly unveil an approach to transformatively addressing how mathematics learning, outside of a formal high school setting, could contribute to students' math aptitude. A Web 2.0 system has been deployed, focusing on promoting students' collaborative learning. A big data architecture is applied to addressing voluminous data, which ensures that unstructured Web 2.0 data are always ready for analysis in real time.","2327-0594","978-1-4673-5000-6","10.1109/ICSESS.2013.6615322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6615322","STEM (Science, Technology, Engineering, and Mathematics);high school;self-learning systems;web 2.0;transformative education;big data","Collaboration;Simple object access protocol;Logic gates;Transforms;Artificial neural networks","","3","","17","IEEE","30 Sep 2013","23-25 May 2013","23-25 May 2013","IEEE","IEEE Conferences"
"Data Engineering with Google Cloud Platform: A practical guide to operationalizing scalable data analytics systems on GCP","A. Wijaya",NA,Data Engineering with Google Cloud Platform: A practical guide to operationalizing scalable data analytics systems on GCP,"","2022","","","","","Build and deploy your own data pipelines on GCP, make key architectural decisions, and gain the confidence to boost your career as a data engineerKey FeaturesUnderstand data engineering concepts, the role of a data engineer, and the benefits of using GCP for building your solutionLearn how to use the various GCP products to ingest, consume, and transform data and orchestrate pipelinesDiscover tips to prepare for and pass the Professional Data Engineer examBook DescriptionWith this book, you'll understand how the highly scalable Google Cloud Platform (GCP) enables data engineers to create end-to-end data pipelines right from storing and processing data and workflow orchestration to presenting data through visualization dashboards. Starting with a quick overview of the fundamental concepts of data engineering, you'll learn the various responsibilities of a data engineer and how GCP plays a vital role in fulfilling those responsibilities. As you progress through the chapters, you'll be able to leverage GCP products to build a sample data warehouse using Cloud Storage and BigQuery and a data lake using Dataproc. The book gradually takes you through operations such as data ingestion, data cleansing, transformation, and integrating data with other sources. You'll learn how to design IAM for data governance, deploy ML pipelines with the Vertex AI, leverage pre-built GCP models as a service, and visualize data with Google Data Studio to build compelling reports. Finally, you'll find tips on how to boost your career as a data engineer, take the Professional Data Engineer certification exam, and get ready to become an expert in data engineering with GCP. By the end of this data engineering book, you'll have developed the skills to perform core data engineering tasks and build efficient ETL data pipelines with GCP.What you will learnLoad data into BigQuery and materialize its output for downstream consumptionBuild data pipeline orchestration using Cloud ComposerDevelop Airflow jobs to orchestrate and automate a data warehouseBuild a Hadoop data lake, create ephemeral clusters, and run jobs on the Dataproc clusterLeverage Pub/Sub for messaging and ingestion for event-driven systemsUse Dataflow to perform ETL on streaming dataUnlock the power of your data with Data StudioCalculate the GCP cost estimation for your end-to-end data solutionsWho this book is forThis book is for data engineers, data analysts, and anyone looking to design and manage data processing pipelines using GCP. You'll find this book useful if you are preparing to take Google's Professional Data Engineer exam. Beginner-level understanding of data science, the Python programming language, and Linux commands is necessary. A basic understanding of data processing and cloud computing, in general, will help you make the most out of this book.","","9781800565067","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10162346.pdf&bkn=10162346&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Leveraging the Data Continuum for Advanced Root Cause Analysis","P. Barar; E. McCormick","Smart Manufacturing Synopsys, Inc, Austin, TX, United States; Factory Controls Qorvo, Inc, Richardson, TX, United States",2024 35th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC),"6 Jun 2024","2024","","","01","05","As semiconductor processing has developed and become increasingly complex over time, the amount of data and sources of data have also increased. This trend complicates the data analysis tasks performed by many fab engineers throughout the industry, requiring the need to gather data from multiple sources and reach conclusions quickly and efficiently. In the case of root cause analysis for a deviation or excursion, it is especially important for analysis solutions to pinpoint possible root causes quickly and allow the engineer to contain and resolve the issue before it becomes a major quality incident. Today, there are effective solutions to address some of these cases. However, more advanced and automated analysis solutions are needed to unlock interactivity across the full data continuum not only within the fab, but across the life cycle of the device. One approach, which is used by the new Fab.da solution provided by Synopsys, organizes the individual data components into a data lakehouse, demonstrates performance improvements when compared to older technologies, and unlocks new use cases in the areas of decision support and joining with data from the design and mask optimization space.","2376-6697","979-8-3503-8455-0","10.1109/ASMC61125.2024.10545529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10545529","","Performance evaluation;Root cause analysis;Correlation;Databases;Soft sensors;Process control;Semiconductor device manufacture","","","","12","IEEE","6 Jun 2024","13-16 May 2024","13-16 May 2024","IEEE","IEEE Conferences"
"What About the Data? A Mapping Study on Data Engineering for AI Systems","P. Heck","Fontys University of Applied Sciences, Eindhoven, Netherlands",2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN),"18 Jun 2024","2024","","","43","52","AI systems cannot exist without data. Now that AI models (data science and AI) have matured and are readily available to apply in practice, most organizations struggle with the data infrastructure to do so. There is a growing need for data engineers that know how to prepare data for AI systems or that can setup enterprise-wide data architectures for analytical projects. But until now, the data engineering part of AI engineering has not been getting much attention, in favor of discussing the modeling part. In this paper we aim to change this by perform a mapping study on data engineering for AI systems, i.e., AI data engineering. We found 25 relevant papers between January 2019 and June 2023, explaining AI data engineering activities. We identify which life cycle phases are covered, which technical solutions or architectures are proposed and which lessons learned are presented. We end by an overall discussion of the papers with implications for practitioners and researchers. This paper creates an overview of the body of knowledge on data engineering for AI. This overview is useful for practitioners to identify solutions and best practices as well as for researchers to identify gaps.CCS CONCEPTS•Software and its engineering;•Information systems→Data structures;•Computing methodologies → Artificial intelligence;","","979-8-4007-0591-5","","Nederlandse Organisatie voor Wetenschappelijk Onderzoek; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556368","data-centric AI;AI engineering;data engineering;data architecture;DataOps;MLOps;data quality","Training;Pipelines;Computer architecture;Production;Data engineering;Data models;Software","","3","","50","","18 Jun 2024","14-15 April 2024","14-15 April 2024","IEEE","IEEE Conferences"
"Data Engineering with Apache Spark, Delta Lake, and Lakehouse: Create scalable pipelines that ingest, curate, and aggregate complex data in a timely and secure way","M. Kukreja; D. Zburivsky",NA; NA,"Data Engineering with Apache Spark, Delta Lake, and Lakehouse: Create scalable pipelines that ingest, curate, and aggregate complex data in a timely and secure way","","2021","","","","","Understand the complexities of modern-day data engineering platforms and explore strategies to deal with them with the help of use case scenarios led by an industry expert in big dataKey FeaturesBecome well-versed with the core concepts of Apache Spark and Delta Lake for building data platformsLearn how to ingest, process, and analyze data that can be later used for training machine learning modelsUnderstand how to operationalize data models in production using curated dataBook DescriptionIn the world of ever-changing data and schemas, it is important to build data pipelines that can auto-adjust to changes. This book will help you build scalable data platforms that managers, data scientists, and data analysts can rely on. Starting with an introduction to data engineering, along with its key concepts and architectures, this book will show you how to use Microsoft Azure Cloud services effectively for data engineering. You'll cover data lake design patterns and the different stages through which the data needs to flow in a typical data lake. Once you've explored the main features of Delta Lake to build data lakes with fast performance and governance in mind, you'll advance to implementing the lambda architecture using Delta Lake. Packed with practical examples and code snippets, this book takes you through real-world examples based on production scenarios faced by the author in his 10 years of experience working with big data. Finally, you'll cover data lake deployment strategies that play an important role in provisioning the cloud resources and deploying the data pipelines in a repeatable and continuous way. By the end of this data engineering book, you'll know how to effectively deal with ever-changing data and create scalable data pipelines to streamline data science, ML, and artificial intelligence (AI) tasks.What you will learnDiscover the challenges you may face in the data engineering worldAdd ACID transactions to Apache Spark using Delta LakeUnderstand effective design strategies to build enterprise-grade data lakesExplore architectural and design patterns for building efficient data ingestion pipelinesOrchestrate a data pipeline for preprocessing data using Apache Spark and Delta Lake APIsAutomate deployment and monitoring of data pipelines in productionGet to grips with securing, monitoring, and managing data pipelines models efficientlyWho this book is forThis book is for aspiring data engineers and data analysts who are new to the world of data engineering and are looking for a practical guide to building scalable data platforms. If you already work with PySpark and want to use Delta Lake for data engineering, you'll find this book useful. Basic knowledge of Python, Spark, and SQL is expected.","","9781801074322","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163257.pdf&bkn=10163257&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Urban Intelligence: a Modular, Fully Integrated, and Evolving Model for Cities Digital Twinning","G. Castelli; A. Cesta; M. Diez; M. Padula; P. Ravazzani; G. Rinaldi; S. Savazzi; M. Spagnuolo; L. Strambini; G. Tognola; E. F. Campana","Engineering, ICT and Technology for Energy and Transportation Dept. (DIITET), National Research Council (CNR), Rome, Italy; Institute of Cognitive Sciences and Technologies (ISTC), National Research Council (CNR), Rome, Italy; Institute of Marine Engineering (INM), National Research Council (CNR), Rome, Italy; Construction Technologies Institute (ITC), National Research Council (CNR), Milan, Italy; Institute of Electronics, Computer and Telecommunication, Engineering (IEIIT), National Research Council, (CNR), Milan, Italy; Institute for Systems Analysis and Computer Science (IASI), National Research Council (CNR), Rome, Italy; Institute of Electronics, Computer and Telecommunication, Engineering (IEIIT), National Research Council (CNR), Milan, Italy; Institute for Applied Mathematics and Information Technologies (IMATI), National Research Council (CNR), Genoa, Italy; Institute of Electronics, Computer and Telecommunication, Engineering (IEIIT), National Research Council (CNR), Milan, Italy; Institute of Electronics, Computer and Telecommunication, Engineering (IEIIT), National Research Council, (CNR), Milan, Italy; Engineering, ICT and Technology for Energy and Transportation Dept. (DIITET), National Research Council (CNR), Rome, Italy",2019 IEEE 16th International Conference on Smart Cities: Improving Quality of Life Using ICT & IoT and AI (HONET-ICT),"21 Nov 2019","2019","","","033","037","The Urban Intelligence (UI) paradigm proposes an ecosystem of technologies to improve urban environment, wellbeing, quality of life and smart city systems. It fosters the definition of a digital twin of the city, namely a cyber-physical counterpart of all the city systems and sub-systems. Here we propose a novel approach to UI that extends available frameworks combining advanced multidisciplinary modelling of the city, simulation and learning tools with numerical optimization techniques, each of them specialized for the digital representation of city systems and subsystems, including not only city infrastructures, but also city users and their interactions. UI provides sets of candidate policies in complex scenarios and supports policy makers and stakeholders in designing sustainable and personalized solutions. The main characteristics of the proposed UI architecture are (a) fully multidisciplinary integration of city layers, (b) connection and evolution with the city, (c) integration of participative strategies to include “human-oriented” information, and (d) modularity of application.","1949-4106","978-1-7281-3971-5","10.1109/HONET.2019.8907962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907962","digital twins;decision making;multidisciplinary analysis and optimization;data lake management;wireless sensing;data/model driven learning and reasoning;know-how integration","Urban areas;Sensors;Data models;Computational modeling;Analytical models;Numerical models;Optimization","","29","","22","IEEE","21 Nov 2019","6-9 Oct. 2019","6-9 Oct. 2019","IEEE","IEEE Conferences"
"Using Extraction, Transformation and Loading Procedures for Digitalisation of Buildings","J. L. Hernández; D. Arévalo; S. Martín; K. Katsigarakis; G. N. Lilis; D. Rovas; I. De Miguel","Energy Division, CARTIF technology centre, Boecillo, Spain; Energy Division, CARTIF technology centre, Boecillo, Spain; Energy Division, CARTIF technology centre, Boecillo, Spain; IEDE, University College London, London, UK; IEDE, University College London, London, UK; IEDE, University College London, London, UK; Universidad de Valladolid, Valladolid, Spain",2024 9th International Conference on Smart and Sustainable Technologies (SpliTech),"5 Aug 2024","2024","","","1","6","The digitalisation of the building stock necessitates the integration of a wide array of digital and non-digital data sources into a cohesive framework that adheres to standardized data formats. Achieving this integration involves employing various extraction, transformation, and loading processes. These processes play a crucial role in converting raw data collected from building sites into instances that align with the specified unified format. This work delves into extraction, transformation, and loading methods utilized across nine pilot building sites situated in different countries, each marked by substantial data diversity. The heterogeneity among data sources and, consequently, datasets, is effectively addressed by a customized gathering process. This process incorporates static data to enhance the overall quality, enabling better-informed decision-making. The result is a harmonized building data repository with 10 use cases and more than 8000 data points, facilitating the application of intelligent services for energy-efficient management strategies. Enrichment of data is also achieved by synchronization approaches to ensure the coherence of the data.","","978-953-290-135-1","10.23919/SpliTech61897.2024.10612635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612635","Data lake;Extraction;Transformation and Loading (ETL);interoperability;data syncing;timeseries;static data","Databases;Soft sensors;Buildings;Loading;Decision making;Transforms;Synchronization","","1","","13","","5 Aug 2024","25-28 June 2024","25-28 June 2024","IEEE","IEEE Conferences"
"Local Ontologies Merging in Data Ponds","J. Kachaoui; A. Belangour","Information Technology and Modeling, Hassan II University, Casablanca, Morocco; Information Technology and Modeling, Hassan II University, Casablanca, Morocco",2020 International Conference on Intelligent Systems and Computer Vision (ISCV),"23 Sep 2020","2020","","","1","7","Today, Ontologies have a major place in knowledge representation and modeling. They are used to formalize a domain knowledge and add a semantic layer to current systems and applications. Ontologies make it possible to explicitly represent the knowledge of a domain by means a formal language so that they can be manipulated automatically and shared easily. They are widely used in various fields of research such as Knowledge Representation (KR) and Data Integration (DI). However, the effectiveness to interoperate learning objects among various learning object repositories is often decreased because of using different ontological schemes for annotating learning objects into every learning object repository. Hence, semantic heterogeneity and structural differences between ontologies need to be resolved so as to generate common ontology to expedite learning object reusability. This paper focused on automated ontology mapping and merging concept. The study significance lies in an algorithmic approach for mapping attributes of learning objects/concepts and merging them based on mapped attributes; identifying suitable threshold value for mapping and merging.","","978-1-7281-8041-0","10.1109/ISCV49265.2020.9204097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204097","Ontology;Data Lake;Knowledge representation;Semantic;Data Ponds","Computer vision;Heuristic algorithms;Merging;Semantics;Buildings;Formal languages;Data integration","","1","","45","IEEE","23 Sep 2020","9-11 June 2020","9-11 June 2020","IEEE","IEEE Conferences"
"An Integrated Blockchain Approach for Provenance of Rotorcraft Maintenance Data","J. R. Zayas; E. O'Neill; M. A. Seale; A. Ruvinsky; O. Eslinger","University of Puerto Rico at Mayagüez, Mayagüez, P.R.; University of Puerto Rico at Mayagüez, Mayagüez, P.R.; U.S. Army Engineer, Research, and Development Center, Vicksburg, Mississippi, USA; U.S. Army Engineer, Research, and Development Center, Vicksburg, Mississippi, USA; U.S. Army Engineer, Research, and Development Center, Vicksburg, Mississippi, USA",2020 IEEE Aerospace Conference,"21 Aug 2020","2020","","","1","8","The U.S. Army Engineer Research and Development Center's Information Technology Laboratory (ITL) is creating a Data Lake Ecosystem to support efficient storage, querying and analysis of terabyte-scale datasets within a High Performance Computing (HPC) environment. The datasets contain important current and historical data, and many datasets may be related to a single subject. The ecosystem must support the ability to perform holistic analysis across datasets and must ensure data integrity and security. For the latter, it is essential to keep a record of the creation and operations performed on a Data Lake object. This type of record-keeping is called data provenance. Assured data provenance can help detect the creation, manipulation, and deletion of objects within the Data Lake Ecosystem. However, developing assured data provenance remains a critical issue. There are challenges in secure collection and storage, verifiability, and privacy of the provenance data. Hence, there is a need for guaranteeing the security and integrity of data provenance for a Data Lake Ecosystem. In this paper, we propose a trusted data provenance application for rotorcraft maintenance data based on blockchain technology. Blockchain-based data provenance facilitates recording and tracking by treating the data as relevant assets in a transactional network. We designed and implemented a proof-of-concept application to collect and verify Data Lake provenance by embedding the data provenance on a private blockchain platform. This application allows the replication of data provenance on every node of a trusted closed network, ensuring high availability and fault tolerance. With the proposed blockchain model, data provenance for unique Data Lake objects can be stored securely and efficiently verified. Results from evaluations demonstrate that with blockchain technology, it is possible to provide secure, immutable, and reliable data provenance that is essential for maintaining the integrity of information in a Data Lake environment.","1095-323X","978-1-7281-2734-7","10.1109/AERO47225.2020.9172700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172700","","Ecosystems;Big Data applications;Data models;Stability analysis;Blockchains;Maintenance;Security;Streams;Secure storage;Research and development","","1","","12","IEEE","21 Aug 2020","7-14 March 2020","7-14 March 2020","IEEE","IEEE Conferences"
"An Engineering Data Trusted Sharing Service Platform Based on Blockchain","Q. Shen","Information Center, CCCC Fourth HarborEngineering Co., LTD, Guangzhou, China",2025 10th International Conference on Computer and Communication System (ICCCS),"14 Jul 2025","2025","","","210","214","With the digital transformation of enterprises, the requirements for the integration of systems in the construction industry are getting higher and higher. Data standardization, system decoupling and data docking, and data lake warehouse construction have become one of the key research directions. Traditional data storage and sharing methods are often vulnerable to various threats and attacks, and there are risks of tampering, deletion, forgery, and leakage. This paper builds an engineering data trusted sharing service platform based on blockchain technology, which improves the blockchain using the SM2 elliptic curve public key cryptography algorithm and SM3 cryptographic hash algorithm. This platform can be applied to various types of engineering enterprises to achieve convenient and secure sharing of engineering data.","2995-3251","979-8-3315-2314-5","10.1109/ICCCS65393.2025.11069819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11069819","Engineering data;blockchain;data sharing;national secret algorithm;data collection","Elliptic curves;Distributed ledger;Memory;Standardization;Public key cryptography;Forgery;Fabrics;Blockchains;Secure storage;Construction industry","","","","11","IEEE","14 Jul 2025","18-21 April 2025","18-21 April 2025","IEEE","IEEE Conferences"
"Digital Twin Ready Data Available in the Green Deal Data Space","J. Masó; A. Brobia; M. Zamzov; I. Serall; T. Hodson; R. Palma; F. Noardo; L. Bastin; V. Lush",CREAF; CREAF; KWB Kompetenz Wasser Berlin; CREAF; ECMWF; Poznan Supercomputing and Networking Center; OGC; Aston University; Aston University,IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium,"5 Sep 2024","2024","","","3589","3591","The Destination Earth (DestinE) initiative will develop and deploy a service infrastructure of computer processing, data and software. The Green Deal Data Space will organize the available data to contribute to the data lake of the DestinE infrastructure. This paper focuses on how to overcome data challenges in the Green Deal Data Space by producing Digital Twin Ready Data under the big data paradigm. In the Green Deal Data Space, the traditional organization of data in layers is no longer efficient as data is constantly evolving and mixed in new ways. First, there is a need for a new organization based on a flexible and encompassing Information Model composed by a suite of ontologies reusing best practices, and existing standards. Secondly, dynamic multidimensional data cubes replace the traditional two-dimensional view. Third, the OGC APIs offer a set of building blocks to implement data filtering for extracting the data with its provenance metadata.The AD4GD project will demonstrate the proposed capabilities of the Green Deal Data Space in three pilots about water pollution in Berlin’s small lakes, biodiversity connectivity in Catalonia and air quality for the Copernicus Atmosphere Monitoring Service.While data spaces should allow for data exchange in a secure environment that enabling the digital economy, this aspects are out of scope of this communication.","2153-7003","979-8-3503-6032-5","10.1109/IGARSS53475.2024.10641950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10641950","Data space;semantics;data cubes;APIs;digital twin","Vocabulary;Filtering;Green products;Standards organizations;Europe;Organizations;Extraterrestrial measurements","","","","13","IEEE","5 Sep 2024","7-12 July 2024","7-12 July 2024","IEEE","IEEE Conferences"
"Bringing Extract, Transform, and Load to Life via Agentic AI","G. Hurlburt","Board of Advisors, University System of Maryland at Southern Maryland, California, MD, USA",IT Professional,"22 Dec 2025","2025","27","6","90","95","The process of extraction, transform, and load (ETL) is multifaceted, incorporating many often-laborious batch processing techniques to 1) extract data from disparate multimedia sources, 2) transform these data in accordance with a known data architecture or schema, and 3) seamlessly load the properly conditioned data into a structured repository, which can take many forms. Applied agentic artificial intelligence offers the potential for ETL to be fully automated with often missing semantic analysis elements, performing accurately in real time, with human intervention required only to resolve potential conflicts as they arise.","1941-045X","","10.1109/MITP.2025.3632496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11311402","","Engineering profession;Semantics;Batch production systems;Real-time systems;Data mining;Information analysis","","","","9","IEEE","22 Dec 2025","Nov.-Dec. 2025","","IEEE","IEEE Magazines"
"Real-Time Tracking of Aircrafts in Crowdsourced Air Traffic Networks with Simple Localization Estimates","A. C. Bannour; R. Moussa; T. Bejaoui","LaTICE Lab, University of Tunis, Tunis, Tunisia; LaTICE Lab, University of Tunis, Tunis, Tunisia; MEDIATRON Lab, University of Carthage, Tunis, Tunisia","2020 International Symposium on Networks, Computers and Communications (ISNCC)","25 Dec 2020","2020","","","1","6","Crowd-sourced air traffic communication networks have gained importance over the past decade. They use distributed networks that are randomly deployed. Contrary to traditional and carefully planned receiver networks, crowd-sourced use of cheap sensors poses a number of new challenges to existing localization algorithms. The purpose of this paper is twofold: First, to survey the literature on Aircrafts' real-time tracking in Crowdsourced Air Traffic Networks, and Second, sketch a big data architecture allowing real-time tracking of aircrafts and predicting missing localization data.","","978-1-7281-5628-6","10.1109/ISNCC49221.2020.9297328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297328","","Aircraft;Trajectory;Sensors;Aircraft navigation;Hidden Markov models;Real-time systems;Airports","","","","15","IEEE","25 Dec 2020","20-22 Oct. 2020","20-22 Oct. 2020","IEEE","IEEE Conferences"
"A Tale of Location-Based User Authentication","E. Falk; V. Toth; A. Knaff; R. State","University of Luxembourg, Luxembourg; CTIE, Luxembourg; Grand Ducal Police, Luxembourg; University of Luxembourg, Luxembourg",2019 IEEE International Conference on Big Data and Smart Computing (BigComp),"4 Apr 2019","2019","","","1","4","The attitude towards passwords has drastically changed over the past years. Although they protected workstations from illicit access for decades, with todays increased computational power, simple passwords became easy targets for attacks, whereas complex passwords are difficult to remember for the users. It appears as if the classical password protection has become obsolete and has to give way to similarly secured schemes, which are seamless for users. Novel methodologies may be sound and secure from a technical point of view, their success will be challenged by the simple question whether a user feels secure or not. In this work, we propose a proximity based login and session locking scheme, based on bluetooth beacons. We describe the big data architecture required to implement secured location-based services in smart buildings. To round our contribution out, we describe a medium scale user study with 40 participants, conducted to answer the question: Do users feel secure?","2375-9356","978-1-5386-7789-6","10.1109/BIGCOMP.2019.8679440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8679440","","Authentication;IP networks;Password;Servers;Bluetooth;Computer architecture","","1","","9","IEEE","4 Apr 2019","27 Feb.-2 March 2019","27 Feb.-2 March 2019","IEEE","IEEE Conferences"
"A Hybrid Architecture for Secure Management of Manufacturing Data in Industry 4.0","A. Adhikari; M. Winslett","Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, USA",2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),"6 Jun 2019","2019","","","973","978","In this paper, we analyze the suitability of the methods available today for securely managing the wide variety of data produced by the manufacturing sector. We propose a hybrid information architecture for manufacturing, based on decentralized blockchains, cloud-based WORM storage and ordinary cloud storage. We point out shortcomings in the technology available today for realizing this architecture. In particular, we identify a need for low-cost IoT-based systems to capture, identify, preprocess, encrypt and transmit factory floor data to the corresponding data storage subsystems. We describe our proof-of-concept implementation of such an IoT system, along with the factory case study that inspired it, and argue that this system is sufficiently inexpensive to be retrofitted into today's factories.","","978-1-5386-9151-9","10.1109/PERCOMW.2019.8730717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8730717","Data Architecture;Manufacturing;Security;Digital Threads;Big Data;IoT;Blockchain;WORM","Production facilities;Manufacturing;Blockchain;Grippers;Companies;Sensors;Cloud computing","","8","1","13","IEEE","6 Jun 2019","11-15 March 2019","11-15 March 2019","IEEE","IEEE Conferences"
"Big Provenance Stream Processing for Data Intensive Computations","I. Suriarachchi; S. Withana; B. Plale","School of Informatics, Computing and Engineering, Indiana University, Bloomington, IN, USA; School of Informatics, Computing and Engineering, Indiana University, Bloomington, IN, USA; School of Informatics, Computing and Engineering, Indiana University, Bloomington, IN, USA",2018 IEEE 14th International Conference on e-Science (e-Science),"27 Dec 2018","2018","","","245","255","In the business and research landscape of today, data analysis consumes public and proprietary data from numerous sources, and utilizes any one or more of popular data-parallel frameworks such as Hadoop, Spark and Flink. In the Data Lake setting these frameworks co-exist. Our earlier work has shown that data provenance in Data Lakes can aid with both traceability and management. The sheer volume of fine-grained provenance generated in a multi-framework application motivates the need for on-the-fly provenance processing. We introduce a new parallel stream processing algorithm that reduces fine-grained provenance while preserving backward and forward provenance. The algorithm is resilient to provenance events arriving out-of-order. It is evaluated using several strategies for partitioning a provenance stream. The evaluation shows that the parallel algorithm performs well in processing out-of-order provenance streams, with good scalability and accuracy.","","978-1-5386-9156-4","10.1109/eScience.2018.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8588658","Big Data, Big Provenance, Stream Processing","Lakes;Sparks;Out of order;Tagging;Twitter;Partitioning algorithms;Big Data","","9","","44","IEEE","27 Dec 2018","29 Oct.-1 Nov. 2018","29 Oct.-1 Nov. 2018","IEEE","IEEE Conferences"
"Data Quality Management for Real-World Graduation Prediction","H. -D. Nguyen-Pham; K. T. VO; T. Nguyen; T. -A. Nguyen-Hoang; N. -T. Dinh; H. -T. Nguyen","Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; The Industrial University of Ho Chi Minh City, Vietnam; Aalto University, Finland",2024 International Conference on Advanced Technologies for Communications (ATC),"7 Mar 2025","2024","","","701","706","The rapid growth of diverse and multi-sourced data has rendered traditional data storage models inadequate to han-dle the sheer volume and complexity. Data Lakes, which store all raw data and all data versions in an easily accessible format, are well-suited for deep data analysis and valuable insights discovery. However, the quality of this data is not guaranteed, raising the question of how to utilize this vast repository effectively. Our research proposes a four-step data quality management process profile, implement, monitor, and improve to oversee and ensure data usability within a data lake. This process employs five commonly used evaluation criteria: accuracy, completeness, consistency, uniqueness, and timeliness. Our study focuses on higher education data, an area that has not been extensively explored in previous research, using real-world data from a uni-versity's computer science department. The application context is managing the quality of input data for a machine-learning model that predicts student graduation outcomes. Two advanced boosting machine learning models, LightGBM and CatBoost, are employed, resulting in a 5% improvement in performance. Our research aims to provide a comprehensive solution for assessing data quality in higher education, saving significant time, effort, and cost while enhancing the reliability of data utilization from data lakes.","2162-1039","979-8-3503-5398-3","10.1109/ATC63255.2024.10908184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10908184","educational data mining;data quality manage-ment;graduation prediction;big data","Solid modeling;Data integrity;Computational modeling;Education;Predictive models;Big Data applications;Data models;Reliability;Usability;Monitoring","","1","","29","IEEE","7 Mar 2025","17-19 Oct. 2024","17-19 Oct. 2024","IEEE","IEEE Conferences"
"Tsdat: An Open-Source Data Standardization Framework for Marine Energy and Beyond","C. Lansing; M. Levin; C. Sivaraman; R. Fao; F. Driscoll","Advanced Computing, Mathematics, and Data Division Pacific Northwest National Laboratory, Richland, U.S.A.; Advanced Computing, Mathematics, and Data Division Pacific Northwest National Laboratory, Richland, U.S.A.; Advanced Computing, Mathematics, and Data Division Pacific Northwest National Laboratory, Richland, U.S.A.; Water Power, Energy Conversion & Storage Systems National Renewable Energy Laboratory, Golden, U.S.A.; Water Power, Energy Conversion & Storage Systems National Renewable Energy Laboratory, Golden, U.S.A.",OCEANS 2021: San Diego – Porto,"15 Feb 2022","2021","","","1","6","Many organizations are tasked with the collection and processing of large quantities of data from various measurement devices. Data reported from these sources are often not interoperable with datasets and software used by analysts and other organizations in the same domain, introducing barriers for collaboration on large-scale projects. This poses a particular problem for cross-device comparisons and machine learning applications, which rely on large quantities of data from multiple sources. To address these challenges, the open-source Time-Series Data Pipelines (Tsdat) Python framework was developed by Pacific Northwest National Laboratory, with strategic guidance and direction provided by the National Renewable Energy Laboratory and Sandia National Laboratories to facilitate collaboration and accelerate advancements in the marine energy domain through the development of an open-source ecosystem of tools. This paper will describe the Tsdat framework and the data standards within which it operates. A beta version of Tsdat has been released and is being used by several projects in marine energy, wind energy, and building energy systems.","0197-7385","978-0-692-93559-0","10.23919/OCEANS44145.2021.9706101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706101","Python;open-source;data standards;data lake;big data;interoperability","Wind energy;Instruments;Standards organizations;Buildings;Collaboration;Organizations;Task analysis","","1","","23","","15 Feb 2022","20-23 Sept. 2021","20-23 Sept. 2021","IEEE","IEEE Conferences"
"Serverless Analytics with Amazon Athena: Query structured, unstructured, or semi-structured data in seconds without setting up any infrastructure","A. Virtuoso; M. T. Hocanin; A. Wishnick; R. Pathak",NA; NA; NA; NA,"Serverless Analytics with Amazon Athena: Query structured, unstructured, or semi-structured data in seconds without setting up any infrastructure","","2021","","","","","Get more from your data with Amazon Athena’s ease-of-use, interactive performance, and pay-per-query pricingKey FeaturesExplore the promising capabilities of Amazon Athena and Athena’s Query Federation SDKUse Athena to prepare data for common machine learning activitiesCover best practices for setting up connectivity between your application and Athena and security considerationsBook DescriptionAmazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using SQL, without needing to manage any infrastructure. This book begins with an overview of the serverless analytics experience offered by Athena and teaches you how to build and tune an S3 Data Lake using Athena, including how to structure your tables using open-source file formats like Parquet. You’ll learn how to build, secure, and connect to a data lake with Athena and Lake Formation. Next, you’ll cover key tasks such as ad hoc data analysis, working with ETL pipelines, monitoring and alerting KPI breaches using CloudWatch Metrics, running customizable connectors with AWS Lambda, and more. Moving on, you’ll work through easy integrations, troubleshooting and tuning common Athena issues, and the most common reasons for query failure. You will also review tips to help diagnose and correct failing queries in your pursuit of operational excellence. Finally, you’ll explore advanced concepts such as Athena Query Federation and Athena ML to generate powerful insights without needing to touch a single server. By the end of this book, you’ll be able to build and use a data lake with Amazon Athena to add data-driven features to your app and perform the kind of ad hoc data analysis that often precedes many of today’s ML modeling exercises.What you will learnSecure and manage the cost of querying your dataUse Athena ML and User Defined Functions (UDFs) to add advanced features to your reportsWrite your own Athena Connector to integrate with a custom data sourceDiscover your datasets on S3 using AWS Glue CrawlersIntegrate Amazon Athena into your applicationsSetup Identity and Access Management (IAM) policies to limit access to tables and databases in Glue Data CatalogAdd an Amazon SageMaker Notebook to your Athena queriesGet to grips with using Athena for ETL pipelinesWho this book is forBusiness intelligence (BI) analysts, application developers, and system administrators who are looking to generate insights from an ever-growing sea of data while controlling costs and limiting operational burden, will find this book helpful. Basic SQL knowledge is expected to make the most out of this book.","","9781800567863","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163042.pdf&bkn=10163042&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Vocational Education Digital Enterprise Architecture Framework (VEDEAF)","T. Rujira; P. Nilsook; P. Wannapiroon","Division of Information and Communication Technology for Education, Faculty of Technical Education, King Mongkut's University of Technology North Bangkok, Bangkok, Thailand; Division of Information and Communication Technology for Education, Faculty of Technical Education, King Mongkut's University of Technology North Bangkok, Bangkok, Thailand; Division of Information and Communication Technology for Education, Faculty of Technical Education, King Mongkut's University of Technology North Bangkok, Bangkok, Thailand",2021 9th International Conference on Information and Education Technology (ICIET),"12 May 2021","2021","","","63","67","The purpose of this research was follows: 1) synthesis of components of enterprise architecture and 2) to develop a vocational education digital enterprise architecture framework (VEDEAF) 3) evaluate of VEDEAF. Which have been studied from theories, documents and researches related to enterprise architecture, high performance organization, digital organization and operating process within Vocational Education College. The results of the research showed that components of VEDEAF consist of six component which are 1) Business Architecture, 2) Data Architecture, 3) Application Architecture, 4) Infrastructure Architecture, 5) Security Architecture and 6) Human Capital Architecture. Each components also divided into sub-module as follows; Business Architecture divided into 2 submodules which are Mission and Core Processes; Data Architecture divided into 2 sub-modules which are Core Process Data and Supporting Process data; Application Architecture divided into 3 sub-modules which are Instructional Application, Process Application and Integration Application; Infrastructure Architecture divided into 5 sub-modules which are Communication Platform, Operating System, Hardware Platform, Network and Data Communication Platform and Server Platform; Human Capital Architecture divided into 4 sub-modules which are Executive, Teacher, Student and Administration. To evaluation results of VEDEAF, the result found that the appropriate is at very high levels.","","978-1-6654-1933-8","10.1109/ICIET51873.2021.9419576","King Mongkut's University of Technology North Bangkok; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419576","digital transformation;enterprise architecture;high performance organization","Operating systems;Digital transformation;Education;Organizations;Big Data applications;Hardware;Servers","","6","","53","IEEE","12 May 2021","27-29 March 2021","27-29 March 2021","IEEE","IEEE Conferences"
"Crime Pattern Detection Utilizing Power BI Visualizations on the Microsoft Fabric Data Platform With the Public data.police.uk Dataset","A. Todosijević; P. Dakić; T. Heričko; Ž. Kljajić; V. Todorović","Faculty of Informatics and Computing, Singidunum University, Belgrade, Serbia; Faculty of Informatics and Computing, Singidunum University, Belgrade, Serbia; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia; Faculty of Business Economics, Pan-European University Apeiron, Banja Luka, Bosnia & Herzegovina; Faculty of Business Studies and Law, MB University, Belgrade, Serbia",2025 15th International Conference on Advanced Computer Information Technologies (ACIT),"9 Oct 2025","2025","","","593","598","This paper presents a big data-driven platform for crime pattern detection using Power BI visualizations on Microsoft Fabric, built upon the public data.police.uk dataset. Law enforcement agencies require scalable analytics to extract actionable insights from large, complex datasets. We implemented a Data Lakehouse architecture to process around 8,500 crime data files i n C SV format from multiple regions, with Python-based metadata cataloging for structured access to crime outcomes, stop-and-search records, and street-level incidents. Dataflows and Notebooks in Fabric addressed regional inconsistencies and enabled efficient data transformation. Power BI reports provided intuitive and interactive visualizations for exploring geographic and temporal crime trends. Performance testing demonstrated up to 40% faster query response times compared to traditional warehouses, and regional crime analysis that previously took days was completed within hours. The results indicated that the platform scaled efficiently while maintaining stable performance under growing data volumes. Our approach demonstrates how unified analytics and visualization environments can democratize access to crime data insights, supporting evidence-based policing and public safety decision-making.","2770-5226","979-8-3315-9544-9","10.1109/ACIT65614.2025.11185634","Erasmus; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11185634","Data Platform;Microsoft Fabric;data.police.uk;Crime Analytics;Data Lakehouse Architecture","Law enforcement;Soft sensors;Decision making;Data visualization;Computer architecture;Metadata;Fabrics;Real-time systems;Time factors;Testing","","3","","14","IEEE","9 Oct 2025","17-19 Sept. 2025","17-19 Sept. 2025","IEEE","IEEE Conferences"
"Identifying vital nodes on temporal networks: An edge-based K-shell decomposition","Z. Ye; X. Zhan; Y. Zhou; C. Liu; Z. -K. Zhang","Alibaba Research Center for Complexity Sciences, Hangzhou Normal University, Hangzhou, P. R. China; Alibaba Research Center for Complexity Sciences, Hangzhou Normal University, Hangzhou, P. R. China; Alibaba Research Center for Complexity Sciences, Hangzhou Normal University, Hangzhou, P. R. China; Alibaba Research Center for Complexity Sciences, Hangzhou Normal University, Hangzhou, P. R. China; Alibaba Research Center for Complexity Sciences, Hangzhou Normal University, Hangzhou, P. R. China",2017 36th Chinese Control Conference (CCC),"11 Sep 2017","2017","","","1402","1407","There is an ever-increasing interest in studying temporal networks nowadays, as temporal networks can illustrate the real-world system more accurately. To date, how to characterize nodes' importance is still unclear in temporal networks. In this work, we first use a time window graph model to cut the temporal network into slices, and then we give an indicator for network centrality according to the edge-based κ-shell decomposition for the temporal networks, which is named as temporal κ-shell decomposition. We mainly use the size of the largest component after removing the nodes with large centrality value to test the method's performance. The numerical experiments on several real networks indicate that the temporal κ-shell method outperforms some other indicators, and the results with different time window size show that the improvement is also robust.","1934-1768","978-988-15639-3-4","10.23919/ChiCC.2017.8027547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8027547","Temporal Network;Time Window Graph Model;K-shell Decomposition;Robustness","Security;Robustness;Network topology;Weight measurement;Indexes;Stability criteria","","10","","21","","11 Sep 2017","26-28 July 2017","26-28 July 2017","IEEE","IEEE Conferences"
"Cloud Scale Analytics with Azure Data Services: Build modern data warehouses on Microsoft Azure","P. Borosch",NA,Cloud Scale Analytics with Azure Data Services: Build modern data warehouses on Microsoft Azure,"","2021","","","","","A practical guide to implementing a scalable and fast state-of-the-art analytical data estateKey FeaturesStore and analyze data with enterprise-grade security and auditingPerform batch, streaming, and interactive analytics to optimize your big data solutions with easeDevelop and run parallel data processing programs using real-world enterprise scenariosBook DescriptionAzure Data Lake, the modern data warehouse architecture, and related data services on Azure enable organizations to build their own customized analytical platform to fit any analytical requirements in terms of volume, speed, and quality. This book is your guide to learning all the features and capabilities of Azure data services for storing, processing, and analyzing data (structured, unstructured, and semi-structured) of any size. You will explore key techniques for ingesting and storing data and perform batch, streaming, and interactive analytics. The book also shows you how to overcome various challenges and complexities relating to productivity and scaling. Next, you will be able to develop and run massive data workloads to perform different actions. Using a cloud-based big data-modern data warehouse-analytics setup, you will also be able to build secure, scalable data estates for enterprises. Finally, you will not only learn how to develop a data warehouse but also understand how to create enterprise-grade security and auditing big data programs. By the end of this Azure book, you will have learned how to develop a powerful and efficient analytical platform to meet enterprise needs.What you will learnImplement data governance with Azure servicesUse integrated monitoring in the Azure Portal and integrate Azure Data Lake Storage into the Azure MonitorExplore the serverless feature for ad-hoc data discovery, logical data warehousing, and data wranglingImplement networking with Synapse Analytics and Spark poolsCreate and run Spark jobs with Databricks clustersImplement streaming using Azure Functions, a serverless runtime environment on AzureExplore the predefined ML services in Azure and use them in your appWho this book is forThis book is for data architects, ETL developers, or anyone who wants to get well-versed with Azure data services to implement an analytical data estate for their enterprise. The book will also appeal to data scientists and data analysts who want to explore all the capabilities of Azure data services, which can be used to store, process, and analyze any kind of data. A beginner-level understanding of data analysis and streaming will be required.","","9781800562141","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10162677.pdf&bkn=10162677&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Design and Implementation of an Embedded Edge-Processing Water Quality Monitoring System for Underground Waters","C. Correa; D. Dujovne; F. Bolaño","Department of Power and Machinery, Faculty of Agricultural Engineering, University of Concepción, Chillán, Chile; Escuela de Informática y Telecomunicaciones, Universidad Diego Portales, Santiago, Chile; Department of Power and Machinery, Faculty of Agricultural Engineering, University of Concepción, Chillán, Chile",IEEE Embedded Systems Letters,"26 May 2023","2023","15","2","81","84","Global warming effects are seen around the world and Latin American countries are not an exception, especially for expanding drought areas. Therefore, underground water resources used in the region are incrementing exponentially. However, temporal and spatial underground water information concerning availability and quality is scarce, disabling proper decision making. In order to close that breach, we propose and embedded edge-processing Internet of Things (IoT)-based water quality monitoring system. This letter introduces the design and implementation of this solution, specifically targeted to monitor irrigation and drinking water extracted from water wells. The system is designed to be deployed in central Chile, considering the topographic conditions, which severely affect power availability and communication resources. The captured data are stored in a data lake, for further processing according to water quality models.","1943-0671","","10.1109/LES.2022.3184925","CORFO Water Technology Consortium CoTH20(grant numbers:20CTECGH-145896); Centro de Recursos Hídricos para la Agricultura y la Minería(grant numbers:Conicyt/Fondap/15130015); Conicyt Advanced Human Capital Program of the Government of Chile; CI4 Center for Industry 4.0; CYTED AgIoT Project(grant numbers:520rt0011); Proyecto Asociativo UDP “Plataformas Digitales como modelo organizacional.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802658","Edge processing;Internet of Things (IoT);underground water;wireless","Sensors;Water quality;Monitoring;Image edge detection;Event detection;Water resources;Big Data applications;Embedded systems;Edge computing;Internet of Things;Climate change;Global warming","","18","","11","IEEE","21 Jun 2022","June 2023","","IEEE","IEEE Journals"
"FinDS2: A Novel Data Synthesis System for Fintech Product Risks","X. Du; X. Guo; F. Zhou; M. Gu; Z. Lu; C. Wang","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Foreign Studies, Shanghai University of Finance and Economics, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; Business Analysis BU, GienTech Technology Co.,Ltd, Shanghai, China",2024 IEEE 11th International Conference on Cyber Security and Cloud Computing (CSCloud),"2 Aug 2024","2024","","","73","78","This paper starts from the application scenarios and pain points in the financial industry, focusing on the synthesis of financial technology (Fintech) product risk data. By integrating existing research in the field of data synthesis, we propose a novel Fintech Data Synthesis System (FinDS2). To implement this system, we have designed and developed a data synthesis product that leverages cloud computing and micro-services. The product includes a cloud-native data lake, an intelligent algorithm engine, and a SAAS tool engine. It collects data on regulatory rules and penalties in the finance industry and offers highly configurable and automated features. By tailoring the synthesis process to Fintech application scenarios, our proposed FinDS2 generates high-quality synthetic data efficiently. Through practical validation, we demonstrate that the synthesized data closely resembles the original data, effectively meeting the data synthesis needs for managing Fintech product risk.","2693-8928","979-8-3503-7698-2","10.1109/CSCloud62866.2024.00020","Natural Science Foundation of China(grant numbers:92046024,92146002,61873309); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605154","Cloud-native;Data synthesis;Fintech;Machine learning","Cloud computing;Statistical analysis;Pain;Focusing;Finance;Big Data applications;Engines","","1","","23","IEEE","2 Aug 2024","28-30 June 2024","28-30 June 2024","IEEE","IEEE Conferences"
"What Does “Real Time” Really Mean?","M. Kihn; A. C. Lin",NA; NA,"Customer 360: How Data, AI, and Trust Change Everything","","2025","","","99","105","Summary <p>Newer technologies, including CDPs and data warehouses, are putting more real‐time data into the hands of practitioners, who can use it to improve their service, chatbots, product recommendations, campaigns, analytics, and so on. Delivering in right‐time requires a strategic calculus of what the customer expects and a behind‐the‐scenes balance among systems, resources, and goals. A typical configuration—embraced by a number of enterprise CDPs—supports a real‐time process for some streaming data, data change actions, and flows, while also having a data lake or lake house where data are located for refinement, processing, and storage. Many CDPs maintain a subset of customer data in a so‐called “hot store” or in‐memory database. This can be called the real‐time profile. The purpose of this real‐time profile is to make certain frequently used or high‐value data available. A key use for these low‐latency data graphs is for AI and GenAI models.</p>","","9781394273638","10.1002/9781394308668.ch11","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10954382.pdf&bkn=10950212&pdfType=chapter","","Real-time systems;Hands;Electronic mail;Data warehouses;Costs;Chatbots;Airline industry;Social networking (online);Big Data applications;Artificial intelligence","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"A Systems Approach to the Digital Transformation of Military Installation Planning","H. Y. Bastian; M. M. Mitchell; R. K. Buchanan; S. Wolters; J. Richards; P. R. Ables","Dept. of Systems Eng, ORCEN United States Military Academy, NY, USA; Information Technology Laboratory, Engineer Research & Dev. Center, Vicksburg, MS, USA; Information Technology Laboratory, Engineer Research & Dev. Center, Vicksburg, MS, USA; Environmental Laboratory, Engineer Research & Dev. Center, Vicksburg, MS, USA; Information Technology Laboratory, Engineer Research & Dev. Center, Vicksburg, MS, USA; Information Technology Laboratory, Engineer Research & Dev. Center, Vicksburg, MS, USA",2025 IEEE International systems Conference (SysCon),"30 May 2025","2025","","","1","3","Data has become increasingly crucial for decisionmaking and analysis across the United States (US) government in a complex world with evolving risks. The volume, velocity, and variety of data collected by installations require more effort to understand and synthesize the various types of data. For military installations to modernize and mitigate current and future threats, they need to revolutionize installation master planning. Installation master planning is the process of planning to develop land, facilities, and infrastructure while ensuring sustainability, efficient use of resources, and risk management. PLANNER is designed to digitize and operationalize integrated installation planning, automating data collection and organization to reduce the workforce required by master planners, environmental planners, and energy managers by accessing multiple data sources through the data lake provided by the Virtual Toolbox for Installation Mission Effectiveness (VTIME). It applies a comprehensive systems approach to identify and acquire the relevant data sources required for risk and resilience analysis, provides a single place to access and analyze the data, and provides decision support in near real-time.","2472-9647","979-8-3315-0818-0","10.1109/SysCon64521.2025.11014865","United States Military Academy; Department of Defense; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11014865","PLANNER;VTIME;Installation Resilience;Data Mapping;Risk Analysis","Soft sensors;Digital transformation;Government;Data collection;Big Data applications;Real-time systems;Planning;Risk management;Sustainable development;Resilience","","","","6","USGov","30 May 2025","7-10 April 2025","7-10 April 2025","IEEE","IEEE Conferences"
"Graph-Fraudster: Adversarial Attacks on Graph Neural Network-Based Vertical Federated Learning","J. Chen; G. Huang; H. Zheng; S. Yu; W. Jiang; C. Cui","Institute of Cyberspace Security, College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, China; Institute of Cyberspace Security, College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; Zhejiang Police College, Big Data and Cyber Security Research Institute, Hangzhou, China; College of Computer Science, Hangzhou Dianzi University, Hangzhou, China",IEEE Transactions on Computational Social Systems,"31 Mar 2023","2023","10","2","492","506","Graph neural network (GNN) has achieved great success on graph representation learning. Challenged by large-scale private data collected from user side, GNN may not be able to reflect the excellent performance, without rich features and complete adjacent relationships. Addressing the problem, vertical federated learning (VFL) is proposed to implement local data protection through training a global model collaboratively. Consequently, for graph-structured data, it is a natural idea to construct a GNN-based VFL (GVFL) framework. However, GNN has been proven vulnerable to adversarial attacks. Whether the vulnerability will be brought into the GVFL has not been studied. This is the first study of adversarial attacks on GVFL. A novel adversarial attack method is proposed, named Graph-Fraudster. It generates adversarial perturbations based on the noise-added global node embeddings via the privacy leakage and the gradient of pairwise node. Specifically, first, Graph-Fraudster steals the global node embeddings and sets up a shadow model of the server for the attack generator. Second, noise is added into node embeddings to confuse the shadow model. Finally, the gradient of pairwise node is used to generate attacks with the guidance of noise-added node embeddings. Extensive experiments on five benchmark datasets demonstrate that Graph-Fraudster achieves the state-of-the-art attack performance compared with baselines in different GNN based GVFLs. Furthermore, Graph-Fraudster can remain a threat to GVFL even if two possible defense mechanisms are applied. In addition, some suggestions are put forward for the future work to improve the robustness of GVFL. The code and datasets can be downloaded at https://github.com/hgh0545/Graph-Fraudster.","2329-924X","","10.1109/TCSS.2022.3161016","National Natural Science Foundation of China(grant numbers:62072406,62103374); Key Laboratory of Ministry of Public Security(grant numbers:2020DSJSYS001); Key Research and Development Projects in Zhejiang Province(grant numbers:2021C01117); 2020 Industrial Internet Innovation Development Project(grant numbers:TC200H01V); “Ten Thousand Talents Program” in Zhejiang Province(grant numbers:2020R52011); Basic Public Welfare Research Project of Zhejiang Province(grant numbers:LGF20F020016); Open Project of the Key Laboratory of Public Security Informatization Application Based on Big Data Architecture(grant numbers:2020DSJSYS003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745270","Adversarial attack;defense;graph neural network (GNN);privacy leakage;vertical federated learning (VFL)","Servers;Perturbation methods;Data privacy;Security;Privacy;Data models;Training","","34","","44","IEEE","30 Mar 2022","April 2023","","IEEE","IEEE Journals"
"Implementing a data management infrastructure for big healthcare data","H. Kondylakis; L. Koumakis; M. Tsiknakis; K. Marias","Computational BioMedicine Laboratory, FORTH-ICS, Greece, GR; Computational BioMedicine Laboratory, FORTH-ICS, Greece, GR; Department of Informatics Engineering of the Technological Educational, Institute of Crete; Department of Informatics Engineering of the Technological Educational, Institute of Crete",2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),"9 Apr 2018","2018","","","361","364","The advancements in healthcare have brought to the fore the need for flexible access to health-related information and created an ever-growing demand for efficient data management infrastructures. To this direction, in this paper, we present an effective and efficient data management infrastructure implemented for the iManageCancer EU project. The architecture focuses on enabling data access to multiple, heterogeneous and diverse data source that are initially available in a data lake. Parts of these data are integrated and semantically uplifted using a modular ontology. This integration can be either at run-time or through an ETL process ensuring efficient access to the integrated information. A unique feature of out platform is that it allows the uninterrupted, continuous evolution of ontologies/terminologies. Finally, summarization tools enable the quick understanding of the available information, whereas APIs and anonymization services ensure the secure access to the requested information.","","978-1-5386-2405-0","10.1109/BHI.2018.8333443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8333443","","Ontologies;Tools;Semantics;Databases;Lakes;Cancer;Data models","","6","","15","IEEE","9 Apr 2018","4-7 March 2018","4-7 March 2018","IEEE","IEEE Conferences"
"37 Technology Under Your Skin: Three Challenges of Microchip Implants","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","193","196","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933579.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"16 Edge Computing Paradigm","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","81","86","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933572.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"13 Understanding Dark Data","A. Banafa",NA,Quantum Computing and Other Transformative Technologies,"","2022","","","65","68","This book explores quantum computing as a transformative technology and its applications in communications, cryptography, teleportation, IoT, AI, and blockchain, in addition to the revolutionary concept of quantum internet. It also explains the concept of dark, small, thick data, and clarifies what the concept of a data lake. Other exciting technologies like edge/fog computing, CDN, SDN, wearable technology and IoE topics are discussed in details in the book. Information security applications like zero trust model, zero-day vulnerability and heuristic analysis, and use of AI in cybersecurity are explored. Two of the most intriguing concepts in computing “affective computing” and “autonomic computing” are explained and simplified. The blockchain applications presented include blockchain and supply chain, crowdsourcing, cryptocurrency, and IoT. The book ends with a look at using technology to fight COVID-19 and future pandemics.","","9788770226837","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9933535.pdf&bkn=9933493&pdfType=chapter","","","","","","","","31 Oct 2022","","","River Publishers","River eBook Chapters"
"Optimize cloud computations using edge computing","S. Singh","IBM Software Labs (ISL), Pune, India","2017 International Conference on Big Data, IoT and Data Science (BID)","12 Apr 2018","2017","","","49","53","The IoT devices captures data and sends it to Cloud for computation but data transfer process from IoT device to Cloud can take lot of time if volume of data is large. Therefore, it makes sense to process captured data locally at IoT edge node to avoid latency. In Edge Computing, the Gateway stores data and perform computations along with traffic aggregation and routing. While Edge analytics allows pre-processing and filtering of the data closer to where it's being created but the data which falls within normal range can be stored in low cost IoT storage and abnormal readings will be sent to Data Lake or in-memory database. Edge Computing will boost traditional Cloud computing model with service nodes placed at the network edges. It will help traditional data center cloud models by reducing latency and increased bandwidth. In future computation and data processing power will slowly shift towards edge devices like sensors, drones, driverless cars etc. Playing augmented reality, 3D video games, content-based video analysis is a challenge on mobile phone due to limited processing power and battery life. Realtime analysis of massive sensor data is needed in industries like manufacturing, mining, transportation to detect anomalies and send alerts. Therefore, Edge Computing and Cloud computing are likely to follow more of a hybrid approach and complement each other. This paper talks about Edge computing architecture, computational offloading approaches, Edge Computing challenges and benefits etc.","","978-1-5090-6593-6","10.1109/BID.2017.8336572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336572","Edge Computing;Computation Offloading;Internet of Things(IoT);Machine-to-Machine(M2M) Sensor;IoT Edge;CloneCloud;ThinkAir;MACS;COCA;Greengrass","Cloud computing;Edge computing;Smart phones;Servers;Sensors;Data processing","","72","","15","IEEE","12 Apr 2018","20-22 Dec. 2017","20-22 Dec. 2017","IEEE","IEEE Conferences"
"Research on the Architecture of NQI One-Stop Service Cloud Platform in Smart Grid Measurement Field","A. Zheng; Y. Xu; H. Shang; Y. Liu; Y. Wang","China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China","2019 4th International Conference on Mechanical, Control and Computer Engineering (ICMCCE)","27 Jan 2020","2019","","","775","7754","The basic situation of NQI (National Quality Infrastructure) in the field of smart grid measurement is introduced. Aiming at the information requirement of NQI in the field of smart grid measurement, the construction scheme and purpose of NQI one-stop service cloud platform are proposed. The technical architecture of cloud platform is studied, the operation and security management of cloud platform are introduced. The data architecture of cloud platform is studied, the data access scheme and data acquisition method are designed in accordance with the current business situation, and the data model based on NQI is proposed. The application architecture of cloud platform is studied, and the service design of cloud platform is discussed according to the application goal of cloud platform. Finally, the further development of cloud platform and its application in real business are prospected.","","978-1-7281-4689-8","10.1109/ICMCCE48743.2019.00178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969463","smart grid;measurement;NQI;cloud platform;architecture design;data acquisition","Cloud computing;Regulators;Security management;Data acquisition;Computer architecture;Product design;Smart grids;Quality assessment;Monitoring;Business","","1","","14","IEEE","27 Jan 2020","24-26 Oct. 2019","24-26 Oct. 2019","IEEE","IEEE Conferences"
"Design and Implementation of Customer Service Data Warehouse System for Electric Power Marketing Based on Data Mining Technology","L. Yu; H. Chen; Z. Wang; S. Su; X. Zhu","State Grid Beijing Electric Power Company Customer Service Center, Beijing, China; State Grid Beijing Electric Power Company, Beijing, China; State Grid Beijing Electric Power Company, Beijing, China; State Grid Beijing Electric Power Company Customer Service Center, Beijing, China; State Grid Beijing Electric Power Company Customer Service Center, Beijing, China","2023 International Conference on Power, Electrical Engineering, Electronics and Control (PEEEC)","1 Feb 2024","2023","","","981","986","Based on the continuous improvement of the informatization level of power grid and the increasing data accumulated in the information management system of power grid enterprises, this paper puts forward a power marketing analysis system based on data mining. In order to realize the design of the system architecture, require the system to meet the requirements of compatibility and share system information, an electric power marketing analysis system is designed. Design business architecture, application architecture, data architecture and technical architecture according to the requirements analysis results. The power marketing analysis system mainly includes data mining module, result analysis module and system management module. In order to ensure the security of the system, the security structure of the system is designed and tested. Practice shows that the system has strong management ability, decision-making ability and query ability, fast response speed, simple operation and good interface, which can improve the competitiveness and economic benefits of enterprises.","","979-8-3503-2912-4","10.1109/PEEEC60561.2023.00192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10414820","Data mining technology;electricity marketing;data warehouse system design and implementation","Decision making;Data warehouses;Predictive models;Power systems;Data mining;Security;Business","","","","11","IEEE","1 Feb 2024","25-27 Sept. 2023","25-27 Sept. 2023","IEEE","IEEE Conferences"
"Research on Digital Twin System Architecture for Intelligent Manufacturing Internal Control","S. Lyu","Graduate School, Our Lady of Fatima University, Manila, Philippines",2023 9th Annual International Conference on Network and Information Systems for Computers (ICNISC),"25 Mar 2024","2023","","","539","542","Aiming at the internal control issue of intelligent manufacturing, this paper proposes an architecture system on the basis of digital twin. Combined with the digital twin technology model, this research offers a better solution for the internal control optimization of intelligent manufacturing with complex constraints and uncertainties. In this paper, the hierarchy of technical architecture of intelligent manufacturing internal control system based on digital twin is defined. The construction mechanism of multi-level and multi-dimensional virtual workshop is put forward, and the basic unit model of multi-dimensional fusion is described. A data architecture model of data collection, processing, storage and control driven by twin data is proposed. This research aims to provide some reference for the efficient development of internal control in the intelligent manufacturing process of manufacturing enterprises.","","979-8-3503-0668-2","10.1109/ICNISC60562.2023.00043","Ministry of Education; Social Science Planning Project of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10473419","digital twin;virtual simulation;intelligent manufacturing;internal control","Uncertainty;Processor scheduling;Computational modeling;Systems architecture;Process control;Computer architecture;Production","","","","5","IEEE","25 Mar 2024","27-29 Oct. 2023","27-29 Oct. 2023","IEEE","IEEE Conferences"
"Research on Intelligent Management System for Building Intelligent Information Team of Talents in Colleges and Universities","H. Wei; Y. Hongzhi","Yantai Institute of Science and Technology, Yantai, Shandong, China; Yantai Institute of Science and Technology, Yantai, Shandong, China","2024 IEEE 3rd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)","8 Apr 2024","2024","","","1309","1313","This paper introduces a university personnel information management system based on service-oriented architecture access mode and cloud storage technology. Through the construction of the system architecture and database E- R diagram, the cloud storage and access of college human resource management are realized. It is well integrated with the current university human resource management model based on its mature business logic and data architecture. The system can not only solve the information requirements of the school staff, but also provide detailed information statistics for the school leaders to help them make scientific decisions.","","979-8-3503-8098-9","10.1109/EEBDA60612.2024.10485743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10485743","University talent management;intelligent management system;service-oriented;middleware","Cloud computing;Software algorithms;Systems architecture;Software;Service-oriented architecture;Personnel;Remuneration","","","","8","IEEE","8 Apr 2024","27-29 Feb. 2024","27-29 Feb. 2024","IEEE","IEEE Conferences"
"An Architecture for Dynamic Data Source Integration","I. Gorton; J. Almquist; K. Dorow; Peng Gong; D. Thurman","Empirical Software Engineering, National ICT Australia Eveleigh, Sydney, Australia; NA; Information Sciences and Engineering, Pacific Northwest National Laboratory, Richland, WA, USA; Biomedical and Multimedia Information Technology Group, School of Information Technologies, University of Sydney, Australia; Information Sciences and Engineering, Pacific Northwest National Laboratory, Richland, WA, USA",Proceedings of the 38th Annual Hawaii International Conference on System Sciences,"24 Jan 2005","2005","","","276c","276c","Integrating multiple heterogeneous data sources in to applications is a time-consuming, costly and error-prone engineering task. Relatively mature technologies exist that make integration tractable from an engineering perspective. These technologies however have many limitations, and hence present opportunities for breakthrough research. This paper briefly describes some of these limitations. It then provides an overview of the Data Concierge research project and prototype that is attempting to provide solutions to some of these limitations. The paper focuses on the core architecture and mechanisms in the Data Concierge for dynamically attaching to a previously unidentified source of information. The generic API supported by the Data Concierge is described, along with the architecture and prototype tools for describing the meta-data necessary to facilitate dynamic integration. In addition, we describe the outstanding challenges that remain to be solved before the Data Concierge concept can be realized.","1530-1605","0-7695-2268-8","10.1109/HICSS.2005.80","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1385807","","Information technology;Application software;Biomedical engineering;Prototypes;Data engineering;Australia;Design engineering;Joining processes;Middleware;Computer architecture","","2","1","5","IEEE","24 Jan 2005","6-6 Jan. 2005","6-6 Jan. 2005","IEEE","IEEE Conferences"
"Building Privacy-Aware Data Pipelines: Balancing Scalability, Compliance, and Performance in Modern Data Architectures","G. R. Mittoor; P. Udayaraju; S. Putteti","The Wendy's Company, Dublin, Ohio, USA; Department of CSE, School of SEAS, SRM University - AP; Zoominfo Technologies, Bentonville, Arkansas, USA",2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS),"25 Apr 2025","2025","","","951","957","In cloud computing, data is generated from various sources in different locations, such as database management systems, data streaming environments, and files, and is automatically transferred to a data lake. Managing that data in the data lake is a challenging problem that involves developing a scalable model to integrate, process, and move it from one source to another with optimized cost and performance. The earlier research used various optimisation, data management and processing tools, but their performance efficiency is poor. This paper has been motivated to improve the overall performance by implementing the Random Forest algorithm for an overview of the incoming data, which is passed into a cost-effective data pipeline that helps to ingest and process massive amounts of incoming data daily. It also involves Apache Spark cloud services integrating the data seamlessly to manage storage and processing. Based on the data privacy and governance policies the RF model monitors and secures sensitive data in the input dataset. The simulation output is obtained by executing the proposed model in the cloud Apache framework, and the efficiency is verified regarding execution time, response time for user query, and accuracy. It is also verified that the data transmission with the cost efficiency for the healthcare dataset simulated in the Spark, S3, and AWS lake provides an aware pipeline model. A large-scale healthcare dataset is used in the simulation to confirm the efficacy of the data pipelining model, and the data transmission rate, claims, and cost efficiency are verified.","","979-8-3315-0574-5","10.1109/ICMLAS64557.2025.10968671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10968671","Data Pipeline;Data Scalability;AWS;Apache Spark;Healthcare Data Pipelining","Radio frequency;Cloud computing;Analytical models;Costs;Accuracy;Computational modeling;Scalability;Medical services;Data models;Pipeline processing","","","","18","IEEE","25 Apr 2025","10-12 March 2025","10-12 March 2025","IEEE","IEEE Conferences"
"Prognosis Smart System AI-based Applied to Equipment Health Monitoring in 4.0 Industry Scenario","A. Silva; G. F. M. Souza",University of São Paulo; University of São Paulo,2021 Annual Reliability and Maintainability Symposium (RAMS),"22 Nov 2021","2021","","","1","6","In the age of IIoT - Industrial Internet of Things, data lake, data mining, big data, and cloud computing, the smart manufacturing enables to make more informed decisions in real-time by using the database extracted from sensors in its equipment. During an operational campaign, the Health Monitoring System (HMS) also allows an understanding of how component degradation is affecting the performance of the equipment. Through a structure supported by AI, as data lake and cloud computing, the HMS provides to monitored equipment a fault detection system, early warning alarms to prevent failures and a calculation of the remaining useful life (RUL).The purpose of this paper is to present a prognosis smart system based on AI applied to HMS to support decision-making regarding operational performance of equipment. A Recurrent Neural Network (RNN) procedure is developed to continuously analyze the mass of monitoring data generated during the machine operation. The ability to learn the behavior patterns of the collected signals and in this way to be able to make parameter predictions with high accuracy makes artificial neural networks a powerful tool to carry out an effective prognosis. Machine operational parameters are monitored simultaneously by the prognosis smart system. Then, this information is processed by the neural network and used to characterize the machine operational condition. Upon detecting a failure trend for one or more parameters monitored by recognizing deterioration patterns, the prognosis system calculates the remaining useful life (RUL) and allows maintainers to take early actions before the failure occurrence.The proposed methodology is applied as part of a HMS of a hydro generator based on parameters registered in operator inspections routes designed to identify critical equipment degradation. The registered data representing one operational year are used to train the neural network regarding normal and abnormal machine condition. After training, the neural network is able to predict failure trends for monitored temperature parameters of the hydro-generator lubricating system that is critical to support equipment performance. Comparing prediction data and data collected by the sensors, the developed neural network reached about 0,98 RMSE score. The remaining useful life prognosis proved to be an important tool to avoid hydro generator components unexpected failures which may affect power output and cause penalties to the power generation company.","2577-0993","978-1-7281-8017-5","10.1109/RAMS48097.2021.9605722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605722","artificial intelligence;health monitoring;smart prognosis;remaining useful life","Temperature sensors;Temperature measurement;Degradation;Recurrent neural networks;Neural networks;Tools;Market research","","2","","15","IEEE","22 Nov 2021","24-27 May 2021","24-27 May 2021","IEEE","IEEE Conferences"
"Real-Time Estimated Time of Arrival Prediction System using Historical Surveillance Data","A. Muñoz Hernández; D. Scarlatti; P. Costas","Boeing Research & Technology Europe; Boeing Research & Technology Europe, Madrid, Spain; Boeing Research & Technology Europe, Madrid, Spain",2019 45th Euromicro Conference on Software Engineering and Advanced Applications (SEAA),"21 Nov 2019","2019","","","174","177","Prediction of Estimated Times of Arrival (ETA) is a challenging problem for the aviation industry. Flights recurrently deviate from their scheduled time of arrival, which has negative downstream consequences that affect the efficiency of operations. Therefore, accurate and up-to-date ETA estimations prior to its landing can help in optimizing the actions to be taken by the different air transportation agents whenever schedule deviations are incurred, and thus reduce the economic, logistic and environmental impact that they cause. This presentation exposes an infrastructure for high-fidelity computation of accurate ETA in real-time, based on a data-driven approach that leverages the use of recorded aircraft trajectories. This infrastructure is composed of different elements: (1) a live ADS-B tracks gathering system embedded in a lambda-architecture cluster, with capabilities for real-time distribution and data lake storage (2) an ETA prediction machine learning model, employing the actual 4D aircraft position as input; and (3) a hybrid cloud architecture to support real-time visualization and distributions of ETA predictions. The proposed infrastructure has been successfully validated in a real environment (Transforming Transport, an European Commission funded project). This infrastructure enables real-time computation and distribution of accurate ETA for any arrival operation of interest. Results supported the envisioned benefits of getting such accurate ETA, which basically turn into a reduction of associated costs for airport authorities and airlines.","","978-1-7281-3421-5","10.1109/SEAA.2019.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906713","machine learning;big data;real-time;visualization","Surveillance;Atmospheric modeling;Predictive models;Data visualization;Biological system modeling;Machine learning;Real-time systems","","6","","12","IEEE","21 Nov 2019","28-30 Aug. 2019","28-30 Aug. 2019","IEEE","IEEE Conferences"
"Data Modeling for Azure Data Services: Implement professional data design and structures in Azure","P. t. Braake",NA,Data Modeling for Azure Data Services: Implement professional data design and structures in Azure,"","2021","","","","","Choose the right Azure data service and correct model design for successful implementation of your data model with the help of this hands-on guideKey FeaturesDesign a cost-effective, performant, and scalable database in AzureChoose and implement the most suitable design for a databaseDiscover how your database can scale with growing data volumes, concurrent users, and query complexityBook DescriptionData is at the heart of all applications and forms the foundation of modern data-driven businesses. With the multitude of data-related use cases and the availability of different data services, choosing the right service and implementing the right design becomes paramount to successful implementation. Data Modeling for Azure Data Services starts with an introduction to databases, entity analysis, and normalizing data. The book then shows you how to design a NoSQL database for optimal performance and scalability and covers how to provision and implement Azure SQL DB, Azure Cosmos DB, and Azure Synapse SQL Pool. As you progress through the chapters, you'll learn about data analytics, Azure Data Lake, and Azure SQL Data Warehouse and explore dimensional modeling, data vault modeling, along with designing and implementing a Data Lake using Azure Storage. You'll also learn how to implement ETL with Azure Data Factory. By the end of this book, you'll have a solid understanding of which Azure data services are the best fit for your model and how to implement the best design for your solution.What you will learnModel relational database using normalization, dimensional, or Data Vault modelingProvision and implement Azure SQL DB and Azure Synapse SQL PoolsDiscover how to model a Data Lake and implement it using Azure StorageModel a NoSQL database and provision and implement an Azure Cosmos DBUse Azure Data Factory to implement ETL/ELT processesCreate a star schema model using dimensional modelingWho this book is forThis book is for business intelligence developers and consultants who work on (modern) cloud data warehousing and design and implement databases. Beginner-level knowledge of cloud data management is expected.","","9781801076708","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163462.pdf&bkn=10163462&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Geospatial Data Analytics on AWS: Discover how to manage and analyze geospatial data in the cloud","S. Bateman; J. Gnanachandran; J. DeMuth",NA; NA; NA,Geospatial Data Analytics on AWS: Discover how to manage and analyze geospatial data in the cloud,"","2023","","","","","Build an end-to-end geospatial data lake in AWS using popular AWS services such as RDS, Redshift, DynamoDB, and Athena to manage geodata Purchase of the print or Kindle book includes a free PDF eBook.Key FeaturesExplore the architecture and different use cases to build and manage geospatial data lakes in AWSDiscover how to leverage AWS purpose-built databases to store and analyze geospatial dataLearn how to recognize which anti-patterns to avoid when managing geospatial data in the cloudBook DescriptionManaging geospatial data and building location-based applications in the cloud can be a daunting task. This comprehensive guide helps you overcome this challenge by presenting the concept of working with geospatial data in the cloud in an easy-to-understand way, along with teaching you how to design and build data lake architecture in AWS for geospatial data. You’ll begin by exploring the use of AWS databases like Redshift and Aurora PostgreSQL for storing and analyzing geospatial data. Next, you’ll leverage services such as DynamoDB and Athena, which offer powerful built-in geospatial functions for indexing and querying geospatial data. The book is filled with practical examples to illustrate the benefits of managing geospatial data in the cloud. As you advance, you’ll discover how to analyze and visualize data using Python and R, and utilize QuickSight to share derived insights. The concluding chapters explore the integration of commonly used platforms like Open Data on AWS, OpenStreetMap, and ArcGIS with AWS to enable you to optimize efficiency and provide a supportive community for continuous learning. By the end of this book, you’ll have the necessary tools and expertise to build and manage your own geospatial data lake on AWS, along with the knowledge needed to tackle geospatial data management challenges and make the most of AWS services.What you will learnDiscover how to optimize the cloud to store your geospatial dataExplore management strategies for your data repository using AWS Single Sign-On and IAMCreate effective SQL queries against your geospatial data using AthenaValidate postal addresses using Amazon Location servicesProcess structured and unstructured geospatial data efficiently using RUse Amazon SageMaker to enable machine learning features in your applicationExplore the free and subscription satellite imagery data available for use in your GISWho this book is forIf you understand the importance of accurate coordinates, but not necessarily the cloud, then this book is for you. This book is best suited for GIS developers, GIS analysts, data analysts, and data scientists looking to enhance their solutions with geospatial data for cloud-centric applications. A basic understanding of geographic concepts is suggested, but no experience with the cloud is necessary for understanding the concepts in this book.","","9781804610572","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251273.pdf&bkn=10251273&pdfType=book","","","","","","","","14 Sep 2023","","","Packt Publishing","Packt Publishing eBooks"
"Architecture of Data Recognition System Using Machine Learning and TensorFlow","S. Tripura; S. Lanka",NA; NA,2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT),"22 Mar 2024","2024","","","1694","1699","This research study analyzed how the structure of software architecture is applied in image recognition process in the field of data science and mainly focus on the concept of image recognition is, the types of data required and the scope of the volume of data needed for the undertaking. In general concepts behind data science will be explained, such as how the data is processed into a usable format, and the strategies used to categorize and sort the data. Architecture of tools used analyze the image recognition, their functionalities and why python is commonly used for processing large amounts of data like TensorFlow and Keras. This study analyses both the functional and non-functional requirements that image recognition require of thes e tools and how they are achieved","","979-8-3503-2753-3","10.1109/IDCIoT59759.2024.10467371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10467371","Big Data;Image Recognition;Data Science;TensorFlow;Keras;Json. Python","Training;Performance evaluation;Image recognition;Software architecture;Soft sensors;Computer architecture;Machine learning","","1","","15","IEEE","22 Mar 2024","4-6 Jan. 2024","4-6 Jan. 2024","IEEE","IEEE Conferences"
"Construction and Application of the ""Dual Carbon"" One-stop Digital Service Intelligent System","X. Li; Y. Chen; J. Liu; S. Wang; X. Liu; J. Zhang","Intelligent Energy Division, Tianjin Richsoft Power Information Technology Co. Ltd., Tianjin, China; Intelligent Energy Division, Tianjin Richsoft Power Information Technology Co. Ltd., Tianjin, China; Intelligent Energy Division, Tianjin Richsoft Power Information Technology Co. Ltd., Tianjin, China; Intelligent Energy Division, Tianjin Richsoft Power Information Technology Co. Ltd., Tianjin, China; Intelligent Energy Division, Tianjin Richsoft Power Information Technology Co. Ltd., Tianjin, China; Intelligent Energy Division, Tianjin Richsoft Power Information Technology Co. Ltd., Tianjin, China",2024 International Conference on Advances in Electrical Engineering and Computer Applications (AEECA),"4 Mar 2025","2024","","","678","685","In order to promote China's ""dual carbon"" Digital transformation, a ""dual carbon"" one-stop digital service intelligent system with ""carbon"" as the main body has been constructed. Firstly, the key technologies of multi-source heterogeneous data processing methods, carbon emission calculation methods, and analysis of carbon emission influencing factors were elaborated in detail, providing theoretical support for the implementation of system functions.Then, the seven core functions of the intelligent system, as well as the business architecture and data architecture of the intelligent system, were introduced, achieving the research and development and construction of the ""dual carbon"" one-stop digital service intelligent system. Finally, focusing on the needs of a certain national level new area, a demonstration application of the ""dual carbon"" one-stop digital service intelligent system has been carried out. The ""dual carbon"" one-stop digital service intelligent system provides one-stop service support for the whole process of ""Carbon Calculation - Carbon Observation - Carbon Analysis - Carbon Management"" in the region, and it can provide an effective solution for the green and low-carbon transformation of the regional economy.","","979-8-3503-5526-0","10.1109/AEECA62331.2024.00120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10898286","codouble carbon;multi source heterogeneous data;carbon emission calculation;digital services;intelligent system construction","Focusing;Carbon dioxide;Computer architecture;Emissions trading;Low carbon economy;Intelligent systems;Carbon;Sustainable development;Research and development;Monitoring","","1","","25","IEEE","4 Mar 2025","16-18 Aug. 2024","16-18 Aug. 2024","IEEE","IEEE Conferences"
"Cloud Computing Demystified for Aspiring Professionals: Hone your skills in AWS, Azure, and Google cloud computing and boost your career as a cloud engineer","D. Santana; A. Malik",NA; NA,"Cloud Computing Demystified for Aspiring Professionals: Hone your skills in AWS, Azure, and Google cloud computing and boost your career as a cloud engineer","","2023","","","","","Gain in-depth knowledge of cloud computing concepts and apply them to accelerate your career in any cloud engineering roleKey FeaturesGet to grips with key cloud computing concepts, cloud service providers, and best practicesExplore demonstrations for cloud computing models using real-world examplesAdopt the self-paced learning strategy and get industry-ready for cloud engineering rolesPurchase of the print or Kindle book includes a free eBook in the PDF formatBook DescriptionIf you want to upskill yourself in cloud computing domains to thrive in the IT industry, then you’ve come to the right place. Cloud Computing Demystified for Aspiring Professionals helps you to master cloud computing essentials and important technologies offered by cloud service providers needed to succeed in a cloud-centric job role. This book begins with an overview of transformation from traditional to modern-day cloud computing infrastructure, and various types and models of cloud computing. You’ll learn how to implement secure virtual networks, virtual machines, and data warehouse resources including data lake services used in big data analytics — as well as when to use SQL and NoSQL databases and how to build microservices using multi-cloud Kubernetes services across AWS, Microsoft Azure, and Google Cloud. You'll also get step-by-step demonstrations of infrastructure, platform, and software cloud services and optimization recommendations derived from certified industry experts using hands-on tutorials, self-assessment questions, and real-world case studies. By the end of this book, you'll be ready to successfully implement cloud computing standardized concepts, services, and best practices in your workplace.What you will learnGain insights into cloud computing essentials and public, private, hybrid, and multi-cloud deployment modelsExplore core cloud computing services such as IaaS, PaaS, and SaaSDiscover major public cloud providers such as AWS, Microsoft, and GoogleUnlock the power of IaaS, PaaS, and SaaS with AWS, Azure, and GCPCreate secure networks, containers, Kubernetes, compute, databases, and API services on cloudDevelop industry-based cloud solutions using real-world examplesGet recommendations on exam preparation for cloud accreditationsWho this book is forThe book is for aspiring cloud engineers, as well as college graduates, IT enthusiasts, and beginner-level cloud practitioners looking to get into cloud computing or transforming their career and upskilling themselves in a cloud engineering role in any industry. A basic understanding of networking, database development, and data analysis concepts and experience in programming languages such as Python and C# will help you get the most out of this book.","","9781803230573","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163446.pdf&bkn=10163446&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Semantic Multimedia Fog Computing and IoT Environment: Sustainability Perspective","M. A. Rahman; M. S. Hossain; E. Hassanain; G. Muhammad",University of Prince Mugrin; King Saud University; University of Prince Mugrin; King Saud University,IEEE Communications Magazine,"17 May 2018","2018","56","5","80","87","We propose a fog-cloud hybrid architecture that can support a massive ad hoc crowd composed of a massive social network and distributed IoT nodes around a smart city environment. The fog computing framework is introduced to support energy efficiency by incorporating IoT nodes that act as an interface to the ad hoc crowd, is aware of user contexts within its vicinity, can do real-time processing of user requests, supports a constrained amount of data offloading, and pass the geo-tagged multimedia data available from the subset of the ad hoc crowd to the big data repository in the cloud. The framework leverages a sustainable crowdsourcing incentive model for both the ad hoc crowd and the IoT infrastructure provider. The proposed sustainable framework can potentially support context-aware smart city services such as finding a lost person within the crowd, showing green and health risk prone zones, semantic and location-aware notifications of events of interest, semantic IoT-based routing, and dealing with emergency situations. We present a communication architecture between mobile users and fog nodes, and between fog nodes and the cloud, a sustainability and energy efficiency model, and massive geo-tagged, multimedia big data architecture.","1558-1896","","10.1109/MCOM.2018.1700907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360855","","Smart cities;Cloud computing;Edge computing;Semantics;Multimedia communication;Computer architecture;Social network services;Energy efficiency;Ad hoc networks","","51","","13","IEEE","17 May 2018","May 2018","","IEEE","IEEE Magazines"
"Hierarchical Hybrid Networks for Automatic Pulmonary Blood Vessel Segmentation in Computed Tomography Images","Q. Zhou; R. Zhao; Y. Hu; J. Wang; R. Zhou","School of Information Science & Engineering, Lanzhou University, Lanzhou, China; School of Information Science & Engineering, Lanzhou University, Lanzhou, China; School of Information Science & Engineering, Lanzhou University, Lanzhou, China; School of Information Science & Engineering, Lanzhou University, Lanzhou, China; School of Information Science & Engineering, Lanzhou University, Lanzhou, China",IEEE/ACM Transactions on Computational Biology and Bioinformatics,"8 Aug 2024","2024","21","4","778","788","Pulmonary arterial hypertension (PAH) is considered the third most common cardiovascular disease after coronary heart disease and hypertension. The diagnosis of PAH is mainly based on the comprehensive judgment of computed tomography and other medical image examinations. Medical image processing based on deep learning has achieved significant success. However, the data belongs to the patient's privacy; therefore, the medical institutions as data custodians have the responsibility to protect the security of their data privacy. This situation makes medical institutions face a dilemma when building data-driven deep learning-assisted medical diagnosis methods. On the one hand, they need to pursue more high-quality data based on Big Data architecture for deep learning; on the other hand, they need to protect patient privacy to avoid data leakage. In response to the above challenges, we propose a hierarchical hybrid automatic segmentation model for pulmonary blood vessels based on local learning and federated learning approaches for segmenting the pulmonary blood vessels. The experiments prove the proposal could automatically segment the vessels from the original CT. It also indicates that the model based on a federated learning approach can achieve impressive performance under the premise of protecting data privacy for Big Data.","1557-9964","","10.1109/TCBB.2023.3281828","National Key R&D Program of China(grant numbers:2020YFC0832500); Gansu Province Key Research and Development Plan -Industrial Project(grant numbers:22YF7GA004); Ministry of Education-China Mobile Research Foundation(grant numbers:MCM20170206); Fundamental Research Funds for the Central Universities(grant numbers:lzujbky-2022-kb12); Supercomputing Center of Lanzhou University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10141871","Pulmonary mediastinal window segmentation;pulmonary blood vessel segmentation;deep learning;federated learning","Lung;Image segmentation;Blood vessels;Computed tomography;Medical diagnostic imaging;Data privacy;Federated learning","Humans;Tomography, X-Ray Computed;Deep Learning;Algorithms;Pulmonary Artery;Neural Networks, Computer;Image Processing, Computer-Assisted","6","","51","IEEE","1 Jun 2023","July-Aug. 2024","","IEEE","IEEE Journals"
"Planning a Case for Shared Data Retrieval across the European Maritime Common Information Sharing Environment","A. Mihailović; N. Kapidani; Ž. Lukšić; R. Tournier; G. Vella; M. Moutzouris; B. de Sousa; A. Blum; Z. Paladin","Administration for Maritime Safety and Port Management, Bar, Montenegro; Administration for Maritime Safety and Port Management, Bar, Montenegro; Administration for Maritime Safety and Port Management, Bar, Montenegro; Institut de Recherche en Informatique de Toulouse, Universite Toulouse 1 Capitole, France; Engineering Ingegneria Informatic SPA, Italy; Satways Ltd., Greece; Escola Naval, Base Naval de Lisboa, Portugal; Secrétariat general de la mer, France; Administration for Maritime Safety and Port Management, Bar, Montenegro",2022 26th International Conference on Information Technology (IT),"30 Mar 2022","2022","","","1","6","This paper outlines an example method and trial scenario phases for extending the existing tools for maritime surveillance across the maritime regions of Europe. There are continuous dedicated efforts throughout European collaborations for advancing the features of Common Information Sharing Environment (CISE), which is a European Union (EU) initiative for ubiquitous information sharing across the maritime and land borders, as well as between the national sectors. The EFFECTOR EU project introduces a novel concept in the information exchange: the data lake, intended for providing a common smart data repository for diverse and comprehensive data analysis and storage that emanates from diverse sources within the local, regional, national, and international scope. Setting up of the data lake facilities and broadened information exchange is established and validated through early trials planned to be conducted in the project. Administration for Maritime Safety and Port Management (AMSPM) is integrating maritime surveillance data from Montenegro in the EU information exchanges and vice versa. The EFFECTOR project's French maritime trial offers an implementation of the broadened scope of uses of advanced data exchanges, analysis storage, and retrieval. A case of retroactive data analysis and deductions is to be demonstrated through collaboration of AMSPM in the French maritime trial with other project partners. The trial scenario planning includes two vessels coming into the French waters near Marseille from distant ports, one via a stop-over in Montenegro and the other from Portugal.","","978-1-6654-2127-0","10.1109/IT54280.2022.9743531","Research Executive Agency (REA); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743531","","Data analysis;Surveillance;Europe;Information sharing;Collaboration;Seaports;Big Data applications","","2","","15","IEEE","30 Mar 2022","16-19 Feb. 2022","16-19 Feb. 2022","IEEE","IEEE Conferences"
"MetaLens: A Web-Based Tool for Multi-Format Metadata Exploration","S. Dongarkar; O. Kulkarni; A. Aparadh; M. Panjwani; T. Shingde","Department of Computer Science And Engineering, Walchand College of Engineering, Sangli, Sangli, India; Department of Computer Science And Engineering, Walchand College of Engineering, Sangli, Sangli, India; Department of Information Technology, Walchand College of Engineering, Sangli, Sangli, India; Department of Computer Science And Engineering, Walchand College of Engineering, Sangli, Sangli, India; Department of Information Technology, Walchand College of Engineering, Sangli, Sangli, India",2025 International Conference on Future Technologies (ICFT),"21 Jan 2026","2025","","","1","6","MetaLens is a format-agnostic metastore viewer that is web-based, developed to standardize the metadata exploration phase of heterogeneous storage systems. The rise of open data lake formats, including Apache Iceberg, Delta Lake, Apache Hudi, and Parquet, has occurred quickly and has empowered organizations to manage analytical workloads at scale while benefiting from schema evolution, transactional guarantees, and time travel. These big advancements have also made metadata management a challenge as previous solutions, including Hive Metastore and AWS Glue, remain format-specific with limited visualization and are tightly-coupled to execution engines. MetaLens extracts and visualizes schemas, partitions, properties, and version histories directly from object storage paths and does not require a traditional centralized or pre-registered metastore/catalog to be functional. The evaluation across various data lake formats (Parquet, Iceberg, Delta, Hudi) and storage backends (Amazon S3, Azure Blob, MinIO) confirmed that MetaLens accurately extracts and visualizes the metadata and is useful for schema evolution and partition analysis. MetaLens was revealed to provide a consistent, lightweight, and extensible metadata exploration experience with improved transparency, flexibility, and adaptability compared to traditional catalog approaches.","","979-8-3315-6815-3","10.1109/ICFT66708.2025.11336690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11336690","Metadata exploration;data lakes;Parquet;Iceberg;Delta Lake;Hudi;schema evolution;multi-cloud;microservices architecture","Standards organizations;Data visualization;Organizations;Metadata;Lakes;Big Data applications;Icebergs;History;Usability;Engines","","","","24","IEEE","21 Jan 2026","7-8 Nov. 2025","7-8 Nov. 2025","IEEE","IEEE Conferences"
"Open Data Platform as a Source of ML-Driven Innovations in the Energy Sector","F. Nepsha; V. Voronin; S. Kovalyov","RTSoft Smart Grid, LLC, Gubkin University T.F. Gorbachev Kuzbass State Technical University, Moscow, Russia; Mining industry digital transformation laboratory, T.F. Gorbachev Kuzbass State Technical University, Kemerovo, Russia; Institute of control sciences of Russian academy of sciences, Moscow, Russia",2023 Belarusian-Ural-Siberian Smart Energy Conference (BUSSEC),"31 Oct 2023","2023","","","1","6","This article explores the challenges and potential solutions associated with the accumulation and utilization of open data in the energy sector, particularly in the context of machine learning (ML)-driven innovations. The growing adoption of Internet of Things (IoT) technologies has led to a significant increase in data generation, creating opportunities for leveraging big data processing and ML methods. However, the lack of an effective ecosystem for ML-driven innovations in the energy sector hampers progress. The article discusses the main problems related to open data accumulation and usage and reviews existing publications on organizing open data in the energy sector. It proposes an ecosystem approach to establish an open data platform that meets stakeholders' needs and accelerates innovation. Additionally, it introduces the application of a data lakehouse architecture as an efficient storage and management solution for the platform. By addressing the challenges and implementing the suggested solutions, the energy sector can unlock the full potential of open data, foster collaboration, and drive transformative innovations.","","979-8-3503-5807-0","10.1109/BUSSEC59406.2023.10296377","Ministry of Science and Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10296377","energy sector;open data;ML-driven innovation;data-driven innovation;digital platform","Industries;Technological innovation;Renewable energy sources;Ecosystems;Machine learning;Maintenance engineering;Power systems","","2","","40","IEEE","31 Oct 2023","25-29 Sept. 2023","25-29 Sept. 2023","IEEE","IEEE Conferences"
"Cloud Data Security","L. Fife; A. Kraus; B. Lewis",NA; NA; NA,The Official (ISC)2 CCSP CBK Reference,"","2021","","","43","85","Responsibility for many elements of cloud security are shared between the cloud service provider and the cloud consumer, while each party retains exclusive control over some elements. Data in each phase of the lifecycle faces specific risks, and the cloud security practitioner should thoroughly understand these risks and appropriate mitigations specific to each phase. Data dispersion in cloud environments can have both positive and negative impacts on an organization's security. There are universal threats to data at rest regardless of the location, including on‐premises or legacy environments, local workstation storage, and cloud services. Encryption in cloud services may be implemented at a variety of layers, from the user‐facing application all the way down to the physical storage devices. There are a number of important terms associated with data discovery and business intelligence, including the following: data lake and data warehouse, data mart, data mining, and online analytic processing.","","9781119603450","10.1002/9781119603399.ch2","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821808.pdf&bkn=9820844&pdfType=chapter","","Cloud computing;Security;Organizations;Phase control;Dispersion;Media;Encryption","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Peer-to-peer disaggregated telemetry for autonomic machine-learning-driven transceiver operation","F. Paolucci; A. Sgambelluri; M. Felipe Silva; A. Pacini; P. Castoldi; L. Valcarenghi; F. Cugini","CNIT, Pisa, Italy; Scuola Superore Sant'Anna, Pisa, Italy; Engineering Institute, Los Alamos National Laboratory, Los Alamos, NM, USA; Scuola Superore Sant'Anna, Pisa, Italy; Scuola Superore Sant'Anna, Pisa, Italy; Scuola Superore Sant'Anna, Pisa, Italy; CNIT, Pisa, Italy",Journal of Optical Communications and Networking,"1 Jul 2022","2022","14","8","606","620","Autonomic networking and monitoring will drive the evolution of next generation software defined networking (SDN) optical networks towards the zero touch networking paradigm. Optical telemetry services will play a key role to enable advanced network awareness at device and component granularity. Optical disaggregation is pushing the adoption of open models, enabling multi-vendor interoperability, including telemetry. Moreover, due to whitebox programmability and the adoption of open source micro services, it is becoming feasible to monitor data streams from optical devices related to quality of transmission key performance indicators. Finally, due to mature big data analytics platforms, including machine learning and artificial intelligence, the telemetry data lake is processed to effectively detect network anomalies. However, current centralized telemetry architectures are prone to scalability issues, suboptimal soft failure recovery due to operational mode limitations, and/or the inability of the SDN controller of tuning finer or proprietary transmission parameters. Conversely, a number of soft failures might be detected and recovered directly at the optical card transmitter, often in a hitless fashion, also relying on optimized vendor-proprietary configurations. The paper proposes what we believe to be a novel peer-to-peer telemetry (P2PT) service ready for next generation digital coherent optics cards, for local processing and soft failure recovery at the transceiver agent level. The P2PT architecture, workflow, and subscription extensions are conceived to enable direct and fast recovery at the transceiver level, resorting to optical signal retuning and adaptations. Experimental evaluations, including lightweight machine learning detection at the card agent, are provided in a multi-vendor disaggregated optical network testbed to assess different soft failure use cases and P2PT service scalability.","1943-0639","","10.1364/JOCN.456666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9812947","","Telemetry;Monitoring;Optical network units;Optical receivers;Optical signal processing;Optical transmitters;Optical sensors","","7","","","","1 Jul 2022","August 2022","","IEEE","IEEE Journals"
"The Digital System Architecture for Multi-Level Collaborative Monitoring and Analysis of Converter Station Main Equipment","S. Liu; Q. Wang; L. Zhang; S. Zheng","State Grid Economic and Technological Research Institute Co., Ltd, Beijing, China; State Grid Corporation of China, Beijing, China; North China Electric Power University, Beijing, China; North China Electric Power University, Beijing, China",2024 4th International Conference on Smart Grid and Energy Internet (SGEI),"14 Mar 2025","2024","","","512","517","The existing converter station monitoring and analysis system faces issues such as low data aggregation efficiency and difficulty in application iteration and upgrading. Therefore, a multi-level collaborative converter station main equipment monitoring and analysis digital system architecture is studied. Firstly, based on the business requirements of converter station equipment monitoring and analysis, real-time and non-real-time business applications are proposed, along with the demand for full integration of data. Secondly, a three-level collaborative converter station equipment information system architecture for headquarters, provincial companies, and converter stations is constructed. The application architecture for monitoring, analysis, and model training at each level is planned, along with a data architecture covering full data collection, unified data model integration, and cross-domain data interaction. Lastly, a digital technical architecture for equipment monitoring and analysis is proposed, including multi-level collaborative application training and sharing, holographic data collection based on multiple aggregation nodes, data correlation and model mapping, and cross-level data interaction technology. Based on the above digital system architecture, the data matching of equipment ledger, status, inspection, experiment, and process multi-business flow data is achieved. Transparent data interaction between on-site business applications and model exchange among headquarters, provincial companies, and converter stations at multiple levels is also realized.","","979-8-3503-6831-4","10.1109/SGEI63936.2024.10914109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10914109","Converter Station;Digital Transformation;Equipment Monitoring;Equipment Analysis","Training;Analytical models;Digital systems;Collaboration;Companies;Inspection;Data models;Real-time systems;Monitoring;Business","","1","","6","IEEE","14 Mar 2025","13-15 Dec. 2024","13-15 Dec. 2024","IEEE","IEEE Conferences"
"AI Jargon and Development","S. Rashidi",NA,"Your AI Survival Guide: Scraped Knees, Bruised Elbows, and Lessons Learned from Real-World AI Deployments","","2024","","","169","189","Summary <p>There are many verticals within computer science including software development (like websites), research and development (developing new computer languages), machine learning (discovering and/or using different algorithms to analyze large sets of data), architecture (making sure software and hardware integrate, like our phone with our downloaded apps), and more. The real application of AI dates back to the early 1900s with early myths and folklore depicting machines with human‐like intelligence. The foundations of AI as a reality was really born in the realms of philosophy, mathematics, and early computing. In the middle of last century, AI quickly became the topic of sci‐fi movies, making it a bit more mainstream and the topic of many conversations. Programmers from around the world also jumped into the realm of AI. We're seeing progression from virtual assistants to recommendations engines with AI systems now becoming part of our everyday lives.</p>","","9781394272655","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10951360.pdf&bkn=10950178&pdfType=chapter","","Artificial intelligence;Computer science;Human intelligence;Electronic mail;Servers;Internet;History;Feeds;Chatbots;Social networking (online)","","","","","","8 Apr 2025","","","Wiley","Wiley AI eBook Chapters"
"Technology Roadmapping: Monitoring the Status of a Technology Roadmap with Data‐driven Roadmapping Approach","N. Gerdsri; U. Pora; S. Puengrusme; R. Vatananan","College of Management, Mahidol University, Bangkok, Thailand; Technopreneurship and Innovation Management Program, Chulalongkorn University, Bangkok, Thailand; College of Management, Mahidol University, Bangkok, Thailand; College of Management, Mahidol University, Bangkok, Thailand",Future-Oriented Technology Assessment: A Manager's Guide with Case Applications,"","2025","","","371","400","Summary <p>Under the changing business environment and emergence of breakthrough technologies, keeping a roadmap alive appears to be a major challenge for many organizations because a roadmap itself reflects only a snapshot of an organization's strategic plan based on the information at the point when a roadmap is developed. It is crucial for an organization to monitor changes in its business environment as well as the development progress that may exert different effects on a roadmap and assess whether such changes are sufficiently relevant and significant. If so, then an updated version of a roadmap will be required. With the incorporation of proper data architecture into the roadmapping approach, the status of a roadmap can be actively monitor so that management can make a timely decision on whether a roadmap needs to be slightly adjusted, totally revised, or remain unchanged.</p>","","9781119909866","10.1002/9781119909880.ch13","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10676367.pdf&bkn=10676345&pdfType=chapter","","Monitoring;Organizations;Reviews;Vehicles;Transmission line measurements;Stakeholders;Schedules","","","","","","11 Sep 2024","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Mastering MongoDB 6.x: Expert techniques to run high-volume and fault-tolerant database solutions using MongoDB 6.x","A. Giamas",NA,Mastering MongoDB 6.x: Expert techniques to run high-volume and fault-tolerant database solutions using MongoDB 6.x,"","2022","","","","","Design and build solutions with the most powerful document database, MongoDBKey FeaturesLearn from the experts about every new feature in MongoDB 6 and 5Develop applications and administer clusters using MongoDB on premise or in the cloudExplore code-rich case studies showcasing MongoDB’s major features followed by best practicesBook DescriptionMongoDB is a leading non-relational database. This book covers all the major features of MongoDB including the latest version 6. MongoDB 6.x adds many new features and expands on existing ones such as aggregation, indexing, replication, sharding and MongoDB Atlas tools. Some of the MongoDB Atlas tools that you will master include Atlas dedicated clusters and Serverless, Atlas Search, Charts, Realm Application Services/Sync, Compass, Cloud Manager and Data Lake. By getting hands-on working with code using realistic use cases, you will master the art of modeling, shaping and querying your data and become the MongoDB oracle for the business. You will focus on broadly used and niche areas such as optimizing queries, configuring large-scale clusters, configuring your cluster for high performance and availability and many more. Later, you will become proficient in auditing, monitoring, and securing your clusters using a structured and organized approach. By the end of this book, you will have grasped all the practical understanding needed to design, develop, administer and scale MongoDB-based database applications both on premises and on the cloud.What you will learnUnderstand data modeling and schema design, including smart indexingMaster querying data using aggregationUse distributed transactions, replication and sharding for better resultsAdminister your database using backups and monitoring toolsSecure your cluster with the best checklists and adviceMaster MongoDB Atlas, Search, Charts, Serverless, Realm, Compass, Cloud Manager and other tools offered in the cloud or on premisesIntegrate MongoDB with other big data sourcesDesign and deploy MongoDB in mobile, IoT and serverless environmentsWho this book is forThis book is for MongoDB developers and database administrators who want to learn how to model their data using MongoDB in depth, for both greenfield and existing projects. An understanding of MongoDB, shell command skills and basic database design concepts is required to get the most out of this book.","","9781803234830","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10162679.pdf&bkn=10162679&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Data Engineering with AWS Cookbook: A recipe-based approach to help you tackle data engineering problems with AWS services","T. N. Phạm; G. H. González; V. Khan; H. Nofal",NA; NA; NA; NA,Data Engineering with AWS Cookbook: A recipe-based approach to help you tackle data engineering problems with AWS services,"","2024","","","","","Master AWS data engineering services and techniques for orchestrating pipelines, building layers, and managing migrationsKey FeaturesGet up to speed with the different AWS technologies for data engineeringLearn the different aspects and considerations of building data lakes, such as security, storage, and operationsGet hands on with key AWS services such as Glue, EMR, Redshift, QuickSight, and Athena for practical learningPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionPerforming data engineering with Amazon Web Services (AWS) combines AWS's scalable infrastructure with robust data processing tools, enabling efficient data pipelines and analytics workflows. This comprehensive guide to AWS data engineering will teach you all you need to know about data lake management, pipeline orchestration, and serving layer construction. Through clear explanations and hands-on exercises, you’ll master essential AWS services such as Glue, EMR, Redshift, QuickSight, and Athena. Additionally, you’ll explore various data platform topics such as data governance, data quality, DevOps, CI/CD, planning and performing data migration, and creating Infrastructure as Code. As you progress, you will gain insights into how to enrich your platform and use various AWS cloud services such as AWS EventBridge, AWS DataZone, and AWS SCT and DMS to solve data platform challenges. Each recipe in this book is tailored to a daily challenge that a data engineer team faces while building a cloud platform. By the end of this book, you will be well-versed in AWS data engineering and have gained proficiency in key AWS services and data processing techniques. You will develop the necessary skills to tackle large-scale data challenges with confidence.What you will learnDefine your centralized data lake solution, and secure and operate it at scaleIdentify the most suitable AWS solution for your specific needsBuild data pipelines using multiple ETL technologiesDiscover how to handle data orchestration and governanceExplore how to build a high-performing data serving layerDelve into DevOps and data quality best practicesMigrate your data from on-premises to AWSWho this book is forIf you're involved in designing, building, or overseeing data solutions on AWS, this book provides proven strategies for addressing challenges in large-scale data environments. Data engineers as well as big data professionals looking to enhance their understanding of AWS features for optimizing their workflow, even if they're new to the platform, will find value. Basic familiarity with AWS security (users and roles) and command shell is recommended. ","","9781805126850","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10818433.pdf&bkn=10818433&pdfType=book","","","","","","","","30 Dec 2024","","","Packt Publishing","Packt Publishing eBooks"
"Azure Databricks Cookbook: Accelerate and scale real-time analytics solutions using the Apache Spark-based analytics service","P. Raj; V. Jaiswal",NA; NA,Azure Databricks Cookbook: Accelerate and scale real-time analytics solutions using the Apache Spark-based analytics service,"","2021","","","","","Get to grips with building and productionizing end-to-end big data solutions in Azure and learn best practices for working with large datasetsKey FeaturesIntegrate with Azure Synapse Analytics, Cosmos DB, and Azure HDInsight Kafka Cluster to scale and analyze your projects and build pipelinesUse Databricks SQL to run ad hoc queries on your data lake and create dashboardsProductionize a solution using CI/CD for deploying notebooks and Azure Databricks Service to various environmentsBook DescriptionAzure Databricks is a unified collaborative platform for performing scalable analytics in an interactive environment. The Azure Databricks Cookbook provides recipes to get hands-on with the analytics process, including ingesting data from various batch and streaming sources and building a modern data warehouse. The book starts by teaching you how to create an Azure Databricks instance within the Azure portal, Azure CLI, and ARM templates. You’ll work through clusters in Databricks and explore recipes for ingesting data from sources, including files, databases, and streaming sources such as Apache Kafka and EventHub. The book will help you explore all the features supported by Azure Databricks for building powerful end-to-end data pipelines. You'll also find out how to build a modern data warehouse by using Delta tables and Azure Synapse Analytics. Later, you’ll learn how to write ad hoc queries and extract meaningful insights from the data lake by creating visualizations and dashboards with Databricks SQL. Finally, you'll deploy and productionize a data pipeline as well as deploy notebooks and Azure Databricks service using continuous integration and continuous delivery (CI/CD). By the end of this Azure book, you'll be able to use Azure Databricks to streamline different processes involved in building data-driven apps.What you will learnRead and write data from and to various Azure resources and file formatsBuild a modern data warehouse with Delta Tables and Azure Synapse AnalyticsExplore jobs, stages, and tasks and see how Spark lazy evaluation worksHandle concurrent transactions and learn performance optimization in Delta tablesLearn Databricks SQL and create real-time dashboards in Databricks SQLIntegrate Azure DevOps for version control, deploying, and productionizing solutions with CI/CD pipelinesDiscover how to use RBAC and ACLs to restrict data accessBuild end-to-end data processing pipeline for near real-time data analyticsWho this book is forThis recipe-based book is for data scientists, data engineers, big data professionals, and machine learning engineers who want to perform data analytics on their applications. Prior experience of working with Apache Spark and Azure is necessary to get the most out of this book.","","9781789618556","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10162379.pdf&bkn=10162379&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Decarbonizing the Aerospace Scope 3 emissions with efficient data monitoring framework","P. Durai; J. Nalavade","Liverpool John Moores University, England; upGrad Education Pvt. Ltd, Mumbai, (India)",2023 16th International Conference on Developments in eSystems Engineering (DeSE),"21 Mar 2024","2023","","","534","539","Aerospace is one of the most difficult industries to decarbonize, contributing 2.5% of global CO2 emissions. Achieving climate-neutral operations is a common challenge faced due to principal factors such as scale, expenses, and legal hurdles of placing innovative technology in the air. Jet fuel is a cost-effective technology; however, a major drawback is the enormous amounts of carbon released from the fuel. It can be appreciated that calculating and then eliminating Scope 3 emissions is an arduous concept since it accounts for a larger amount of carbon footprint for most aerospace industries. In terms of the volume of Scope 3 emissions, there is a rising urgency to cut them and transition to more sustainable methods of flying.To support the Paris Agreement various research and studies have been conducted to discover the causes of Scope 3 emissions and to minimize the impact that is bringing to this environment, but there is no clear industry-wide framework for tracking Aerospace Scope 3 emissions overall. The aim of this research is to develop a single data monitoring framework to gather and make use of data from diverse streams of aircraft operations. The primary objective of our study is to choose the appropriate datasets for the various Scope 3 emissions from airplanes and include those datasets into our proposed methodology to create informative results and seek to minimize GHG emissions in the environment.We employ big data analytical technologies to accomplish the study objectives. Our model is created in such a way that allows it to adjust for both batch and real-time inputs. The paper also discusses the data architecture and evaluation metrics used to assess the effectiveness of the framework. Aerospace companies can use this framework to monitor and manage their emissions, set targets, and develop strategies to reduce their carbon footprint. The results show that the framework can provide valuable insights into emissions data and help stakeholders make informed decisions to reduce their environmental impact.","","979-8-3503-8134-4","10.1109/DeSE60595.2023.10469041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10469041","Sustainable Aviation;Scope 3 Emissions;Data Monitoring Framework;Aerospace;Carbon footprint;Climate Change;Carbon-Neutral;Big Data Analytics","Measurement;Reliability engineering;Real-time systems;Fuels;Stakeholders;Aerospace industry;Monitoring","","","","14","IEEE","21 Mar 2024","18-20 Dec. 2023","18-20 Dec. 2023","IEEE","IEEE Conferences"
"Using UML and OCL Models to Realize High-Level Digital Twins","P. Muñoz; J. Troya; A. Vallecillo","ITIS Software. Universidad de Málaga, Spain; ITIS Software. Universidad de Málaga, Spain; ITIS Software. Universidad de Málaga, Spain",2021 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C),"20 Dec 2021","2021","","","212","220","Digital twins constitute virtual representations of physically existing systems. However, their inherent complexity makes them difficult to develop and prove correct. In this paper we explore the use of UML and OCL, complemented with an executable language, SOIL, to build and test digital twins at a high level of abstraction. We also show how to realize the bidirectional connection between the UML models of the digital twin in the USE tool with the physical twin, using an architectural framework centered on a data lake. We have built a prototype of the framework to demonstrate our ideas, and validated it by developing a digital twin of a Lego Mindstorms car. The results allow us to show some interesting advantages of using high-level UML models to specify virtual twins, such as simulation, property checking and some other types of tests.","","978-1-6654-2484-4","10.1109/MODELS-C53483.2021.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643725","Model-based Software Engineering;Model-based Testing;Digital Twins;UML;OCL;USE","Digital twin;Unified modeling language;Soil;Big Data applications;Software;Proposals;Synchronization","","22","","35","IEEE","20 Dec 2021","10-15 Oct. 2021","10-15 Oct. 2021","IEEE","IEEE Conferences"
"Efficient Sampling Algorithm for Electric Machine Design Calculations incorporating Empirical Knowledge","M. Heroth; H. C. Schmid; W. Hofmann","Chair of Electrical Machines and Drives, Technische Universität Dresden, Dresden; Development Department for Electrical Machines, ZF Friedrichshafen AG, Schweinfurt, Germany; Chair of Electrical Machines and Drives, Technische Universität Dresden, Dresden",2022 International Conference on Electrical Machines (ICEM),"13 Oct 2022","2022","","","1089","1095","In order to meet the increasing demand for electric vehicles, automotive suppliers such as ZF Friedrichshafen AG are trying to develop modular electric motor platforms. In order to find the optimal platform and to be able to use machine learning techniques, a large amount of data is required. This article shows an overall concept that includes a central database. With this it is possible to build a continuously growing data lake to support the electric machine design with a data-driven solution. The efficient sampling algorithm developed makes it possible to incorporate empirical knowledge into the sampling. In addition, it is possible to reuse calculated designs and no design is calculated more than once. This achieves the efficient generation of large amounts of data, which enable the use of machine learning.","2381-4802","978-1-6654-1432-6","10.1109/ICEM51905.2022.9910814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9910814","Adaptive Algorithms;Constrained Space;Design of Experiments;Electric Machines;Machine Learning;Multimedia Database;Space-Filling","Machine learning algorithms;Electric machines;Databases;Machine learning;Electric vehicles;Big Data applications;Filling","","7","","23","EU","13 Oct 2022","5-8 Sept. 2022","5-8 Sept. 2022","IEEE","IEEE Conferences"
"Towards Optimizing Storage Costs on the Cloud","K. Mukherjee; R. Shah; S. Saini; K. Singh; Khushi; H. Kesarwani; K. Barnwal; A. Chauhan",Adobe Research; Adobe Research; IIT Roorkee; IIT Roorkee; IIT Roorkee; IIT Roorkee; IIT Roorkee; UT Austin,2023 IEEE 39th International Conference on Data Engineering (ICDE),"26 Jul 2023","2023","","","2919","2932","We study the problem of optimizing data storage and access costs on the cloud while ensuring that the desired performance or latency is unaffected. We first propose an optimizer that optimizes the data placement tier (on the cloud) and the choice of compression schemes to apply, for given data partitions with temporal access predictions. Secondly, we propose a model to learn the compression performance of multiple algorithms across data partitions in different formats to generate compression performance predictions on the fly, as inputs to the optimizer. Thirdly, we propose to approach the data partitioning problem fundamentally differently than the current default in most data lakes where partitioning is in the form of ingestion batches. We propose access pattern aware data partitioning and formulate an optimization problem that optimizes the size and reading costs of partitions subject to access patterns.We study the various optimization problems theoretically as well as empirically, and provide theoretical bounds as well as hardness results. We propose a unified pipeline of cost minimization, called SCOPe that combines the different modules. We extensively compare the performance of our methods with related baselines from the literature on TPC-H data as well as enterprise datasets (ranging from GB to PB in volume) and show that SCOPe substantially improves over the baselines. We show significant cost savings compared to platform baselines, of the order of 50% to 83% on enterprise Data Lake datasets that range from terabytes to petabytes in volume.","2375-026X","979-8-3503-2227-9","10.1109/ICDE55515.2023.00223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10184773","storage costs;multi-tiering;compression;data partitioning;optimization","Costs;Pipelines;Memory;Predictive models;Big Data applications;Prediction algorithms;Minimization","","3","","46","IEEE","26 Jul 2023","3-7 April 2023","3-7 April 2023","IEEE","IEEE Conferences"
"SE-VFC: Secure and Efficient Outsourcing Computing in Vehicular Fog Computing","X. Liu; W. Chen; Y. Xia; C. Yang","School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, China; School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, China",IEEE Transactions on Network and Service Management,"8 Sep 2021","2021","18","3","3389","3399","Fog-aided computing is an emerging computing paradigm developed for providing various computation services to end users in vehicular fog computing. However, fog vehicles may be untrusted, and results from malicious operations may cause serious accidents. Therefore, we propose a secure and efficient outsourcing computing scheme in vehicular fog computing (SE-VFC), which performs outsourcing computing through fog vehicles with computing resources, and combines lightweight Boneh-Lynn-Shacham (BLS) signature and group signature to achieve batch anonymous authentication of fog vehicles while protecting their privacy in multiple outsourcing tasks. We also verify the correctness of the outsourcing computing results. Security analysis shows that our scheme can authenticate the fog vehicles in the outsourcing computation and preserve their privacy, it can also trace the malicious ones if necessary. Compared with the existing schemes, our scheme has relatively low communication and computation overhead, thus it is quite efficient for batch authentication especially in multiple computing tasks. Extensive simulation results verify the effectiveness and practicality of our proposed scheme in vehicular fog computing.","1932-4537","","10.1109/TNSM.2021.3080138","Zhejiang Provincial Natural Science Foundation of China(grant numbers:LY19F020021); National Natural Science Foundation of China(grant numbers:61873232); Science and Technology Program of the Ministry of Public Security(grant numbers:2018GABJC33); New Talent Plan of Zhejiang Province(grant numbers:2020R427062); Opening Project of Key Laboratory of Ministry of Public Security (Public Security Information Application Based on Big-data Architecture)(grant numbers:2020DSJSYS005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430621","Outsourcing computing;vehicular fog computing;Boneh-Lynn-Shacham (BLS) signature;attribute-based encryption (ABE)","Outsourcing;Security;Task analysis;Edge computing;Encryption;Resource management;Servers","","26","","43","IEEE","13 May 2021","Sept. 2021","","IEEE","IEEE Journals"
"HDRS: A Hybrid Reputation System With Dynamic Update Interval for Detecting Malicious Vehicles in VANETs","X. Liu; O. Ma; W. Chen; Y. Xia; Y. Zhou","School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; College of Computer Sciences, Zhejiang University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China",IEEE Transactions on Intelligent Transportation Systems,"10 Aug 2022","2022","23","8","12766","12777","The reputation-based scheme is a promising solution to prevent malicious behaviors in Vehicular Ad-hoc Networks (VANETs). However, traditional centralized reputation schemes are not suited for distributed networks, while decentralized reputation schemes are vulnerable to malicious vehicles spreading false messages. Most of these schemes assume that the behavior of vehicles can be accurately measured as reputation from the communication, ignoring that malicious vehicles may behave intelligently to avoid being detected. In this paper, we propose a hybrid reputation system (HDRS) which allows vehicles and roadside units (RSU) to complete reputation evaluations separately and provide references to each other. HDRS utilizes a reliability evaluation module to filter out unreliable calculation results and reference records. Furthermore, HDRS includes a dynamic adjustment mechanism for the reputation update interval, employing Analytic Hierarchy Process (AHP) and reliability evaluation results to resist intelligent attacks. Simulation results illustrate that HDRS can maintain a high detection rate and low false-positive rate for detecting malicious vehicles in different environments. Compared with existing schemes, HDRS increases the detection rates of collusion and intelligent attacks by 30% and 16%, respectively.","1558-0016","","10.1109/TITS.2021.3117289","Zhejiang Province Natural Science Foundation(grant numbers:LY19F020021); National Natural Science Foundation of China(grant numbers:61873232); New Talent Plan of Zhejiang Province(grant numbers:2020R427062); Opening Project of Key Laboratory of Ministry of Public Security (Public Security Information Application Based on Big-data Architecture)(grant numbers:2020DSJSYS005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565821","VANETs;reputation system;hybrid architecture;reliability evaluation;dynamic adjustment","Reliability;Vehicle dynamics;Vehicular ad hoc networks;Intelligent transportation systems;Blacklisting;Trust management;Switches","","25","","35","IEEE","8 Oct 2021","Aug. 2022","","IEEE","IEEE Journals"
"An Improved Differential Evolution Framework Using Network Topology Information for Critical Nodes Detection","S. Yu; Y. Wang; J. Li; X. Fang; J. Chen; Z. Zheng; C. Fu","Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, China; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, China; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, China; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, China; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, China; Zhejiang Police College, Hangzhou, China; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, China",IEEE Transactions on Computational Social Systems,"31 Mar 2023","2023","10","2","448","457","Critical nodes detection (CND) focuses on identifying the nodes that significantly impact the network’s robustness and is applied in various fields such as power grids, communication networks, and disease spreading. However, detecting the critical nodes is a challenging nondeterministic polynomial time complete (NP-complete) problem. One possible solution is using the evolutionary algorithm which has a high global search capability. However, the existing evolutionary algorithms for CND only focus on independent nodes, ignoring the underlying relationship among the nodes. Thus, in this work, we proposed a new topology-combined differential evolution framework called TDE to explore the possibility of improving the performance by fusing topology information, which designs individual genotypes through node degree, and new mutation and decoding-based selection operators are designed for these genotypes to use topology information effectively. The experiments on synthetic and real networks show that it is feasible to improve the search capability of the algorithm by fusing node degree information.","2329-924X","","10.1109/TCSS.2022.3217071","National Natural Science Foundation of China(grant numbers:62103374); Basic Public Welfare Research Project of Zhejiang Province(grant numbers:LGF20F020016); National Key Research and Development Program of China(grant numbers:2018AAA0100800); Open Project of Key Laboratory of Ministry of Public Security Information Application Based on Big Data Architecture(grant numbers:2020DSJSYS003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940229","Complex network;critical nodes detection (CND);differential evolution (DE);evolutionary computation","Network topology;Topology;Evolutionary computation;Approximation algorithms;Decoding;Measurement;Encoding","","15","","44","IEEE","4 Nov 2022","April 2023","","IEEE","IEEE Journals"
"FLD-SRC: Fingerprint Liveness Detection for AFIS Based on Spatial Ridges Continuity","C. Yuan; P. Yu; Z. Xia; X. Sun; Q. M. J. Wu","Engineering Research Center of Digital Forensics, Ministry of Education, School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China; Engineering Research Center of Digital Forensics, Ministry of Education, School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China; College of Cyber Security, Jinan University, Guangzhou, China; Engineering Research Center of Digital Forensics, Ministry of Education, School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada",IEEE Journal of Selected Topics in Signal Processing,"14 Jul 2022","2022","16","4","817","827","Automatic fingerprint identification system (AFIS) uses fingerprint to authenticate users, which is legal if the user is enrolled. However, numerous studies reveal that it is susceptible to spoofing attacks where a third person might freely synthesize counterfeit fingerprints to trick the scanner. To resist spoofing attacks, it makes fingerprint liveness detection (FLD) highly desirable. Most of previous work was to directly input the whole fingerprints into convolutional neural network, making it impossible to fully explore the relationship of spatial ridges, especially those with the latent fine-grained minutia on fingerprint ridges. Accordingly, in this paper, we exploit the relationship of spatial ridges in fingerprints and propose a novel FLD method based on spatial ridges continuity (FLD-SRC). Several fingerprint patches are first selected utilizing ridge texture saturation, and then uniformly split into several slices and thus construct the spatial continuity between pixels and between slices. Next, the proposed FLD-SRC learns deep features from fingerprints and eliminates redundant information. After that, the extracted feature maps are treated as a sequence and analyzed the intra-continuity by cascade gated recurrent unit (GRU). A discriminant slice grouping subnetwork is then developed to model the correlation between ridges slices and implicitly discover the discriminant inter-continuity. Pruning strategy is further utilized to reduce network parameters and promote its practical application in real scenarios. Experimental results, evaluated on three publicly available datasets, show the competitiveness of our method. Furthermore, in addition to reducing computational complexity, our method also shows the best ACE performance in cross-material and cross-sensor cases.","1941-0484","","10.1109/JSTSP.2022.3174655","National Natural Science Foundation of China(grant numbers:62102189,62122032,U1536206,U1836110,U1836208); National Key R&D Program of China(grant numbers:2018YFB1003205); Jiangsu Basic Research Programs-Natural Science Foundation(grant numbers:BK20200807); Research Startup Foundation of NUIST(grant numbers:2020r015); Key Laboratory of Public Security Information Application Based on Big-Data Architecture; Ministry of Public Security of the People's Republic of China(grant numbers:2021DSJSYS006); Collaborative Innovation Center of Atmospheric Environment and Equipment Technology fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9782106","AFIS;FLD;GRU;intra-continuity;pruning","Feature extraction;Correlation;Surface roughness;Rough surfaces;Fabrication;Surface treatment;Hardware","","14","","47","IEEE","25 May 2022","June 2022","","IEEE","IEEE Journals"
"TRAMS: A Secure Vehicular Crowdsensing Scheme Based on Multi-Authority Attribute-Based Signature","X. Liu; W. Chen; Y. Xia; R. Shen","School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China",IEEE Transactions on Intelligent Transportation Systems,"10 Aug 2022","2022","23","8","12790","12800","Recently, vehicular crowdsensing networks have attracted much attention because of their ability to provide efficient and convenient information services for the Internet of Vehicles. How to achieve on-demand message authentication and provide privacy protection of sensing vehicles are challenging in accurate sensing tasks. We propose a secure vehicular crowdsensing scheme based on multi-authority attribute-based signature (TRAMS), which allows the publisher to flexibly customize a fine-grained policy that the potential participants must satisfy and uses attribute-based signature to authenticate sensed messages while protecting the privacy of the sensing vehicle. Also, we propose a multi-authority key management scheme, which can improve vehicle-based sensing efficiency in the Internet of Vehicles. Performance analysis shows that our scheme can not only achieve massage authentication while protecting the privacy of the sensing vehicle, but also ensure fine-grained message authentication to meet the expectation of the publisher on demand. And compared with the single-authority schemes in vehicular communication, our multi-authority TRAMS can achieve efficient message authentication for vehicular crowdsensing applications which require timely task feedback.","1558-0016","","10.1109/TITS.2021.3117400","Zhejiang Provincial Natural Science Foundation(grant numbers:LY19F020021); National Natural Science Foundation of China(grant numbers:61873232); New Talent Plan of Zhejiang Province(grant numbers:2020R427062); Opening Project of Key Laboratory of Ministry of Public Security (Public Security Information Application Based on Big-Data Architecture)(grant numbers:2020DSJSYS005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9568772","Vehicular crowdsensing;attribute-based signature (ABS);multi-authority","Crowdsensing;Sensors;Privacy;Authentication;Task analysis;Message authentication;Servers","","12","","37","IEEE","12 Oct 2021","Aug. 2022","","IEEE","IEEE Journals"
"A Policy Enforcement Framework for Secure Data Dissemination in Vehicular Ad Hoc Network","Y. Xia; X. Liu; J. Ou; W. Chen","College of Computer Sciences, Zhejiang University, Hangzhou, China; School of Information Science, and Technology, Hangzhou Normal University, Hangzhou, China; College of Computer Sciences, Zhejiang University, Hangzhou, China; School of Information Science, and Technology, Hangzhou Normal University, Hangzhou, China",IEEE Transactions on Vehicular Technology,"17 Dec 2021","2021","70","12","13304","13314","In vehicular ad hoc networks (VANETs), enforcing expressive and suitable access policy is of great importance to achieve desirable and accurate data dissemination services. Recently, secure data dissemination schemes based on attribute-based encryption in VANETs have received considerable attention for their ability of fine-grained access control. Therefore, how to enforce accurate access policy in dynamic VANETs becomes significant yet very challenging. In order to achieve timely, flexible, and accurate data dissemination, we propose a policy enforcement framework for secure data dissemination, which enables data-sender vehicles with high mobility and RSUs with broad perception ability to co-design access control policy. Also, we design a policy combination method, which enforces an expressive access control policy based on the disjunctive norm form (DNF) formed by different attributes. Then we propose a policy conflict resolution based on confidence weights to deal with conflict policies. Finally, the experimental results demonstrate that our proposed scheme is applicable and efficient for secure data dissemination in VANETs.","1939-9359","","10.1109/TVT.2021.3121335","National Natural Science Foundation of China(grant numbers:61873232); Zhejiang Province Natural Science Foundation(grant numbers:LY19F020021); Opening Project of Key Laboratory of Ministry of Public Security (Public Security Information Application Based on Big-data Architecture)(grant numbers:2020DSJSYS005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580705","VANETs;data dissemination;policy combination;access control","Access control;Data dissemination;Vehicular ad hoc networks;Encryption","","8","","40","IEEE","19 Oct 2021","Dec. 2021","","IEEE","IEEE Journals"
"A Machine Learning Approach in Predictive Maintenance in the IoT Enabled Industry 4.0","S. Madasamy; B. P. Shankar; R. K. Yadav; J. K. P","Solution Architect, Pilvi Systems Inc, Lewisville, TX, USA; Department of Computer Science and Engineering, Faculty of Engineering and Technology, Alliance University, Karnataka, India; Department of Computer Science and Engineering, SRM Institute of Science and Technology, Ghaziabad, Uttar Pradesh, India; Department of Electronics and Communication Engineering, St Joseph Engineering College, Mangaluru, Karnataka, India",2023 4th International Conference on Smart Electronics and Communication (ICOSEC),"16 Oct 2023","2023","","","418","423","Predictive maintenance using machine learning is a powerful technique for industries seeking to enhance their operations with minimize downtime. In an IoT-enabled Industry 4.0 environment, this approach can be taken to a new level by leveraging the vast amounts of data generated by connected devices. To implement a machine learning methodology to projecting conservation in an Industry 4.0 environment, several key steps need to be taken. First, data from IoT devices across the industrial ecosystem should be collected and centralized in a data lake or similar storage system. This data should include information on equipment health, sensor readings, and other relevant metrics. Next, the data should be preprocessed and transformed to ensure its quality and consistency. This may involve cleaning, normalization, and feature engineering to create relevant variables for use in machine learning models. Once the data has been preprocessed, a range of machine learning models can be trained on it to predict equipment failures or other maintenance issues. This may involve ongoing tuning and optimization of model hyperparameters or retraining the models on new data as it becomes available. Finally, the predictions generated by the machine learning models should be integrated into a broader maintenance management system to enable timely action. This may include triggering maintenance requests, generating work orders, or even automating maintenance tasks through the use of robots or other industrial automation technologies. By implementing a machine learning method to projecting preservation in an IoT-enabled Industry 4.0 environment, industries can optimize their operations, minimize downtime, and improve overall equipment effectiveness.","","979-8-3503-0088-8","10.1109/ICOSEC58147.2023.10276226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10276226","Predictive maintenance;artificial intelligence;maintenance task;machine learning;Internet of Things","Biological system modeling;Machine learning;Maintenance engineering;Predictive models;Robot sensing systems;Data models;Fourth Industrial Revolution","","1","","25","IEEE","16 Oct 2023","20-22 Sept. 2023","20-22 Sept. 2023","IEEE","IEEE Conferences"
"UMAP: Urban mobility analysis platform to harvest car sharing data","A. Ciociola; M. Cocca; D. Giordano; M. Mellia; A. Morichetta; A. Putina; F. Salutari","Politecnico di Torino; Politecnico di Torino; Politecnico di Torino; Politecnico di Torino; Politecnico di Torino; Politecnico di Torino, Torino, Piemonte, IT; Politecnico di Torino","2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","28 Jun 2018","2017","","","1","8","Car sharing is nowadays a popular means of transport in smart cities. In particular, the free-floating paradigm lets the customers look for available cars, book one, and then start and stop the rental at their will, within a specific area. This is done thanks to a smartphone app, which contacts a web-based backend to exchange information. In this paper we present UMAP, a platform to harvest the data freely made available on the web by these backends and to extract driving habits in cities. We design UMAP with two specific purposes. Firsty UMAP fetches data from car sharing platforms in real time. Secondly, it processes the data to extract advanced information about driving patterns and user's habits. To extract information, UMAP augments the data available from the car sharing platforms with mapping and direction information fetched from other web platforms. This information is stored in a data lake where historical series are built, and later analyzed using analytics modules easy to design and customize. We prove the flexibility of UMAP by presenting a case of study for the city of Turin. We collect car sharing usage data for over 50 days to characterize both the temporal and spatial properties of rentals, and to characterize customers' habits in using the service, which we contrast with public transportation alternatives. Results provide insights about the driving style and needs, which are useful for smart city planners, and prove the feasibility of our approach.","","978-1-5386-0435-9","10.1109/UIC-ATC.2017.8397566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8397566","","Automobiles;Urban areas;Data mining;Crawlers;Google;Tools;Data acquisition","","16","","13","IEEE","28 Jun 2018","4-8 Aug. 2017","4-8 Aug. 2017","IEEE","IEEE Conferences"
"MobiSpaces: An Architecture for Energy-Efficient Data Spaces for Mobility Data","C. Doulkeridis; G. M. Santipantakis; N. Koutroumanis; G. Makridis; V. Koukos; G. S. Theodoropoulos; Y. Theodoridis; D. Kyriazis; P. Kranas; D. Burgos; R. Jimenez-Peris; M. M. G. Duarte; M. Sakr; E. Zimányi; A. Graser; C. Heistracher; K. Torp; I. Chrysakis; T. Orphanoudakis; E. Kapassa; M. Touloupou; J. Neises; P. Petrou; S. Karagiorgou; R. Catelli; D. Messina; M. C. Compagnucci; M. Falsetta","University of Piraeus, Piraeus, Greece; University of Piraeus, Piraeus, Greece; University of Piraeus, Piraeus, Greece; University of Piraeus, Piraeus, Greece; University of Piraeus, Piraeus, Greece; University of Piraeus, Piraeus, Greece; University of Piraeus, Piraeus, Greece; University of Piraeus, Piraeus, Greece; LeanXcale, Madrid, Spain; LeanXcale, Madrid, Spain; LeanXcale, Madrid, Spain; Université Libre de Bruxelles, Brussels, Belgium; Université Libre de Bruxelles, Brussels, Belgium; Université Libre de Bruxelles, Brussels, Belgium; Austrian Institute of Technology, Vienna, Austria; Austrian Institute of Technology, Vienna, Austria; Aalborg University, Denmark; Netcompany-Intrasoft, Luxembourg; Netcompany-Intrasoft, Luxembourg; University of Nicosia, Cyprus; University of Nicosia, Cyprus; Fujitsu, Germany; UBITECH, Cyprus; UBITECH, Cyprus; Engineering Ingegneria Informatica S.p.A., Italy; NA; White Label Consultancy, Copenhagen, Denmark; GFT, Italy",2023 IEEE International Conference on Big Data (BigData),"22 Jan 2024","2023","","","1487","1494","In this paper, we present an architecture for mobility data spaces enabling trustworthy and reliable data operations along with its main constituent parts. The architecture makes use of a data lake for scalable storage of diverse mobility data sets, on top of which separate computing and storage layers are implemented to allow independent scaling with a data operations toolbox providing all data operations. Furthermore, to cater for mobility analytics, machine learning and artificial intelligence support, an edge analytics suite is provided that encompasses distributed algorithms for mobility analytics and federated learning, thereby exploiting edge computing technologies. In turn, this is supported by a resource allocator that monitors the energy consumption of data-intensive operations and provides this information to the platform for intelligent task placement in edge devices, aiming at energy-efficient operations. As a result, an end-to-end platform is proposed that combines data services and infrastructure services towards supporting mobility application domains, such as urban and maritime.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386539","data spaces;mobility data;data governance;edge analytics","Federated learning;Visual analytics;Semantics;Distributed databases;Computer architecture;Energy efficiency;Resource management","","10","","28","IEEE","22 Jan 2024","15-18 Dec. 2023","15-18 Dec. 2023","IEEE","IEEE Conferences"
"Computing Infrastructure Of IoT Applications In Smart Agriculture: A Systematical Review","M. H. Thi; L. Hoang Son; N. T. Quoc Vinh; N. Thi Huong Quynh","Faculty of Information Technology, The University of Danang – University of Science and Education, Da Nang, Vietnam; VNU Information Technology Insitute, Vietnam National University, Ha Noi, Vietnam; Faculty of Information Technology, The University of Danang – University of Science and Education, Da Nang, Vietnam; Department of Science, Technology, and Environment, Ministry of Education and Training, Ha Noi, Vietnam",2021 6th International Conference on Innovative Technology in Intelligent System and Industrial Applications (CITISIA),"28 Feb 2022","2021","","","1","9","The study reviews current computing infrastructure of Internet-of-Things based applications in smart agriculture. The purpose is to identify key areas of state-of-arts computing technologies, data architecture, network technologies, and artificial intelligence, as well as ongoing challenges in these fields. To deliver the best of our knowledge, we review the latest research published in peer-reviewed journals and conferences from 2019 to 2021 depending on a four-step selection process of identification, screening, eligibility, and inclusion exclusion criteria. To examine these documents, a systematic review is conducted, and two main questions are answered. The output indicates that the improvements of computing infrastructure of IoT create exciting opportunities for real-world smart agriculture applications for evaluating, monitoring, enhancing the resource quality of nature such as soil, water, crop, etc. We conclude by summarizing that they are most commonly used in terms of network technologies, computing technologies, and data storage technologies of IoT. It could be considered like the kickoff point for the other forthcoming multi-disciplinary examination in smart applications and especially smart agriculture.","","978-1-6654-1784-6","10.1109/CITISIA53721.2021.9719974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9719974","Computing infrastructure;Internet of Things (IoT);Smart Agriculture;Artificial Intelligent","Computers;Systematics;Memory;Crops;Soil;Internet of Things;Intelligent systems","","3","","58","IEEE","28 Feb 2022","24-26 Nov. 2021","24-26 Nov. 2021","IEEE","IEEE Conferences"
"Data Architectures’ Evolution and Protection","I. I. Sinan; J. Degila; V. Nwaocha; S. A. Onashoga","Africa Centre of Excellence on Technology Enhanced Learning, National Open University of Nigeria, Abuja, Nigeria; Africa Centre of Mathematical Sciences, Computer Science and Applications, University of Abomey, Porto-Novo, Benin; Africa Centre of Excellence on Technology Enhanced Learning, National Open University of Nigeria, Abuja, Nigeria; Department of Computer Science, Federal University of Agriculture, Abeokuta, Nigeria","2022 International Conference on Electrical, Computer and Energy Technologies (ICECET)","9 Sep 2022","2022","","","1","6","Nowadays, data architecture allows us to store, manage, analyze, and visualize a limitless quantity of data. It has gone through several stages to get to this point, overcoming various hurdles and challenges. This study highlights these stages of evolution, starting with traditional architecture and progressing to data-informed architecture, data-driven architecture, and finally, data-centric architecture. It also devises a conceptual framework to identify the requirements for transitioning from one stage to other benefits of each architecture. The study’s results include a discussion of security vulnerabilities based on confidentiality, integrity, and availability (CIA Triad) and recommendations for future research.","","978-1-6654-7087-2","10.1109/ICECET55527.2022.9872597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9872597","Security;Challenges;Traditional architecture;Data-informed architecture;Data-driven architecture;Datacentric architecture","Data visualization;Computer architecture;Computer security","","3","","50","IEEE","9 Sep 2022","20-22 July 2022","20-22 July 2022","IEEE","IEEE Conferences"
"An AI-based Architecture Framework for Improving End-of-line Reliability Tests of Electric Motors","M. Soytürk; K. Coşkun; O. İzmitlioğlu; B. Tümer; D. Güneş; S. Saraçoğlu; B. Bulut; H. B. Ketmen; İ. Hanedar; T. Aşan; E. Aydın","Marmara University, İstanbul, Turkey; Marmara University, İstanbul, Turkey; Marmara University, İstanbul, Turkey; Marmara University, İstanbul, Turkey; Arçelik A.Ş., İstanbul, Turkey; Arçelik A.Ş., İstanbul, Turkey; Enforma Bilişim A.Ş., İstanbul, Turkey; Enforma Bilişim A.Ş., İstanbul, Turkey; PAVOTEK A.Ş., İstanbul, Turkey; PAVOTEK A.Ş., İstanbul, Turkey; WAT Motor A.Ş., Tekirdağ, Turkey",IECON 2022 – 48th Annual Conference of the IEEE Industrial Electronics Society,"9 Dec 2022","2022","","","1","6","End-of-line (EOL) tests are an important step to detect and respond to reliability issues that electric motors face. In addition to conventional signal processing methods to establish automated test systems, Artificial Intelligence (AI) and Machine Learning (ML) based methods in recent years, managed to become a major enabler for smart manufacturing thanks to advancements in hardware and software components. Inevitably, the importance of quality data made its way into considerations and requirements of automated fault detection and condition monitoring systems. In this regard, this study proposes an AI-based testing framework for electric motors. We provide information on the reasons of faults observed and a test procedure to detect them. We also give detailed specifications on hardware (sensors and data collection equipment), and provide a data architecture and analysis on properties of ML models that make sense to be used in such scenarios.","2577-1647","978-1-6654-8025-3","10.1109/IECON49645.2022.9968853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9968853","test framework;electric motor failure detection;artificial intelligence","Computer architecture;Signal processing;Throughput;Hardware;Software;Software reliability;Sensors","","2","","26","IEEE","9 Dec 2022","17-20 Oct. 2022","17-20 Oct. 2022","IEEE","IEEE Conferences"
"Blockchain Technologies for Chain of Custody Authentication","K. Chandramouli; R. Horincar; C. J. Naurois; D. Pallmer; D. Faure; W. M&#xfc;ller; K. Demestichas","Multimedia and Vision Research Group, School of Electronic Engineering and Computer Science, Venaka Media Limited,Queen Mary University of London, London,London, UK,UK; Thales, Courbevoie, France; Thales, Courbevoie, France; Fraunhofer IOSB, Karlsruhe, Germany; Thales, Courbevoie, France; Fraunhofer IOSB, Karlsruhe, Germany; Institute of Communication and Computer Systems, National Technical University of Athens, Athens, Greece",Security Technologies and Social Implications,"","2023","","","262","289","Technological advances are rapidly and radically changing human society, with “smart” sensors and gadgets penetrating almost all facets of daily life. The mass availability of these technologies has resulted in an exponential increase in the quantity of generated data. Together with the simultaneous exponential growth in computing power, this has driven rapid advances in the application of machine learning (ML) and artificial intelligence (AI). These developments in the fields of data availability and AI technologies present even greater challenges for law enforcement and policing, while simultaneously opening huge opportunities. Complementing the benefits of these technologies by the law enforcement authorities, criminals are also equally exploiting technology. A part of the digital world is the increasing abundance of digital evidence; from CCTV footage to emails to phone records, evidence has now gone digital and there is a requirement to ensure it is accessible, readable, and has long‐term integrity when current technology, systems, or formats have been replaced or decommissioned. There is a further requirement for a seamless interface between policing and the criminal justice system to ensure digital evidence can be presented easily and without delay. As the quantity of data being used in criminal investigations becomes increasing larger, there is a critical need to maintain records tracing the origin and processing of evidence collected in digital format to authenticate the validity of the evidence. Addressing this need, the multimedia analysis and correlation engine for organized crime prevention and investigation (MAGNETO) project proposed the use of blockchain technologies for tracking and recording the processing of information within the big‐data architecture of the criminal investigation platform. The novelty of the proposed framework relies on the use of semantic technologies for knowledge formalization and the use of immutable technology based on hashing solutions to prevent evidentiary modifications. The platform addresses the need for mitigating the impact of cognitive bias to ensure the investigation platform offers objectivity in processing evidence.","","9781119834151","10.1002/9781119834175.ch11","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9930735.pdf&bkn=9928039&pdfType=chapter","","Magnetic recording;Europe;Magnetic resonance imaging;Law;Soft sensors;Semantics;Blockchains","","","","","","26 Oct 2022","","","IEEE","Wiley-IEEE Press eBook Chapters"
"A Distributed Data Fabric Architecture based on Metadate Knowledge Graph","X. Li; M. Yang; X. Xia; K. Zhang; K. Liu","China Telecom Corporation Limited Research Institute, Beijing, China; China Telecom Corporation Limited Research Institute, Beijing, China; China Telecom Corporation Limited Research Institute, Beijing, China; China Telecom Corporation Limited Research Institute, Beijing, China; China Telecom Corporation Limited Research Institute, Beijing, China",2022 5th International Conference on Data Science and Information Technology (DSIT),"17 Nov 2022","2022","","","1","7","Just like talent, capital and land, data is becoming one of the market-oriented elements and driving profound intelligent changes in traditional industries. Data governance is a key process to improve the availability, integrity, and security of data. For large group enterprises like telecom operators, it is not simple to manage the massive data scattered in different departments, different facilities, different regions, and different systems. This paper creatively proposes a distributed data fabric architecture based on metadate knowledge graph to solve this problem. The functional architecture consists of six layers, including acquisition storage layer, data management layer, knowledge graph layer, data directory layer, model application layer, user request layer, etc. A feasible framework is designed to guide how to implement this architecture, and several key enabling technologies have been studied. Instead of storing the full amount of data in a centralized data lake, we choose to centralize the metadata into the data warehouse. This can avoid the problems of data privacy disclosure, long data turnover time, wrong data entry into the lake and high operation and maintenance cost. Specifically, the enhanced data knowledge directory derived from the lower-level global metadata knowledge map is constructed, including static data resource directory, static business resource directory, and dynamic enhanced knowledge directory automatically generated based on user input. The proposed architecture has been used in the practical application in China Telecom Group and alleviates the difficulty of massive data query to a certain extent.","","978-1-6654-9868-5","10.1109/DSIT55514.2022.9943831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943831","big data;metadata;knowledge graph;data fabric","Data privacy;Machine learning algorithms;Government;Distributed databases;Metadata;Data warehouses;Fabrics","","8","","15","IEEE","17 Nov 2022","22-24 July 2022","22-24 July 2022","IEEE","IEEE Conferences"
"Large Scale Distributed Data Processing for a Network of Humanoid Telepresence Robots","I. Steve Cardenas; P. Kumar Paladugula; J. -H. Kim","Advanced Telerobotics Research Lab Computer Science, Kent State University, Kent, Ohio, USA; Advanced Telerobotics Research Lab Computer Science, Kent State University, Kent, Ohio, USA; Advanced Telerobotics Research Lab Computer Science, Kent State University, Kent, Ohio, USA","2020 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)","8 Oct 2020","2020","","","1","9","We present an open-source data lake architecture implemented to store and process data from robotic systems at large scale. In particular, we leverage our architecture for the use case of processing data from a network of humanoid telepresence robotic avatars that are controlled by human operators wearing immersive telepresence control suits. Our architecture leverages well-established open-source technologies and integrates into existing robot frameworks and middleware such as Robot Operating System (ROS) and Data Distribution Service (DDS).","","978-1-7281-9615-2","10.1109/IEMTRONICS51293.2020.9216366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216366","cloud robotics;big data;IoT;distributed systems","Cloud computing;Robot sensing systems;Lakes;Telepresence;Distributed databases;Humanoid robots","","4","","34","IEEE","8 Oct 2020","9-12 Sept. 2020","9-12 Sept. 2020","IEEE","IEEE Conferences"
"Adopting Data Mesh principles to Boost Data Sharing for Clinical Trials","M. Falconi; P. Plebani","Politecnico di Milano, Milan, Italy; Politecnico di Milano, Milan, Italy",2023 IEEE International Conference on Digital Health (ICDH),"28 Aug 2023","2023","","","298","306","An effective clinical research requires the availability of relevant data and tools that make possible their efficient analysis. Among the several possibilities, data mesh, a distributed data architecture that is organized around specific domains and provides a self-service platform for accessing and using the data, is gaining the attention of the data and software engineering communities, mainly because of its ability to reduce the tension between the platform that manages the data and the teams that are in charge of managing them. Nevertheless, data mesh mainly focuses on how to manage data in a single organization by defining the sphere of responsibilities in the data management. Conversely, the continuous increase of data produced by hospitals calls for new approaches that enable the data sharing between clinical research centers.Goal of this paper is to extend the data mesh approach by considering the sharing of data among organizations which are members of a federation. Under the umbrella of a clinical trial which defines a temporary agreement among hospitals, a federated data mesh solution is designed to support the data management when data products from different organizations are considered. This implies the study on how the data ownership defined in the data mesh somehow becomes data sovereignty when data is shared with other organizations.","","979-8-3503-4103-4","10.1109/ICDH60066.2023.00051","Health; Health; Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10224715","Federated data management;Big Data Analytics;Data sharing","Hospitals;Distributed databases;Organizations;Computer architecture;Clinical trials;Electronic healthcare;Data governance","","4","","25","IEEE","28 Aug 2023","2-8 July 2023","2-8 July 2023","IEEE","IEEE Conferences"
"Spatio-Temporal Evolution of a Socio-Environmental System: The Alps, A Case Study","D. Ziébelin; P. Genoud","Univ. Grenoble Alpes, France; Univ. Grenoble Alpes, France",2018 International Workshop on Big Geospatial Data and Data Science (BGDDS),"27 Jan 2019","2018","","","1","4","It is still a problem for current information systems and modeling methods to make heterogeneous data sources interoperable and to link data sets obtained from a common territory by different experts (biologists, ecologists, geographers, hydrologists etc.)Existing observation systems are complex and can record either a long term observation at the large scale, or short term validity data at, for example, the molecular or cellular level or territorial and regional level. The objective of this project is to develop an infrastructure to allow the different available observation data sets to be brought into a coordinated platform able to address questions relating to different correlated impacts from the natural environment, land use or climate evolution. The challenge concerns multidisciplinary interoperability and modeling interdependent observation systems, across different space scales and time granularity. Our approach requires developing a multidimensional spatio-temporal model (4D + spatial scale + time granularity) based on a semantic linked data architecture.","","978-1-5386-1437-2","10.1109/BGDDS.2018.8626832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8626832","geospatial application;environment;interoperability;standard;semantic web","Ontologies;Biological system modeling;Standards;Databases;Metadata;Interoperability","","","","15","IEEE","27 Jan 2019","22-23 Sept. 2018","22-23 Sept. 2018","IEEE","IEEE Conferences"
"Solusi247","B. K. Pradekso",SOLUSI247,2020 International Symposium on Community-centric Systems (CcS),"20 Oct 2020","2020","","","18","18","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. HGrid is a Hadoop data engineering tool made by solusi247 for Map Reduce, Spark and Storm frameworks which has been built since 2011 to help programmers building server-side data processing applications by automatically generate codes based on visually designed workflow. The biggest challenge to build this tool was to make most of the functions, modules, libraries and even workflow schemes (nearly) compatible between frameworks and to make a multipurpose single Integrated Development Environment (IDE) for Big Data availlable in the desktop and on the cloud. The development of the HGrid library starts with the collection of functions needed, how they can be implemented in each framework and how the codes can be generated. HGrid generated codes were also benchmarked against some commercially availlable tools to ensure good performance. HGrid is also designed to be visual, robust and user friendly although it still need to be improved in user experience part. It is also designed for average programmers and analysts. Data engineering libraries has been continuosly developed to ease application development with target near zero programming at the programmers side. HGrid has been used largely at the telco operators in Indonesia, in the largest banks, government institutions, hospitals and military to build complex applications such as Data Lake, Mediation Device, Media Analytics and many others.","","978-1-7281-8741-9","10.1109/CcS49175.2020.9231309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231309","","Visualization;Codes;Storms;Programming;Media;Data engineering;Libraries","","","","0","IEEE","20 Oct 2020","23-26 Sept. 2020","23-26 Sept. 2020","IEEE","IEEE Conferences"
"Anyplace: A Crowdsourced Indoor Information Service","K. Georgiou; T. Constambeys; C. Laoudias; L. Petrou; G. Chatzimilioudis; D. Zeinalipour-Yazti","Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus; KIOS Research Center for Intelligent Systems and Networks, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Oxford, Oxford, UK; Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Panepistemio Kyprou, Nicosia, Nicosia, CY",2015 16th IEEE International Conference on Mobile Data Management,"14 Sep 2015","2015","1","","291","294","People do most of their activities, business, commerce, entertainment and socializing indoors. As all of these are increasingly aided by online services and indoor spaces are becoming bigger and more complex, there is a growing need for cost-effective indoor localization, mapping, navigation and information services. In this paper, we present a complete Indoor Information Service, coined Anyplace, which has an open, modular, extensible and scalable architecture, making it ideal for a wide range of applications. Our service features three highly desirable properties, namely crowd sourcing, scalability and accuracy. Anyplace implements a set of crowd sourcing-supportive mechanisms to handle the enormous amount of crowd-sensed data, filter incorrect user contributions and exploit Wi-Fi data from heterogeneous mobile devices. Moreover, it uses a big-data architecture for efficient storage and retrieval of localization and mapping data. Finally, our service relies on the abundance of sensory data on smartphones (e.g., Wi-Fi signal strength and inertial measurements) to deliver reliable indoor geolocation information that received several international awards.","2375-0324","978-1-4799-9972-9","10.1109/MDM.2015.80","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7264335","crowdsourcing;indoor;search;navigation","Buildings;Navigation;IEEE 802.11 Standard;Smart phones;Google;Crowdsourcing;Servers","","24","1","5","IEEE","14 Sep 2015","15-18 June 2015","15-18 June 2015","IEEE","IEEE Conferences"
"Demonstration abstract: Crowdsourced indoor localization and navigation with Anyplace","L. Petrou; G. Larkou; C. Laoudias; D. Zeinalipour-Yazti; C. G. Panayiotou","Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus; KIOS Research Center for Intelligent Systems and Networks, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus; KIOS Research Center for Intelligent Systems and Networks, University of Cyprus, Nicosia, Cyprus",IPSN-14 Proceedings of the 13th International Symposium on Information Processing in Sensor Networks,"8 Jul 2014","2014","","","331","332","In this demonstration paper, we present the Anyplace system that relies on the abundance of sensory data on smartphones (e.g., WiFi signal strength and inertial measurements) to deliver reliable indoor geolocation information. Our system features two highly desirable properties, namely crowdsourcing and scalability. Anyplace implements a set of crowdsourcing-supportive mechanisms to handle the enormous amount of crowdsensed data, filter incorrect user contributions and exploit WiFi data from heterogeneous mobile devices. Moreover, Anyplace follows a big-data architecture for efficient and scalable storage and retrieval of localization and mapping data.","","978-1-4799-3147-7","10.1109/IPSN.2014.6846788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6846788","Crowdsourcing;indoor localization;navigation","Navigation;IEEE 802.11 Standards;Buildings;Smart phones;Crowdsourcing;Servers;Computer architecture","","12","1","7","IEEE","8 Jul 2014","15-17 April 2014","15-17 April 2014","IEEE","IEEE Conferences"
"Managing services in the telecom cloud: An example for CDN","L. Velasco","Optical Communications Group (GCO), Universitat Politècnica de Catalunya (UPC), Barcelona, Spain",2016 18th International Conference on Transparent Optical Networks (ICTON),"25 Aug 2016","2016","","","1","1","Telecom operators are considering the deployment of Content Delivery Networks (CDN) to better control and manage video contents injected into the network. Cache nodes placed close to end users can manage access contents and adapt them to users' devices, while reducing video traffic in the core. By adopting the recently standardized MPEG-DASH technique, video contents can be delivered over HTTP, so HTTP servers can be used to serve contents, while packagers running as software can prepare live contents. This paves the way for virtualizing the CDN function. In this talk, a CDN manager is proposed to adapt the virtualized CDN function to current and future demand. A Big Data architecture, fulfilling the ETSI NFV guidelines, allows controlling virtualized components while collecting and pre-processing data. Re-optimization problems minimizing CDN costs while ensuring the highest quality are triggered based on threshold violations; data stream mining sketches transform collected into modelled data and statistical linear regression and machine learning techniques are proposed to produce estimation of future scenarios. Exhaustive simulation over a realistic scenario reveal remarkable costs reduction by dynamically reconfiguring the CDN. Finally, the feasibility of the proposed architecture is experimentally assessed in a real environment.","2161-2064","978-1-5090-1467-5","10.1109/ICTON.2016.7550672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550672","","Telecommunications;Costs;Computer architecture;Transforms;Transform coding;Software;Servers","","2","","","IEEE","25 Aug 2016","10-14 July 2016","10-14 July 2016","IEEE","IEEE Conferences"
"Electrosense: Open and Big Spectrum Data","S. Rajendran; R. Calvo-Palomino; M. Fuchs; B. Van den Bergh; H. Cordobes; D. Giustiniano; S. Pollin; V. Lenders",KU Leuven; Universidad Carlos III of Madrid; SeRo Systems; KU Leuven; IMDEA Networks Institute; IMDEA Networks Institute; KU Leuven; Armasuisse,IEEE Communications Magazine,"12 Jan 2018","2018","56","1","210","217","While radio spectrum allocation is well regulated, there is little knowledge about its actual utilization over time and space. This limitation hinders taking effective actions in various applications including cognitive radios, electrosmog monitoring, and law enforcement. We introduce Electrosense, an initiative that seeks a more efficient, safe and reliable monitoring of the electromagnetic space by improving the accessibility of spectrum data for the general public. A collaborative spectrum monitoring network is designed that monitors the spectrum at large scale with low-cost spectrum sensing nodes. The large set of data is stored and processed in a big data architecture and provided back to the community with an open spectrum data as a service model, that allows users to build diverse and novel applications with different requirements. We illustrate useful usage scenarios of the Electrosense data.","1558-1896","","10.1109/MCOM.2017.1700200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8121869","","Monitoring;Sensors;Spread spectrum communication;Computer architecture;Crowdsourcing;Data models;Time-frequency analysis","","143","","15","IEEE","28 Nov 2017","Jan. 2018","","IEEE","IEEE Magazines"
"Context Rich Hybrid Navigation Using WiFi and Geomagnetic Sensors in Smartphones and Map Generation Using Lidar","A. Jayakody; S. Lokuliyana; V. N. N. Weerawardene; K. D. P. S. Somathilake; A. M. D. D. U. Ishara","Department of Information Systems Engineering, Faculty of Computing, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Information Systems Engineering, Faculty of Computing, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Information Systems Engineering, Faculty of Computing, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Information Systems Engineering, Faculty of Computing, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Information Systems Engineering, Faculty of Computing, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka",2019 National Information Technology Conference (NITC),"11 Jun 2020","2019","","","60","65","Navigation systems perform a huge role in traveling component of life. Most importantly it helps people to get to places even in foreign or unfamiliar environments. This research introduces a way of mapping environments with less effort, which shows that mapping an indoor environment is an easy task that could be performed by any tech savvy individual. This has been done by examining several projects and researches conducted by various personnel and organizations including NASA. It has become clear that the technology ‘LIDAR,’ is clearly feasible for the requirement of indoor map generation. A software was later built to accommodate the device which is built using LIDAR and to give the user a better experience in map generation. The software helps to overcome the limitations that are imposed by the device. The overall product with the device and software integrated provides an ideal low-budget solution for the users. The proposed system service features three highly desirable properties, namely accuracy, scalability, and crowdsourcing. IPS is implemented with a set of crowdsourcing-supportive mechanisms to handle the collective amount of raw data, filter incorrect user contributions and exploit Wi-Fi data from diverse mobile devices. Furthermore, it uses a big-data architecture for efficient storage and retrieval of localization and mapping data. In this research, the service relies on the sensitive data collected by smartphones (Wi-Fi signal strength and geomagnetic measurements) to deliver reliable indoor geolocation information.","2279-3895","978-1-7281-5569-2","10.1109/NITC48475.2019.9114502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9114502","LIDAR;Map;NASA;crowdsourcing;indoor navigation;scalability;accuracy","Laser radar;Accuracy;Indoor navigation;Scalability;Software;Sensors;IP networks;Personnel;Wireless fidelity;Smart phones","","","","23","IEEE","11 Jun 2020","8-10 Oct. 2019","8-10 Oct. 2019","IEEE","IEEE Conferences"
"A novel BIG DATA architecture in support of ADS-B data analytic","E. Boci; S. Thistlethwaite",Exelis; Exelis,"2015 Integrated Communication, Navigation and Surveillance Conference (ICNS)","11 Jun 2015","2015","","","1","18","With 87,000 flights per day, America's ground based radar system has hit a growth ceiling. The FAA has undertaken the implementation effort of the Next Generation Air Transportation System (NextGen) initiative that would transform today's air transportation and ensure increased safety and capacity in the National Airspace System (NAS).","2155-4951","978-1-4799-8952-2","10.1109/ICNSURV.2015.7121281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7121281","","","","4","","","IEEE","11 Jun 2015","21-23 April 2015","21-23 April 2015","IEEE","IEEE Conferences"
