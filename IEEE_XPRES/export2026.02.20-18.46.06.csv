"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Data Lake: A Case of Study of a Big Data Analytics Architecture for Public Procurements","D. Sosa; J. Paciello","Polytechnic Faculty, National University of Asuncion, Asuncion, Paraguay; Polytechnic Faculty, National University of Asuncion, Asuncion, Paraguay",2021 Eighth International Conference on eDemocracy & eGovernment (ICEDEG),"13 Sep 2021","2021","","","194","198","Big Data technologies are facing problems of volume, velocity, variety and veracity of data, attending to the wide expansion of emerging technologies like IoT and IoE. Cyberocracy proposes a decision-making process of a Government based on the effective use of information. An important effort in this line, focusing on government public procurement, has been carried out by the Open Contracting Partnership (OCP), promoting the publication of more volumes of public procurement data in non-relational and machine processable formats every day. This work analyzes the underlying Big Data infrastructure for the analysis of public procurement data through a comparative case of study between a technology proposed by the OCP called KingFisher and emergent technologies based on Data Lakes.With an emphasis on storage requirements to support a high volume of payloads, also considering criteria of velocity and RAM use. Preliminary results show encouraging findings especially in terms of volume required by a Data Lake, even for different payload scenarios, up to 10 times less storage than the relational database-based model.","2573-1998","978-1-6654-2512-4","10.1109/ICEDEG52154.2021.9530976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530976","Big Data;IoT;IoE;Data Lake;Cyberocracy;Public Procurements","Procurement;Solid modeling;Government;Decision making;Random access memory;Focusing;Big Data","","2","","17","IEEE","13 Sep 2021","28-30 July 2021","28-30 July 2021","IEEE","IEEE Conferences"
"The research of big data architecture on telecom industry","F. Su; Y. Peng; X. Mao; X. Cheng; W. Chen","China Unicom Network Technology Research Institute; National Satellite Meteorological Center; China National Institute of Standardization, Beijing, China; China Unicom Network Technology Research Institute; China Unicom Network Technology Research Institute",2016 16th International Symposium on Communications and Information Technologies (ISCIT),"24 Nov 2016","2016","","","280","284","In Big Data era, telecom operators have massive data resources, such as user call data, user online data, user location data, network performance data, and so on. These data reaches PB level and is distributed in the NEs and interfaces. How to effectively carry out the collection, parsing, analysis for the amount of data to support the network construction, maintenance and optimization is a major opportunities and challenges that the telecom operators face. This paper proposes a big data platform (BDP) to solve the above problem for telecom industries. Through the collection of telecom network data, the BDP can realize data parsing, storage and analysis for MR(Measure Report), CDR(Call Detail Record), OMC(Operation and Maintenance Centre) data and etc. It can achieve a unified storage and management of all types of data. Based on BDP, operators can carry out big data analysis and data mining to realize the value of data. Finally, this paper builds a testing platform for BDP to test the performance of big data loading and big data analysis. The results of experiment show that the performance of data loading and analysis of BDP is better than traditional data warehouse. It can be applied by the telecom operators to be the foundational infrastructure to carry on the future application of big data.","","978-1-5090-4099-5","10.1109/ISCIT.2016.7751636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7751636","Big Data;Hadoop;ETL;MPP Database","Big data;Telecommunications;Data visualization;Data analysis;Industries;Maintenance engineering;Data mining","","10","","30","IEEE","24 Nov 2016","26-28 Sept. 2016","26-28 Sept. 2016","IEEE","IEEE Conferences"
"Efficient Data Exchange Between Typical Data Lake and DWH Corporate Systems","A. Suleykin; A. Bobkova; P. Panfilov; I. Chumakov","Russian Academy of Sciences, Doctoral School V.A. Trapeznikov Institute of Control Sciences, Moscow, Russia; Department of Business Informatics, Graduate School of Business, HSE University, Moscow, Russia; Department of Business Informatics, Graduate School of Business, HSE University, Moscow, Russia; Digital Marketing&e-Commerce Liebherr Appliances Liebherr-International Deutschland GmbH, Mooscow, Russia","2021 International Conference on Electrical, Computer and Energy Technologies (ICECET)","11 Feb 2022","2021","","","1","6","In the last five years, many companies around the world have been successfully implemented Apache Hadoop as a main Data Lake storage for all data presented in the organization. At the same time, the adoption of other Open-Source technologies has been also increasing for years, such as classical MPP-based systems for Analytical workloads. Thus, the question of efficient and fast data integration between Apache Hadoop and other organizational data storage systems is highly important for enterprises, where business and decision makers need the minimum delay of big heterogeneous data exchange between Hadoop and other storages. In this paper, we compare different options for loading data from Apache Hadoop, representing the Data Lake of organization, into Open-Source MPP Greenplum database with the role of classical data warehouse for analytical workloads, and choose the best one. Also, we identify potential risks of using different data loading methods.","","978-1-6654-4231-2","10.1109/ICECET52533.2021.9698468","RFBR(grant numbers:20-07-00958); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9698468","Big Data;Data Lake;Hadoop Distributed File System;Greenplum;Massively Parallel Processing;Data Warehouse","Loading;Distributed databases;Data integration;Cluster computing;Computer architecture;Production;Data warehouses","","","","11","IEEE","11 Feb 2022","9-10 Dec. 2021","9-10 Dec. 2021","IEEE","IEEE Conferences"
"Open Data Lake to Support Machine Learning on Arctic Big Data","A. M. Olawoyin; C. K. Leung; A. Cuzzocrea","Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; iDEA Lab University of Calabria, Rende, Italy",2021 IEEE International Conference on Big Data (Big Data),"13 Jan 2022","2021","","","5215","5224","The era of big data is evolving with the introduction of the data lake concept. While a data warehouse provides a well-structured model to manage big data, a data lake accepts data of any types and formats with or without schema and provides access to the data for diverse communities of users. A data lake provides flexible, agile, and scalable solution to manage the ever-increasing volume of big data we are witnessing in the world today, including many siloed data collected over the years by researchers through Arctic expeditions. In this paper, we present our conceptual model of a data lake for integrating the diverse huge amount of data collected by researchers during Arctic expedition. We also design a baseline metadata using a data-driven approach to manage the disparately huge structured, semi-structured, and unstructured data collected from the Arctic region. The resulting open data lake not only effectively manages big Arctic data but also supports machine learning on these big data.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671453","big data;data management;data lake;open data;reusability;FAIR principle;CARE principle;Arctic data;Arctic expedition;machine learning;data mining","Renewable energy sources;Visual analytics;Machine learning;Production;Metadata;Lakes;Data warehouses","","23","","78","IEEE","13 Jan 2022","15-18 Dec. 2021","15-18 Dec. 2021","IEEE","IEEE Conferences"
"The Automation of the Data Lake Ingestion Process from Various Sources","A. Tunjić","Multicom d.o.o., Zagreb, Croatia","2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","11 Jul 2019","2019","","","1276","1281","In a big data environment, it is often necessary to ingest data from different sources into a unique storage. Because of low memory price, system distribution and failure tolerance, that storage is typically HDFS. It enables users to manipulate data with different tools from the Hadoop ecosystem. The process of data ingestion seems simple. However, because sources can be different database systems, structured, semi-structured and unstructured data complicate the ingestion procedure. It is usually not enough to just store everything. Data needs to be stored in such a way that enables users to quickly access and manipulate it. There are many ingestion-specific solutions in the big data ecosystem. This paper will describe an implemented system for data ingestion from MSSQL, MySQL and Postgres into a Hive database. The process starts with creating tables with corresponding metadata, continues with the ingestion process and ends with a description of how the process is automated. The implementation of Sqoop as an open-source tool and Hue, a web user interface from Cloudera, will be described.","2623-8764","978-953-233-098-4","10.23919/MIPRO.2019.8756864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756864","hadoop;sqoop;hive;data ingestion automation;big data","Tools;Big Data;Metadata;Relational databases;Servers;Password","","1","","8","","11 Jul 2019","20-24 May 2019","20-24 May 2019","IEEE","IEEE Conferences"
"Data Lake Management for Educational Analysis","D. Martinez-Mosquera; V. Beltrán; D. Riofrío-Luzcando; J. Carrión-Jumbo","Department of Informatics and Computer Science, Escuela Politécnica Nacional, Digital School, Universidad Internacional SEK, Quito, Ecuador; Digital School, Universidad Internacional SEK, Quito, Ecuador; Digital School, Universidad Internacional SEK, Quito, Ecuador; Digital School, Universidad Internacional SEK, Quito, Ecuador",2022 IEEE Sixth Ecuador Technical Chapters Meeting (ETCM),"9 Nov 2022","2022","","","1","5","This article presents an approach to managing an educational analytical system in a data lake. This solution covers higher education institutions' requirements for managing large volumes generated by their students and teachers. This work deals with the problem of the lack of organization when implementing a data lake due to the fact that there are no well-known or standardized methods for its administration. Our methodology proposes dividing the data lake into three zones: (1) landing tier, (2) staging tier, and (3) consumption tier, and transforming the data for each zone under the guidance of the Common Data Model and One Data Model. The main goal is to avoid the educational data lake from converting into a data swamp. This methodology was implemented at University as a case study over an open-source data lake environment. The results obtained figures that historical data analysis barriers are overcome thanks to the high capabilities of the data lake. In addition, this approach can be applied to other institutions with great flexibility, with commodity solutions, and regardless of the source data format.","","978-1-6654-8744-3","10.1109/ETCM56276.2022.9935751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9935751","big data;common data model;data lake;education;HDFS;one data model","Data lakes;Analytical models;Data analysis;Standards organizations;Education;Organizations;Big Data applications","","1","","18","IEEE","9 Nov 2022","11-14 Oct. 2022","11-14 Oct. 2022","IEEE","IEEE Conferences"
"A Big Data Lake for Multilevel Streaming Analytics","R. Liu; H. Isah; F. Zulkernine","School of Computing, Queen’s University, Kingston, Canada; School of Computing, Queen’s University, Kingston, Canada; School of Computing, Queen’s University, Kingston, Canada",2020 1st International Conference on Big Data Analytics and Practices (IBDAP),"5 Nov 2020","2020","","","1","6","Large organizations are seeking to create new architectures and scalable platforms to effectively handle data management challenges due to the explosive nature of data rarely seen in the past. These data management challenges are largely posed by the availability of streaming data at high velocity from various sources in multiple formats. The changes in data paradigm have led to the emergence of new data analytics and management architecture. This paper focuses on storing high volume, velocity and variety data in the raw formats in a data storage architecture called a data lake. First, we present our study on the limitations of traditional data warehouses in handling recent changes in data paradigms. We discuss and compare different open source and commercial platforms that can be used to develop a data lake. We then describe our end-to-end data lake design and implementation approach using the Hadoop Distributed File System (HDFS) on the Hadoop Data Platform (HDP). Finally, we present a real-world data lake development use case for data stream ingestion, staging, and multilevel streaming analytics which combines structured and unstructured data. This study can serve as a guide for individuals or organizations planning to implement a data lake solution for their use cases.","","978-1-7281-8106-6","10.1109/IBDAP50342.2020.9245460","IBM Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9245460","Hadoop Data Platform;Hadoop Distributed File System;NiFi;streaming data;unstructured data","Data analysis;Distributed databases;Organizations;Lakes;Big Data;Data warehouses;Planning","","11","","17","IEEE","5 Nov 2020","25-26 Sept. 2020","25-26 Sept. 2020","IEEE","IEEE Conferences"
"Design and Implementation of Manufacturing Data Lake in Hadoop","S. Munirathinam; S. Sun; J. Rosin; H. Sirigibathina; A. Chinthakindi","Data Science, Micron Technology Inc., Manassas, VA, USA; Quality Assurance, Micron Technology Inc., Manassas, VA, USA; Information Technology, Micron Technology Inc., Manassas, VA, USA; Information Technology, Micron Technology Inc., Manassas, VA, USA; Quality Assurance, Micron Technology Inc., Manassas, VA, USA","2019 IEEE International Conference on Smart Manufacturing, Industrial & Logistics Engineering (SMILE)","23 Jan 2020","2019","","","19","23","The manufacturing industry generates vast amounts of data today and modern semiconductor manufacturing is one of the key contributors to this tsunami of data. Efficient storage and analysis of data have a significant impact on productivity and profit. In this paper, we will explore design and implementation of a manufacturing Data Lake in Hadoop ecosystem and how the data is used to generate business intelligence.","","978-1-5386-7998-2","10.1109/SMILE45626.2019.8965302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965302","Big Data;Hadoop;Hive;Data Lake;Semiconductor Manufacturing","Productivity;Electronics industry;Ecosystems;Semiconductor device manufacture;Big Data applications;Tsunami;Explosives;Manufacturing;Engines;Logistics","","5","","11","IEEE","23 Jan 2020","20-21 April 2019","20-21 April 2019","IEEE","IEEE Conferences"
"BASIS: A big data architecture for smart cities","C. Costa; M. Y. Santos","ALGORITMI Research Centre, University of Minho, Guimarães, Portugal; ALGORITMI Research Centre, University of Minho, Guimarães, Portugal",2016 SAI Computing Conference (SAI),"1 Sep 2016","2016","","","1247","1256","Nowadays, cities are the common choice for living, representing a complex system where governments need to perform adequately, despite current restrictions, in order to satisfy the needs of the citizens and overcome economic, social and environmental sustainability challenges. The Smart City term emerges to conceptualize the need to understand citizens, namely their services demand and their relevance in a participatory government. Smart Cities are known for their human dynamics, which makes recurrent use of permanently connected devices, frequently known as Internet of Things (IoT). Consequently, since these new cities generate a vast volume of data with significant variety and velocity, they have the potential to be one of the richest and challenging systems to generate Big Data and to benefit from its adequate storage, processing, analysis and public availability. This paper presents a Big Data architecture for Smart Cities, entitled BASIS, whose specification pays particular attention to the creation of multiple abstraction layers, from the most conceptual to the most technological, fulfilling the lack of technological detail often observed in the literature. BASIS also pays particular attention to the public availability of data. Tested in a demonstration case, the obtained results reveal adequate capability to store, process, analyse and make available Big Data in the context of Smart Cities.","","978-1-4673-8460-5","10.1109/SAI.2016.7556139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556139","Big Data;Smart Cities;Big Data Architecture;Big Data Analytics","Big data;Smart cities;Computer architecture;Data mining;Context;Distributed databases","","29","","22","IEEE","1 Sep 2016","13-15 July 2016","13-15 July 2016","IEEE","IEEE Conferences"
"A big data architecture for managing oceans of data and maritime applications","I. Lytra; M. -E. Vidal; F. Orlandi; J. Attard","Enterprise Information Systems, University of Bonn & Fraunhofer IAIS, Germany; Universidad Simón Bolívar, Venezuela; Enterprise Information Systems, University of Bonn & Fraunhofer IAIS, Germany; Enterprise Information Systems, University of Bonn & Fraunhofer IAIS, Germany","2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)","5 Feb 2018","2017","","","1216","1226","Data in the maritime domain is growing at an unprecedented rate, e.g., terabytes of oceanographic data are collected every month, and petabytes of data are already publicly available. Big data from heterogeneous sources such as sensors, buoys, vessels, and satellites could potentially fuel a large number of interesting applications for environmental protection, security, fault prediction, shipping routes optimization, and energy production. However, because of several challenges related to big data and the high heterogeneity of the data sources, such applications are still underdeveloped and fragmented. In this paper, we analyze challenges and requirements related to big maritime data applications and propose a scalable data management solution. A big data architecture meeting these requirements is described, and examples of its implementation in concrete scenarios are provided. The related data value chain and use cases in the context of a European project, BigDataOcean, are also described.","","978-1-5386-0774-9","10.1109/ICE.2017.8280019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8280019","Big Data;Big Data Applications;Oceanographic Data;Maritime Applications","Marine vehicles;Temperature sensors;Big Data applications;Sea measurements;Engines","","19","","8","IEEE","5 Feb 2018","27-29 June 2017","27-29 June 2017","IEEE","IEEE Conferences"
"Banking Comprehensive Risk Management System Based on Big Data Architecture of Hybrid Processing Engines and Databases","S. Ma; H. Wang; B. Xu; H. Xiao; F. Xie; H. -N. Dai; R. Tao; R. Yi; T. Wang","Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Department of ICT and Natural Sciences, Norwegian University of Sci. & Tech., Aalesund, Norway; School of Economics and Commerce, South China University of Technology, Guangdong, China; College of Computer, Guangdong University of Technology, Guangdong, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Faculty of Information Tech., Macau University of Sci. and Tech., Macau, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China; Division of Science and Technology, Fujian Rural Credit Union, Fujian, China","2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","6 Dec 2018","2018","","","1844","1851","Banks are shifting from a simple credit risk management model to the comprehensive risk management model. Banking risks come from many channels and systems. Big data technology provides an innovative and effective solution for data management, and thus is suitable to be applied in the risk management scenarios that require high-quality data and complex data analysis. This paper firstly proposes big data architecture of hybrid processing engines and databases. This architecture uses Hadoop ecosystem with ETL and Spark processing engines, and using massive parallel processing databases (MPP), transactional databases, and HDFS. Then a banking comprehensive risk management system prototype based on the proposed big data architecture is implemented. Comparisons and evaluations clearly demonstrate that the proposed system has better performance.","","978-1-5386-9380-3","10.1109/SmartWorld.2018.00310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8560288","comprehensive risk management;big data;hybrid architecture","Technological innovation;Databases;Smart cities;Computer architecture;Banking;Big Data;Systems support;Risk management;Sparks;Engines","","2","","31","IEEE","6 Dec 2018","8-12 Oct. 2018","8-12 Oct. 2018","IEEE","IEEE Conferences"
"Open-Source Big Data Analytics Architecture for Businesses","M. O. Gökalp; K. Kayabay; M. Zaki; A. Koçyiğit; P. E. Eren; A. Neely","Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Informatics Institute Middle East Technical University, Ankara, Turkey; Institute for Manufacturing, University of Cambridge, Cambridgeshire, UK",2019 1st International Informatics and Software Engineering Conference (UBMYK),"23 Jan 2020","2019","","","1","6","Unaware of existing big data technologies, organizations fail to develop a big data capability despite its disruptive impact on today’s competitive business environment. To determine the shortcomings and strengths of developing a big data architecture with open-source tools from technical and managerial perspectives, this study (1) systematically reviews the available open-source big data technologies to present a comprehensive picture, and (2) proposes an open-source architecture for businesses to take as a reference while developing big data analytics capabilities. Lastly, we discuss technical, domain-specific, and firm-specific soft challenges related to establishing a big data architecture in an organization, and how these challenges are reshaping the big data research domain.","","978-1-7281-3992-0","10.1109/UBMYK48245.2019.8965572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965572","Big Data;Big Data Technologies;Big Data Analytics;Reference Architecture;Systematic Review","Computer architecture;Organizations;Big Data;Informatics;Systematic literature review;Software engineering","","12","","39","IEEE","23 Jan 2020","6-7 Nov. 2019","6-7 Nov. 2019","IEEE","IEEE Conferences"
"The Danish National Energy Data Lake: Requirements, Technical Architecture, and Tool Selection","H. B. Hamadou; T. Bach Pedersen; C. Thomsen","Department of Computer Science, Aalborg University, Aalborg, Denmark; Department of Computer Science, Aalborg University, Aalborg, Denmark; Department of Computer Science, Aalborg University, Aalborg, Denmark",2020 IEEE International Conference on Big Data (Big Data),"19 Mar 2021","2020","","","1523","1532","Renewable Energy Sources such as wind and solar do not emit CO2 but their production vary considerably depending on time and weather. Thus, it is important to use the flexibility in device loads to shift energy consumption to follow the production. For example, an Electrical Vehicle (EV) can be charged very flexibly between arriving home at 5PM and leaving again at 7AM. Utilizing all available energy flexibility requires applying machine learning and AI on massive amounts of Big Data from many different actors and devices, ranging from private consumers, over companies, to energy network operators, and using this to create digital solutions to enable and exploit flexibility. The project Flexible Energy Denmark (FED) is building the foundation for this for the entire Danish society. Specifically, FED collects data from a number of Living Labs (LLs) in representative real-life physical environments. The data is stored in the Danish National Energy Data Lake, called FED Data Lake (FEDDL) to enable efficient and advanced analysis. FEDDL is built using only open source tools which can run both on-premise and in cloud settings. In this paper, we describe the requirements for FEDDL based on a representative LL case study, present its technical architecture, and provide a comparison of relevant tools along with the arguments for which ones we selected.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378368","Data Lake;Energy Data;Living Labs;Data Ingestion;Data Governance;Data Security;Open Source;GDPR","Wind;Renewable energy sources;Production;Machine learning;Tools;Big Data;Lakes","","7","","44","IEEE","19 Mar 2021","10-13 Dec. 2020","10-13 Dec. 2020","IEEE","IEEE Conferences"
"A novel big data architecture in support of ADS-B data analytic","E. Boci; S. Thistlethwaite","Exelis, Herndon, VA; Exelis, Herndon, VA","2015 Integrated Communication, Navigation and Surveillance Conference (ICNS)","11 Jun 2015","2015","","","C1-1","C1-8","The first building block of the Federal Aviation Administration's (FAA) Next Generation Air Transportation System (NextGen) initiative to modernize the US national airspace system (NAS) was the implementation of the Automatic Dependent Surveillance-Broadcast (ADS-B) ground infrastructure. A primary aspect of the ADS-B program design is the terrestrial radio station infrastructure. It determined the terrestrial radio stations layout throughout the US and was optimized to meet system performance, safety and security in the NAS. In March 2014, the FAA completed the nationwide infrastructure upgrade, enabling air traffic controllers to track aircraft with greater accuracy and reliability, while giving pilots more information in the cockpit. More than 650 ADS-B radios communicate with equipped aircraft, supporting the new satellite-based surveillance system. Currently, the ADS-B system ingests processes and stores large data sets, while operating at ten percent capacity. As aircraft avionics equipage increases, the volume of data and storage needs will increase beyond our existing system's capacity and processing capability. A new, Hadoop-based architecture was tested to ingest and analyze billions of CAT033 reports in minutes. This paper presents the “Big Data” approach that was adopted to support fast analytics of large ADS-B data volume.","2155-4951","978-1-4799-8952-2","10.1109/ICNSURV.2015.7121218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7121218","","Computer architecture;Big data;Hardware;Lakes;Aircraft;Software;Aerospace electronics","","14","1","12","IEEE","11 Jun 2015","21-23 April 2015","21-23 April 2015","IEEE","IEEE Conferences"
"Building a Data Lake for Smart Building Data: Architecture for Data Quality and Interoperability","J. L. Hernández; S. Martín; P. Kapsalis; K. Katsigarakis; E. Sarmas; V. Marinakis","Energy Division, CARTIF Technology Centre, Boecillo, Valladolid, Spain; Energy Division, CARTIF Technology Centre, Boecillo, Valladolid, Spain; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece; Faculty of the Built Environment, University College of London, London, United Kindom; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece; Decision Support Systems Laboratory, National Technical University of Athens, Athens, Greece","2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)","15 Dec 2023","2023","","","1","8","Building data is growing, where sources are heterogeneous and still treated as silos from different building domains (energy, architecture elements or automation networks, among others). This leads to a lock-in when providing capabilities of data exploitation, such as added-value services, artificial intelligence services or machine-learning activities. Assuring data integration via interoperability mechanisms becomes then pivotal in building data management schemas. Under this perspective, this paper presents an architecture of a data lake that integrates heterogeneous data sources from diverse building domains with the aim of homogenising data-sets and creating data-quality procedures to ensure high-quality services to make better decisions. Based on enriched data between static and dynamic data-sets, the data lake ultimate develops business intelligence mechanism to extract knowledge and information.","","979-8-3503-1806-7","10.1109/IISA59645.2023.10345892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10345892","data lake;data quality;interoperability;digitalisation;smart buildings","Smart buildings;Architecture;Data integrity;Soft sensors;Buildings;Pipelines;Metadata","","5","","16","IEEE","15 Dec 2023","10-12 July 2023","10-12 July 2023","IEEE","IEEE Conferences"
"Big Data as the Big Game Changer","G. Smorodin; O. Kolesnichenko","EMC Academic Alliance Russia & CIS, St. Petersburg, Russia; Security Analysis Bulletin, Moscow, Russia",2015 9th International Conference on Application of Information and Communication Technologies (AICT),"30 Nov 2015","2015","","","40","43","Big Data is the phenomenon of the Information era. Big Data is a new dimension to explore, collecting Big Data we fix the time. Big Data has some functions, including impact on society, form spatio-temporal structures, change the world and future, and integration society with IT technologies. Most important aspect is risk in Cloud computing. To leverage risks, secure Cloud services and get additional benefits an Integrated Approach should be applied. It is important to separate the various kinds of “Security” needs when considering Cloud computing issues. Also Security Analyst should be included into Data Science Team. Data-driven economy is based on three points: open data, legislation for Big Data, and education. For students is very important practical training that engages students into the culture of Big Data Analytics. This opportunity provides the EMC Academic Alliance Russia & CIS through the establishment of ad-hoc Big Data Analytics Teams among universities. The results of the first stage of launched in 2015 the Big Data Analytics Multicenter Study are presented.","","978-1-4673-6856-8","10.1109/ICAICT.2015.7338512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7338512","Big Data;Data Analytics Multicenter Study;Cloud computing;Security Integrated Approach;Federation Business Data Lake","Terrorism;Big data;Force;Blogs","","6","","8","IEEE","30 Nov 2015","14-16 Oct. 2015","14-16 Oct. 2015","IEEE","IEEE Conferences"
"A fully integrated open-source toolkit for mining healthcare big-data: architecture and applications","A. R. Rao; D. Clarke","Fairleigh Dickinson University, NJ, USA; Fairleigh Dickinson University, NJ, USA",2016 IEEE International Conference on Healthcare Informatics (ICHI),"8 Dec 2016","2016","","","255","261","We create an analytics toolkit based on open-source modules that facilitate the exploration of healthcare-related datasets. We illustrate our framework by providing a detailed analysis of physician and hospital ratings data. Our technique should prove valuable to software developers, big-data architects, hospital administrators, policy makers and patients. As an illustration of the capabilities of our toolkit, we examine a controversial issue in the medical field regarding the relationship between seniority of medical professionals and clinical outcomes. We use a publicly available dataset of national hospital ratings in the USA to suggest that there is no significant association between experience of medical professionals and hospital ratings as defined by the US government.","","978-1-5090-6117-4","10.1109/ICHI.2016.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7776351","","Hospitals;Medical diagnostic imaging;Government;Data visualization;Data models;Surgery","","24","","27","IEEE","8 Dec 2016","4-7 Oct. 2016","4-7 Oct. 2016","IEEE","IEEE Conferences"
"Fast-data architecture proposal to alert people in emergency","W. Velásquez; A. Munoz-Arcentales; J. Salvachúa","Escuela Técnica Superior de Ingenieros de Telecomunicación, Universidad Politécnica de Madrid, Spain; Escuela Superior Politécnica del Litoral, ESPOL, Guayaquil, Ecuador; Escuela Técnica Superior de Ingenieros de Telecomunicación, Universidad Politécnica de Madrid, Spain",2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC),"26 Feb 2018","2018","","","165","168","This paper states a brief overview of technologies related to Smart Cities and Big Data ecosystems in order to develop and present an architecture proposal for deploying services using the paradigm of Fast Data. The main goal of this architecture, is to present a set of tools and how it could be integrated for providing fast data services focus on Resilient Smart Cities. Finally, proposals for analysis the response times, delays, incidents, and future works are presented.","","978-1-5386-4649-6","10.1109/CCWC.2018.8301721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301721","Fast Data;Architecture;Emergency;Smart City;IoT;Big Data","Big Data;Proposals;Real-time systems;Smart cities;Emergency services;Tools;Sparks","","3","","29","IEEE","26 Feb 2018","8-10 Jan. 2018","8-10 Jan. 2018","IEEE","IEEE Conferences"
"Security situation awareness method of power mobile application based on big data architecture","L. Yong; C. Mu; D. ZaoJian; C. Lu","State Grid Key Laboratory of Information & Network Security State Grid Smart Grid Research Enstitute Co., Ltd, Nanjing, China; State Grid Key Laboratory of Information & Network Security State Grid Smart Grid Research Enstitute Co., Ltd, Nanjing, China; State Grid Key Laboratory of Information & Network Security State Grid Smart Grid Research Enstitute Co., Ltd, Nanjing, China; State Grid Key Laboratory of Information & Network Security State Grid Smart Grid Research Enstitute Co., Ltd, Nanjing, China",2022 5th International Conference on Data Science and Information Technology (DSIT),"17 Nov 2022","2022","","","1","6","According to the characteristics of security threats and massive users in power mobile applications, a mobile application security situational awareness method based on big data architecture is proposed. The method uses open-source big data technology frameworks such as Kafka, Flink, Elasticsearch, etc. to complete the collection, analysis, storage and visual display of massive power mobile application data, and improve the throughput of data processing. The security situation awareness method of power mobile application takes the mobile terminal threat index as the core, divides the risk level for the mobile terminal, and predicts the terminal threat index through support vector machine regression algorithm (SVR), so as to construct the security profile of the mobile application operation terminal. Finally, through visualization services, various data such as power mobile applications and terminal assets, security operation statistics, security strategies, and alarm analysis are displayed to guide security operation and maintenance personnel to carry out power mobile application security monitoring and early warning, banning disposal and traceability analysis and other decision-making work. The experimental analysis results show that the method can meet the requirements of security situation awareness for threat assessment accuracy and response speed, and the related results have been well applied in a power company.","","978-1-6654-9868-5","10.1109/DSIT55514.2022.9943899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943899","component;situational awareness;power mobile application;big data architecture;SVR;terminal threat index","Support vector machines;Visualization;Law;Big Data;Throughput;Threat assessment;Mobile applications","","","","16","IEEE","17 Nov 2022","22-24 July 2022","22-24 July 2022","IEEE","IEEE Conferences"
"Data Lake Architecture for Air Traffic Management","R. Raju; R. Mital; D. Finkelsztein","SGT, A KBRwyle Business Unit, Cambridge, MA, U.S.A; SGT, A KBRwyle Business Unit, Cambridge, MA, U.S.A; SGT, A KBRwyle Business Unit, Cambridge, MA, U.S.A",2018 IEEE/AIAA 37th Digital Avionics Systems Conference (DASC),"9 Dec 2018","2018","","","1","6","The air traffic transformation underway in the US with the FAA NextGen and in Europe with SESAR relies on information sharing and system interoperability to increase efficiencies, safety and capacity. The proliferation and dissemination of flight, weather, aeronautical, and environmental data by all air traffic participants represents a treasure trove of air traffic optimization opportunities awaiting to be exploited. Traditional data exploitation methods and tools tend to rely on structured data stores and analytical capability architected to answer defined and current questions. SGT, in collaboration with the US DOT Volpe National Transportation Systems Center, developed a prototype air transportation cloud based Data Lake to harness big data from a variety of sources and build the current and next generation of analytics capability. The Data Lake prototype ingests data from multiple sources including FAA sources like SFDPS, TFMData, TBFM, STDDS, ITWS, and AEDT data sources, and stores it in raw, processed, and refined format. The prototype offers an illustration for how users can realize powerful air traffic related data analysis using structured, unstructured and semi-structured data using open source tools to execute queries, searches, processing streams and to visualize data. Using a combination of traditional SQL and NOSQL, Open-Source and COTS products - PostgreSQL, Elastic-Logstash-Kibana, Apache Kafka, Apache Spark and visualization tools like Tableau, D3 and others, the project shows how analysts can quickly and easily build powerful data pipelines and statistical models.","2155-7209","978-1-5386-4112-5","10.1109/DASC.2018.8569361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8569361","Data Lake;Data Analytics;Volpe","Lakes;Tools;Fuels;Data analysis;XML;Data visualization;Prototypes","","9","","1","IEEE","9 Dec 2018","23-27 Sept. 2018","23-27 Sept. 2018","IEEE","IEEE Conferences"
"Big Data Architecture for Automatic Transformation and Validation of Heterogeneous Geospatial Data Compliant with INSPIRE Directive","M. Negru; B. -C. Mocanu; C. Negru; I. Petre","Computer Science Dept., National University of Science and Technology POLITEHNICA, Bucharest, Romania; Computer Science Dept., National University of Science and Technology POLITEHNICA, Bucharest, Romania; Computer Science Dept., National University of Science and Technology POLITEHNICA, Bucharest, Romania; National Institute for Research Development in Informatics ICI, Bucharest, Romania",2025 24th RoEduNet Conference: Networking in Education and Research (RoEduNet),"30 Oct 2025","2025","","","1","6","Geospatial data playa fundamental role in decision-making processes within government entities, private sector organizations and in the context of natural resource management. The integration and harmonization of geospatial data from heterogeneous sources represents a significant challenge in the context of the implementation of the INSPIRE (Infrastructure for Spatial Information in Europe) Directive. The need for stan-dardization of geospatial data, both on a global scale and in the context of the INSPIRE Directive, is primarily driven by the need for interoperability, integration and efficient analysis of spatial information from different systems, formats and semantic structures. In this paper we propose a comprehensive and extensible architecture for the automatic transformation and harmonization of heterogeneous spatial data into INSPIRE-compliant formats, that ensures interoperability within the European infrastructure. Our solution is based on open-source technologies and tools and is validated using the official INPIRE Reference Validation tool.","2247-5443","979-8-3315-5713-3","10.1109/RoEduNet68395.2025.11208431","Ministry of Research, Innovation and Digitization(grant numbers:PN-IV-PCB-RO-MD-2024-0364); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11208431","INSPIRE Directive;Geospatial data;Big data;Data management","Standards organizations;Europe;Distributed databases;Big Data;Spatial databases;Stability analysis;Geospatial analysis;Time factors;Interoperability;Thermal stability","","","","22","IEEE","30 Oct 2025","17-20 Sept. 2025","17-20 Sept. 2025","IEEE","IEEE Conferences"
"Analysis of big data security practices","P. Revathy; R. Mukesh","OCBC Bank Limited, Singapore; Hindustan University, Chennai, India",2017 3rd International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT),"21 Jun 2018","2017","","","264","267","In modern world, huge amount of data is common across all businesses which aim to unlock new economy from these sources. Hadoop was developed to analyze large scale data repository in a parallel computing architecture. The main task in this process is to handle this “Big Data” by applying proper strategies. So, present industry is focusing on the methods in which this “Big Data” can be used for their business growth. There's no suspicion that the setup of Data Lake on hadoop can provide a new way of analytics and intuition analysis. Beyond experimentations and POCs, today Hadoop is considered more into production. As we are moving towards the stage where Hadoop is considered for real-time production scenarios and major chunk of the production data is normally sensitive, or subject to many control measures, it becomes high priority to consider the security aspects in hadoop before deciding on Hadoop installation for any enterprise. This paper evaluates various issues in Hadoop ecosystem and its popular distributions by top big data players in the market. It further intends to investigate and compare the current security features being provided in those big data distributions along with other open source big data security solutions to help in building secure big data environment.","","978-1-5386-1144-9","10.1109/ICATCCT.2017.8389145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8389145","Big Data;Hadoop;Security Measures;Hadoop Security Tools;Hadoop Tools-Security Comparision","Encryption;Authentication;Big Data;Authorization;Tools","","5","","17","IEEE","21 Jun 2018","21-23 Dec. 2017","21-23 Dec. 2017","IEEE","IEEE Conferences"
"Challenges and Opportunities in Big Data Analytics for Industry 4.0: A Systematic Evaluation of Current Architectures","A. R. Kretzer; F. Barreto Vavassori Benitti; F. Siqueira","Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil; Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil; Department of Informatics and Statistics (INE), Federal University of Santa Catarina (UFSC), Florianópolis, Santa Catarina, Brazil",IEEE Access,"30 Oct 2025","2025","13","","183419","183447","The current efforts to integrate Big Data Analytics (BDA) into Industry 4.0 manufacturing systems, despite their usefulness for enhancing data-driven decision-making, are constrained by the lack of architectural standards for data management. This systematic mapping study analyzes many BDA architectures proposed in the literature, revealing a fragmented landscape in which the proposed architectures are largely conceptual with limited industrial validation. Our analysis identifies dominant technological patterns, such as Apache Kafka for ingestion, Spark for processing, and Hadoop and Hive for storage, with the majority of implementations favoring open-source solutions. Despite their theoretical importance, real-time analytics capabilities remain underutilized in practice. This study synthesizes a unified conceptual reference architecture with eight fundamental layers to provide a framework for comparative analysis. We document an imbalance in layer development: storage and processing receive comprehensive attention while querying, infrastructure management, and monitoring layers remain underdeveloped. Implementation approaches show distinct patterns in deployment strategies and data handling, with structured and semi-structured data well supported, whereas unstructured data integration presents ongoing challenges. Future research should focus on developing standardized modular frameworks, benchmarking methodologies, and integrating modern data lakehouse architectures to bridge the gap between theoretical proposals and production-ready systems.","2169-3536","","10.1109/ACCESS.2025.3624558","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES) (Research Organization Registry (ROR) identifier: 00x0ma614) for the Article Processing Charge; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11214321","Big data analytics (BDA);Industry 4.0;Industrial Internet of Things (IIoT);smart manufacturing;cyber-physical systems (CPS);data lake","Fourth Industrial Revolution;Manufacturing;Systematics;Computer architecture;Artificial intelligence;Pipelines;Industrial Internet of Things;Big Data applications;Computer science;Focusing","","","","86","CCBY","22 Oct 2025","2025","","IEEE","IEEE Journals"
"Research on Technology and Industry Situation of Lakehouse","Y. Liu; P. Ma; J. Tian","China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China","2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","29 May 2024","2023","","","2198","2203","The concept of ""Lakehouse"" was proposed by Databricks in 2020. Since ""Lakehouse"" was first written into Gartner’s Hype Cycle for Data Management in 2021, as a new technology, ""Lakehouse"" has received unprecedented attention from the enterprises who need digital transformation. More enterprises believe lakehouse is an important infrastructure for digital transformation. Currently, lakehouse is still in its early stage of development. It is not merely a technical research endeavor, but rather a gradual integration of technologies, representing a transitional phase in the evolution of heterogeneous data platform towards integration. This paper focuses on the lakehouse technology, sorts out the development history of the data platform and the practice path of lakehouse technology. It also lists main manufactures and products of lakehouse and provides the judgments for the future development of lakehouse.","2324-9013","979-8-3503-8199-3","10.1109/TrustCom60117.2023.00308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10538987","data platform;data warehouse;data lake;lakehouse","Industries;Data privacy;Digital transformation;Security;History","","5","","38","IEEE","29 May 2024","1-3 Nov. 2023","1-3 Nov. 2023","IEEE","IEEE Conferences"
"Solution for detecting sensitive data inside a data lake","S. Tovernić; V. Banović; Z. Hrastić; K. Plantić; A. Šandić; M. Baranović","Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Zagreb, Croatia","2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","2 Jul 2018","2018","","","1284","1288","This paper is the result of a project realized by a team of current master's degree students. The team created an algorithm for recognition of sensitive data, primarily name, surname and OIB (Croatian personal identification number). Same algorithm iterates across given unstructured texts and appoints tags for documents considering the existence of specific sensitive data. This process offers a way for companies to narrow down the search for personal information if a client demands removal of his data. Similar algorithm was implemented for working with server logs as well, which are represented as data streams and analysed in real time. To provide insight on the quantity of sensitive information and how it is distributed across different types of documents the team created a dashboard that shows statistical data accumulated by developed algorithms. The solution is stored on Cloudera, Apache Hadoop-based open source platform designed for data management and analytics, which is deployed on Microsoft Azure cloud infrastructure.","","978-953-233-095-3","10.23919/MIPRO.2018.8400232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400232","","Electric potential;Software algorithms;Semantics;Tagging;Software;Real-time systems;Teamwork;Microelectronics;Information and communication technology;Servers","","6","","20","","2 Jul 2018","21-25 May 2018","21-25 May 2018","IEEE","IEEE Conferences"
"Consideration and Research on Data Architecture for the Future Cyber Society","F. Miao; W. Yang; Y. Xie; W. Fan","Big Data Research Institute, Chengdu University, Chengdu, China; Cyber Security College, Chengdu University of Technology, Chengdu, China; Geophysics College, Chengdu University of Technology, Chengdu, China; Big Data Research Institute, Chengdu University, Chengdu, China","2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","9 Apr 2020","2019","","","1671","1676","The future cyber society is a virtual world made of data, contrasted with the real world made of material. Human beings are already living in these two interacted and fusional worlds. Various of data are not only the kind of valuable resources, but also the new cognitions of methodology from the viewpoint of data. There are too many characteristics and attributions of data we even didn't really know, such as data philosophy, data thinking, data theory, data rules, data assets, data ownership, data protection, data sharing, data application, data method, data architecture, etc. We need to build an open, safety, sharable, ecological data platform to manage all kinds of data and support various applications for the future cyber society. A simple architecture of data-oriented and data ownership-based, constructed of one-body with two-wings for building complex information systems was proposed and it may be suitable for the future ordered cyber data society.","","978-1-7281-4034-6","10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9060237","Data-ism, data architecture, data ownership, data encryption, data registration, public key infrastructure, data security application","Big Data;Computers;Computer architecture;Internet;Collaboration","","5","","15","IEEE","9 Apr 2020","19-23 Aug. 2019","19-23 Aug. 2019","IEEE","IEEE Conferences"
"A Model for the Analytical Performance of Data Lake in Stock Market Analysis with Databricks Delta Lake","S. Kamalakkannan; A. Yasmin; A. R; P. Kavitha","Department of Information Technology, School of Computing Sciences, Vels Institute of Science, Technology & Advanced Studies, Pallavaram, Chennai, India; Department of Computer Science, JBAS College for women, Chennai, India; Faculty of Computing, Engineering and Science, University of South Wales, Treforest/Newport Campus, United Kingdom; Department of Computer Applications, School of Computing Sciences, Vels Institute of Science, Technology & Advanced Studies, Pallavaram, Chennai, India",2023 International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS),"6 Dec 2023","2023","","","1065","1071","Stock market investments are highly rewarding but also high in risk. Modern investors use variety of tools to take informed investment decisions. In the current era of digital world, financial service industry has generated huge volume and immense verities of data with extreme speed. Due to the rapid growth in data collection and the heterogeneous nature and complexity of the data, there is a need for Big Data analytical solution that would be able to deal with the stock market data. Large volumes of unstructured, heterogeneous raw data can be stored in a massively scalable manner using data lakes, which are the ideal solution to the big data storage conundrum. The ability of a data lake to preserve data in its original format while processing it at runtime using a schema on-read technique is its key feature. The challenge faced in the data lake is performing analytics which is a significant tool to calculate and analyze the stock market. The proposed architecture of Azure Databricks DeltaLake (ADDL) with Azure DataLake Storage Generation 2 (ADLSG2) is used for analytical processes like Fibonacci retracement for better stock analysis, which aid in forecasting the market price for better investment. As a result, the research focus is to produce a storage having read as well as write capabilities by taking into consideration the Extract-Load-Transform (ELT) operation on the datasource. In this experimental databricks implementation, runtime is performed using open source of Apache Spark API and a highly improved execution engine, which results in a significant performance improvement when comparing to the standard source of Apache Spark available on the ADLS platform. Additionally, the Fibonacci retracement level calculation is achieved with the analytics and forecasting of test close price with various ML and DL techniques such as KNN, LSTM are compared with original price of the test data for better prediction of forecast close price.","","979-8-3503-0085-7","10.1109/ICSSAS57918.2023.10331900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10331900","Big data analytics;ADLSG2;Databricks Delta Lake;ELT;stock market;Fibonacci retracement;LSTM;Apache spark","Cloud computing;Runtime;Costs;Cluster computing;Lakes;Writing;Big Data applications","","1","","22","IEEE","6 Dec 2023","18-20 Oct. 2023","18-20 Oct. 2023","IEEE","IEEE Conferences"
"Toward a Big Data Architecture for Security Events Analytic","L. Fetjah; K. Benzidane; H. E. Alloussi; O. E. Warrak; S. Jai-Andaloussi; A. Sekkaki","Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco; Computer Science Department, Faculty of Sciences Ain Chock, Casablanca, Morocco",2016 IEEE 3rd International Conference on Cyber Security and Cloud Computing (CSCloud),"18 Aug 2016","2016","","","190","197","Cloud Computing did come up with so many attractive advantages such as scalability, flexibility, accessibility, rapid application deployment, and user self service. However in hindsight, Cloud Computing makes ensuring security within these environments so much challenging. Therefore traditional security mechanisms such as firewalls and antivirus softwares have proven insufficient and incapable of dealing with the sheer amount of data and events generated within a Cloud infrastructure. Herein, we present a highly scalable module based system that relies upon Big Data techniques and tools providing a comprehensive solution to process and analyze relevant events (packets flow, logs files) in order to generate an informative decisions that will be handled accordingly and swiftly.","","978-1-5090-0946-6","10.1109/CSCloud.2016.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545918","Cloud Computing;Security Information and Event Management (SIEM);Security Intelligence;Big Data;Hadoop;Spark;ITIL;SKMS","Security;Big data;Cloud computing;Sparks;Organizations;Context;Correlation","","7","","16","IEEE","18 Aug 2016","25-27 June 2016","25-27 June 2016","IEEE","IEEE Conferences"
"DataCockpit: A Toolkit for Data Lake Navigation and Monitoring Utilizing Quality and Usage Information","A. Narechania; S. Chakraborty; S. Agarwal; A. R. Sinha; R. A. Rossi; F. Du; J. Hoffswell; S. Guo; E. Koh; A. Endert; S. Navathe","Georgia Institute of Technology, Atlanta, USA; Georgia Institute of Technology, Atlanta, USA; Georgia Institute of Technology, Atlanta, USA; Adobe Research, Bengaluru, India; Adobe Research, San Jose, USA; Databricks, San Francisco, USA; Adobe Research, Seattle, USA; Adobe Research, San Jose, USA; Adobe Research, San Jose, USA; Georgia Institute of Technology, Atlanta, USA; Georgia Institute of Technology, Atlanta, USA",2023 IEEE International Conference on Big Data (BigData),"22 Jan 2024","2023","","","5305","5310","Modern organizations amass their datasets into centralized repositories called data lakes, affording analytics as needed. The resultant scale and complexity of these data lakes, however, can make data navigation and monitoring challenging for users. We present DataCockpit, a Python toolkit that leverages datasets, usage logs, and associated meta-data to provision data usage and quality characteristics. DataCockpit computes these characteristics for each attribute (e.g., number of times it was queried for subsequent use in downstream applications) and record (e.g., number of non-missing, valid values) and aggregates them at the level of datasets. We develop a visual monitoring tool, powered by DataCockpit, and demonstrate how it can assist data / system administrators as well as end-users to effectively navigate and monitor a data lake. DataCockpit and the monitoring tool are available as open source software for developers to build custom monitoring applications on top of data lakes.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386133","data usage;data quality;monitoring;navigation;visualization;toolkit","Visualization;Navigation;Aggregates;Relational databases;Organizations;Big Data applications;Complexity theory","","1","","38","IEEE","22 Jan 2024","15-18 Dec. 2023","15-18 Dec. 2023","IEEE","IEEE Conferences"
"Policy-Based Access Control System for Delta Lake","Z. Chen; H. Shao; Y. Li; H. Lu; J. Jin","School of Software Engineering, Southeast University, Nanjing, Jiangsu, China; School of Computer Science and Engineering, Southeast University, Suzhou, Jiangsu, China; China Information Consulting & Designing Institute CO, LTD, Nanjing, Jiangsu, China; School of Information Engineering, Nanjing Audit University, Nanjing, Jiangsu, China; School of Computer Science and Engineering, Southeast University, Nanjing, Jiangsu, China",2022 Tenth International Conference on Advanced Cloud and Big Data (CBD),"25 Jan 2023","2022","","","60","65","Delta lake is a new generation of data storage solutions. It stores both transaction log and data files in one directory, and provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing on top of existing data lakes, such as S3, ADLS, GCS, and HDFS. Different from data warehouses, delta lakes allow data to be stored in the original format, retain complete data information, and provide efficient and low-cost storage solutions for data computing and analysis businesses. However, Since Delta Lake metadata is scattered in different resource files, the lack of a unified metadata view increases the difficulty of data governance. Also, Delta Lake adopts an open source storage system as the underlying storage, and its basic access control does not isolate different users, which may lead the risk of data leakage. At present, most common storage systems use data tables’ row and column fields for access control, while delta lake treats the file group as an object. In this paper, aiming at the difficulty of data governance, we design a data lake metadata management method to achieve unified and efficient management of metadata information in heterogeneous data. Then, we design a policy-based data lake access control mechanism, combined with the open source permission framework, and complete the access request for different users and roles in Delta Lake.","","979-8-3503-0971-3","10.1109/CBD58033.2022.00020","National Natural Science Foundation of China; Key Laboratory of Computer Network and Information Integration; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024547","Data Lake;Delta Lake;Metadata;Access Control","Access control;Memory;Lakes;Metadata;Lead;Data warehouses;Big Data applications","","3","","16","IEEE","25 Jan 2023","4-5 Nov. 2022","4-5 Nov. 2022","IEEE","IEEE Conferences"
"Data Lake Organization","F. Nargesian; K. Pu; B. Ghadiri-Bashardoost; E. Zhu; R. J. Miller","Department of Computer Science, University of Rochester, Rochester, NY, USA; Department of Computer Science, University of Ontario Institute of Technology, Oshawa, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Microsoft Research, Redmond, WA, USA; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA",IEEE Transactions on Knowledge and Data Engineering,"7 Dec 2022","2023","35","1","237","250","We consider the problem of building an organizational directory of data lakes to support effective user navigation. The organization directory is defined as an acyclic graph that contains nodes representing sets of attributes and edges indicating subset relationships between nodes. A probabilistic model is constructed to model user navigational behaviour. The model also predicts the likelihood of users finding relevant tables in a data lake given an organization. We formulate the data lake organization problem as an optimization over the organizational structure in order to maximize the expected likelihood of discovering tables by navigating. An approximation algorithm is proposed with an analysis of its error bound. The effectiveness and efficiency of the algorithm are evaluated on both synthetic and real data lakes. Our experiments show that our algorithm constructs organizations that outperform many existing organizations including an existing hand-curated taxonomy, a linkage graph, and a common baseline organization. We have also conducted a formal user study which shows that navigation can help users discover relevant tables that are not easily accessible by keyword search queries. This suggests that keyword search and navigation using an organization are complementary modalities for data discovery in data lakes.","1558-2191","","10.1109/TKDE.2021.3091101","NSERC Discovery(grant numbers:RGPIN-2017-05265); National Science Foundation(grant numbers:IIS-1956096,IIS-2107050); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693372","Data lake;dataset discovery;taxonomy;structure learning","Organizations;Big Data applications;Navigation;Lakes;Inspection;Taxonomy;Aquaculture","","5","","51","IEEE","25 Jan 2022","1 Jan. 2023","","IEEE","IEEE Journals"
"Simplify Big Data Analytics with Amazon EMR: A beginner’s guide to learning and implementing Amazon EMR for building data analytics solutions","S. Mishra",NA,Simplify Big Data Analytics with Amazon EMR: A beginner’s guide to learning and implementing Amazon EMR for building data analytics solutions,"","2022","","","","","Design scalable big data solutions using Hadoop, Spark, and AWS cloud native servicesKey FeaturesBuild data pipelines that require distributed processing capabilities on a large volume of dataDiscover the security features of EMR such as data protection and granular permission managementExplore best practices and optimization techniques for building data analytics solutions in Amazon EMRBook DescriptionAmazon EMR, formerly Amazon Elastic MapReduce, provides a managed Hadoop cluster in Amazon Web Services (AWS) that you can use to implement batch or streaming data pipelines. By gaining expertise in Amazon EMR, you can design and implement data analytics pipelines with persistent or transient EMR clusters in AWS. This book is a practical guide to Amazon EMR for building data pipelines. You'll start by understanding the Amazon EMR architecture, cluster nodes, features, and deployment options, along with their pricing. Next, the book covers the various big data applications that EMR supports. You'll then focus on the advanced configuration of EMR applications, hardware, networking, security, troubleshooting, logging, and the different SDKs and APIs it provides. Later chapters will show you how to implement common Amazon EMR use cases, including batch ETL with Spark, real-time streaming with Spark Streaming, and handling UPSERT in S3 Data Lake with Apache Hudi. Finally, you'll orchestrate your EMR jobs and strategize on-premises Hadoop cluster migration to EMR. In addition to this, you'll explore best practices and cost optimization techniques while implementing your data analytics pipeline in EMR. By the end of this book, you'll be able to build and deploy Hadoop- or Spark-based apps on Amazon EMR and also migrate your existing on-premises Hadoop workloads to AWS.What you will learnExplore Amazon EMR features, architecture, Hadoop interfaces, and EMR StudioConfigure, deploy, and orchestrate Hadoop or Spark jobs in productionImplement the security, data governance, and monitoring capabilities of EMRBuild applications for batch and real-time streaming data analytics solutionsPerform interactive development with a persistent EMR cluster and NotebookOrchestrate an EMR Spark job using AWS Step Functions and Apache AirflowWho this book is forThis book is for data engineers, data analysts, data scientists, and solution architects who are interested in building data analytics solutions with the Hadoop ecosystem services and Amazon EMR. Prior experience in either Python programming, Scala, or the Java programming language and a basic understanding of Hadoop and AWS will help you make the most out of this book.","","9781801077729","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163079.pdf&bkn=10163079&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Tsdat: An Open-Source Data Standardization Framework for Marine Energy and Beyond","C. Lansing; M. Levin; C. Sivaraman; R. Fao; F. Driscoll","Advanced Computing, Mathematics, and Data Division Pacific Northwest National Laboratory, Richland, U.S.A.; Advanced Computing, Mathematics, and Data Division Pacific Northwest National Laboratory, Richland, U.S.A.; Advanced Computing, Mathematics, and Data Division Pacific Northwest National Laboratory, Richland, U.S.A.; Water Power, Energy Conversion & Storage Systems National Renewable Energy Laboratory, Golden, U.S.A.; Water Power, Energy Conversion & Storage Systems National Renewable Energy Laboratory, Golden, U.S.A.",OCEANS 2021: San Diego – Porto,"15 Feb 2022","2021","","","1","6","Many organizations are tasked with the collection and processing of large quantities of data from various measurement devices. Data reported from these sources are often not interoperable with datasets and software used by analysts and other organizations in the same domain, introducing barriers for collaboration on large-scale projects. This poses a particular problem for cross-device comparisons and machine learning applications, which rely on large quantities of data from multiple sources. To address these challenges, the open-source Time-Series Data Pipelines (Tsdat) Python framework was developed by Pacific Northwest National Laboratory, with strategic guidance and direction provided by the National Renewable Energy Laboratory and Sandia National Laboratories to facilitate collaboration and accelerate advancements in the marine energy domain through the development of an open-source ecosystem of tools. This paper will describe the Tsdat framework and the data standards within which it operates. A beta version of Tsdat has been released and is being used by several projects in marine energy, wind energy, and building energy systems.","0197-7385","978-0-692-93559-0","10.23919/OCEANS44145.2021.9706101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706101","Python;open-source;data standards;data lake;big data;interoperability","Wind energy;Instruments;Standards organizations;Buildings;Collaboration;Organizations;Task analysis","","1","","23","","15 Feb 2022","20-23 Sept. 2021","20-23 Sept. 2021","IEEE","IEEE Conferences"
"CRISIS: Integrating AIS and Ocean Data Streams Using Semantic Web Standards for Event Detection","A. Soares; R. Dividino; F. Abreu; M. Brousseau; A. W. Isenor; S. Webb; S. Matwin","Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Defence Research and Development Canada (DRDC), Halifax, Nova Scotia; Defence Research and Development Canada (DRDC), Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia",2019 International Conference on Military Communications and Information Systems (ICMCIS),"19 Sep 2019","2019","","","1","7","Information deluge is still an issue in the maritime environment, creating situations where data are sometimes underutilized or in more extreme cases, not utilized, in the decision-making process. In part, this is due to the high volume of incoming data that are available to the operational community. However, better exploitation of these data streams can be accomplished through techniques that focus on the semantics of the incoming stream, to discover information-based alerts that generate knowledge that is only obtainable when considering the totality of the streams. In this paper, we present an agile data architecture for real-time data representation, integration, and querying situations over heterogeneous data streams using Semantic Web Technologies, with the goal of improved knowledge interoperability. We apply the framework to the maritime ship traffic domain to discover real-time traffic alerts by querying and reasoning across multiple streams.","","978-1-5386-9383-4","10.1109/ICMCIS.2019.8842749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842749","","Marine vehicles;Semantics;Real-time systems;Ontologies;Standards;Resource description framework","","22","","26","Crown","19 Sep 2019","14-15 May 2019","14-15 May 2019","IEEE","IEEE Conferences"
"Hybrid big data architecture for high-speed log anomaly detection","P. Tangsatjatham; N. Nupairoj","Department of Computer Engineering, Chulalongkorn University, Bangkok, Thailand; Department of Computer Engineering, Chulalongkorn University, Bangkok, Thailand",2016 13th International Joint Conference on Computer Science and Software Engineering (JCSSE),"21 Nov 2016","2016","","","1","6","Log processing can be very challenging, especially for environments with lots of servers. In these environments, log data is large, coming at high-speed, and have various formats, the classic case of big data problem. This makes anomaly detection very difficult due to the fact that to get good accuracy, large amount of data must be processed in real-time. To solve this problem, this paper proposes a hybrid architecture for log anomaly detection using Apache Spark for data processing and Apache Flume for data collecting. To demonstrate the capabilities of our proposed solution, we implement a SARIMA-based anomaly detection as a case study. The experimental results clearly indicated that our proposed architecture can support log processing in large-scale environment effectively.","","978-1-5090-2033-1","10.1109/JCSSE.2016.7748933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748933","Hadoop;Real-Time;Log Processing;Largs-Scale;Hybrid Processing","Computer architecture;Sparks;Real-time systems;Bandwidth;Servers;Data processing;Predictive models","","3","","16","IEEE","21 Nov 2016","13-15 July 2016","13-15 July 2016","IEEE","IEEE Conferences"
"Exploring a Framework for Identity and Attribute Linking across Heterogeneous Data Systems","N. Wilder; J. M. Smith; A. Mockus","University of Tennessee, Knoxville, Tennessee; University of Tennessee, Knoxville, Tennessee; University of Tennessee, Knoxville, Tennessee",2016 IEEE/ACM 2nd International Workshop on Big Data Software Engineering (BIGDSE),"16 Jan 2017","2016","","","19","25","Online-activity-generated digital traces provide opportunities for novel services and unique insights as demonstrated in, for example, research on mining software repositories. The inability to link these traces within and among systems, such as Twitter, GitHub, or Reddit, inhibit the advances in this area. Furthermore, no single approach to integrate data from these disparate sources is likely to work. We aim to design Foreseer, an extensible framework, to design and evaluate identity matching techniques for public, large, and low-accuracy operational data. Foreseer consists of three functionally independent components designed to address the issues of discovery and preparation, storage and representation, and analysis and linking of traces from disparate online sources. The framework includes a domain specific language for manipulating traces, generating insights, and building novel services. We have applied it in a pilot study of roughly 10TB of data from Twitter, Reddit, and StackExchange including roughly 6M distinct entities and, using basic matching techniques, found roughly 83,000 matches among these sources. We plan to add additional entity extraction and identification algorithms, data from other sources, and design tools for facilitating dynamic ingestion and tagging of incoming data on a more robust infrastructure using Apache Spark or another distributed processing framework. We will then evaluate the utility and effectiveness of the framework in applications ranging from identifying malicious contributors in software repositories to the evaluation of the utility of privacy preservation schemes.","","978-1-4503-4152-3","10.1145/2896825.2896833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811382","Entity Extraction;Entity Identification;Identity Linking;Domain Specific Language;Big Data Architecture","Joining processes;Data mining;Data processing;Twitter;Software;C languages;Pattern matching","","1","","21","","16 Jan 2017","16-16 May 2016","16-16 May 2016","IEEE","IEEE Conferences"
"Toward Sustainable Data Practices: Integrating Open Data With SDG-Based Data Lake Frameworks","A. Kulkarni; C. Ramanathan; V. E. Venugopal","International Institute of Information Technology, Bangalore, Bengaluru, India; International Institute of Information Technology, Bangalore, Bengaluru, India; International Institute of Information Technology, Bangalore, Bengaluru, India",IEEE Technology and Society Magazine,"11 Apr 2024","2024","43","1","62","69","Achieving sustainable development goals (SDGs) necessitates the adoption of sustainable policies, which entails a crucial task of policy formulation. Policymakers must consider multiple factors, such as the present development status, which can be assessed using diverse data points, as well as the policy’s impact and an action plan outlining its implementation [1]. These data points typically originate from various sources, primarily governmental bodies encompassing statistics, budgets, legislation, public services, and geospatial data (maps, satellite imagery), along with domain users comprising individuals, organizations, and governments [2]. The SDGs are intricately crafted, taking into account a multitude of factors and pinpointing key indicators that influence these factors. These factors typically span across diverse data points sourced from various sectors. For instance, in assessing the student dropout rate, it is imperative to consider factors such as the availability of transportation facilities, basic hygiene amenities, access to drinking water, and the effectiveness of government-organized schemes in utilization and impact. Employing an open data framework coupled with advanced artificial intelligence (AI) models has the potential to facilitate in-depth exploration and analysis, providing valuable insights into the complex interplay of these factors and contributing to a more comprehensive understanding of SDG-related challenges and opportunities.","1937-416X","","10.1109/MTS.2024.3365591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10496885","","Transportation;Legislation;Big Data applications;Data models;Satellite images;Geospatial analysis;Artificial intelligence;Sustainable development;Water resources;Open data;Climate change","","1","","14","IEEE","11 Apr 2024","March 2024","","IEEE","IEEE Magazines"
"Lakehouse Data Platform Technology Overview","Y. Liu; J. Tian; S. Yu; X. Han; X. Jia","China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China; China Academy of Information and Communications Technology, Beijing, China",2024 International Conference on Ubiquitous Computing and Communications (IUCC),"2 Jul 2025","2024","","","499","504","Since the concept of ‘Lakehouse’ was first introduced in Gartner's Maturity Model report in the field of data management in 2021, it has attracted significant attention as an innovative technology in the context of enterprise digital transformation. An increasing number of enterprises are viewing ‘Lakehouse’ as a crucial infrastructure for their digital transformation. The construction of the lakehouse platform addresses challenges related to the integration of streaming and batch processing, such as atomic transactions, consistent updates, and metadata performance bottlenecks. This enables the lakehouse platform to not only fulfill short-term business needs but also to support long-term data application requirements. This paper elaborates on the development history of data platform, the evolution path of the lakehouse data platform, its implementation solutions, standardization, and future development trends.","","979-8-3315-1199-9","10.1109/IUCC65928.2024.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11049315","data platform;data warehouse;data lake;lakehouse","Digital transformation;Standardization;Metadata;Data warehouses;Big Data applications;Ubiquitous computing;Market research;History;Context modeling;Business","","2","","16","IEEE","2 Jul 2025","20-22 Dec. 2024","20-22 Dec. 2024","IEEE","IEEE Conferences"
"From big data to smart data: A genomic information systems perspective","A. L. Palacio; Ó. P. López","Universitat Politecnica de Valencia, Valencia, Valenciana, ES; Universitat Politecnica de Valencia, Valencia, Valenciana, ES",2018 12th International Conference on Research Challenges in Information Science (RCIS),"9 Jul 2018","2018","","","1","11","During the last two decades, data generated by Next Generation Sequencing Technologies have revolutionized our understanding of human biology and improved the study on how changes (variations) in the DNA are involved in the risk of suffering a certain disease. A huge amount of genomic data is publicly available and frequently used by the research community in order to extract meaningful and reliable gene-disease relationships. However, management of this exponential growth of data has become a challenge for biologists; under such a big data problem perspective, they are forced to delve into a lake of complex data spread in over thousand heterogeneous repositories, represented in multiple formats and with different levels of quality; but when data are used to solve a concrete problem only a small part of that “data lake” is really significant; this is what we call the “smart” data perspective. Using conceptual models and the principles of data quality management, adapted to the genomic domain, we propose a systematic approach to move from a big data to a smart data perspective. The aim of this approach is to populate an Information System with genomic data which must be accessible, informative and actionable enough to extract valuable knowledge.","2151-1357","978-1-5386-6517-6","10.1109/RCIS.2018.8406658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8406658","Conceptual Modelling;Data Quality;Big Data;Smart Data;Genomics","Genomics;Bioinformatics;Big Data;Data integrity;Diseases;Data models","","7","","","IEEE","9 Jul 2018","29-31 May 2018","29-31 May 2018","IEEE","IEEE Conferences"
"Geospatial Big Data for a Sustainable and Green Smart City","Y. Gacha; M. A. B. Rhaiem; T. Abdellatif","SERCOM Laboratory, University of Carthage, Carthage, Tunisia; RIADI Laboratory, University Manouba, Manouba, Tunisia; SERCOM Laboratory, University of Carthage, Carthage, Tunisia",2023 International Conference on Cyberworlds (CW),"6 Dec 2023","2023","","","217","224","Green cities are becoming increasingly important in today’s urban landscape. Smart cities, with their interconnected and intelligent infrastructure combined with advanced technologies, provide an ideal environment for promoting green initiatives. This paper presents a comprehensive survey that aims to highlight the role of geospatial big data technologies in the assertion of green smart cities. Indeed, we show how geospatial big data contributes to solving environmental issues related to cities such as air pollution, water pollution, green zones and biodiversity loss, climate change, and the efficient management of energy and renewable energy. Additionally, this paper suggests a basic and general geospatial big data architecture and presents the main open-source frameworks that can aid in the development of such big data systems for sustainable and green city planners.","2642-3596","979-8-3503-1565-3","10.1109/CW58918.2023.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10337569","Geospatial big data;Sustainable and Green Smart City;Environment issues;Energy management;Renewable energy","Climate change;Geospatial analysis;Big Data;Sustainable development;Green design;Smart cities;Environmental factors;Energy management;Renewable energy sources","","","","77","IEEE","6 Dec 2023","3-5 Oct. 2023","3-5 Oct. 2023","IEEE","IEEE Conferences"
"Cloud Native Data Platform for Network Telemetry and Analytics","D. Tovarňák; M. Raček; P. Velan","Masaryk University, Brno, Czech Republic; Masaryk University, Brno, Czech Republic; Masaryk University, Brno, Czech Republic",2021 17th International Conference on Network and Service Management (CNSM),"2 Dec 2021","2021","","","394","396","In this manuscript, we present a prototype of a modular data platform that is able to continuously ingest, process, retain, and analyse large amounts of network telemetry data in a scalable and straightforward manner. It follows a recently proposed Data Lakehouse architectural pattern, which is an evolution of two well-known approaches used in this area – data warehouses and data lakes. The platform is based on open standards and open-source components, and it follows cloud native principles in order to be able to run in modern computing environments such as public, private, and hybrid clouds. The primary focus of the prototype is network telemetry and analytics over traffic flows and infrastructure logs for the purposes of cyber-security digital forensics and incident response. During the demonstration part, we will further describe internal workings of the presented data platform and showcase its capabilities and possible applications on a public dataset.","2165-963X","978-3-903176-36-2","10.23919/CNSM52442.2021.9615568","Ministry of the Interior of the Czech Republic(grant numbers:VI20202022164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615568","Data Lakehouse;Network Flows;Log Data","Digital forensics;Prototypes;Data warehouses;Big Data applications;Telemetry;Standards;Open source software","","9","","5","","2 Dec 2021","25-29 Oct. 2021","25-29 Oct. 2021","IEEE","IEEE Conferences"
"Connection of Dynamic and Static Data: A Data Lake for Building Digitalisation","J. L. Hernández; D. Arévalo; S. Martín; K. Katsigarakis; G. N. Lilis; D. Rovas; I. De Miguel","Energy Division, CARTIF technology centre, Boecillo, Spain; Energy Division, CARTIF technology centre, Boecillo, Spain; Energy Division, CARTIF technology centre, Boecillo, Spain; IEDE University College London, London, UK; IEDE University College London, London, UK; IEDE University College London, London, UK; Universidad de Valladolid, Valladolid, Spain",2024 IEEE International Workshop on Metrology for Living Environment (MetroLivEnv),"6 Aug 2024","2024","","","262","267","The landscape of building data is expanding, with heterogeneous sources that are often treated as isolated silos across different building domains such as energy, architecture elements, or automation networks. This siloed approach creates a lock-in scenario, limiting the potential for effective data exploitation, including the provision of added-value services, artificial intelligence, or machine-learning activities. To overcome this challenge, ensuring data integration through interoperability mechanisms becomes crucial within building data management frameworks. In line with this perspective, this work introduces a data lake that harmonizes heterogeneous data sources from various building domains. The primary goal is to standardize datasets, ensuring the delivery of high-quality services to facilitate better decision-making. These datasets are enriched by interactions between static and dynamic datasets. This holistic approach aims to break down silos and unlock the full potential of building data for informed decision-making processes.","","979-8-3503-8501-4","10.1109/MetroLivEnv60384.2024.10615827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615827","","Soft sensors;Buildings;Semantics;Decision making;Sociology;Data collection;Big Data applications","","","","13","IEEE","6 Aug 2024","12-14 June 2024","12-14 June 2024","IEEE","IEEE Conferences"
"Collaboration of Digital Twins Through Linked Open Data: Architecture With FIWARE as Enabling Technology","J. Conde; A. Munoz-Arcentales; Á. Alonso; G. Huecas; J. Salvachúa","Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Departamento de Ingeniería de Sistemas Telemáticos, ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain",IT Professional,"16 Jan 2023","2022","24","6","41","46","The collaboration of the real world and the virtual world, known as Digital Twin, has become a trend with numerous successful use cases. However, there are challenges mentioned in the literature that must be addressed. One of the most important issues is the difficulty of collaboration of Digital Twins due to the lack of standardization in their implementation. This article continues a previous work that proposed a generic architecture based on the FIWARE components to build Digital Twins in any field. Our work proposes the use of Linked Open Data as a mechanism to facilitate the communication of Digital Twins. We validate our proposal with a use case of an urban Digital Twin that collaborates with a parking Digital Twin. We conclude that Linked Open Data in combination with the FIWARE ecosystem is a real reference option to deploy Digital Twins and to enable the collaboration between Digital Twins.","1941-045X","","10.1109/MITP.2022.3224826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017408","","Ecosystems;Collaboration;Standardization;Market research;Digital twins;Proposals;Open data","","17","","15","IEEE","16 Jan 2023","1 Nov.-Dec. 2022","","IEEE","IEEE Magazines"
"A Smart Shop Floor Information System Architecture Based on the Unified Namespace","F. Salcher; S. Finck; M. Hellwig","JR-Centre for Robust Decision Making, Vorarlberg University of Applied Sciences, Dornbirn, Austria; JR-Centre for Robust Decision Making, Vorarlberg University of Applied Sciences, Dornbirn, Austria; JR-Centre for Robust Decision Making, Vorarlberg University of Applied Sciences, Dornbirn, Austria","2024 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)","18 Dec 2024","2024","","","1","9","Modern research in the field of Smart Manufacturing often focuses on the big data aspect, where the goal is to obtain actionable insights from the data. In this paper, the focus is shifted back to the Smart Shop Floor and how to efficiently derive information with the big data tasks that follow as simple as possible. A condensed literature review of the existing architectures and frameworks for Smart Manufacturing is combined with the experience of practitioners to assess the requirements for a Smart Shop Floor Information System Architecture. On this basis, an architecture is proposed that consists of eight modular building blocks. After a detailed description of the roles and functionalities of these building blocks, a reference implementation using readily available, open-source tools and technologies is laid out. This reference implementation intends to strike the right balance between generality and specificity. It provides the reader with a tangible starting point for implementing and adapting the proposed architecture to their own needs.","2693-8855","979-8-3503-6243-5","10.1109/ICE/ITMC61926.2024.10794387","Christian Doppler Research Association; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10794387","Smart Manufacturing;Information System Architecture;Data Architecture;Industry 4.0;IIoT","Technological innovation;Event detection;Architecture;Bibliographies;Big Data;Fourth Industrial Revolution;Complexity theory;Smart manufacturing;Information systems","","2","","47","IEEE","18 Dec 2024","24-28 June 2024","24-28 June 2024","IEEE","IEEE Conferences"
"Development of the Concept and Architecture of an Automated System for Updating Physical Knowledge for Information Support of Search Design","A. Bobunov; D. Korobkin; S. Fomenkov","CAD Department, Volgograd State Technical University, Volgograd, Russia; CAD Department, Volgograd State Technical University, Volgograd, Russia; CAD Department, Volgograd State Technical University, Volgograd, Russia",2023 International Russian Smart Industry Conference (SmartIndustryCon),"1 May 2023","2023","","","281","288","For developing an automated system for updating physical knowledge for information support of search design, it is necessary to choose a technology stack that would meet the implementation requirements. In view of the sanctions currently imposed on the Russian Federation, it is worth considering mainly open projects and/or domestic developments. We will highlight the main criteria that it is desirable to take into account when designing the architecture of an automated system to support the synthesis of new technical systems and technologies: (a) ability to store and process large amounts of data; (b) unification access for all data analysis procedures; (c) maximum automation of all stages; (d) modularity of the structure, focus on the expansion of functionality; (e) focus on open source solutions and software of domestic manufacturers, excluding rigid binding to paid foreign solutions. As a result of the work done, various aspects of the implementation of the required automated system were analyzed. A review of various software systems and cloud products showed that the concept of building data lakes (Data Lake) in conjunction with the distributed processing tools of the Apache Hadoop ecosystem is used for big data processing. An architecture framework based on a centralized data warehouse and Hadoop components is proposed. It will be possible to increase the functionality of the platform by adding new microservices that connect to the storage and distributed processing tools via the API, as well as using a single web service for managing and displaying data analysis results from these microservices.","","978-1-6654-6429-1","10.1109/SmartIndustryCon57312.2023.10110764","Russian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10110764","architecture;physical knowledge;information support;search design","Distributed processing;Data analysis;Web services;Architecture;Ecosystems;Microservice architectures;Computer architecture","","3","","20","IEEE","1 May 2023","27-31 March 2023","27-31 March 2023","IEEE","IEEE Conferences"
"DIGO: An Open Data Architecture for e-Government","A. L. Machado; J. M. Parente de Oliveira","Divisão de Ciencia da Computação (IEC), Instituto Tecnológico De Aeronáutica, Sao Jose dos Campos, Brazil; Divisão de Ciência da Computação (IEC), Instituto Tecnológico De Aeronáutica, Sao Jose dos Campos, Brazil",2011 IEEE 15th International Enterprise Distributed Object Computing Conference Workshops,"10 Oct 2011","2011","","","448","456","Currently most governing bodies publish their data on the World Wide Web (WWW). These data are available on e-Government Web Portals in unstructured formats using current Web languages, making them difficult to reuse and to generate new information. In this context, access to relevant, accurate public information, and possible reuse by other applications become increasingly complex. Open Government Data (OGD) means the publication of data in open raw formats (open data). There are tools to put open data on the WWW. However, this tools doesn't work with an architecture covering all aspects of data reuse. The aim of this paper is to show an architecture called Delivering Information of Government (DIGO) to allow access to primary data by machines in open data so that citizens interested in doing so can combine them (linked open data) and produce new information and mashup applications, consequently, enabling OGD and data fusion on the Linking Open Data (LOD) cloud.","2325-6605","978-0-7695-4426-7","10.1109/EDOCW.2011.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037649","open data;open government data;linked open data;ontologies;e-Government","Semantics;Portals;Electronic government;Data mining;Context;Resource description framework","","18","","24","IEEE","10 Oct 2011","29 Aug.-2 Sept. 2011","29 Aug.-2 Sept. 2011","IEEE","IEEE Conferences"
"A Hybrid Architecture for Secure Management of Manufacturing Data in Industry 4.0","A. Adhikari; M. Winslett","Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, USA",2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),"6 Jun 2019","2019","","","973","978","In this paper, we analyze the suitability of the methods available today for securely managing the wide variety of data produced by the manufacturing sector. We propose a hybrid information architecture for manufacturing, based on decentralized blockchains, cloud-based WORM storage and ordinary cloud storage. We point out shortcomings in the technology available today for realizing this architecture. In particular, we identify a need for low-cost IoT-based systems to capture, identify, preprocess, encrypt and transmit factory floor data to the corresponding data storage subsystems. We describe our proof-of-concept implementation of such an IoT system, along with the factory case study that inspired it, and argue that this system is sufficiently inexpensive to be retrofitted into today's factories.","","978-1-5386-9151-9","10.1109/PERCOMW.2019.8730717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8730717","Data Architecture;Manufacturing;Security;Digital Threads;Big Data;IoT;Blockchain;WORM","Production facilities;Manufacturing;Blockchain;Grippers;Companies;Sensors;Cloud computing","","8","1","13","IEEE","6 Jun 2019","11-15 March 2019","11-15 March 2019","IEEE","IEEE Conferences"
"Cloud data architecture applied to urban management","F. Devin; A. Jourdan; D. Laffly; Y. Le Nir","EISTI, pau, France; EISTI, pau, France; University of toulouse, Toulouse, France; EISTI, pau, France",2016 Eighth International Conference on Knowledge and Systems Engineering (KSE),"1 Dec 2016","2016","","","327","332","Open Data now provides access to updated data dedicated to urban development. The traditional approach of using production data for decision on land management needs to be rethought in the light of these new opportunities and should therefore addressed towards dynamic management of geographic information. Institutional sites such as INSEE semantically annotate their data facilitating the discovery of contextual data. Linked Open Data cloud network offers semantic access to a huge amount of thematic data including an important geographic subset. These new opportunities always generate a greater amount of usable data. Big Data tools, like Spark, make it easy to handle this amount unbounded data via conventional data-mining algorithms. We group all these issues under the generic name of Cloud Data that has sense only if it is integrated perfectly into a cloud computing environment for efficient processing and reactive application (SaaS application, Restfull services, D3JS library, …). We offer an example of a dedicated application for the Pau urban community in which all Cloud Data is integrated as a SaaS (Software as a Service).","","978-1-4673-8929-7","10.1109/KSE.2016.7758075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7758075","","Predictive models;Computational modeling;Clustering algorithms;Cloud computing;Semantics;Sparks;Urban areas","","","","16","IEEE","1 Dec 2016","6-8 Oct. 2016","6-8 Oct. 2016","IEEE","IEEE Conferences"
"TensorBank: Tensor Lakehouse for Foundation Model Training","R. Kienzler; J. Schmude; N. Simumba; B. Blumenstiel; M. Freitag; D. Kimura; Z. A. Nagy; M. Behrendt; H. Hamann; S. K. Mukkavilli; D. S. Civitarese",IBM Research Europe; IBM Research; IBM Research; IBM Research Europe; IBM Research; IBM Research; IBM Research Europe; IBM Research and Development; IBM Research; IBM Research Europe; IBM Research,2023 IEEE International Conference on Big Data (BigData),"22 Jan 2024","2023","","","3350","3354","Storing and streaming high dimensional data for foundation model training became a critical requirement with the rise of foundation models beyond natural language. In this paper we introduce TensorBank – a petabyte scale tensor lakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU memory at wire speed based on complex relational queries. We use Hierarchical Statistical Indices (HSI) for query acceleration. Our architecture allows to directly address tensors on block level using HTTP range reads. Once in GPU memory, data can be transformed using PyTorch transforms. We provide a generic PyTorch dataset type with a corresponding dataset factory translating relational queries and requested transformations as an instance. By making use of the HSI, irrelevant blocks can be skipped without reading them as those indices contain statistics on their content at different hierarchical resolution levels. This is an opinionated architecture powered by open standards and making heavy use of open-source technology. Although, hardened for production use using geospatial-temporal data, this architecture generalizes to other use cases like computer vision, computational neuroscience, biological sequence analysis and more.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386912","data lakehouse;data streaming;database indexing;foundation models;tensor streaming;tensor query","Training;Acute respiratory distress syndrome;Tensors;Computational modeling;Wires;Graphics processing units;Computer architecture","","3","","29","IEEE","22 Jan 2024","15-18 Dec. 2023","15-18 Dec. 2023","IEEE","IEEE Conferences"
"CLODA: A Crowdsourced Linked Open Data Architecture","G. Larkou; J. Metochi; G. Chatzimilioudis; D. Zeinalipour-Yazti","Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus",2013 IEEE 14th International Conference on Mobile Data Management,"29 Jul 2013","2013","2","","104","109","In this paper we present our Crowdsourced Linked Open Data Architecture (CLODA), a first attempt to combine crowdsourcing, localization and location-based services to generate, collect, validate and relate real-world, geo-spatial and multidimensional information using smartphones and other mobile devices. CLODA focuses on the construction of URI addressable, interlinked and semi-structured data following the Linked-Open Data (LOD) paradigm. The validity of the constructed data is then contributed by a participating crowd. We present our prototype implementation on top of Google Maps and a blend of in-house technologies, particularly our indoor positioning framework, coined Airplace, our trajectory similarity framework, coined SmartTrace, our neighborhood detection framework, coined Proximity and our smartphone testing platform coined SmartLab.","2375-0324","978-0-7695-4973-6","10.1109/MDM.2013.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6569072","Linked Open Data;Crowdsourcing;Smartphones","Smart phones;Prototypes;Google;Trajectory;Mobile communication;Libraries;Androids","","4","","29","IEEE","29 Jul 2013","3-6 June 2013","3-6 June 2013","IEEE","IEEE Conferences"
"Linked Data Principles for Data Lakes","A. Adamou; M. D'Aquin",NA; NA,Data Lakes,"","2020","","","145","169","Linked Data are based on a set of principles and technologies to exploit the architecture of the Web in order to represent and provide access to machine‐readable, globally integrated information. This chapter provides an overview of what Linked Data means, and of the general approach to create and consume Linked Data resources. It shows how this approach can be used at different levels in a data lake, including basic graph‐based data storage and querying, data integration and data cataloging. To exemplify the application of Linked Data principles and technologies for data lakes, a demonstrating scenario is given in the context of the creation and application of a large data platform for a smart city: the Milton Keynes Data Hub. Both Linked Data and data lakes operate under principles that could be interpreted as an assumption of levity towards the traditional rigor of database systems.","","9781119720423","10.1002/9781119720430.ch7","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822439.pdf&bkn=9820901&pdfType=chapter","","Linked data;Big Data applications;Resource description framework;Vocabulary;Standards;Publishing;Ontologies","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"Geospatial Data Analytics on AWS: Discover how to manage and analyze geospatial data in the cloud","S. Bateman; J. Gnanachandran; J. DeMuth",NA; NA; NA,Geospatial Data Analytics on AWS: Discover how to manage and analyze geospatial data in the cloud,"","2023","","","","","Build an end-to-end geospatial data lake in AWS using popular AWS services such as RDS, Redshift, DynamoDB, and Athena to manage geodata Purchase of the print or Kindle book includes a free PDF eBook.Key FeaturesExplore the architecture and different use cases to build and manage geospatial data lakes in AWSDiscover how to leverage AWS purpose-built databases to store and analyze geospatial dataLearn how to recognize which anti-patterns to avoid when managing geospatial data in the cloudBook DescriptionManaging geospatial data and building location-based applications in the cloud can be a daunting task. This comprehensive guide helps you overcome this challenge by presenting the concept of working with geospatial data in the cloud in an easy-to-understand way, along with teaching you how to design and build data lake architecture in AWS for geospatial data. You’ll begin by exploring the use of AWS databases like Redshift and Aurora PostgreSQL for storing and analyzing geospatial data. Next, you’ll leverage services such as DynamoDB and Athena, which offer powerful built-in geospatial functions for indexing and querying geospatial data. The book is filled with practical examples to illustrate the benefits of managing geospatial data in the cloud. As you advance, you’ll discover how to analyze and visualize data using Python and R, and utilize QuickSight to share derived insights. The concluding chapters explore the integration of commonly used platforms like Open Data on AWS, OpenStreetMap, and ArcGIS with AWS to enable you to optimize efficiency and provide a supportive community for continuous learning. By the end of this book, you’ll have the necessary tools and expertise to build and manage your own geospatial data lake on AWS, along with the knowledge needed to tackle geospatial data management challenges and make the most of AWS services.What you will learnDiscover how to optimize the cloud to store your geospatial dataExplore management strategies for your data repository using AWS Single Sign-On and IAMCreate effective SQL queries against your geospatial data using AthenaValidate postal addresses using Amazon Location servicesProcess structured and unstructured geospatial data efficiently using RUse Amazon SageMaker to enable machine learning features in your applicationExplore the free and subscription satellite imagery data available for use in your GISWho this book is forIf you understand the importance of accurate coordinates, but not necessarily the cloud, then this book is for you. This book is best suited for GIS developers, GIS analysts, data analysts, and data scientists looking to enhance their solutions with geospatial data for cloud-centric applications. A basic understanding of geographic concepts is suggested, but no experience with the cloud is necessary for understanding the concepts in this book.","","9781804610572","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251273.pdf&bkn=10251273&pdfType=book","","","","","","","","14 Sep 2023","","","Packt Publishing","Packt Publishing eBooks"
"TabSketchFM: Sketch-Based Tabular Representation Learning for Data Discovery Over Data Lakes","A. Khatiwada; H. Kokel; I. Abdelaziz; S. Chaudhury; J. Dolby; O. Hassanzadeh; Z. Huang; T. Pedapati; H. Samulowitz; K. Srinivas",Northeastern University; IBM Research; IBM Research; IBM Research; IBM Research; IBM Research; Rensselaer Polytechnic Institute; IBM Research; IBM Research; IBM Research,2025 IEEE 41st International Conference on Data Engineering (ICDE),"20 Aug 2025","2025","","","1523","1536","Enterprises have a growing need to identify relevant tables in data lakes; e.g. tables that are unionable, joinable, or subsets of each other. Tabular neural models can be help-ful for such data discovery tasks. In this paper, we present TabSketchFM, a neural tabular model for data discovery over data lakes. First, we propose novel pre-training: a sketch-based approach to enhance the effectiveness of data discovery in neural tabular models. Second, we finetune the pretrained model for identifying unionable, joinable, and subset table pairs and show significant improvement over previous tabular neural models. Third, we present a detailed ablation study to highlight which sketches are crucial for which tasks. Fourth, we use these finetuned models to perform table search; i.e., given a query table, find other tables in a corpus that are unionable, joinable, or that are subsets of the query. Our results demonstrate significant improvements in F1 scores for search compared to state-of-the-art techniques. Finally, we show significant transfer across datasets and tasks establishing that our model can generalize across different tasks and over different data lakes.","2375-026X","979-8-3315-3603-9","10.1109/ICDE65448.2025.00118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113110","tabular foundational model;data discovery;data lakes;tabular transformer;tabular neural network","Representation learning;Big Data applications;Data engineering;Data models","","","","60","IEEE","20 Aug 2025","19-23 May 2025","19-23 May 2025","IEEE","IEEE Conferences"
"Large Scale Distributed Data Processing for a Network of Humanoid Telepresence Robots","I. Steve Cardenas; P. Kumar Paladugula; J. -H. Kim","Advanced Telerobotics Research Lab Computer Science, Kent State University, Kent, Ohio, USA; Advanced Telerobotics Research Lab Computer Science, Kent State University, Kent, Ohio, USA; Advanced Telerobotics Research Lab Computer Science, Kent State University, Kent, Ohio, USA","2020 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)","8 Oct 2020","2020","","","1","9","We present an open-source data lake architecture implemented to store and process data from robotic systems at large scale. In particular, we leverage our architecture for the use case of processing data from a network of humanoid telepresence robotic avatars that are controlled by human operators wearing immersive telepresence control suits. Our architecture leverages well-established open-source technologies and integrates into existing robot frameworks and middleware such as Robot Operating System (ROS) and Data Distribution Service (DDS).","","978-1-7281-9615-2","10.1109/IEMTRONICS51293.2020.9216366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216366","cloud robotics;big data;IoT;distributed systems","Cloud computing;Robot sensing systems;Lakes;Telepresence;Distributed databases;Humanoid robots","","4","","34","IEEE","8 Oct 2020","9-12 Sept. 2020","9-12 Sept. 2020","IEEE","IEEE Conferences"
"Open Data Platform as a Source of ML-Driven Innovations in the Energy Sector","F. Nepsha; V. Voronin; S. Kovalyov","RTSoft Smart Grid, LLC, Gubkin University T.F. Gorbachev Kuzbass State Technical University, Moscow, Russia; Mining industry digital transformation laboratory, T.F. Gorbachev Kuzbass State Technical University, Kemerovo, Russia; Institute of control sciences of Russian academy of sciences, Moscow, Russia",2023 Belarusian-Ural-Siberian Smart Energy Conference (BUSSEC),"31 Oct 2023","2023","","","1","6","This article explores the challenges and potential solutions associated with the accumulation and utilization of open data in the energy sector, particularly in the context of machine learning (ML)-driven innovations. The growing adoption of Internet of Things (IoT) technologies has led to a significant increase in data generation, creating opportunities for leveraging big data processing and ML methods. However, the lack of an effective ecosystem for ML-driven innovations in the energy sector hampers progress. The article discusses the main problems related to open data accumulation and usage and reviews existing publications on organizing open data in the energy sector. It proposes an ecosystem approach to establish an open data platform that meets stakeholders' needs and accelerates innovation. Additionally, it introduces the application of a data lakehouse architecture as an efficient storage and management solution for the platform. By addressing the challenges and implementing the suggested solutions, the energy sector can unlock the full potential of open data, foster collaboration, and drive transformative innovations.","","979-8-3503-5807-0","10.1109/BUSSEC59406.2023.10296377","Ministry of Science and Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10296377","energy sector;open data;ML-driven innovation;data-driven innovation;digital platform","Industries;Technological innovation;Renewable energy sources;Ecosystems;Machine learning;Maintenance engineering;Power systems","","2","","40","IEEE","31 Oct 2023","25-29 Sept. 2023","25-29 Sept. 2023","IEEE","IEEE Conferences"
"BLEND: A Unified Data Discovery System","M. Esmailoghli; C. Schnell; R. J. Miller; Z. Abedjan","TU Berlin & BIFOLD, Berlin, Germany; Leibniz Universität Hannover, Hannover, Germany; University of Waterloo, Waterloo, Canada; TU Berlin & BIFOLD, Berlin, Germany",2025 IEEE 41st International Conference on Data Engineering (ICDE),"20 Aug 2025","2025","","","737","750","Most research on data discovery has so far focused on improving individual discovery operators such as join, correlation, or union discovery. However, in practice, a combination of these techniques and their corresponding indexes may be necessary to support arbitrary discovery tasks. We propose BLEND, a comprehensive data discovery system that supports existing operators and enables their flexible pipelining. BLEND is based on a set of lower-level operators that serve as fundamental building blocks for more complex and sophisticated user tasks. To reduce the execution runtime of discovery pipelines, we propose a unified index structure and a rule- and cost-based optimizer that rewrites SQL statements into low-level operators when possible. We show the superior flexibility and efficiency of our system compared to ad-hoc discovery pipelines and stand-alone solutions.","2375-026X","979-8-3315-3603-9","10.1109/ICDE65448.2025.00061","German Research Foundation(grant numbers:387872445); NSF(grant numbers:IIS-2107248,IIS-1956096,IIS-2325632); Canada Excellence Research Chairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112882","join discovery;join;union;data discovery system;correlation search;data lake;index structure;keyword search;data discovery","Correlation;Runtime;Keyword search;Data engineering;Big Data applications;Indexes;Pipeline processing","","1","","70","IEEE","20 Aug 2025","19-23 May 2025","19-23 May 2025","IEEE","IEEE Conferences"
"Peer-to-peer disaggregated telemetry for autonomic machine-learning-driven transceiver operation","F. Paolucci; A. Sgambelluri; M. Felipe Silva; A. Pacini; P. Castoldi; L. Valcarenghi; F. Cugini","CNIT, Pisa, Italy; Scuola Superore Sant'Anna, Pisa, Italy; Engineering Institute, Los Alamos National Laboratory, Los Alamos, NM, USA; Scuola Superore Sant'Anna, Pisa, Italy; Scuola Superore Sant'Anna, Pisa, Italy; Scuola Superore Sant'Anna, Pisa, Italy; CNIT, Pisa, Italy",Journal of Optical Communications and Networking,"1 Jul 2022","2022","14","8","606","620","Autonomic networking and monitoring will drive the evolution of next generation software defined networking (SDN) optical networks towards the zero touch networking paradigm. Optical telemetry services will play a key role to enable advanced network awareness at device and component granularity. Optical disaggregation is pushing the adoption of open models, enabling multi-vendor interoperability, including telemetry. Moreover, due to whitebox programmability and the adoption of open source micro services, it is becoming feasible to monitor data streams from optical devices related to quality of transmission key performance indicators. Finally, due to mature big data analytics platforms, including machine learning and artificial intelligence, the telemetry data lake is processed to effectively detect network anomalies. However, current centralized telemetry architectures are prone to scalability issues, suboptimal soft failure recovery due to operational mode limitations, and/or the inability of the SDN controller of tuning finer or proprietary transmission parameters. Conversely, a number of soft failures might be detected and recovered directly at the optical card transmitter, often in a hitless fashion, also relying on optimized vendor-proprietary configurations. The paper proposes what we believe to be a novel peer-to-peer telemetry (P2PT) service ready for next generation digital coherent optics cards, for local processing and soft failure recovery at the transceiver agent level. The P2PT architecture, workflow, and subscription extensions are conceived to enable direct and fast recovery at the transceiver level, resorting to optical signal retuning and adaptations. Experimental evaluations, including lightweight machine learning detection at the card agent, are provided in a multi-vendor disaggregated optical network testbed to assess different soft failure use cases and P2PT service scalability.","1943-0639","","10.1364/JOCN.456666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9812947","","Telemetry;Monitoring;Optical network units;Optical receivers;Optical signal processing;Optical transmitters;Optical sensors","","7","","","","1 Jul 2022","August 2022","","IEEE","IEEE Journals"
"HDRS: A Hybrid Reputation System With Dynamic Update Interval for Detecting Malicious Vehicles in VANETs","X. Liu; O. Ma; W. Chen; Y. Xia; Y. Zhou","School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; College of Computer Sciences, Zhejiang University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China",IEEE Transactions on Intelligent Transportation Systems,"10 Aug 2022","2022","23","8","12766","12777","The reputation-based scheme is a promising solution to prevent malicious behaviors in Vehicular Ad-hoc Networks (VANETs). However, traditional centralized reputation schemes are not suited for distributed networks, while decentralized reputation schemes are vulnerable to malicious vehicles spreading false messages. Most of these schemes assume that the behavior of vehicles can be accurately measured as reputation from the communication, ignoring that malicious vehicles may behave intelligently to avoid being detected. In this paper, we propose a hybrid reputation system (HDRS) which allows vehicles and roadside units (RSU) to complete reputation evaluations separately and provide references to each other. HDRS utilizes a reliability evaluation module to filter out unreliable calculation results and reference records. Furthermore, HDRS includes a dynamic adjustment mechanism for the reputation update interval, employing Analytic Hierarchy Process (AHP) and reliability evaluation results to resist intelligent attacks. Simulation results illustrate that HDRS can maintain a high detection rate and low false-positive rate for detecting malicious vehicles in different environments. Compared with existing schemes, HDRS increases the detection rates of collusion and intelligent attacks by 30% and 16%, respectively.","1558-0016","","10.1109/TITS.2021.3117289","Zhejiang Province Natural Science Foundation(grant numbers:LY19F020021); National Natural Science Foundation of China(grant numbers:61873232); New Talent Plan of Zhejiang Province(grant numbers:2020R427062); Opening Project of Key Laboratory of Ministry of Public Security (Public Security Information Application Based on Big-data Architecture)(grant numbers:2020DSJSYS005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565821","VANETs;reputation system;hybrid architecture;reliability evaluation;dynamic adjustment","Reliability;Vehicle dynamics;Vehicular ad hoc networks;Intelligent transportation systems;Blacklisting;Trust management;Switches","","25","","35","IEEE","8 Oct 2021","Aug. 2022","","IEEE","IEEE Journals"
"Serverless Analytics with Amazon Athena: Query structured, unstructured, or semi-structured data in seconds without setting up any infrastructure","A. Virtuoso; M. T. Hocanin; A. Wishnick; R. Pathak",NA; NA; NA; NA,"Serverless Analytics with Amazon Athena: Query structured, unstructured, or semi-structured data in seconds without setting up any infrastructure","","2021","","","","","Get more from your data with Amazon Athena’s ease-of-use, interactive performance, and pay-per-query pricingKey FeaturesExplore the promising capabilities of Amazon Athena and Athena’s Query Federation SDKUse Athena to prepare data for common machine learning activitiesCover best practices for setting up connectivity between your application and Athena and security considerationsBook DescriptionAmazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using SQL, without needing to manage any infrastructure. This book begins with an overview of the serverless analytics experience offered by Athena and teaches you how to build and tune an S3 Data Lake using Athena, including how to structure your tables using open-source file formats like Parquet. You’ll learn how to build, secure, and connect to a data lake with Athena and Lake Formation. Next, you’ll cover key tasks such as ad hoc data analysis, working with ETL pipelines, monitoring and alerting KPI breaches using CloudWatch Metrics, running customizable connectors with AWS Lambda, and more. Moving on, you’ll work through easy integrations, troubleshooting and tuning common Athena issues, and the most common reasons for query failure. You will also review tips to help diagnose and correct failing queries in your pursuit of operational excellence. Finally, you’ll explore advanced concepts such as Athena Query Federation and Athena ML to generate powerful insights without needing to touch a single server. By the end of this book, you’ll be able to build and use a data lake with Amazon Athena to add data-driven features to your app and perform the kind of ad hoc data analysis that often precedes many of today’s ML modeling exercises.What you will learnSecure and manage the cost of querying your dataUse Athena ML and User Defined Functions (UDFs) to add advanced features to your reportsWrite your own Athena Connector to integrate with a custom data sourceDiscover your datasets on S3 using AWS Glue CrawlersIntegrate Amazon Athena into your applicationsSetup Identity and Access Management (IAM) policies to limit access to tables and databases in Glue Data CatalogAdd an Amazon SageMaker Notebook to your Athena queriesGet to grips with using Athena for ETL pipelinesWho this book is forBusiness intelligence (BI) analysts, application developers, and system administrators who are looking to generate insights from an ever-growing sea of data while controlling costs and limiting operational burden, will find this book helpful. Basic SQL knowledge is expected to make the most out of this book.","","9781800567863","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163042.pdf&bkn=10163042&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Semantic Multimedia Fog Computing and IoT Environment: Sustainability Perspective","M. A. Rahman; M. S. Hossain; E. Hassanain; G. Muhammad",University of Prince Mugrin; King Saud University; University of Prince Mugrin; King Saud University,IEEE Communications Magazine,"17 May 2018","2018","56","5","80","87","We propose a fog-cloud hybrid architecture that can support a massive ad hoc crowd composed of a massive social network and distributed IoT nodes around a smart city environment. The fog computing framework is introduced to support energy efficiency by incorporating IoT nodes that act as an interface to the ad hoc crowd, is aware of user contexts within its vicinity, can do real-time processing of user requests, supports a constrained amount of data offloading, and pass the geo-tagged multimedia data available from the subset of the ad hoc crowd to the big data repository in the cloud. The framework leverages a sustainable crowdsourcing incentive model for both the ad hoc crowd and the IoT infrastructure provider. The proposed sustainable framework can potentially support context-aware smart city services such as finding a lost person within the crowd, showing green and health risk prone zones, semantic and location-aware notifications of events of interest, semantic IoT-based routing, and dealing with emergency situations. We present a communication architecture between mobile users and fog nodes, and between fog nodes and the cloud, a sustainability and energy efficiency model, and massive geo-tagged, multimedia big data architecture.","1558-1896","","10.1109/MCOM.2018.1700907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360855","","Smart cities;Cloud computing;Edge computing;Semantics;Multimedia communication;Computer architecture;Social network services;Energy efficiency;Ad hoc networks","","51","","13","IEEE","17 May 2018","May 2018","","IEEE","IEEE Magazines"
