"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Integrated Framework for Simulated Business Intelligence and Real-Time Analytics to Enhance Agility in Industry 4.0 Decision-Making","B. I. Sowan; A. Altarawneh; M. Fasha","Dept. of Bus. Intell. & Data Analytics, University of Petra, Amman, Jordan; Dept. of Computer Science, Brunel University of London, London, UK; Dept. of Bus. Intell. & Data Analytics, University of Petra, Amman, Jordan",2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA),"2 Jun 2025","2025","","","1","6","Agility and real-time responsiveness are critical for achieving competitiveness in Industry 4.0. This study introduces an innovative framework that integrates simulation-driven business intelligence and real-time analytics to enhance decision-making processes in dynamic industrial environments. The proposed framework employs advanced multi-agent systems, operational data stores, and machine learning models to process high-velocity data streams, optimize operational workflows, and provide actionable insights. By adopting a layered architecture for data integration, simulation, and decision support, the framework ensures adaptability and scalability. Experimental results demonstrate significant improvements in processing speed, predictive accuracy, and decision latency when compared to traditional approaches. Applications across sectors such as manufacturing and logistics validate its effectiveness, showcasing its ability to transform raw data into valuable insights for strategic and operational decisions. This work establishes a solid foundation for future research, including blockchain integration for secure decision-making and real-time analytics in smart city ecosystems.","","979-8-3315-2365-7","10.1109/ICCIAA65327.2025.11013709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11013709","Supply Simulated Business Intelligence;Real-Time Analytics;Organizational Agility;Industry 4.0;Multi-Agent Systems;Decision Support Framework","Smart cities;Scalability;Decision making;Transforms;Solids;Real-time systems;Fourth Industrial Revolution;Business intelligence;Streams;Multi-agent systems","","","","20","IEEE","2 Jun 2025","28-30 April 2025","28-30 April 2025","IEEE","IEEE Conferences"
"A Framework for Live Situational Awareness in Stream-Based 5G Applications","S. Loss; K. Costa; L. Gurgel; R. Sales; V. Brito; T. Batista; E. Cavalcante; F. Lopes; A. R. Neto; N. Cacho","Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil; Federal University of Rio Grande do Norte, Natal, Brazil",2025 IEEE Latin Conference on IoT (LCIoT),"19 Aug 2025","2025","","","202","205","The increasing integration of technology into public safety systems generates vast amounts of data that demand efficient, real-time analytics to provide actionable insights. However, managing such large-scale data streams poses significant challenges, mainly due to the limited computational resources of edge devices and the high processing requirements. This paper introduces the Stream AI Analytics for Live Situational Awareness (SAALSA) framework, a solution that leverages 5G connectivity, Internet of Things (IoT) devices, edge computing, and artificial intelligence (AI) to address these challenges. A first-responder use case highlights the framework’s ability to facilitate real-time data processing for public safety scenarios and improve decision-making and operational efficiency.","","979-8-3315-1118-0","10.1109/LCIoT64881.2025.11118567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11118567","situational awareness;public safety;Internet of Things;5G;edge computing;stream analytics","5G mobile communication;Decision making;Data processing;Public security;Real-time systems;Internet of Things;Artificial intelligence;Edge computing","","1","","6","IEEE","19 Aug 2025","23-25 April 2025","23-25 April 2025","IEEE","IEEE Conferences"
"Research on the Application of Flink Streaming Data Technology in the Construction of Automobile Internationalization Platform","K. Kai; G. Yaxin; Z. Fan","China Automotive Technology and Research Center Co., Ltd., Tianjin, China; China Automotive Technology and Research Center Co., Ltd., Tianjin, China; China Automotive Technology and Research Center Co., Ltd., Tianjin, China","2025 Asia-Europe Conference on Cybersecurity, Internet of Things and Soft Computing (CITSC)","27 Mar 2025","2025","","","778","782","This paper analyzes the core advantages of Flink streaming data technology, including high throughput, low latency and strong scalability, and shows its superiority in processing large-scale automobile data streams. Aiming at the complex business needs of the automobile internationalization platform, a streaming data fusion algorithm is designed, which can integrate multi-source data from different countries and regions in real time, such as user behavior data, vehicle performance data and market feedback data. The algorithm optimizes the data stream processing process to achieve efficient data integration and analysis, and provides support for real-time decision-making of the platform. To verify the effect of the algorithm, this paper conducts model simulation based on Flink streaming data technology. The results show that the algorithm can significantly improve the platform response speed and data processing accuracy when processing cross-border data. Specifically, the simulation data shows that the response time of the platform is reduced by about 30% when the data flow is high, and the data processing accuracy is improved by 15%. In addition, the accuracy of the platform in market demand forecasting is improved by 20%, which enhances the stability and efficiency when facing massive data. The experimental results show that the proposed streaming data fusion algorithm significantly improves the real-time decision-making ability of the platform, especially in cross-border data integration and market demand forecasting.","","979-8-3315-0420-5","10.1109/CITSC64390.2025.00145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10936478","Flink stream;automobile internationalization platform;stream data fusion algorithm;data technology","Accuracy;Data integration;Demand forecasting;Throughput;Real-time systems;Stability analysis;Automobiles;Low latency communication;Streams;Automotive engineering","","2","","8","IEEE","27 Mar 2025","10-12 Jan. 2025","10-12 Jan. 2025","IEEE","IEEE Conferences"
"IoT-Driven Predictive Maintenance in Industry 4.0 Using Optimized Granger-Inspired GNN and Decision Support System with Big Data","V. V. Patil","Department of AI and DS, Shri Chhatrapati Shivaji Maharaj College of Engineering, Maharashtra, India","2025 IEEE 7th International Conference on Computing, Communication and Automation (ICCCA)","19 Jan 2026","2025","","","1","5","Traditional methods fail to satisfy contemporary industrial needs but the rapid development of Industry 4.0 makes it possible to maintain factories through the integration of data systems with Internet of Things. The implementation of modern maintenance techniques results in multiple performance issues together with unanticipated equipment malfunctions and increasing operational costs for business operations. This research establishes an IoT-based predictive maintenance structure which encompasses GNN with optimized decision support systems features. Circular measurement using streaming operational data becomes possible after industrial machines receive IoT sensors through the implementation of the system. A Granger Causality-Inspired GNN model specially designed to handle this specific data type performs efficiently for detecting dependencies between machine components and delivering dependable failure predictions successfully. The predictive model shows better performance than traditional approaches because it builds failure identification through causal relationships. A Decision Support System (DSS) operates together with the framework to use predictive insights that help select proactive maintenance approaches which cut maintenance time and maximize resources. The efficiency of systems improves through big data analytics because it analyses significant industrial data to create flexible performance within various industrial applications. Experimental runs demonstrate that the deployed strategy enhances both accurate forecasts and decreases faulty indications thus enabling optimized maintenance program operations for better operational productivity and lower expenditure. The system integrates IoT technology with deep learning approaches together with decision intelligence to develop an Industry 4.0 suitable intelligent predictive maintenance program. Analysis proves that linking graph-based learners to industrial IoT networks develops predictive proactive maintenance operations at lower expense.","","979-8-3315-6980-8","10.1109/ICCCA66364.2025.11325385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11325385","IoT;Predictive Maintenance;Graph Neural Network;Granger Causality;Decision Support System;Industry 4.0;Big Data Analytics","Decision support systems;Accuracy;Big Data;Predictive models;Graph neural networks;Real-time systems;Maintenance;Fourth Industrial Revolution;Sensors;Predictive maintenance","","","","13","IEEE","19 Jan 2026","28-30 Nov. 2025","28-30 Nov. 2025","IEEE","IEEE Conferences"
"Information management and decision support in critical infrastructure emergencies at the local level","C. J. Romanowski; S. Mishra; R. K. Raj; T. Howles; J. Schneider","Rochester Institute of Technology, Rochester, New York, USA; Rochester Institute of Technology, Rochester, New York, USA; Rochester Institute of Technology, Rochester, New York, USA; Rochester Institute of Technology, Rochester, New York, USA; Rochester Institute of Technology, Rochester, New York, USA",2013 IEEE International Conference on Technologies for Homeland Security (HST),"2 Jan 2014","2013","","","113","118","In a critical infrastructure disaster incident, emergency managers are often compelled to make time-critical decisions based on incomplete information streaming in at disparate times from multiple data sources. As the incident progresses, the ability to predict where additional resources will be needed is crucial to both response and recovery. Decision making and prediction in this context requires combining (fusing) incoming data streams; presenting relevant information from these streams in a form appropriate for each user; and using data from similar historical events to predict resource needs and incident evolution. This paper discusses the role of data fusion, data integration, and data mining in decision making for municipal or regional emergency managers. It also explores the implementation of web-based decision support tools. Finally, the paper makes recommendations for improving information management and streamlining decision support.","","978-1-4799-1535-4","10.1109/THS.2013.6698985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698985","critical infrastructure protection;emergency operations;data fusion;decision support;data mining","Data integration;Fires;Real-time systems;Decision making;Databases;Data mining;Information management","","5","","15","IEEE","2 Jan 2014","12-14 Nov. 2013","12-14 Nov. 2013","IEEE","IEEE Conferences"
"Digital Twin-Enabled Urban Management: Multi-Modal Data Fusion for Real-Time City Simulation and Prediction","R. Praveen; N. S. Boob; M. MuhsnHasan; S. Bansal; L. Kansal; B. Rajalakshmi","Utilities America, LTIMindtree Limited, Houston, Texas, USA; Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Chennai, Tamilnadu, India; Department of Computers Techniques Engineering, College of Technical Engineering, The Islamic University, Najaf, Iraq; Department of Electronics and Communication Engineering, GLA University, Mathura, India; Lovely Professional University, Phagwara, India; Department of Computer Science Engineering, New Horizon College of Engineering, Bangalore, India",2025 International Conference on Computing and Communications (COMPUTINGCON),"20 Feb 2026","2025","","","1","7","The growing complexity of modern urban environments demands advanced solutions for dynamic monitoring, simulation, and management. Digital Twin (DT) technology, when coupled with multi-modal data fusion, presents a transformative approach to real-time urban simulation and predictive analytics. This paper explores the integration of heterogeneous data sources-such as IoT sensor feeds, satellite imagery, social media streams, and traffic logsinto a unified digital twin framework for smart city governance. The proposed methodology employs machine learning algorithms and AI-driven fusion techniques to synchronize virtual representations with real-world conditions in near real-time. By enabling accurate city-scale modeling and forecasting, the framework supports informed decision-making in areas such as traffic control, environmental monitoring, public safety, and infrastructure maintenance. Experimental results from a pilot implementation demonstrate improvements in urban resilience, response time, and resource optimization. This study contributes to the advancement of intelligent urban systems by offering a scalable and adaptive model that enhances city situational awareness and operational efficiency through digital twin-enabled simulation.","","979-8-3315-2253-7","10.1109/COMPUTINGCON64838.2025.11376962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11376962","Digital Twin;Smart City;Multi-Modal Data Fusion;Real-Time Simulation;Urban Prediction;AI-Enabled Governance","Accuracy;Smart cities;Social networking (online);Data integration;Predictive models;Real-time systems;Digital twins;Satellite images;Synchronization;Optimization","","","","13","IEEE","20 Feb 2026","1-3 Sept. 2025","1-3 Sept. 2025","IEEE","IEEE Conferences"
"Immersive Financial Data Visualization Using Augmented Reality Smart Glasses: A Framework for Real-Time Investment Decision Support","S. Meganathan","The University of Texas at Austin, Austin, TX, USA",2025 2nd International Conference on Electronic Circuits and Signaling Technologies (ICECST),"30 Dec 2025","2025","","","940","946","This study introduces a modular and scalable system for real-time financial data visualisation utilising AR smart glasses for immersive and intuitive investment decision-making. In the proposed system architecture, a Data Integration Layer processes high-frequency financial streams using real-time preprocessing, a Spatial Visualisation Engine renders dynamic charts and heatmaps using optimised AR rendering, and an Interaction System allows gesture, voice, and eye-tracking-based control. The Unity3D-developed system prototype for Microsoft HoloLens and Nreal Air shows interactive 3D financial dashboards in actual space. Decision accuracy, cognitive burden, and user satisfaction are better than desktop-based interfaces in varied user tests. Biometric authentication and visual obfuscation protect privacy, while adaptation testing assures performance in different environments. The findings show that AR can improve financial data interpretation by improving clarity, engagement, and situational awareness in real time. AI-driven personalisation and financial institution implementation are future goals.","","979-8-3315-9481-7","10.1109/ICECST66106.2025.11307512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11307512","Augmented Reality;Financial Data Visualization;Smart Glasses;Real-Time Analytics;Investment Decision Support;Human-Computer Interaction;Biometric Authentication","Decision making;Data visualization;Prototypes;Data integration;Rendering (computer graphics);Real-time systems;Spatial databases;Investment;Smart glasses;Testing","","","","23","IEEE","30 Dec 2025","23-25 Oct. 2025","23-25 Oct. 2025","IEEE","IEEE Conferences"
"Fusing Information, Crowdsourcing and Mobility","V. Zadorozhny; M. Lewis","School of Information Sciences, University of Pittsburgh, Pittsburgh, PA, USA; School of Information Sciences, University of Pittsburgh, Pittsburgh, PA, USA",2014 IEEE 15th International Conference on Mobile Data Management,"9 Oct 2014","2014","2","","4","6","In this seminar we will consider how concepts of information fusion, crowdsourcing and mobility complement each other and accelerate novel advanced research directions in mobile data management. We will elaborate on each of those concepts and explore their synergy under a prominent scenario of situation assessment in multi-robot search and rescue missions.","2375-0324","978-1-4799-5705-7","10.1109/MDM.2014.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916865","","Crowdsourcing;Streaming media;Data integration;Robot kinematics;Mobile communication;Educational institutions","","","","14","IEEE","9 Oct 2014","14-18 July 2014","14-18 July 2014","IEEE","IEEE Conferences"
"Using heterogeneous multilevel swarms of UAVs and high-level data fusion to support situation management in surveillance scenarios","P. Bouvry; S. Chaumette; G. Danoy; G. Guerrini; G. Jurquet; A. Kuwertz; W. Muller; M. Rosalie; J. Sander","University of Luxembourg, SnT/FSTC-CSC, Luxembourg; Univ. Bordeaux, LaBRI, Talence, France; University of Luxembourg, SnT/FSTC-CSC, Luxembourg; Thales Airborne Systems, Pessac, France; Thales Airborne Systems, Pessac, France; Fraunhofer IOSB, Karlsruhe, Germany; Fraunhofer-Institut fur Optronik Systemtechnik und Bildauswertung, Karlsruhe, Baden-WÃ¼rttemberg, DE; University of Luxembourg, SnT/FSTC-CSC, Luxembourg; Fraunhofer IOSB, Karlsruhe, Germany",2016 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI),"13 Feb 2017","2016","","","424","429","The development and usage of Unmanned Aerial Vehicles (UAVs) quickly increased in the last decades, mainly for military purposes. This technology is also now of high interest in non-military contexts like logistics, environmental studies and different areas of civil protection. While the technology for operating a single UAV is rather mature, additional efforts are still necessary for using UAVs in fleets (or swarms). The Aid to SItuation Management based on MUltimodal, MUltiUAVs, MUltilevel acquisition Techniques (ASIMUT) project which is supported by the European Defence Agency (EDA) aims at investigating and demonstrating dedicated surveillance services based on fleets of UAVs. The aim is to enhance the situation awareness of an operator and to decrease his workload by providing support for the detection of threats based on multi-sensor multi-source data fusion. The operator is also supported by the combination of information delivered by the heterogeneous swarms of UAVs and by additional information extracted from intelligence databases. As a result, a distributed surveillance system increasing detection, high-level data fusion capabilities and UAV autonomy is proposed.","","978-1-4673-9708-7","10.1109/MFI.2016.7849525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849525","","Surveillance;Data integration;Cameras;Optical sensors;Optical imaging;Streaming media;Unmanned aerial vehicles","","25","","19","IEEE","13 Feb 2017","19-21 Sept. 2016","19-21 Sept. 2016","IEEE","IEEE Conferences"
"An Integrated UGV-UAV System for Real-Time Disaster Management: A Multi-Protocol Communication Framework","R. Hejazi; M. Iqbal; A. Ara; D. Jaber","College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia; College of Communications and Networks Engineering, Prince Sultan University, Riyadh, Saudi Arabia; College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia; College of Communications and Networks Engineering, Prince Sultan University, Riyadh, Saudi Arabia",2025 8th International Conference on Enterprise Systems (ES),"29 Aug 2025","2025","","","1","6","In response to the increasing frequency and severity of natural disasters, the need for efficient and reliable disaster management systems has become more critical than ever. This paper presents the design and implementation of an integrated disaster management framework that leverages Unmanned Ground Vehicles (UGVs) and Unmanned Aerial Vehicles (UAVs) for real-time environmental assessment and search operations. The proposed system employs a multi-protocol communication architecture to enhance data transmission reliability, utilizing the MQTT protocol for lightweight and efficient messaging and RTMP for live video streaming. Additionally, the system incorporates AI-driven face detection and recognition capabilities to improve personnel identification in disaster zones, achieving a mean Average Precision (mAP) of 45.63%. Experimental evaluations demonstrate the effectiveness of the proposed system in maintaining low-latency communication and high-accuracy AI-based recognition, underscoring its potential to enhance disaster response efficiency and decision-making. This research contributes to the advancement of resilient and intelligent disaster management solutions, paving the way for future improvements in autonomous search and rescue operations.","2572-6609","979-8-3315-8890-8","10.1109/ES64449.2025.11136250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11136250","Disaster Management;Unmanned Ground Vehicles (UGVs);Unmanned Aerial Vehicles (UAVs);Real-time Video Streaming;MQTT Protocol;RTMP Protocol;Face Detection and Recognition;Communication Protocols;IoT (Internet of Things);Flask Web Server;MongoDB;Nginx;Real-time Data Communication","Protocols;Disasters;Face recognition;Disaster management;Real-time systems;Land vehicles;Reliability;Internet of Things;Face detection;Data communication","","","","18","IEEE","29 Aug 2025","12-13 April 2025","12-13 April 2025","IEEE","IEEE Conferences"
"SIMACOP: Small Units Management C4ISR System","M. Esteve; I. Perez-Llopis; L. E. Hernandez-Blanco; C. E. Palau; F. Carvajal","Communications Department. ETSIT, Universidad Politécnica de Valencia, Valencia, Spain; Communications Department. ETSIT, Universidad Politécnica de Valencia, Valencia, Spain; Communications Department. ETSIT, Universidad Politécnica de Valencia, Valencia, Spain; Communications Department. ETSIT, Universidad Politécnica de Valencia, Valencia, Spain; Communications Department. ETSIT, Universidad Politécnica de Valencia, Valencia, Spain",2007 IEEE International Conference on Multimedia and Expo,"8 Aug 2007","2007","","","1163","1166","Current military command and control information systems aim is to elaborate the common operational picture (COP) focused on the higher hierarchical levels, from battalion level and upwards. However, in majority of present conflicts, including peacekeeping missions, many operations are carried by small units like platoons and downwards. It would be extremely useful a command and control tool which: (i) allows obtaining the COP at platoon and squad level; (ii) facilitates command and control decisions from different tactical locations; (iii) allows shared awareness based self-synchronization among platoons and (iv) acquires individualized data from troop units, particularly video flows and geolocation. In this paper, a practical research in this field is described based on the development of a command, control, computers, communications, intelligence, surveillance and reconaissance (C4ISR) multimedia system designed to proof the most advanced concepts in current C2IS (command and control information systems) development.","1945-788X","1-4244-1016-9","10.1109/ICME.2007.4284862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4284862","","Command and control systems;Streaming media;Wireless sensor networks;Multimedia systems;Biosensors;Fires;Management information systems;Sensor fusion;Global Positioning System;Cameras","","10","","9","IEEE","8 Aug 2007","2-5 July 2007","2-5 July 2007","IEEE","IEEE Conferences"
"Distributed Mission and Data Management System for Airborne Maritime Surveillance","G. R. Gandhi; R. Rajesh; C. Jayamohan; R. Sharma","Center for Airborne Systems, Defence R & D Organisation, Bengaluru, India; Center for Airborne Systems, Defence R & D Organisation, Bengaluru, India; Center for Airborne Systems, Defence R & D Organisation, Bengaluru, India; Center for Airborne Systems, Defence R & D Organisation, Bengaluru, India","2021 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","7 Dec 2021","2021","","","1","5","Mission and Data Management System (MDMS) is the brain of any airborne surveillance system which includes mission planning and loading, provision of loading mission parameter data, command & control of different sensors and sub sensors, state management, periodic health monitoring, supply of discrete timing data, streaming of navigation data, integration of surveillance data from sensors like Radar, Identification Friend or Foe (IFF) and Automatic Identification System (AIS), providing decision aids, mission data, video, audio recording and retrieval. This paper provides a framework for integrating multitude of sensors for maritime surveillance using Mission Management System (MMS) and Multifunctional Tactical Console (MTC), which are constituent components of MDMS, in an integration test bed. The tight integration of various sensors to MMS will enhance the capability of the sensors as an integrated suite and the output from the various sensors are fused for enhancing the situational awareness. Such an architecture will enable mission ready integrated command and control of various sensors with high availability.","2766-2101","978-1-6654-2849-1","10.1109/CONECCT52877.2021.9622525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622525","Maritime Surveillance;Distributed System;Service Oriented Architecture;Mission Management System (MMS);Multifunctional Tactical Console (MTC)","Surveillance;Scalability;Loading;Distributed databases;Computer architecture;Sensor fusion;Streaming media","","1","","10","IEEE","7 Dec 2021","9-11 July 2021","9-11 July 2021","IEEE","IEEE Conferences"
"Manipulating Business Intelligence Tools for Actionable Big Data Insights: A Framework for Enterprise Decision-Making","M. Al Khaldy; F. Aburub; M. Alauthman","Department of Business Intellgence and Data Analytics, University of Petra, Amman, Jordan; Department of Business Intellgence and Data Analytics, University of Petra, Amman, Jordan; Department of Information Security, University of Petra, Amman, Jordan","2025 International Conference on Networking, Sensing and Control (ICNSC)","10 Feb 2026","2025","","","498","502","Organizations are increasingly inundated with large and diverse data streams that hold substantial potential for optimizing decision-making processes. Yet many enterprises fail to convert these expanding data assets into clear strategic advantages. This paper proposes a comprehensive framework for integrating modern business intelligence (BI) tools within big data ecosystems, aiming to streamline the transformation of massive, heterogeneous datasets into actionable insights. The methodology features a layered architecture encompassing data acquisition, preparation, analysis, visualization, and the deployment of insights across enterprise hierarchies. Three case studies in distinct industry sectors show that framework adoption can reduce decision latency by an average of 47%, improve analytical accuracy by 23%, and increase crossfunctional data utilization by 65%. Additionally, the framework offers adaptive mechanisms to accommodate evolving data sources and shifting enterprise objectives. These findings augment theoretical perspectives on BI deployment and provide actionable guidelines for organizations seeking to elevate the strategic value of big data.","2766-8665","979-8-3315-9749-8","10.1109/ICNSC66229.2025.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11372904","Business Intelligence;Big Data Analytics;Decision Support Framework;Predictive Modelling;Real-Time Analytics;Cloud Computing","Industries;Soft sensors;Decision making;Organizations;Big Data;Predictive models;Real-time systems;Business intelligence;Floods;Guidelines","","","","15","IEEE","10 Feb 2026","1-3 Oct. 2025","1-3 Oct. 2025","IEEE","IEEE Conferences"
"Integrated Real-Time Monitoring for Soldier Health and Operational Efficiency: A Multi-Metric Approach","S. Umamaheswari; L. G; B. Shuriya","Dept of Electronics and Communication Engineering, Kumaraguru College of Technology, Coimbatore, India; Department of Electronics and Communication Engineering, Velalar College of Engineering and Technology, Thindal, India; Department of Computer Science Engineering, PPG Institute of Technology, Coimbatore, India","2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)","2 Jun 2025","2025","","","1","6","Protection of soldiers' lives and war readiness in risk-prone areas demands continuous monitoring of health, location, and surroundings. In this paper, a hybrid soldier location tracking, health monitoring, and live video streaming system using smart sensors, RF technology, and ESP32-CAM module is presented. Real-time body temperature, gun detection, oxygen saturation, and heart rate monitoring are based on an ATmega2560 microcontroller and MAX30100 pulse oximeter. Command stations are fed in real-time with secure RF transmit. Real-time video and GPS location are offered to provide situational awareness in order to support timely decisions. The system supports low-latency, high-reliability deployment in hostile ground. Testing is structured to validate robust operation, precise diagnostics, and power conservancy. AI-driven analytics and sophisticated sensor fusion will be the focus of future development for higher battlefield resilience.","","979-8-3315-2543-9","10.1109/ICAECA63854.2025.11012403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11012403","GPS;heart rate;temperature;soldier","Heart rate;Temperature sensors;Radio frequency;Streaming media;Real-time systems;Telecommunication computing;Systems support;Monitoring;Global Positioning System;Testing","","2","","17","IEEE","2 Jun 2025","4-5 April 2025","4-5 April 2025","IEEE","IEEE Conferences"
"Advancing Digital Economy and Entrepreneurship: Multimodal Data Integration and Frontier-Based Benchmarking for Manufacturing Excellence","B. S. Jayaprakasam; N. R. Dyavani; C. Ubagaram; V. Garikipati; R. R. Mandala; K. M","Cognizant Technology Solutions, Texas, USA; Uber Technologies Inc, California, USA; Tata Consultancy Services, Ohio, USA; Innosoft, Sacramento, CA, USA; Tekzone Systems Inc, California, USA; Department of Information Technology, Nandha college of Technology, Erode, India","2025 2nd International Conference on Software, Systems and Information Technology (SSITCON)","22 Jan 2026","2025","","","1","7","The Digital Economy (DE) and entrepreneurship drive the change in manufacturing through productivity, sustainability, and innovation. To enhance the performance of manufacturing, this work suggests a new design of frontierbased benchmarking and multimodal data fusion. Statistical and machine learning provides patterns in multimodal textual, visual, and numerical data that are disgorged. Frontier benchmarking assists an organization to identify its shortfalls since it compares its performance to the industry bests. The result of the strategies was a 28 percent efficiency and a 35 percent innovation in the industrial units that implemented such strategies. It is guaranteed that such process will yield a DE in which targeted production creates digital entrepreneurial and competitiveness. This is an effective integrated production system that will bring about sustainable industrial development since it is a good decision support system. Taken together, the research demonstrates a scalable and meaningful path in the digital age to manufacturing excellence.","","979-8-3315-2623-8","10.1109/SSITCON66133.2025.11341970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11341970","digital economy;entrepreneurship;multimodal data;benchmarking;manufacturing;innovation;sustainability;efficiency;analytics;transformation","Productivity;Technological innovation;Visualization;Digital economy;Entrepreneurship;Data integration;Benchmark testing;Software systems;Manufacturing;Sustainable development","","","","26","IEEE","22 Jan 2026","17-18 Oct. 2025","17-18 Oct. 2025","IEEE","IEEE Conferences"
"Service oriented architecture for the integration of clinical and physiological data for real-time event stream processing","R. Kamaleswaran; C. McGregor; J. Percival","Faculty of Health Sciences, University of Ontario Institute of Technology (UOIT), Oshawa, ONT, Canada; Faculty of Health Sciences, Faculty of Business and Information Technology, University of Ontario Institute of Technology (UOIT), Oshawa, ONT, Canada; Faculty of Business and Information Technology, University of Ontario Institute of Technology (UOIT), Oshawa, ONT, Canada",2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,"13 Nov 2009","2009","","","1667","1670","This paper proposes a framework for the integration of physiological and clinical health data within a service-oriented architecture framework. This integration will subsequently be used in real-time event stream processing in intelligent patient monitoring devices. Service-oriented architecture offers a unique method of integrating health data as information is collected from multiple medical devices that lack any substantial means of standardization. Employing various services to facilitate the transmission and integration of these data will result in significant improvement in both efficacy and analytical velocity of intelligent patient monitoring systems. We demonstrate this approach within the neonatal intensive care setting.","1558-4615","978-1-4244-3296-7","10.1109/IEMBS.2009.5333884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5333884","","Service oriented architecture;Biomedical monitoring;Pediatrics;Computational Intelligence Society;Patient monitoring;Intelligent systems;Psychology;Clinical diagnosis;Information technology;Computer architecture","Electronic Health Records;Intensive Care Units, Neonatal;Systems Integration","4","","16","IEEE","13 Nov 2009","3-6 Sept. 2009","3-6 Sept. 2009","IEEE","IEEE Conferences"
"The ICARUS project - Command, Control and Intelligence (C2I)","S. Govindaraj; K. Chintamani; J. Gancet; P. Letier; B. van Lierde; Y. Nevatia; G. De Cubber; D. Serrano; M. Esbri Palomares; J. Bedkowski; C. Armbrust; J. Sanchez; A. Coelho; I. Orbe","Space Applications Services, Zaventem, Belgium; Space Applications Services, Zaventem, Belgium; Space Applications Services, Zaventem, Belgium; Space Applications Services, Zaventem, Belgium; Space Applications Services, Zaventem, Belgium; Space Applications Services, Zaventem, Belgium; RMA, Brussels, Belgium; ASCAMM, Barcelona, Spain; Atos, Madrid, Spain; IMM, Warsaw, Poland; Technische Universitat Kaiserslautem, Germany; Integrasys, Madrid, Spain; University of Porto, Porto, Portugal; Estudios GIS, Minano, Spain","2013 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)","23 Jan 2014","2013","","","1","4","This paper describes the features and concepts behind the Command, Control and Intelligence (C2I) system under development in the ICARUS project, which aims at improving crisis management with the use of unmanned search and rescue robotic appliances embedded and integrated into existing infrastructures. A beneficial C2I system should assist the search and rescue process by enhancing first responder situational awareness, decision making and crisis handling by designing intuitive user interfaces that convey detailed and extensive information about the crisis and its evolution. The different components of C2I, their architectural and functional aspects are described along with the robot platform used for development and field testing.","2374-3247","978-1-4799-0880-6","10.1109/SSRR.2013.6719356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719356","","Robot kinematics;Robot sensing systems;Exoskeletons;Three-dimensional displays","","23","","11","IEEE","23 Jan 2014","21-26 Oct. 2013","21-26 Oct. 2013","IEEE","IEEE Conferences"
"Leveraging Artificial Intelligence and Big Data in Healthcare Provider Systems: Enhancing Patient Care and Operational Efficiency","L. P. Gorrepati; R. Kalapala; G. S. Sargam","Software Developer, Camelot Integrated Solutions Inc, Richmond, Virginia, United States of America; AWS Certified Solution Architect, Senior cloud solutions architect, Red Hat Certified Engineer (RHCE), State Compensation Insurance Fund, Pleasanton, CA, USA; Sr. Lead Architect State Compensation Insurance Fund, Pleasanton, CA, USA","2025 Third International Conference on Cyber Physical Systems, Power Electronics and Electric Vehicles (ICPEEV)","22 Dec 2025","2025","","","1","6","The convergence of large-scale data analytics and advanced computational techniques is remaking contemporary healthcare provider systems by facilitating evidence-based clinical and business decision-making. Conventional healthcare infrastructures tend to struggle with fragmented information systems, delayed diagnostics, and ineffective utilization of resources, leading to higher costs and suboptimal patient outcomes. This research introduces a cohesive data-driven healthcare platform that leverages heterogeneous healthcare data streams such as electronic health records (EHRs), imaging, biometric sensors, and administrative workflows to improve diagnostic accuracy and optimize hospital workflows. The system proposed utilizes statistical learning models for early disease detection, risk stratification, and real-time patient monitoring, while distributed big data platforms like Apache Spark provide scalable processing, anomaly detection, and predictive analytics. Experimental validation with retrospective hospital records and simulated sensor data showed a 25.8 % gain in diagnostic accuracy, a reduction in average emergency department wait times by 18.2 %, and a 31.4 % boost in bed occupancy efficiency over current systems. Predictive warning for clinical deterioration attained an accuracy of 0.87, recall of 0.91, and a general classification accuracy of 93.2 %, further emphasizing the system's capability to provide actionable insights in high-stakes settings. These results validate that combining computational intelligence methods and big data technologies has the capability to substantially improve not only the quality of patient treatment but also healthcare operations efficiency, providing a scalable and adaptable solution for next-generation provider systems.","","979-8-3315-8606-5","10.1109/ICPEEV67897.2025.11291497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11291497","Artificial Intelligence in Healthcare;Big Data Analytics;Electronic Health Records (EHR);Clinical Decision Support Systems;Predictive Healthcare;Hospital Workflow Optimization;Patient Monitoring;Medical Data Integration;Real-Time Analytics;Healthcare Operational Efficiency;Machine Learning in Medicine;Digital Health Infrastructure","Patient monitoring;Accuracy;Hospitals;Medical services;Big Data;Real-time systems;Data models;Planning;Forecasting;Electronic medical records","","","","12","IEEE","22 Dec 2025","25-27 Sept. 2025","25-27 Sept. 2025","IEEE","IEEE Conferences"
"SATURN (Situational awareness tool for urban responder networks)","H. Zwahlen; A. Yahr; D. Berven; M. T. Chan; M. Merfeld; C. Russ; J. Thornton; J. Mapar","M. I. T. Lincoln Laboratory, Lexington, MA, USA; M. I. T. Lincoln Laboratory, Lexington, MA, USA; M. I. T. Lincoln Laboratory, Lexington, MA, USA; M. I. T. Lincoln Laboratory, Lexington, MA, USA; M. I. T. Lincoln Laboratory, Lexington, MA, USA; M. I. T. Lincoln Laboratory, Lexington, MA, USA; M. I. T. Lincoln Laboratory, Lexington, MA, USA; Science and Technology Directorate, Department of Homeland Security, Washington DC, DC, USA",2012 15th International Conference on Information Fusion,"30 Aug 2012","2012","","","2428","2435","SATURN is a prototype system for the intelligent incorporation of output from surveillance camera networks into an enhanced situational awareness display. It is a web-based, service oriented, open standards platform designed to be accessible to any user with a common browser. SATURN fuses information from an array of sensors including real-time feeds from video cameras. The sensor data is displayed within an intuitive map-based view and is coupled with video analytics algorithms, a chat capability, and collaborative tools for annotation. A principal component of the system is the ability to conduct attribute-based searches for people within live video feeds and for vehicles within archived camera footage. This realtime cueing to events involving people or vehicles of interest provides a potential reduction in manpower and shortened response timeline. SATURN is applicable to a broad set of law enforcement, security, and counterterrorism missions typically addressed by urban responders.","","978-0-9824438-5-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6290598","video analytics;sensor fusion;video;urban responders","Vehicles;Saturn;Image color analysis;Sensors;Cameras;Streaming media;Surveillance","","","","11","","30 Aug 2012","9-12 July 2012","9-12 July 2012","IEEE","IEEE Conferences"
"Technology Selection for Development of Intellectual Road Maintenance Platform","L. Deksne; J. Vempers; J. Kampars","Dept. of Management Information Technolology, Riga Technical University, Riga, Latvia; SIA ZZ Dats, Riga, Latvia; Dept. of Management Information Technolology, Riga Technical University, Riga, Latvia",2021 62nd International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS),"23 Nov 2021","2021","","","1","9","Advanced information systems such as Intellectual road maintenance systems consist of multiple components supporting process integration, big data processing and other functions. A comprehensive literature review is performed to summarize the technologies used to provide similar functions as designed in the winter road maintenance data ecosystem in previous study. Technology assessment for the planned winter road maintenance system using the AHP method is performed. Based on rating made by experts, the most appropriate technologies for platform integration, big data processing, data storage, data streaming and service orchestration are identified.","","978-1-6654-0615-4","10.1109/ITMS52826.2021.9615263","European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615263","AHP;big data;integration;intellectual road maintenance;technology selection","Roads;Bibliographies;Ecosystems;Memory;Analytic hierarchy process;Maintenance engineering;Big Data","","1","","31","IEEE","23 Nov 2021","14-15 Oct. 2021","14-15 Oct. 2021","IEEE","IEEE Conferences"
"On hierarchical multimedia information retrieval","J. You; T. Dillon; J. Liu; E. Pissaloux","School of Computing & Information Technology, Griffith University, QLD, Australia; Hong Kong Polytechnic University, Hong Kong, China; Hong Kong Polytechnic University, Hong Kong, China; Laboratoire de Perception, Université de Rouen, France",Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205),"7 Aug 2002","2001","2","","729","732 vol.2","This paper presents a data warehousing approach to hierarchical multimedia information retrieval. To tackle the key issues such as multimedia data representation, storage, integration, indexing, similarity measures, searching methods and query processing, the proposed algorithms allow one: (1) to extend the concepts of conventional data warehouse and multimedia databases to multimedia data warehouses for effective data representation and storage; (2) to develop a multimedia starflake schema to integrate multiple data streams for hierarchical data representation and indexing; (3) to apply data aggregation techniques for decision support to speed up query processing and searching. In addition, the new system architecture is compared with a conventional database structure. Furthermore, a case study is presented to illustrate the development of a content-based image retrieval system for cyclone pattern recognition. We conclude that the proposed approach can be applied to other multimedia systems with effective data storage, retrieval and integration.","","0-7803-6725-1","10.1109/ICIP.2001.958597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=958597","","Information retrieval;Multimedia databases;Streaming media;Indexing;Query processing;Data warehouses;Warehousing;Velocity measurement;Image databases;Image retrieval","","2","1","8","IEEE","7 Aug 2002","7-10 Oct. 2001","7-10 Oct. 2001","IEEE","IEEE Conferences"
"A Survey on Event Detection Models from Geo Tagged Twitter Stream","N. V; S. Jaganathan","Department of Information Technology, Sri Sairam Engineering College, Chennai, Tamilnadu, India; Department of Computer Science & Engineering, Sri Sivasubramaniya Nadar College of Engineering, Chennai, Tamilnadu, India",2021 4th International Conference on Computing and Communications Technologies (ICCCT),"18 Feb 2022","2021","","","533","537","GeoStreams are spatio temporal continuous data streams which has the spatial information. Spatial information in simple terms is the location details of any surface on the earth. These location details are basically specified by its latitude and longitude values and also have more attributes than location specific information which may be a non-spatial data attribute too. Spatio-temporal documents which arrives continuously as data streams offers basic required information about the various local events. This Paper provides an overview of the various models to detect the events and to discover the trending topics using the geo tagged tweet streams with their implementation, comparison of various parameters and the challenges in the existing models.","","978-1-6654-1447-0","10.1109/ICCCT53315.2021.9711759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711759","Geo Streams;Spatio-temporal;Geo spatial text mining;Event detection;Twitter Stream","Earth;Decision support systems;Social networking (online);Event detection;Computational modeling;Blogs;Traffic control","","","","16","IEEE","18 Feb 2022","16-17 Dec. 2021","16-17 Dec. 2021","IEEE","IEEE Conferences"
"Acceptance of automatic situation assessment in surveillance systems","Y. Fischer; J. Beyerer","Vision and Fusion Laboratory, Karlsruhe Institute of Technology, Karlsruhe, Germany; System Technologies and Image Exploitation (IOSB), Fraunhofer Institute of Optronics, Karlsruhe, Germany",2012 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support,"23 Apr 2012","2012","","","324","331","In today's surveillance systems, there is a need for enhancing the situation awareness of an operator. Supporting the situation assessment process can be done by extending the system with a module for automatic interpretation of the observed environment. In this article we introduce a consistent terminology for the domain of intelligent surveillance systems. We clarify the separation of the real world and the world model, which is used for the internal representation in the system. For the definition of an automatic situation assessment module, we make use of an existing conceptual framework. We will further introduce a concept for an internal representation of situations of interest and show how the existence of such situations can be inferred from sensor observations. Based on these considerations, an automatic situation assessment module for a maritime surveillance system was developed. The module was evaluated with a small user group and the results show that such an automatic support reduces the workload of the user and is highly accepted.","2379-1675","978-1-4673-0345-3","10.1109/CogSIMA.2012.6188404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188404","","Surveillance;Bayesian methods;Hidden Markov models;Data models;Streaming media;Joints;Character recognition","","5","","13","IEEE","23 Apr 2012","6-8 March 2012","6-8 March 2012","IEEE","IEEE Conferences"
"Complex Event Processing for object tracking and intrusion detection in Wireless Sensor Networks","R. Bhargavi; V. Vaidehi; P. T. V. Bhuvaneswari; P. Balamuralidhar; M. G. Chandra","Department of IT, Anna Univerisity, Chennai, India; Department of IT, MIT, Anna University, Chennai, India; Department of Electronics, Anna University, Chennai, India; TCS Innovation Lab, Banglore, India; TCS Innovation Lab, Banglore, India",2010 11th International Conference on Control Automation Robotics & Vision,"4 Feb 2011","2010","","","848","853","Complex Event Processing (CEP) has received wider acceptability due to its systematic and multilevel architecture driven concept approach. CEP is an emerging technology in the field of data processing and identifying patterns of interest from multiple streams of events. High levels of integrated self learning applications can be developed. CEP is used in development of applications which have to deal with voluminous streams of incoming data with the task of finding meaningful events or patterns of events, and respond to the events of interest in real time. In this paper a CEP based application for object detection tracking in a Wireless Sensor Network (WSN) environment is proposed. Also the detection of an intruder using semantic query processing is proposed. ESPER, an open source Complex Event Processing engine is used to develop the application.","","978-1-4244-7815-6","10.1109/ICARCV.2010.5707288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5707288","CEP;Wireless Sensor Network;Semantic Query;Intrusion;ESPER","Radiofrequency identification;Engines;Wireless sensor networks;Servers;Cameras;Real time systems;Streaming media","","8","","9","IEEE","4 Feb 2011","7-10 Dec. 2010","7-10 Dec. 2010","IEEE","IEEE Conferences"
"Designing a fusion of visible and infra-red camera streams for remote tower operations","A. Papenfuss; F. Reuschling; J. Jakobi; T. Rambau; E. Michaelsen; N. Scherer-Negenborn","Institut für Flugführung, Lilienthalplatz 7, Braunschweig, Germany; Institut für Flugführung, Lilienthalplatz 7, Braunschweig, Germany; Institut für Flugführung, Lilienthalplatz 7, Braunschweig, Germany; Institut für Flugführung, Lilienthalplatz 7, Braunschweig, Germany; Department Object Recognition, Fraunhofer-IOSB, Gutleuthausstrasse 1, Ettlingen, Germany; Department Object Recognition, Fraunhofer-IOSB, Gutleuthausstrasse 1, Ettlingen, Germany",2020 IEEE Aerospace Conference,"21 Aug 2020","2020","","","1","11","The research project INVIDEON evaluated requirements, technical solutions and the benefit of fusing visible (VIS) and infra-red (IR) spectrum camera streams into a single panorama video stream. In this paper, the design process for developing a usable and accepted fusion is described. As both sensors have strengthens and weaknesses, INVIDEON proposes a fused panorama optimized out of both sensors to be presented to the ATC officer (ATCO). This paper gives an overview of the project and reports results of acceptance and usability of the INVIDEON solution. The process of supporting the definition of requirements by means of rapid prototyping and taking a user-centered approach is described. Main findings of requirements for fusing VIS and IR camera data for remote tower operations are highlighted and set into context with the air traffic controller's tasks. A specific fusion approach was developed within the project and evaluated by means of recorded IR and VIS data. For evaluation, a testbed was set up at a regional airport and data representing different visibility conditions were selected out of 70 days data recordings. Five air traffic controllers participated in the final evaluation. Subjective data on perceived usability, situational awareness and trust in automation was assessed. Furthermore, qualitative data on HMI design and optimization potential from debriefings and comments was collected and clustered.","1095-323X","978-1-7281-2734-7","10.1109/AERO47225.2020.9172645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172645","","Poles and towers;Sensor fusion;Streaming media;Cameras;Rapid prototyping;Sensors;Recording;Usability;Streams;Optimization","","2","","22","IEEE","21 Aug 2020","7-14 March 2020","7-14 March 2020","IEEE","IEEE Conferences"
"Network System of Systems Manager","J. Dobie; R. Holder","L3Harris Technologies, Inc., Melbourn, Florida; L3Harris Technologies, Inc., Melbourn, Florida","2024 Integrated Communications, Navigation and Surveillance Conference (ICNS)","11 Jun 2024","2024","","","1","14","For several decades, the L3Harris Mission Networks organization has perfected the design, deployment, operations, and management of enterprise-level networks for safety-critical missions using a managed service framework. L3Harris has successfully constructed geographically large and technologically diverse Local Area Network (LAN)/Wide Area Network (WAN) solutions for State and Federal customers by selecting, optimizing, and integrating Commercial off the Shelf (COTS) products and services into an integrated or homogeneous solution meeting exacting performance requirements. These purpose-built network solutions ensure performance and resilience through tailored provisioning and the configuration of highly reliable (e.g., through adaptive redundancy) architectures, diverse service connections and equipment, ubiquitous bandwidth allocation and an unparalleled telecommunication provider governance by a centralized operational support system.Over this same period, there have been key advances in the networking industry which signal the need to evolve beyond our centralized managed services model. These advances include the rapid industry transition from a dedicated Time-division Multiple Access (TDMA)-based solution to multifunction IP-based networks with Quality of Service (QoS) support, the growing deployment of Software Defined Everything (SDE), AI-assisted advanced modeling and simulation, near-universal adoption of cloud-based Infrastructure as a Service (IaaS), design patterns and deployment solutions with the increasing presence of wireless services such as 5G (both fixed and mobile), Long Term Evolution (LTE), Geostationary Orbit (GEO), Low Earth Orbit (LEO) and Medium Earth Orbit (MEO).Within these evolving technologies, network management solutions can move from centralized to federated architectures with the promise of effortless scalability, dynamic adaptability, and seamless collaboration. A federated hierarchical architecture offers organizations a blueprint allowing coordinated management, interoperability of data, resources and processes across heterogeneous systems, locations, and organizational boundaries. To take maximum advantage of such an architecture, we believe there is an opportunity to streamline and optimize network designs through an implementation of a Network System of Systems Manager (NSoSM). The NSoSM is a centralized system used to ingest network telemetry data across one or more networks, process data via AI/ML algorithms, to make informed decisions to improve the delivery of prioritized customer data and improve the usability of mission critical customer applications.The federated architecture construct, consisting of loosely coupled constituent databases for sharing and data exchange, has evolved beyond its origin and the set of standards facilitating its integration. The use of an Open Platform Communications (OPC) Unified Architecture (UA) [01], the International Society of Automation (ISA)-95 model [02], the Manufacturing Enterprise Solutions Association (MESA) Business to Manufacturing Markup Language (B2MML) [03], and message exchange models have improved integration and scalability, resulting in wide adoption in manufacturing environments.The adoption of a federated architecture in enterprise-level, mission critical networks present several challenges. The solution to these challenges can be addressed with three primary capabilities: 1) Integrated Situational Awareness; 2) Integration Gateway, and 3) AI Augmentation and Automated Orchestration, carrying independent value and, when fused together, achieve a NSoSM which autonomously supports a federated ecosystem:Integrated Situational Awareness. Adapting to the increasing volume of technological solutions, the need for highly customized service integrator solutions evolves from a centralized integration of disparate platforms to an enterprise orchestration of integrated System-of-Systems (SoS). This is achieved through creating a hyperconverged monitoring and data collection capability of system logs, synthetic network probes, streaming telemetry and real-time channel performance metrics collected by Fault Management Systems, Network Performance Monitoring and Diagnostics Systems, and Application Performance Monitoring systems. Integrating these COTS solutions, together with Situational Awareness, offer end-to-end (E2E) planning, fault analysis, and command and control (C2) of regulated network environments.Integration Gateway. Of critical importance in the NSoSM model is the need to create a homogeneous, clear user experience across a heterogeneous collection of federated systems. This involves the definition and harmonization of the exchanged data and the technologies used for sending and receiving the exchanged data with intelligent markers to incorporate customer and mission-defined, protections. This involves both the harmonization of data from dissimilar heterogeneous end-systems to a common operating picture and to convert it back to native system languages when suggested configurations are being recommended to optimize customer service performance.AI Augmentation and Automated Orchestration (AIA2O). This capability is comprised of three primary and sequential functions: Datasets, Frameworks and Procedure Validation for AIOps and Command and Control (C2) Orchestration. Data from the Integration Gateway is interpreted into logical threads where Artificial Intelligence (AI)/Machine Learning (ML) algorithms and models apply insight to optimizations required for an improved User Experience (UX), via autonomous orchestration, reducing and sometimes eliminating the human-in-the-loop delay not only reducing the decision chain but also reducing human error. Insights and procedures are validated in a digital twin representation followed by the orchestration of optimizations in a production environment.The Federal Aviation Administration’s publication of Initial Concept of Operations for an Info-Centric National Airspace System asserts that ""The integrated information environment, providing data services including data integration from various sources, allows federated actors to reconcile, contextualize, and share relevant information’’. Additionally, value is perceived by enabling ""multiple entities to provide a federated set of xTM services for flights operating within the same airspace"". Implementing and operating NSoSM capabilities, comprised of an integrated gateway, integrated situational awareness, and AI augmentation and automated orchestration are at the core of where mission critical, enterprise-level networks and SDE are evolving for State, Federal, and Department of Defense (DoD) organizations. L3Harris’ approach to the design of a NSoSM solution provides a limitless overlay adapting to emerging and evolving technologies, meanwhile reduce operating expenses (OpEx) via an ever-growing AI community, enabling independent systems to collectively deliver value that cannot be achieved independently.","2155-4951","979-8-3503-9309-5","10.1109/ICNS60906.2024.10550591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10550591","Network Automation;Machine Learning;Autonomous Networking;Network Data Analytics;Situational Awareness","Command and control systems;Adaptive systems;Mission critical systems;Computer architecture;Organizations;Logic gates;User experience","","2","","12","IEEE","11 Jun 2024","23-25 April 2024","23-25 April 2024","IEEE","IEEE Conferences"
"Leveraging Scalable Cloud Infrastructure for Autonomous Driving Data Lakes and Real-Time Decision Making","J. Chen","Graduate School of Arts and Sciences, Columbia University, New York, United States",2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA),"1 Jul 2025","2025","","","1750","1753","Autonomous driving technology relies heavily on the effective management of vast datasets generated by various sensors and vehicle systems. As such, leveraging scalable cloud infrastructure becomes paramount for improving data handling and decision-making capabilities. In this paper, we introduce the Autonomous Driving Data Lakes (ADDL) framework, designed to streamline the storage, retrieval, and processing of extensive driving data in real-time. By utilizing cloud technology, ADDL ensures tight integration of data from diverse sources to enhance situational awareness for autonomous systems. Our architecture features robust data pipelines that support real-time analytics and machine learning applications, which are crucial for timely and accurate decision-making. Extensive experiments with large-scale datasets demonstrate how our approach significantly boosts processing efficiency, data accessibility, and decision-making reliability. The findings highlight advancements in autonomous driving technologies, addressing the challenges associated with data management and enhancing operational effectiveness in changing driving environments.","","979-8-3315-0976-7","10.1109/AIITA65135.2025.11048068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11048068","Cloud Infrastructure;Autonomous Driving;Decision Making","Decision making;Pipelines;Machine learning;Big Data applications;Real-time systems;Sensor systems;Telemetry;Reliability;Autonomous vehicles;Intelligent sensors","","","","18","IEEE","1 Jul 2025","28-30 March 2025","28-30 March 2025","IEEE","IEEE Conferences"
"A new framework for on-demand virtualization, repurposing and fusion of heterogeneous sensors","Y. Liu; D. Hill; A. Rodriguez; L. Marini; R. Kooper; J. Myers; Xiaowen Wu; B. Minsker","National Center of Supercomputing Applications, University of Illinois, Urbana-Champaign, Urbana, IL, USA; National Center of Supercomputing Applications, University of Illinois, Urbana-Champaign, Urbana, IL, USA; National Center of Supercomputing Applications, University of Illinois, Urbana-Champaign, Urbana, IL, USA; National Center of Supercomputing Applications, University of Illinois, Urbana-Champaign, Urbana, IL, USA; National Center of Supercomputing Applications, University of Illinois, Urbana-Champaign, Urbana, IL, USA; National Center of Supercomputing Applications, University of Illinois, Urbana-Champaign, Urbana, IL, USA; Department of Civil and Environmental Engineering, University of Illinois, Urbana-Champaign, Urbana, IL, USA; Department of Civil and Environmental Engineering, University of Illinois, Urbana-Champaign, Urbana, IL, USA",2009 International Symposium on Collaborative Technologies and Systems,"5 Jun 2009","2009","","","54","63","This paper describes our first step towards the realization of complex and large scale cross-organization virtual observatories by presenting a new semantically-enhanced ldquosensor network as a servicerdquo (SNaaS) framework, which can repurpose existing sensor networks as needed and aggregate and fuse heterogeneous sensors into new virtual sensors in near-real-time. The architecture of this system allows users to create virtual sensors in a Web 2.0 collaborative map interface. Components of the system are highlighted in the paper including a semantically enhanced streaming data toolkit, virtual sensor ontologies and management middleware. Case studies are presented which can allow users to create new virtual rain gages based on the NEXRAD (next generation weather radar) data stream with or without in-situ rain gages on demand in a Chicago urban watershed testbed. The resulting virtual sensor data streams then can be published in multiple formats including a SWE-compliant one so that external SWE-compliant users and applications can seamlessly query and integrate them.","","978-1-4244-4584-4","10.1109/CTS.2009.5067462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5067462","Sensor Web;Virtual Sensor;Ontology;Streaming Data Management;Data Fusion;Web 2.0","Sensor fusion;Sensor phenomena and characterization;Sensor systems;Rain;Large-scale systems;Observatories;Aggregates;Fuses;Service oriented architecture;Collaboration","","9","","51","IEEE","5 Jun 2009","18-22 May 2009","18-22 May 2009","IEEE","IEEE Conferences"
"Biomedical Big Data Analytics for Patient-Centric and Outcome-Driven Precision Health","M. D. Wang","Georgia Institute of Technology and Emory University, USA",2015 IEEE 39th Annual Computer Software and Applications Conference,"24 Sep 2015","2015","3","","1","2","Rapid advancements in biotechnologies such as -omic (genomics, proteomics, metabolomics, lipidomics etc.), next generation sequencing, bio-nanotechnologies, molecular imaging, and mobile sensors etc. accelerate the data explosion in biomedicine and health wellness. Multiple nations around the world have been seeking novel effective ways to make sense of ""big data"" for evidence-based, outcome-driven, and affordable 5P (Patient-centric, Predictive, Preventive, Personalized, and Precise) healthcare. My main research focus is on multi-modal and multi-scale (i.e. molecular, cellular, whole body, individual, and population) biomedical data analytics for discovery, development, and delivery, including translational bioinformatics in biomarker discovery for personalized care; imaging informatics in histopathology for clinical diagnosis decision support; bionanoinformatics for minimally-invasive image-guided surgery; critical care informatics in ICU for real-time evidence-based decision making; and chronic care informatics for patient-centric health. In this talk, first, I will highlight major challenges in biomedical and health informatics pipeline consisting of data quality control, information feature extraction, advanced knowledge modeling, decision making, and proper action taking through feedback. Second, I will present informatics methodological research in (i) data integrity and integration; (ii) case-based reasoning for individualized care; and (iii) streaming data analytics for real-time decision support using a few mobile health case studies (e.g. Sickle Cell Disease, asthma, pain management, rehabilitation, diabetes etc.). Last, there is big shortage of data scientists and engineers who are capable of handling Big Data. In addition, there is an urgent need to educate healthcare stakeholders (i.e. patients, physicians, payers, and hospitals) on how to tackle these grant challenges. I will discuss efforts such as patient-centric educational intervention, community-based crowd sourcing, and Biomedical Data Analytics MOOC development. Our research has been supported by NIH, NSF, Georgia Research Alliance, Georgia Cancer Coalition, Emory-Georgia Tech Cancer Nanotechnology Center, Children's Health Care of Atlanta, Atlanta Clinical and Translational Science Institute, and industrial partners such as Microsoft Research and HP.","0730-3157","978-1-4673-6564-2","10.1109/COMPSAC.2015.343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273312","","Biomedical imaging;Informatics;Bioinformatics;Big data;Cancer;Decision making","","7","","","IEEE","24 Sep 2015","1-5 July 2015","1-5 July 2015","IEEE","IEEE Conferences"
"An integration of data mining and data warehousing for hierarchical multimedia information retrieval","J. You; T. Dillon; J. Liu","School of Computing and Information Technology, Griffith University, Brisbane, QLD, Australia; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong, China; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong, China","Proceedings of 2001 International Symposium on Intelligent Multimedia, Video and Speech Processing. ISIMP 2001 (IEEE Cat. No.01EX489)","7 Aug 2002","2001","","","373","376","The paper presents a new approach to multimedia information retrieval with data warehousing techniques. To tackle the key issues such as multimedia data representation, storage, integration, indexing, similarity measures, searching methods and query processing, the proposed algorithms allow one: 1) to extend the concepts of conventional data warehouse and multimedia database to multimedia data warehouse for effective data representation and storage; 2) to develop a multimedia starflake schema to integrate multiple data streams for hierarchical data representation and indexing; 3) to introduce a dynamic similarity measurement scheme based on statistical feature selection criteria; 4) to apply data aggregation techniques for decision support to speed up query processing and searching. We conclude that the proposed approach can be applied to general multimedia systems with effective data storage, retrieval and integration.","","962-85766-2-3","10.1109/ISIMP.2001.925411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=925411","","Data mining;Warehousing;Multimedia databases;Streaming media;Information retrieval;Indexing;Velocity measurement;Query processing;Data warehouses;Multimedia systems","","5","","14","IEEE","7 Aug 2002","4-4 May 2001","4-4 May 2001","IEEE","IEEE Conferences"
"AI and IoT-Enabled Railway Safety System for Automated Monitoring and Early Warning","M. V; S. K. S; P. S; S. S; V. E","Electronics and Communication Engineering, M. Kumarasamy College of Engineering, Karur, India; Electronics and Communication Engineering, M. Kumarasamy College of Engineering, Karur, India; Electronics and Communication Engineering, M. Kumarasamy College of Engineering, Karur, India; Electronics and Communication Engineering, M. Kumarasamy College of Engineering, Karur, India; Electronics and Communication Engineering, M. Kumarasamy College of Engineering, Karur, India",2025 5th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS),"13 Feb 2026","2025","","","1170","1174","Human and animal railway intrusions continue to be a serious issue of concern to transportation security, resulting in heavy operational and economic losses. This paper introduces an intelligent, AI-based railway safety system combining deep learning and Internet of Things (IoT) technologies for real-time intrusion detection and alerting. The system to be implemented employs YOLOv8 object detection algorithm to reliably detect human beings, animals, and foreign bodies on railroad tracks from video streams. The identified anomalies initiate an automatic alert system, which captures the time stamp of the event, location coordinates, and annotated visual proof. The alert is sent instantly to responsible authorities via IoT-based communication modules for quick response and containment. Experimental confirmation under different illumination and environmental conditions exhibits high detection accuracy, minimal false-alarm rates, and real-time performance stability. The suggested scheme is able to significantly reduce human intervention, enhance situational awareness, and enhance response efficiency. Through the integration of AI-enabled vision analytics and IoT connectivity, the system provides a deployable, cost-effective, and scalable answer to augment railway infrastructure safety at the national level.","","979-8-3315-5284-8","10.1109/ICUIS67429.2025.11380719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11380719","Railway safety;YOLOv8;Internet of Things (IoT);Intrusion detection;Computer vision;Image Processing","Deep learning;Animals;Railway safety;Transportation;Thermal sensors;Rail transportation;Real-time systems;Safety;Internet of Things;Reliability","","","","14","IEEE","13 Feb 2026","26-28 Nov. 2025","26-28 Nov. 2025","IEEE","IEEE Conferences"
"Reality Fusion: Robust Real-time Immersive Mobile Robot Teleoperation with Volumetric Visual Data Fusion","K. Li; R. Bacher; S. Schmidt; W. Leemans; F. Steinicke","Accelerator Division, Deutsche Elektronen Synchrotron DESY, Hamburg, Germany; Accelerator Division, Deutsche Elektronen Synchrotron DESY, Hamburg, Germany; Human-Computer Interaction Group, Hamburg University, Hamburg, Germany; Accelerator Division, Deutsche Elektronen Synchrotron DESY, Hamburg, Germany; Human-Computer Interaction Group, Hamburg University, Hamburg, Germany",2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"25 Dec 2024","2024","","","8982","8989","We introduce Reality Fusion, a novel robot teleoperation system that localizes, streams, projects, and merges a typical onboard depth sensor with a photorealistic, high resolution, high framerate, and wide FoV rendering of the complex remote environment represented as 3D Gaussian splats (3DGS). Our framework enables robust egocentric and exocentric robot teleoperation in immersive VR, with the 3DGS effectively extending spatial information of a depth sensor with limited FoV and balancing the trade-off between data streaming costs and data visual quality. We evaluated our framework through a user study with 24 participants, which revealed that Reality Fusion leads to significantly better user performance, situation awareness, and user preferences. To support further research and development, we provide an open-source implementation with an easy-to-replicate custom-made telepresence robot, a high-performance virtual reality 3DGS renderer, and an immersive robot control package.1","2153-0866","979-8-3503-7770-5","10.1109/IROS58592.2024.10802431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10802431","","Visualization;Three-dimensional displays;Telepresence;Robot control;Virtual reality;Robot sensing systems;Rendering (computer graphics);Spatial resolution;Streams;Research and development","","4","","23","IEEE","25 Dec 2024","14-18 Oct. 2024","14-18 Oct. 2024","IEEE","IEEE Conferences"
"Leveraging AI for Data-Driven Strategic Decisions in Multinational Business Environments","N. Jha; S. -L. Peng; U. Mamodiya; P. Chakrabarti","Vice Principal & HoD (BAF), Department of Accountancy, Thakur College of Science & Commerce, Mumbai; National Taipei University of Business, Taiwan; Associate Professor & Associate Dean (Research), Faculty of Engg. & Tech., Poornima University, Jaipur, India; Pro-President (Research and Academics), Sir Padampat Singhania University, India",2025 7th International Conference on Innovative Data Communication Technologies and Application (ICIDCA),"16 Dec 2025","2025","","","1137","1142","Multinational corporations (MNCs) are facing staggering amounts of data today--structured and unstructured--in the age of global interconnectedness. Organizational decisions have traditionally been made based on scheduled reports or ""the gut."" These approaches fall short in capturing the variations of instantaneous market changes, geopolitical uncertainty, or operational challenges. This paper offers a unique, comprehensive Artificial Intelligence (AI) based decision support framework for MNCs to assist in strategic formulation and/or adaptation. The literature does not currently offer a cohesive, explainable and scaleable architecture and methodology for leveraging real-time analytics, predictive modeling and fairness-aware recommendations in multiple contexts within the business domain. In this paper, we offer a modularized AI System that includes a data ingestion module, multimodal fusion, fairness-aware transformer-based decision engine, and an explainability module that uses SHAP and counterfactual analysis. This system is demonstrated with three distinct industry datasets: supply chain logistics, market sentiment analytics, and HR attrition Experimental results show higher decision accuracy (F1-score: 0.94), lower latency (mean: 37 ms), and increased fairness index (+18%) compared to typical statistical models. Many of the suggested designs were supported by the ablation studies, which state the importance of the multimodal fusion and explainability layers. This research bridges the gap between technical rigor and practical importance, knowing both are essential for making MNCs more competitive in when faced with volatile and competitive contexts.","","979-8-3315-1414-3","10.1109/ICIDCA66325.2025.11280488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11280488","Artificial Intelligence in Business;Fairness-Aware Decision Systems;Multimodal Data Fusion;Explainable AI;Strategic Enterprise Analytics","Industries;Analytical models;Uncertainty;Explainable AI;Supply chains;Predictive models;Transformers;Real-time systems;Indexes;Business","","","","20","IEEE","16 Dec 2025","6-8 Oct. 2025","6-8 Oct. 2025","IEEE","IEEE Conferences"
"SIMACET-FFT: Spanish Army friendly force tracking system","M. Esteve; I. Pérez-Llopis; L. Hernández-Blanco; A. Climente; C. E. Palau","Departamento de Comunicaciones, Universidad Politécnica de Valencia, Spain; Departamento de Comunicaciones, Universidad Politécnica de Valencia, Spain; Departamento de Comunicaciones, Universidad Politécnica de Valencia, Spain; Departamento de Comunicaciones, Universidad Politécnica de Valencia, Spain; Departamento de Comunicaciones, Universidad Politécnica de Valencia, Spain",MILCOM 2009 - 2009 IEEE Military Communications Conference,"15 Jan 2010","2009","","","1","7","SIMACET-FFT (SIstema de MAndo y Control del Ejercito de Tierra - FFT) is a small unit's C2I multimedia system based on COTS technologies with multimedia streaming and sensor fusion capabilities. The granularity of the system allows the location of individual soldiers, making it adequate for small units operations. The system consists of several C2 interconnected nodes and individual nodes (e.g. APC, tanks, soldiers...), with sensor/actuator functionalities. The system makes use of all the radio and cable technologies available in the Spanish Army, from VHF and HF communications up to SATCOM and Personal Combat Radios. SIMACET-FFT is supported by a GIS and a database based in the C2IEDM data model. The system interoperates with the higher echelon Spanish Army C2IS (SIMACET) and with other allied systems by means of NFFI and MIP Block II standards. The system has been tested in several trials and is currently under deployment in the first mechanised infantry battalion.","2155-7586","978-1-4244-5238-5","10.1109/MILCOM.2009.5380108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380108","","Multimedia systems;Streaming media;Force sensors;Control systems;Sensor fusion;Actuators;Communication cables;Geographic Information Systems;Databases;Data models","","","","17","IEEE","15 Jan 2010","18-21 Oct. 2009","18-21 Oct. 2009","IEEE","IEEE Conferences"
"Semantically Enabling the SEMAT Project: Extending Marine Sensor Networks for Decision Support and Hypothesis Testing","T. Myers; I. Atkinson; R. Johnstone","E-Research Centre, James Cook University, QLD, Australia; E-Research Centre, James Cook University, QLD, Australia; Centre of Marine Studies, University of Queensland, QLD, Australia","2010 International Conference on Complex, Intelligent and Software Intensive Systems","15 Apr 2010","2010","","","974","979","The SEMAT project is a multi-institution/multi-discipline program developing advanced wireless sensor networks to collect, store, process and interpret data in coastal systems. The marine environment, specifically coral reefs within the Great Barrier Reef, is one of the initial deployments for a prototype SEMAT network. Wireless sensor networks are being deployed to extract environmental data for research into environmental issues such as climate change, water quality and ecosystem health. Remote monitoring networks in remote marine locations are logistically challenging. However, the interpretation of the complex multidimensional data generated is a problem of at least equal complexity. Application of the semantic tools and methods developed in the Semantic Reef project are being mapped onto the SEMAT use-cases with the goal to develop a data model capable of complex inference, as well as conventional data storage and analysis.","","978-1-4244-5918-6","10.1109/CISIS.2010.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5447385","ontology;sensor networks;semantic web","Testing;Wireless sensor networks;Sea measurements;Prototypes;Data mining;Ecosystems;Remote monitoring;Multidimensional systems;Data models;Memory","","7","","15","IEEE","15 Apr 2010","15-18 Feb. 2010","15-18 Feb. 2010","IEEE","IEEE Conferences"
"An IoT Based Smart Hybrid Firefighting Robot with 360° Visual Intelligence for Industrial Safety Applications","M. S. Al Basar; R. Roy","Department of ME, Sonargaon University (SU), Dhaka, Bangladesh; Atomic Energy Centre, Chattogram, BAEC, Chattogram, Bangladesh","2025 IEEE 2nd International Conference on Computing, Applications and Systems (COMPAS)","12 Feb 2026","2025","","","1","6","Industrial facility fires pose severe risks to human life, property, and business continuity. Conventional firefighting strategies often require direct human intervention in hazardous environments, exposing personnel to life-threatening conditions and limiting the efficiency of emergency responses. To address these challenges, this research presents an IoT-enabled hybrid robotic firefighting framework that integrates multi-sensor fire detection, rule-based autonomy, and dual suppression mechanisms for enhanced industrial safety. A sensor fusion scheme combining flame, smoke, temperature, and vision modalities enables reliable fire detection and localization, while finite-state behavioural logic governs autonomous navigation, suppression mode selection and operator override. Dual suppression agents—water and Aqueous Film-Forming Foam (AFFF)—provide adaptability across Class A and Class B fire scenarios. Experimental validation under controlled flame conditions demonstrated detection latencies of 1.1–2.3 s across distances up to 50 cm, suppression coverage of 0.11–0.15 m2, and real-time situational monitoring with 200–300 ms video latency. These results confirm the feasibility of low-cost, rule-based robotic firefighting solutions in constrained industrial environments.The originality of this study does not lie in the isolated use of commercially available components, but in their systematic integration into a coherent, application-oriented framework tailored to industrial safety in resource-limited regions. This study advances the field by providing a reproducible platform that balances affordability, operational robustness, and practical deployability, thereby bridging the gap between conceptual research and real-world industrial firefighting applications.","","979-8-3315-5525-2","10.1109/COMPAS67506.2025.11381863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11381863","component;formatting;style;styling;insert","Temperature sensors;Visualization;Systematics;Service robots;Fires;Sensor fusion;Robustness;Personnel;Logic;Videos","","","","20","IEEE","12 Feb 2026","23-24 Oct. 2025","23-24 Oct. 2025","IEEE","IEEE Conferences"
"Wide-area motion imagery (WAMI) exploitation tools for enhanced situation awareness","E. Blasch; G. Seetharaman; K. Palaniappan; H. Ling; G. Chen","Air Force Research Laboratory, Rome, NY, USA; Air Force Research Laboratory, Rome, NY, USA; University of Missouri-Columbia, Columbia, MO, USA; Temple University, Philadelphia, PA, USA; Intelligent Fusion Technology, Inc., Germantown, MD, USA",2012 IEEE Applied Imagery Pattern Recognition Workshop (AIPR),"13 Jun 2013","2012","","","1","8","The advent of streaming feeds of full-motion video (FMV) and wide-area motion imagery (WAMI) have overloaded an image analyst's capacity to detect patterns, movements, and patterns of life. To aid in the process of WAMI exploitation, we explore computer vision and pattern recognition methods to cue the user to salient information. For enhanced exploitation and analysis, there is a need to develop WAMI methods for situation awareness. Computer vision algorithms provide cues, contexts, and communication patterns to enhance exploitation capabilities. Multi-source data fusion using exploitation context from the video needs to be linked to semantically extracted elements for situation awareness to aid an operator in rapid image understanding. In this paper, we identify: (1) opportunities from computer vision techniques to improve WAMI target tracking, (2) relate developments of clustering methods for activity-based intelligence and stochastic context-free grammars for accessing, indexing, and linking relevant information to assist processing and exploitation, and (3) address situation awareness methods of multi-intelligence collaboration for future automated video understanding techniques. Our example uses the open-source Columbus Large Image Format (CLIF) WAMI data to demonstrate connection of video-based semantic labeling with other information fusion enterprise capabilities incorporating text-based semantic extraction.","1550-5219","978-1-4673-4559-0","10.1109/AIPR.2012.6528198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6528198","Wide-Area Motion Imagery;Exploitation;Measures of Effectiveness;Stochistic Context-Free Grammar;Enterprise Fusion","Semantics;Feature extraction;Grammar;Computer vision;Three-dimensional printing;Streaming media;Data mining;Uncertainty;Image analysis;Visualization","","64","","105","IEEE","13 Jun 2013","9-11 Oct. 2012","9-11 Oct. 2012","IEEE","IEEE Conferences"
"Secure Surveillance System for Maritime Applications","S. Baccouri; T. Abdellatif","SERCOM Lab, Tunisia Polytechnic School, Tunisia; SERCOM Lab, Tunisia Polytechnic School, Tunisia",2024 IEEE/ACS 21st International Conference on Computer Systems and Applications (AICCSA),"11 Mar 2025","2024","","","1","6","Maritime surveillance is crucial for security, safety, and efficient marine resource management. This paper introduces a Secure Surveillance System that leverages real-time data from environmental sensors and big data systems to enable rapid response and decision-making during Search and Rescue (SAR) operations. Compared to classical SAR systems, the proposed solution is scalable and ensures timely responses while maintaining end-to-end security of exchanged data. For evaluation, we describe and assess an example application of maritime surveillance.","2161-5330","979-8-3315-1824-0","10.1109/AICCSA63423.2024.10912599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10912599","Big Data;SAR;Confidentiality;Integrity;Secure Communication","Surveillance;System performance;Decision making;Computer architecture;Big Data;Throughput;Real-time systems;Sensor systems;Sensors;Resource management","","","","22","IEEE","11 Mar 2025","22-26 Oct. 2024","22-26 Oct. 2024","IEEE","IEEE Conferences"
"3-D Object Tracking in Panoramic Video and LiDAR for Radiological Source–Object Attribution and Improved Source Detection","M. R. Marshall; D. Hellfeld; T. H. Y. Joshi; M. Salathe; M. S. Bandstra; K. J. Bilton; R. J. Cooper; J. C. Curtis; V. Negut; A. J. Shurley; K. Vetter","Nuclear Engineering Department, University of California, Berkeley, Berkeley, CA, USA; Lawrence Berkeley National Laboratory (LBNL), Applied Nuclear Physics (ANP) Program, Berkeley, CA, USA; Lawrence Berkeley National Laboratory (LBNL), Applied Nuclear Physics (ANP) Program, Berkeley, CA, USA; Lawrence Berkeley National Laboratory (LBNL), Applied Nuclear Physics (ANP) Program, Berkeley, CA, USA; Lawrence Berkeley National Laboratory (LBNL), Applied Nuclear Physics (ANP) Program, Berkeley, CA, USA; Nuclear Engineering Department, University of California, Berkeley, Berkeley, CA, USA; Lawrence Berkeley National Laboratory (LBNL), Applied Nuclear Physics (ANP) Program, Berkeley, CA, USA; Lawrence Berkeley National Laboratory (LBNL), Applied Nuclear Physics (ANP) Program, Berkeley, CA, USA; Lawrence Berkeley National Laboratory (LBNL), Applied Nuclear Physics (ANP) Program, Berkeley, CA, USA; Nuclear Engineering Department, University of California, Berkeley, Berkeley, CA, USA; Nuclear Engineering Department, University of California, Berkeley, Berkeley, CA, USA",IEEE Transactions on Nuclear Science,"15 Feb 2021","2021","68","2","189","202","Networked detector systems can be deployed in urban environments to aid in the detection and localization of radiological and/or nuclear material. However, effectively responding to and interpreting a radiological alarm using spectroscopic data alone may be hampered by a lack of situational awareness, particularly in complex environments. This study investigates the use of Light Detection and Ranging (LiDAR) and streaming video to enable real-time object detection and tracking, and the fusion of this tracking information with radiological data for the purposes of enhanced situational awareness and increased detection sensitivity. This work presents an object detection, tracking, and novel source–object attribution analysis that is capable of operating in real time. By implementing this analysis pipeline on a custom-developed system that comprises a static 2 in.  $\times 4$  in.  $\times16$  in. NaI(Tl) detector colocated with a 64-beam LiDAR and four monocular cameras, we demonstrate the ability to accurately correlate trajectories from tracked objects to spectroscopic gamma-ray data in real time and use physics-based models to reliably discriminate between source-carrying and nonsource-carrying objects. In this work, we describe our approach in detail and present a quantitative performance assessment that characterizes the source–object attribution capabilities of both video and LiDAR. Additionally, we demonstrate the ability to simultaneously track pedestrians and vehicles in a mock urban environment and use this tracking information to improve both detection sensitivity and situational awareness using our contextual-radiological data fusion methodology.","1558-1578","","10.1109/TNS.2020.3047646","U.S. Department of Homeland Security through competitively awarded; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309235","Object detection;object tracking;radiological search;source attribution","Laser radar;Object detection;Cameras;Object tracking;Trajectory;Three-dimensional displays;Detectors","","16","","34","IEEE","28 Dec 2020","Feb. 2021","","IEEE","IEEE Journals"
"An Architecture for a Task-Oriented Surveillance System: A Service- and Event-Based Approach","J. Moßgraber; F. Reinert; H. Vagts","System Technologies and Image Exploitation IOSB, Fraunhofer Institute of Optronics, Karlsruhe, Germany; System Technologies and Image Exploitation IOSB, Fraunhofer Institute of Optronics, Karlsruhe, Germany; System Technologies and Image Exploitation IOSB, Fraunhofer Institute of Optronics, Karlsruhe, Germany",2010 Fifth International Conference on Systems,"13 May 2010","2010","","","146","151","Due to the increasing threat posed by crime, industrial espionage and even terrorism, video surveillance systems have become more important and powerful during the last years. While most commercially available surveillance systems have to be managed by human operators, who constantly monitor all video streams, several experimental systems from different research groups already include robust video processing approaches for (semi-) automated surveillance. Still, most research activities focus on a sensororiented approach to video analytics of large and distributed camera networks, aiming to extract, analyze and store all extractable information from the video streams. In real-life applications, however, only a limited set of specific threats needs to be covered. Accordingly, only a small subset of potentially extractable information has to be monitored. Besides the huge amount of raw video data, modern surveillance systems are also extended with other sensors that deliver even more data. As a consequence, a new paradigm is introduced, called task-oriented information and data processing for surveillance systems. In the proposed system NEST (Network Enabled Surveillance and Tracking) following the task-oriented approach, every resource allocation, data acquisition, and analysis process is assigned to a specific surveillance task. In order to meet the requirements of taskoriented surveillance, the proposed architecture combines a Service-Oriented Architecture with an Event-Driven Architecture (Event-driven SOA).","","978-1-4244-6232-2","10.1109/ICONS.2010.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5464144","task-oriented;event-driven SOA;communication buses;surveillance;multi-camera tracking","Data mining;Streaming media;Information analysis;Service oriented architecture;Terrorism;Video surveillance;Power system management;Humans;Computerized monitoring;Robustness","","16","1","10","IEEE","13 May 2010","11-16 April 2010","11-16 April 2010","IEEE","IEEE Conferences"
"Distributing Essential Logical Deductions to Surveillance Personnel and a Video Recorder","T. Räty; M. Lindholm; M. Nieminen; J. Oikarinen","VTT Technical Research Center of Finland, Oulu, Finland; VTT Technical Research Center of Finland, Oulu, Finland; VTT Technical Research Center of Finland, Oulu, Finland; VTT Technical Research Center of Finland, Oulu, Finland","2008 The Second International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies","10 Oct 2008","2008","","","295","304","The Single Location Surveillance Point (SLSP) is an indoor distributed multi-sensor surveillance software system. It encompasses an arbitrary amount of sensors that collect data from a single location, which is the surveillance point. The ensuing sensors are realized: a fingerprint sensor attached to a door with an electronic lock, a video camera, an audio sensor, and a network analyzing monitor. Each sensor collects information from its ambit. Once the crude data has been acquired from the sensors and transmitted to Logical Decision Making Server (LDMS) by the session server, the LDMS automatically performs logical deductions based on the data received from the sensors. The logical deductions create: 1) information for end users or 2) control messages to sensors. Based on the alarms, the LDMS can ordain instructions to the video recorder. The LDMS distributes the logical deductions to the human security administrator of the Security Manager Server (SMSU) and/or the end devices of the nomadic guards. The SLSP system provide the surveillance personnel refined information cogent to occurring events of the surveyed area. The SLSP system intends to decrement the amount of superfluous information rendered to the surveillance personnel, by providing automatically derived information. These two antecedently depicted facets are the main endeavors of the SLSP system distribution of logical deductions. The operability of the constructed prototype indicates that this endeavor is attained. The research is based on the constructive method of the related publications and technologies and the results are derived by the implemented branch of the SLSP system.","","978-0-7695-3367-4","10.1109/UBICOMM.2008.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4641351","","Sensors;Surveillance;Servers;Monitoring;Streaming media;Security;Humans","","2","","23","IEEE","10 Oct 2008","29 Sept.-4 Oct. 2008","29 Sept.-4 Oct. 2008","IEEE","IEEE Conferences"
"Improving Real-Time Data Streaming Security to Promote Patient and Physician Socialization","H. Sachdev; H. Wimmer; L. Chen","Dept. of Information Technology, Georgia Southern University, Statesboro, GA, USA; Dept. of Information Technology, Georgia Southern University, Statesboro, GA, USA; Dept. of Information Technology, Georgia Southern University, Statesboro, GA, USA","2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)","31 Oct 2016","2016","","","309","316","Promoting the socialization of personal health information (PHI) via sharing presents challenges due to confidentiality and privacy protections required by individuals and mandated by HIPAA (Health Insurance Portability and Accountability Act). Sharing PHI facilitates improved clinical decision support and evidence based medicine. The volume, variety, veracity and velocity of PHI is increasing with the advent and commercialization of wearable sensor technology requiring the streaming of real-time personal health data. In order to promote sharing of streaming, sensor-based PHI security and performance are demanded. In response to these concerns, this work instantiates and demonstrates a method to secure streaming of data via RC4 encryption while improving its security by incorporating variable length cipher strength via a proposed PRGA key rotation method. To facilitate this method, multiple keys can be transmitted over disparate mediums or channels in an extension to RC4, dubbed RC4 modified (RC4m). This work serves as an important step toward efficient and secure transmission of PHI to promote sharing in a social context between patient and physician.","","978-1-5090-3936-4","10.1109/BDCloud-SocialCom-SustainCom.2016.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723708","Encryption;Data privacy;Cipher;Cryptography;Random Number Generation;RC4;PHI","Encryption;Ciphers;Medical services;Algorithm design and analysis;Real-time systems","","1","","28","IEEE","31 Oct 2016","8-10 Oct. 2016","8-10 Oct. 2016","IEEE","IEEE Conferences"
"Comprehensive Emergency Vehicle Signaling Through 5G-Enhanced V2X Technologies","L. M. Gladence; R. R; A. T. V S; D. R K; S. S. M; I. T M","Department of Information Technology, School of Computing, Sathyabama Institute of Science and Technology, Chennai, Tamil Nadu, India; Department of Information Technology, School of Computing, Sathyabama Institute of Science and Technology, Chennai, Tamil Nadu, India; Department of Information Technology, School of Computing, Sathyabama Institute of Science and Technology, Chennai, Tamil Nadu, India; Department of Information Technology, School of Computing, Sathyabama Institute of Science and Technology, Chennai, Tamil Nadu, India; Department of Electronics and Communication Engineering, R.M.K. College of Engineering and Technology, Tamil Nadu, India; Department of Electronics and Communication Engineering, R.M.K. College of Engineering and Technology, Tamil Nadu, India",2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS),"24 Sep 2025","2025","","","1298","1304","Emergency vehicles (EVs) frequently experience delays in metropolitan settings because of traffic jams and ineffective traffic infrastructure. A consistent framework for dynamic EV priority is lacking in present systems, despite the fact that V2X technologies like DSRC and 5G allow real-time communication. A clever V2X-based traffic management system that combines sophisticated communication, sensor fusion, and AI-driven decision-making is proposed in this research. In order to identify abnormal vehicle motions and improve situational awareness, the system analyses data from the gyroscope, accelerometer, jerk, and yaw rate. Predictive safety elements that encourage proactive collision avoidance include Time to Collision (TTC) and Deceleration Rate. Additional safety layers include CAN Bus data, RSU monitoring, and rapid speed change detection. With the help of WebRTC and FFmpeg streaming on IP cameras and CBAM for low-latency data exchange, real-time perception is accomplished. Features like C-V2X-powered Lane Change Assist, Turn Assist, and Crash Prevention guarantee safe EV driving. By improving response times and road safety, this integrated system promotes intelligent urban transportation.","","979-8-3315-1250-7","10.1109/ICSCDS65426.2025.11167634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11167634","Yaw Rate;Jerk Analysis;Accelerometer;Gyroscope;Time to Collision (TTC);Deceleration Rate;Cooperative Lane Change Assist;Proactive Crash Prevention","Prevention and mitigation;Sensor fusion;Real-time systems;Gyroscopes;Delays;Vehicle dynamics;Low latency communication;Vehicle-to-everything;Vehicles;Accidents","","","","14","IEEE","24 Sep 2025","6-8 Aug. 2025","6-8 Aug. 2025","IEEE","IEEE Conferences"
"Hybrid Edge-Cloud AI and Blockchain System Architecture for Real-Time Decision-Making in IT Project Management","G. Ganesh; M. A. Nasreen; A. Jaganathan","Computer Science and Engineering Chennai Institute of Technology, Chennai, India; Depatment of Computer Science and Engineering, Chennai Institute Of Technology, Chennai, India; Computer Science and Engineering Chennai Institute of Technology, Chennai, India","2025 4th International Conference on Automation, Computing and Renewable Systems (ICACRS)","14 Jan 2026","2025","","","751","755","In this article a solution is presented for a hybrid edge-cloud AI architecture, integrated with blockchain, to alleviate major IT project issues: latency, energy efficiency, security and decision-making accuracy. Its low- latency processing capabilities contribute to adaptive learning and collaboration by harnessing the computing capabilities of cloud computing and the quick responsiveness of edge devices. The architecture incorporates AI-enabled decision support, blockchain-enabled data integrity, and finite access to resources, all while supporting IT workflows performance, privacy, and scalability. The architecture aspects (low latency, lightweight model, low energy, blockchain data integrity, etc.) allow for, but are not limited to: lightweight AI model deployment through knowledge distillation or model compression; task offloading using reinforcement learning based Neural Architecture Search (NAS); deep Q-learning for resource allocation; federated learning for privacy-preserving training; smart contracts and encrypted communications on blockchain for enhanced security; and the ability to support real-time monitoring employing LSTM-based analytics or AEs for predictive analytics, and early risk monitoring or anomaly detection. . For instance, in phases of the above-mentioned framework, Implementation of this architecture framework managed to reduce latency and energy consumption by around 42.3% and 44.7%, respectively. Improvements in accuracy of AI models reached 12.1% and precision(2.96%) and recall (16.6%) in anomaly detection were also achieved. Furthermore, efficiencies in combined task offloading increased by 59.0%, depending on the model types. This framework's distinctive integration of edge-cloud capabilities, blockchain governance, and real-time analytics enables an autonomous, secured, and efficient environment in project management to help establish intelligent infrastructures in future IT innovations.","","979-8-3315-4886-5","10.1109/ICACRS67045.2025.11324399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11324399","Edge-Cloud AI Architecture;Artificial Intelligence (AI);Real-Time Decision-Making;IT Project Management;Machine Learning;Risk Management;Resource allocation","Accuracy;Decision making;Project management;Computer architecture;Predictive models;Real-time systems;Blockchains;Resource management;Artificial intelligence;Anomaly detection","","","","16","IEEE","14 Jan 2026","10-12 Dec. 2025","10-12 Dec. 2025","IEEE","IEEE Conferences"
"Going Beyond Citizen Data Collection with Mapster: A Mobile+Cloud Real-Time Citizen Science Experiment","Y. Liu; P. Piyawongwisal; S. Handa; L. Yu; Y. Xu; A. Samuel","University of Illinois at Urbana-Champaign, Urbana, IL, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA; Microsoft Research, Microsoft Corporation, Redmond, WA, USA; Microsoft Research, Microsoft Corporation, Redmond, WA, USA",2011 IEEE Seventh International Conference on e-Science Workshops,"16 Jan 2012","2011","","","1","6","Citizens have always played an important role in emergency management such as urban flooding response. New information and communication technologies such as smart phones and computer-based social networks have great potential to transform the roles of citizens in emergency management. However, current digital citizen science projects are usually limited in three areas: 1) limited one-way citizen participation, 2) no processing and integration of citizens' reports with other existing infrastructure sensing data, 3) no personalized near-real-time spatiotemporal visualization tools for citizens to instantly view aggregated data to gain updated situational awareness. We developed a Mapster application that specifically addresses these issues. First, we leveraged Twitter's geo-referenced tweets functionality to design a customized smart phone application for citizens to report a set of events that have been identified in past urban flooding situations such as ""basement flooding"" and ""powerline down"" etc. Second, a Cloud-based semantic streaming data harvesting and processing tool was developed to fetch and process both the Twitter feeds and other infrastructure sensing data such as US National Weather Service's radar data. Third, a user can instantly explore the heterogeneous data processed and provided by the Cloud service through a map-based spatiotemporal animation tool on the smart phone to see how all the events evolve before, during, and after a storm. Such a two-way information flow significantly improves citizen participation and their sense of situational awareness. We present our architecture, implementation, and discussion of issues on citizen science data collection platforms, integration of heterogeneous data sources and future work plan.","","978-1-4673-0026-1","10.1109/eScienceW.2011.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6130723","citizen science;emergency management;mapster;Windows Phone 7;data integration;spatiotemporal animation;urban flooding response","Real time systems;Sensors;Smart phones;Twitter;Floods;Data visualization;Spatiotemporal phenomena","","18","","25","IEEE","16 Jan 2012","5-8 Dec. 2011","5-8 Dec. 2011","IEEE","IEEE Conferences"
"A Suite of Efficient Randomized Algorithms for Streaming Record Linkage","D. Karapiperis; C. Tjortjis; V. S. Verykios","International Hellenic University, Thermi, Thessaloniki, Greece; International Hellenic University, Thermi, Thessaloniki, Greece; Hellenic Open University, Patras, Greece",IEEE Transactions on Knowledge and Data Engineering,"5 Jun 2024","2024","36","7","2803","2813","Organizations leverage massive volumes of information and new types of data to generate unprecedented insights and improve their outcomes. Correctly identifying duplicate records that represent the same entity, such as user, customer, patient and so on, a process commonly known as record linkage, can improve service levels, accelerate sales, or elevate healthcare decision support. Towards this direction, blocking methods are used with the aim to group matching records in the same block using a combination of their attributes as blocking keys. This paper introduces a suite of randomized algorithms specifically crafted for streaming record linkage settings. Using a bounded in-memory data structure, in terms of the number of blocks and positions within each block, our algorithms guarantee that the most frequently accessed and the most recently used blocks remain in main memory and, additionally, the records within a block are renewed on a rolling basis. The operation of our algorithms rely on simple random choices, instead of utilizing cumbersome sorting data structures, which ensure that the probability of inactive blocks and older records to remain in main memory decays in order to free space for more promising blocks and fresher records, respectively. We also introduce an algorithm that performs approximate blocking to tackle the problem of misspellings and typos present in the blocking keys. The experimental evaluation showcases that our proposed algorithms scale efficiently to data streams by providing certain accuracy guarantees.","1558-2191","","10.1109/TKDE.2024.3361022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10418556","Data integration;entity resolution;randomization;record linkage","Couplings;Streams;Soft sensors;Real-time systems;Indexes;Data structures;Approximation algorithms","","4","","24","IEEE","1 Feb 2024","July 2024","","IEEE","IEEE Journals"
"Adaptive Mixture-Based Neural Network Approach for Higher-Level Fusion and Automated Behavior Monitoring","D. Garagic; B. J. Rhodes; N. A. Bomberger; M. Zandipour","Adaptive Reasoning Technologies Directorate, Fusion Technology and Systems, BAE Systems, Advanced Information Technologies, Burlington, MA, USA; Adaptive Reasoning Technologies Directorate, Fusion Technology and Systems, BAE Systems, Advanced Information Technologies, Burlington, MA, USA; Adaptive Reasoning Technologies Directorate, Fusion Technology and Systems, BAE Systems, Advanced Information Technologies, Burlington, MA, USA; Adaptive Reasoning Technologies Directorate, Fusion Technology and Systems, BAE Systems, Advanced Information Technologies, Burlington, MA, USA",2009 IEEE International Conference on Communications,"11 Aug 2009","2009","","","1","6","A novel adaptive mixture-based neural network is presented for exploiting track data to learn normal patterns of motion behavior and detect deviations from normalcy. We have extended our prior approach by introducing multidimensional probability density components to represent class density using an adaptive mixture of such components. The number of components in the adaptive mixture algorithm, as well as the values of the parameters of the density components, is estimated from the data. The network utilizes a recursive version of the Expectation Maximization (EM) algorithm to minimize the Kullback-Leibler information metric by means of stochastic approximation combined with a rule for creation of new components. Learning occurs incrementally in order to allow the system to take advantage of increasing amounts of data without having to take the system offline periodically to update models. Continuous incremental learning enables the models of normal behavior to adapt well to evolving situations while maintaining high levels of performance. In addition, the adaptive mixtures neural network classifies streaming track data as normal or deviant. These capabilities contribute to higher-level fusion situational awareness and assessment objectives by enabling a shift of operator focus from sensor monitoring and activity detection to assessment and response. Our overall motion pattern learning approach learns behavioral patterns at a variety of conceptual, spatial, and temporal levels to reduce massive amounts of track data to a rich set of information regarding operator field of regard that supports rapid decision-making and timely response initiation.","1938-1883","978-1-4244-3435-0","10.1109/ICC.2009.5198703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5198703","","Adaptive systems;Neural networks;Computerized monitoring;Tracking;Motion detection;Multidimensional systems;Approximation algorithms;Stochastic processes;Sensor fusion;Decision making","","5","","16","IEEE","11 Aug 2009","14-18 June 2009","14-18 June 2009","IEEE","IEEE Conferences"
"Machine Learning Support for Radar-Based Surveillance Systems","K. Dästner; S. Haaga; B. von Haßler zu Roseneckh-Köhler; C. Mohrdieck; F. Opitz; E. Schmid","AIRBUS, Ulm, Germany; AIRBUS, Ulm, Germany; AIRBUS, Ulm, Germany; AIRBUS, Ulm, Germany; AIRBUS, Ulm, Germany; AIRBUS, Ulm, Germany",IEEE Aerospace and Electronic Systems Magazine,"7 Jul 2021","2021","36","7","8","25","Nowadays, radar-based surveillance systems already consist of highly complex tracking, sensor data fusion, and identification algorithms, which track the trajectories of moving objects. They are embedded in a real-time middleware with a straight forward processing chain according to the Joint Directors of Laboratories (JDL) fusion model. With the spread of new technologies, e.g., big data, distributed data processing and machine learning open up new possibilities for surveillance systems. Commercial data providers provide trajectories of all kinds of vessels and aircraft worldwide. Best known are automatic dependent surveillance-broadcast and (satellite-) automatic identification system used in air and maritime surveillance. Both are cooperative systems and, meanwhile, also integrated as the sensor source in surveillance systems. An advantage of these trajectories is that in addition to the unique identification of the object by an identifier, e.g., International Civil Aviation Organization code or Maritime Mobile Service Identity (MMSI), with which they can be easily assigned to the generating objects contain additional context data that can be used as labels for supervised machine learning. In addition, they are similar in structure to radar tracks and are, therefore, ideal for analysis and training of learning algorithms. This article gives an overview of how these new technologies in combination with big data of trajectories can be integrated into existing surveillance systems and how machine learning can help to improve situational awareness. It is intended as an overview to show which data and which methods open up new opportunities.","1557-959X","","10.1109/MAES.2020.3001966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9475886","","Heating systems;Machine learning algorithms;Surveillance;Atmospheric modeling;Vegetation;Big Data;Radar tracking;Object recognition;Training data;Spaceborne radar","","7","","83","IEEE","7 Jul 2021","1 July 2021","","IEEE","IEEE Magazines"
"Military Surveillance and Landmine Detection with Safe Path Planning","H. S; K. D. Kumar; S. J. Rishika; V. V. C K; A. V.M; A. S","Amrita School of Artificial Intelligence, Coimbatore, Amrita Vishwa Vidyapeetham, India; Amrita School of Artificial Intelligence, Coimbatore, Amrita Vishwa Vidyapeetham, India; Amrita School of Artificial Intelligence, Coimbatore, Amrita Vishwa Vidyapeetham, India; Amrita School of Artificial Intelligence, Coimbatore, Amrita Vishwa Vidyapeetham, India; Amrita School of Artificial Intelligence, Coimbatore, Amrita Vishwa Vidyapeetham, India; Amrita School of Artificial Intelligence, Coimbatore, Amrita Vishwa Vidyapeetham, India",2025 IEEE 22nd India Council International Conference (INDICON),"20 Feb 2026","2025","","","1","6","In modern military and defense applications, landmine detection and surveillance face more rigorous challenges that require sophisticated autonomous solutions. This paper presents a multi-functional autonomous surveillance robot that integrates dual-layer landmine detection using metal sensing and chemical residue analysis and SLAM-based navigation for GPS-denied terrains, and CNN-based environmental threat classification. Experimental results show a detection accuracy of 94.9% (fire detection), 25 FPS real-time streaming, and successful SLAM-based mapping with dynamic obstacle avoidance, validating the system’s reliability and real-world applicability for defense operations. It comes up with a fire detection using machine learning and temperature detection. The system also utilizes an innovative air vacuum pump with a chemical filter that captures air particles, for explosive detection with trained dogs. The surveillance functionality is complemented by a Raspberry web camera, with real-time video streaming via a Flask-Based web interface. The system is proposed for battlefield safety improvement, human risk reduction, and provision of the optimal solution for threat detection.","2325-9418","979-8-3315-9031-4","10.1109/INDICON68490.2025.11392863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11392863","SLAM;Multi-Sensor Fusion;Autonomous Navigation;Landmine Detection;ROS;Defense Robotics","Landmine detection;Simultaneous localization and mapping;Navigation;Surveillance;Metals;Threat assessment;Safety;Sensors;Chemicals;Videos","","","","17","IEEE","20 Feb 2026","18-20 Dec. 2025","18-20 Dec. 2025","IEEE","IEEE Conferences"
"Social media alert and response to threats to citizens (SMART-C)","N. Adam; J. Eledath; S. Mehrotra; N. Venkatasubramanian","US Department of Homeland Security, Science & Technology Directorate, Washington, DC, USA; SRI International, Princeton, NJ; University of California, Irvine; University of California, Irvine","8th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom)","7 Feb 2013","2012","","","181","189","Social media, such as blogs, Twitter, and information portals, have emerged as the dominant communication mechanism of society. Exploiting such input to gain awareness of an incident is a critical direction for research in effective emergency management. In this paper we present an overview of the SMART-C system, which is part of the social media initiative at the Department of Homeland Security. The system aims to enable robust bidirectional communication between emergency management and the public at large throughout the disaster life-cycle via a multitude of devices and modalities including cell phones, MMS messages, text messages, blogs, Twitter, etc. A discussion of the major components of SMART-C and related research challenges is included. These components include mechanisms to model event level semantic information, a platform for implementing multi-sensor fusion, mechanisms for estimating the veracity of information, data cleaning to reduce uncertainty and enhance accuracy of event detection and notification, and spatiotemporal analyses for pattern and trend analyses for higher level observations.","","978-1-4673-2740-4","10.4108/icst.collaboratecom.2012.250713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6450906","social media;emergency management;alerting;robust data analytics","Real-time systems;Analytical models;Databases;Noise reduction;Reliability;Visualization;Speech","","4","2","42","","7 Feb 2013","14-17 Oct. 2012","14-17 Oct. 2012","IEEE","IEEE Conferences"
"Energy-efficient Wearable-to-Mobile Offload of ML Inference for PPG-based Heart-Rate Estimation","A. Burrello; M. Risso; N. Tomasello; Y. Chen; L. Benini; E. Macii; M. Poncino; D. J. Pagliari","DEI, Università di Bologna, Bologna, Italy; Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy; DEI, Università di Bologna, Bologna, Italy; DEI, Università di Bologna, Bologna, Italy; Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy","2023 Design, Automation & Test in Europe Conference & Exhibition (DATE)","2 Jun 2023","2023","","","1","6","Modern smartwatches often include photoplethysmographic (PPG) sensors to measure heartbeats or blood pressure through complex algorithms that fuse PPG data with other signals. In this work, we propose a collaborative inference approach that uses both a smartwatch and a connected smartphone to maximize the performance of heart rate (HR) tracking while also maximizing the smartwatch's battery life. In particular, we first analyze the trade-offs between running on-device HR tracking or offloading the work to the mobile. Then, thanks to an additional step to evaluate the difficulty of the upcoming HR prediction, we demonstrate that we can smartly manage the workload between smartwatch and smartphone, maintaining a low mean absolute error (MAE) while reducing energy consumption. We benchmark our approach on a custom smartwatch prototype, including the STM32WB55 MCU and Bluetooth Low-Energy (BLE) communication, and a Raspberry Pi3 as a proxy for the smartphone. With our Collaborative Heart Rate Inference System (CHRIS), we obtain a set of Pareto-optimal configurations demonstrating the same MAE as State-of-Art (SoA) algorithms while consuming less energy. For instance, we can achieve approximately the same MAE of TimePPG-Small [1] (5.54 BPM MAE vs. 5.60 BPM MAE) while reducing the energy by 2.03×, with a configuration that offloads 80% of the predictions to the phone. Furthermore, accepting a performance degradation to 7.16 BPM of MAE, we can achieve an energy consumption of 179 uJ per prediction, 3.03× less than running TimePPG-Small on the smartwatch, and 1.82× less than streaming all the input data to the phone.","1558-1101","979-8-3503-9624-9","10.23919/DATE56975.2023.10137129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10137129","PPG;HR;MCUs;TinyML","Heart rate;Energy consumption;Wearable computers;Collaboration;Prototypes;Sensor fusion;Prediction algorithms","","3","","21","","2 Jun 2023","17-19 April 2023","17-19 April 2023","IEEE","IEEE Conferences"
"Autonomy in Use for Information Fusion Systems","E. Blasch","Air Force Office of Scientific Research, Arlington, VA",NAECON 2018 - IEEE National Aerospace and Electronics Conference,"6 Dec 2018","2018","","","1","8","Current trends in autonomy result from many technical advancements in artificial intelligence, information communication, and systems design. Systems design includes the combination of instrumentation, modeling, and computational architectures. Examples of architecture designs are autonomy in motion (AIM) for dynamic data assessment systems (e.g., robotics) and autonomy at rest (AAR) for static data collection systems (e.g., surveillance). However, there is a need for the analysis from streaming data architectures, which necessitates autonomy in use (AIU). AIU requires pragmatic use of message passing and data flow architectures; contextual and theoretic modeling; and user and information fusion. Information fusion provides methods for data aggregation, correlation, and temporal analysis. Together, AIU accesses the dynamic data for autonomy in change (AIC), information fusion from AAR in order to make AIM real-time decisions.","2379-2027","978-1-5386-6557-2","10.1109/NAECON.2018.8556777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8556777","Data Fusion;Autonomy in Use;Context assessment;Information Management","Surveillance;Message passing;Instruments;Computer architecture;Aerodynamics;Market research;Real-time systems","","6","","99","IEEE","6 Dec 2018","23-26 July 2018","23-26 July 2018","IEEE","IEEE Conferences"
"Survey on Advancing Multimodal Remote Sensing in Precision Agriculture","M. Shriwas; K. Sindhi","Department of Electronics Engineering, Jhulelal Institute of Technology, RTMNU, Nagpur, India; Department of Electronics Engineering, Jhulelal Institute of Technology, RTMNU, Nagpur, India",2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA),"21 Feb 2025","2024","","","1","6","Modern technology, such as artificial intelligence and multimodal remote sensing, is driving the rapid advancement of precision agriculture. The review article examines the ways in which resource management and agricultural monitoring can be improved by the combination of machine learning (ML) and deep learning (DL) techniques with remote sensing modalities. This research investigates how recent advancements in sensor technology, including LiDAR, hyperspectral, and multispectral imaging, have transformed agricultural practices. Further discussed in the paper with reference to precision farming are the challenges of data fusion, algorithmic complexity, and the need for dependable, scalable solutions. The study discovers major trends and possible future paths for the field, including the combination of real-time analytics with AI-driven decision support systems, through a detailed examination of case studies and current research. The results set the stage for future investigations and advancements in this crucial field by emphasizing the role that ML and DL play in maximizing agricultural sustainability and productivity.","","979-8-3315-1795-3","10.1109/ICAIQSA64000.2024.10882311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10882311","Precision Agriculture;Multimodal Remote Sensing;Machine Learning;Deep Learning;Crop Monitoring;Resource Management","Precision agriculture;Productivity;Deep learning;Surveys;Reviews;Real-time systems;Resource management;Sustainable development;Monitoring;Farming","","","","18","IEEE","21 Feb 2025","20-21 Dec. 2024","20-21 Dec. 2024","IEEE","IEEE Conferences"
