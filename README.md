# Revis√£o da Literatura: Metodologia TEMAC - Infraestruturas de Dados e IA Operacional

Este reposit√≥rio cont√©m o pipeline de extra√ß√£o, tratamento e an√°lise bibliom√©trica para a condu√ß√£o de uma Revis√£o Sistem√°tica da Literatura utilizando a **Metodologia TEMAC**. 

O projeto integra a investiga√ß√£o e o desenvolvimento de arquiteturas de **Data Lake / Data Lakehouse**, com especial foco na sua aplica√ß√£o ao dom√≠nio de **Comando e Controle**.

## üèóÔ∏è Arquitetura do Reposit√≥rio (Ambiente H√≠brido)

Para garantir o melhor processamento e an√°lise dos metadados cient√≠ficos, este reposit√≥rio adota uma abordagem poliglotas, separando a engenharia de dados da an√°lise bibliom√©trica:

* **Python (Gest√£o com `uv`):** Utilizado para a leitura, limpeza e desduplica√ß√£o dos ficheiros brutos exportados das bases de dados. As bibliotecas principais incluem o `pandas` e analisadores sint√°ticos (parsers) desenvolvidos √† medida.
* **R (Jupyter Kernel):** Utilizado de forma nativa para executar o pacote `bibliometrix` (e a interface Biblioshiny), gerando as estat√≠sticas e os grafos de mapeamento cient√≠fico a partir da base consolidada.

## üìö Bases de Dados e Consolida√ß√£o

O processo de extra√ß√£o abrangeu tr√™s das principais plataformas de indexa√ß√£o cient√≠fica. Devido √†s particularidades de cada exporta√ß√£o, foram desenvolvidos gui√µes (notebooks) espec√≠ficos na pasta `/ajustes_BD/`:

1.  **IEEE Xplore (`ajustes_IEEE.ipynb`):**
    * *Formato:* `.csv`
    * *Processamento:* Concatena√ß√£o em lote e remo√ß√£o de publica√ß√µes duplicadas utilizando as chaves `Document Title` e `DOI`.
2.  **Scopus (`ajustes_SCOPUS.ipynb`):**
    * *Formato:* `.csv`
    * *Processamento:* Empilhamento dos metadados e limpeza cruzada baseada nas colunas `Title` e `DOI`.
3.  **Web of Science - WoS (`ajustes_WoS.ipynb`):**
    * *Formato:* `.txt` (Plain Text / Tags)
    * *Processamento:* Como a WoS n√£o utiliza o formato tabular padr√£o, foi constru√≠do um *parser* customizado em Python para isolar os blocos de texto por tags (como `TI`, `DI`, `UT`). A desduplica√ß√£o ocorre atrav√©s de dicion√°rios iterativos, garantindo que a base final seja reescrita no formato `.txt` perfeitamente compat√≠vel com o ecossistema R.

## üöÄ Como reproduzir este ambiente

Para garantir que o isolamento das depend√™ncias em Python n√£o interfira com os pacotes em R, siga os passos abaixo:

### Pr√©-requisitos
* Ter o [uv](https://github.com/astral-sh/uv) instalado.
* Ter o R instalado no sistema (`sudo apt install r-base r-base-dev` no Linux).

### Instala√ß√£o

1. Clone o reposit√≥rio:
   ```bash
   git clone [https://github.com/seu-usuario/temac.git](https://github.com/seu-usuario/temac.git)
   cd temac
   ```

2. Instale as depend√™ncias do Python:
    ```bash
    uv sync
    ```

3. Instale e configure o Kernel e as depend√™ncias do R:
    ```bash
    # O comando uv run garante que o R enxergue o Jupyter do ambiente virtual
        uv run Rscript config_R/setup_r.R
    ```
    <mark>essa parte demora, mas tenha f√© (talvez possa dar alguns problemas tamb√©m mas nada que sua IA favorita n√£o consiga ajusar</mark>

    Aqui podem dar alguns problemas em rela√ß√£o a alguns programas n√£o instalados no seu OS (no meu caso linux) que s√£o necess√°rios para instalar o pacote bibliometrix.

üíª Execu√ß√£o do Pipeline

Abra o projeto no VS Code (ou no Jupyter Lab).

Execute os ficheiros ajustes_*.ipynb na pasta /ajustes_BD/ para gerar os ficheiros consolidados (base_ieee_consolidada.csv, base_scopus_consolidada.csv e base_wos_consolidada.txt).

Abra o notebook de an√°lise "analise_bibliometrix.ipynb" na pasta "bibliometrix", selecione o Kernel R no canto superior direito do seu editor e inicie o Biblioshiny.

Uma dica, caso o kernel n√£o apare√ßa, voc√™ pode procurar o URL do server do jupyter notebook com esse comando:

```bash
uv run jupyter notebook --no-browser
```